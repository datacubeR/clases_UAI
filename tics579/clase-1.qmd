---
title: "TICS-579-Deep Learning"
subtitle: "Clase 1: Introducci贸n a los Shallow Models"
author: Alfonso Tobar-Arancibia
institute: <alfonso.tobar.a@edu.uai.cl>
format:
  revealjs: 
    width: 1366
    height: 768
    theme: simple
    slide-number: true
    controls: true
    controls-layout: edges
    controls-back-arrows: faded
    transition: slide
    transition-speed: fast
    chalkboard: true
    callout-appearance: simple
    logo: ../logo-uai-blanco.jpeg
    css: ../logo.css
    code-copy: true
    highlight-style: arrow
    pdf-separate-fragments: true
---

# Shallow Models

## Modelo B谩sico de Clasificaci贸n Binaria {.smaller}

Supongamos el siguiente problema de clasificaci贸n binaria:

::: {.callout-note appearance="default" .fragment}
## Sea $\mathcal{y} \sim \text{Bernoulli}(p)$, es decir:
$$P(y) = \begin{cases}
p,  & \text{si y = 1} \\
1-p, & \text{si y=0}
\end{cases}
$$
:::

:::{.callout-important appearance="default" .fragment}
## Pero Ojo  
驴C贸mo estimamos la probabilidad $p$ para asignar una clase?

*  Esta clase puede ser cualquier cosa, por ejemplo, si un correo es spam o no, si es un gato o u perro, etc.
:::

:::{.callout-tip appearance="default" .fragment}
## Regresi贸n Lineal
Una manera es utilizar una combinaci贸n lineal de features (inputs) y par谩metros (pesos). Es decir:

$$\hat{y} = \theta_0 x_0 + \theta_1 x_1 + ... + \theta_n x_n$$
:::


## Modelo B谩sico de Clasificaci贸n Binaria {.smaller}

> Pero tenemos el problema de que $y$ puede tomar cualquier valor real (no est谩 acotada), y necesitamos que $p$ est茅 entre 0 y 1. Para ello podemos aplicar la funci贸n Log铆stica o Sigmoide.

::::{.columns}
:::{.column}
![](img/clase-1/sigmoid.png){.lightbox fig-align="center" width="80%"}
:::
:::{.column}
:::{.callout-warning appearance="default" icon=false}
##  Propiedades de la funci贸n Sigmoide

* Acotada entre 0 y 1. 
* Punto de Inflexi贸n en $x=0$, lo que se transforma en $p=0.5$.
* $\sigma(z)'= \sigma(z)(1-\sigma(z))$.
:::

:::{.callout-tip appearance="default" icon=false}
## Estimaci贸n de la probabilidad
$$ p = \sigma(\hat{y}) = \sigma(\theta_0 x_1 + \theta_1 x_1 + ... + \theta_n x_n)$$

donde $\sigma(x) = \frac{1}{1 + e^{-x}}$ es la funci贸n sigmoide.
:::
:::
::::


## Modelo B谩sico de Clasificaci贸n Binaria {.smaller}

::::{.columns}
:::{.column width="40%"}
![](img/clase-1/dummy_data.png){.lightbox fig-align="center" width="80%"}


:::{.callout-warning appearance="default" icon=false .fragment fragment-index=1}
##  M谩s definiciones
* Llamaremos par谩metros a los valores $\theta_j$, $j=0,...,n$.
* Llamaremos **"Capas"** a un conjunto de par谩metros utilizado para generar un resultado.
:::
:::
:::{.column width="60%"}
:::{.callout-warning appearance="default" icon=false}
##  Definiciones

* Definiremos $(\bar{x}^{(i)})^T = (x_1^{(i)}, x_2^{(i)}, ..., x_n^{(i)})$ como el vector de features del punto $i$.
* Asimismo $y^{(i)}$ ser谩 el label/etiqueta del punto $i$.
* En este caso particular $m=3$ observaciones y $n=2$ features.



:::
:::{.callout-important appearance="default" .fragment fragment-index=2}
## Redes Neuronales
El t茅rmino Red Neuronal es un t茅rmino marketero, lo 煤nico que hace es mostrar de manera gr谩fica lo que nosotros acabamos de definir.

![](img/clase-1/log_reg.png){.lightbox fig-align="center" width="40%"}

:::
:::
::::

## Red Neuronal B谩sica: Regresi贸n Log铆stica {.smaller}

Finalmente, por conveniencia, podemos escribir nuestra Regresi贸n Log铆sitca en notaci贸n matricial: 

:::{.callout-note appearance="default" style="font-size: 130%;"}
## Una observaci贸n
$$p^{(i)} = \sigma((\bar{x}^{(i)})^T \cdot \theta)$$
:::

:::{.callout-tip appearance="default" style="font-size: 130%;"}
### Muchas Observaciones
$$\bar{p} = \sigma(X \cdot \theta)$$

Donde X es el la ***Matriz de Dise帽o/Design Matrix***, que contiene todos los vectores de features.
Adem谩s utilizaremos la definici贸n inicial, en la que si $p\ge 0.5$ entonces $y=1$ y si $p < 0.5$ entonces $y=0$.
:::

## Los Ingredientes de un Algoritmo de Aprendizaje {.smaller}

Hip贸tesis
: > Una funci贸n que describe como mapear inputs (features) con outputs (labels) por medio de par谩metros. En nuestro caso inicial diremos que $h_\theta(X) = \sigma(X \theta)$, donde $\sigma$ es la funci贸n sigmoide.

Loss Function
: > Una funci贸n que especifica cuanta informaci贸n se pierde. Mayor p茅rdida implica m谩s error de estimaci贸n.

M茅todo de Optimizaci贸n
: > Es el responsable de combinar la `hip贸tesis` y la `loss function`. Corresponde a un procedimiento para determinar los par谩metros de la hip贸tesis, minimizando la suma de las p茅rdidas en un set de entrenamiento. 

## Regresi贸n Log铆stica: Loss Function {.smaller}

::::{style="font-size: 70%;"}
Nuestra definici贸n inicial de la Distribuci贸n Bernoulli puede ser rescrita de la siguiente manera:

::::{.columns} 
:::{.column}
$$P(y) = \begin{cases}
p,  & \text{si y = 1} \\
1-p, & \text{si y=0}
\end{cases}
$$
:::
:::{.column}
$$P(y|X) = p^{y} (1-p)^{1-y}$$
:::
::::
::::

:::{.callout-note appearance="default" style="font-size: 110%;"}
## Maximum Likelihood Estimation
Permite calcular los par谩metros $\theta$ que maximizan la probabilidad de observar los datos (que los datos se ajusten a la distribuci贸n esperada por el modelo).

$$\mathcal{L}(\theta) = \prod_{i=1}^m P(y^{(i)}|X^{(i)}) = \prod_{i=1}^m p^{y^{(i)}} (1-p)^{1-y^{(i)}}$$
:::

:::{.callout-important appearance="default" style="font-size: 110%;"}
## Negative Log Likelihood
* La Productoria no es amigable. 
* Es m谩s com煤n minimizar que maximizar.
* Aplicamos Logaritmo a la funci贸n de verosimilitud y cambiamos el signo. 


$$\mathcal{l}(\theta) = -\log(\mathcal{L}(\theta)) = -\sum_{i=1}^m \left(y^{(i)} \log(p^{(i)}) + (1-y^{(i)}) \log(1-p^{(i)})\right)$$
:::

## Regresi贸n Log铆stica: Loss Function {.smaller}

:::{.callout-important appearance="default" icon=false}
## Funci贸n de P茅rdida/Loss Function
Podemos reescribir el Negative Log Likelihood con notaci贸n matricial de la siguiente manera: 
$$L(\theta) = -\left[y^T \log(\bar{p}) + (1-y)^T \log(1-\bar{p})\right]$$

donde $\bar{p} = \sigma(X\theta)$ es el vector de probabilidades estimadas por el modelo.
:::

:::{.callout-warning appearance="default" icon=false}
## Propiedades
* Si $y^{(i)} = 1$, entonces $L(\theta) = -\log(p^{(i)})$.
  * Luego si la probabilidad es cercana a 1, que significa que el modelo predijo correctamente la clase, entonces la p茅rdida es cercana a 0.
  * Pero si la probabilidad es cercana a 0, entonces la p茅rdida es alta.
* Si $y^{(i)} = 0$, entonces $L(\theta) = -\log(1-p^{(i)})$.
  * Luego si la probabilidad es cercana a 0, que significa que el modelo predijo correctamente la clase, entonces la p茅rdida es cercana a 0.
  * Pero si la probabilidad es cercana a 1, entonces la p茅rdida es alta.
:::

:::{.callout-note appearance="default" icon=false} 
### Conclusi贸n
* La Funci贸n de P茅rdida mide cu谩nta informaci贸n se pierde al estimar los par谩metros $\theta$. En otras palabras, mide el error de estimaci贸n de nuestro modelo. Por lo tanto, una **Loss Function** m谩s baja implica un mejor modelo.

* Si minimizamos nuestra funci贸n de p茅rdida, entonces estamos maximizando la probabilidad de observar los datos. Por lo tanto, minimizamos el error de estimaci贸n del modelo.

* A veces est谩 ecuaci贸n aparece como la p茅rdida promedio (es decir, est谩 multiplicada por $\frac{1}{m}$).
:::

## Regresi贸n Log铆stica: M茅todo de Optimizaci贸n 

::::{style="font-size: 80%;"}
:::{.callout-warning appearance="default" icon=false}
##  La par谩metros 贸ptimos del problema est谩n dados por: 

$$\underset{\theta}{argmin} = L(\theta)$$

* Lo cu谩l puede ser resuelto f谩cilmente utilizando un m茅todo de optimizaci贸n como el **Gradient Descent**.
:::

:::{.callout-note appearance="default" appearance="default"}
## Par谩metros 贸ptimos se encuentran con:
$$\theta = \theta - \alpha \nabla_\theta L(\theta)$$
:::

:::{.callout-important appearance="default" icon=false}
##  驴Cu谩nto vale el gradiente de la Funci贸n de P茅rdida?
::::{.columns}
::::{.column}
Vamos a calcular el gradiente haciendo trampa. Puede que algunos se enojen, pero para nosotros es suficiente.
:::
::::{.column}
![](img/clase-1/fuenzi.jpeg){.lightbox fig-align="center" width="30%"} 
:::
::::
:::
::::

## Regresi贸n Log铆sitca: Gradiente {.smaller}

::::{.columns}
:::{.column width="30%"}
Supongamos lo siguiente:

* $a= X \theta$
* $b = \sigma(a)$
* $c = log(b)$
* $d = log(1-b)$
* $e = y^T c$
* $f = (1-y)^T d$
* $L* = e + f$
* $L = -L*$
:::
::::{.column width="70%"}
![](img/clase-1/comp_graph_log_reg.png){.lightbox fig-align="center" width="90%"}
:::
::::


## Regresi贸n Log铆sitca: Calculando el Gradiente {.smaller}

$$
\begin{align*}
\frac{\partial L*}{\partial f} &= \frac{\partial L}{\partial e} = 1 \\
\frac{\partial L*}{\partial d} &= \frac{\partial L}{\partial f} \cdot \frac{\partial f}{\partial d} = (1 - y)^T \\
\frac{\partial L*}{\partial c} &= \frac{\partial L}{\partial e} \cdot \frac{\partial e}{\partial c} = y^T \\
  \frac{\partial L*}{\partial b} &= \frac{\partial L}{\partial c} \cdot \frac{\partial c}{\partial b}  + \frac{\partial L}{\partial d} \cdot \frac{\partial d}{\partial b}= \frac{y^T}{b} - \frac{(1-y)^T}{1-b} \\
\frac{\partial L*}{\partial a} &= \frac{\partial L}{\partial b} \cdot \frac{\partial b}{\partial a} = \left[\frac{y^T}{b} - \frac{(1-y)^T}{1-b}\right] \cdot \sigma(a)' \\
\frac{\partial L*}{\partial \theta} &= \frac{\partial L}{\partial a} \cdot \frac{\partial a}{\partial \theta} = \left[\frac{y^T}{b} - \frac{(1-y)^T}{1-b}\right] \cdot \sigma(a)' \cdot X\\
\frac{\partial L*}{\partial \theta} &=\left[\frac{y^T (1-b) + b (1-y)^T}{b(1-b)}\right] \cdot \sigma(a)' \cdot X\\
\frac{\partial L*}{\partial \theta} &=\left[\frac{y^T - b}{b(1-b)}\right] \cdot \sigma(a)' \cdot X\\
\end{align*}
$$

## Regresi贸n Log铆sitca: Gradiente {.smaller}

$$\frac{\partial L*}{\partial \theta} =\left[\frac{y^T - b}{b(1-b)}\right] \cdot \sigma(a)' \cdot X$$

Luego reemplazamos que $b=\sigma(a)$ y $\sigma(a)'=\sigma(a)(1-\sigma(a))$:

Obtenemos que:

$$\frac{\partial L}{\partial \theta} = \left[\sigma(X\theta)_{m \times 1} - y^T_{1 \times m}\right]X_{m \times (n+1)}$$

::::{.columns}
:::{.column}
:::{.callout-important appearance="default" icon=false}
### Ojo con las dimensiones.
Debemos modificar nuestro c谩lculo de modo que las dimensiones sean compatibles. Luego: 

$$\frac{\partial L}{\partial \theta}_{(n+1) \times 1} = X^T_{(n+1) \times m} \cdot \left[\sigma(X\theta) - y\right]_{m \times 1}$$

* Tengo que tener un gradiente para cada par谩metro (***驴por qu茅 son $n+1$?***)
:::
:::
:::{.column .fragment}

![](img/clase-1/X_design.png){.lightbox fig-align="center" width="70%"}

:::
::::

## Regresi贸n Log铆stica: Update Rule {.smaller}

> Llamaremos Update Rule al Algoritmo que permite ***entrenar un modelo***. En el caso de la Regresi贸n Log铆stica, el Update Rule es:

:::{style="font-size: 130%;"}

$$\theta_{n+1 \times 1} = \theta_{n+1 \times 1} - \alpha \cdot X^T_{(n+1) \times m} \cdot \left[\sigma(X\theta) - y\right]_{m \times 1}$$

:::

:::{.callout-important appearance="default" icon=false}
## か Resumen

* Aplicando este procedimiento es posible definir cualquier ***update rule*** de aprendizaje supervisado. Tan s贸lo se requiere:

* Una Hip贸tesis: En el caso de la Regresi贸n Log铆stica es $h_{\theta}(X) = \sigma(X \theta)$.
* Una Loss Function: En el caso de la regresi贸n Log铆stica es $L(\theta) = -\left[y^T \log(h_{\theta}) + (1-y)^T \log(1-h_\theta)\right]$
* Encontrar los gradientes de la Loss Function.
:::


# Esa fue la clase de hoy く

::: {.footer}
<p xmlns:cc="http://creativecommons.org/ns#" xmlns:dct="http://purl.org/dc/terms/"><span property="dct:title">Tics-579 Deep Learning</span> por Alfonso Tobar-Arancibia est谩 licenciado bajo <a href="http://creativecommons.org/licenses/by-nc-sa/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;">CC BY-NC-SA 4.0

<img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/nc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/sa.svg?ref=chooser-v1"></a></p>
:::
