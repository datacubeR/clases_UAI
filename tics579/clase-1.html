<!DOCTYPE html>
<html lang="en"><head>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-html/tabby.min.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/light-border.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-37eea08aefeeee20ff55810ff984fec1.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/quarto-contrib/glightbox/glightbox.min.js"></script>
<link href="../site_libs/quarto-contrib/glightbox/glightbox.min.css" rel="stylesheet">
<link href="../site_libs/quarto-contrib/glightbox/lightbox.css" rel="stylesheet"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.7.32">

  <meta name="author" content="Alfonso Tobar-Arancibia">
  <title>Clases UAI ‚Äì TICS-579-Deep Learning</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="../site_libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="../site_libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
  </style>
  <link rel="stylesheet" href="../site_libs/revealjs/dist/theme/quarto-673c2e7d040da7fd4b9d655d29f657a0.css">
  <link rel="stylesheet" href="../logo.css">
  <link href="../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="../site_libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="../site_libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="../site_libs/revealjs/plugin/reveal-chalkboard/font-awesome/css/all.css" rel="stylesheet">
  <link href="../site_libs/revealjs/plugin/reveal-chalkboard/style.css" rel="stylesheet">
  <link href="../site_libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
</head>
<body class="quarto-light">
  <div class="reveal">
    <div class="slides">

<section id="title-slide" class="quarto-title-block center">
  <h1 class="title">TICS-579-Deep Learning</h1>
  <p class="subtitle">Clase 1: Tensores</p>

<div class="quarto-title-authors">
<div class="quarto-title-author">
<div class="quarto-title-author-name">
Alfonso Tobar-Arancibia 
</div>
        <p class="quarto-title-affiliation">
            <a href="mailto:alfonso.tobar.a@edu.uai.cl" class="email">alfonso.tobar.a@edu.uai.cl</a>
          </p>
    </div>
</div>

</section>
<section>
<section id="introducci√≥n-al-curso" class="title-slide slide level1 center">
<h1>Introducci√≥n al Curso</h1>

</section>
<section id="historia" class="slide level2 smaller">
<h2>Historia</h2>
<p>La verdad podr√≠amos estudiar historia e importancia de porqu√© el Deep Learning es importante, pero la verdad‚Ä¶</p>
<div class="callout callout-important callout-style-simple">
<div class="callout-body">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-content">
<p>NO TENEMOS TIEMPO PARA ESO.</p>
</div>
</div>
</div>
<div class="columns">
<div class="column" style="width:25%;">
<h4 id="alexnet-2012">Alexnet (2012)</h4>
<p><a href="img/clase-1/alexnet.png" class="lightbox" data-gallery="quarto-lightbox-gallery-1"><img data-src="img/clase-1/alexnet.png"></a></p>
</div><div class="column fragment" style="width:25%;">
<h4 id="transformers-2017">Transformers (2017)</h4>
<p><a href="img/clase-1/transformer.png" class="lightbox" data-gallery="quarto-lightbox-gallery-2"><img data-src="img/clase-1/transformer.png"></a></p>
</div><div class="column fragment" style="width:25%;">
<h4 id="gpt-2019">GPT (2019)</h4>
<p><a href="img/clase-1/gpt.png" class="lightbox" data-gallery="quarto-lightbox-gallery-3"><img data-src="img/clase-1/gpt.png"></a></p>
</div><div class="column fragment" style="width:25%;">
<h4 id="llms-2023-chatgptllama">LLMs (2023) (ChatGPT/Llama)</h4>
<p><a href="img/clase-1/llms.jpg" class="lightbox" data-gallery="quarto-lightbox-gallery-4"><img data-src="img/clase-1/llms.jpg"></a></p>
</div></div>
</section>
<section id="por-qu√©-estudiar-deep-learning" class="slide level2 smaller">
<h2>¬øPor qu√© estudiar Deep Learning?</h2>
<div class="quarto-figure quarto-figure-center">
<figure>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><a href="img/clase-1/google_trends.png" class="lightbox" data-gallery="quarto-lightbox-gallery-5" title="Im√°gen tomada de la Clase de Zico Colter"><img data-src="img/clase-1/google_trends.png" class="quarto-figure quarto-figure-center" style="width:70.0%" alt="Im√°gen tomada de la Clase de Zico Colter"></a></p>
</figure>
</div>
<figcaption>Im√°gen tomada de la Clase de Zico Colter</figcaption>
</figure>
</div>
</section>
<section id="por-qu√©-estudiar-deep-learning-1" class="slide level2 smaller">
<h2>¬øPor qu√© estudiar Deep Learning?</h2>
<div class="callout callout-tip callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Facilidad y Autograd</strong></p>
</div>
<div class="callout-content">
<ul>
<li>Frameworks como Tensorflow, Pytorch o Jax permiten realizar esto de manera mucho m√°s sencilla.
<ul>
<li>Frameworks permiten calcular gradientes de manera autom√°tica.</li>
<li>Antigua mente trabajar en Torch, Caffe o Theano pod√≠a tomar cerca de 50K l√≠neas de c√≥digo.</li>
</ul></li>
</ul>
</div>
</div>
</div>
<div class="callout callout-note callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>C√≥mputo</strong></p>
</div>
<div class="callout-content">
<ul>
<li>Proliferaci√≥n de las GPUs, TPUs, HPUs, IPUs, como sistemas masivos de C√≥mputos.
<ul>
<li><a href="https://www.nytimes.com/2012/06/26/technology/in-a-big-network-of-computers-evidence-of-machine-learning.html">How many computers to identify a cat? 16,000</a></li>
</ul></li>
</ul>
</div>
</div>
</div>
<div class="callout callout-important callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Estado del Arte</strong></p>
</div>
<div class="callout-content">
<ul>
<li>Modelos de Deep Learning pueden generar sistemas que entiendan im√°genes, textos, audios, videos, grafos, etc.</li>
</ul>
</div>
</div>
</div>
</section></section>
<section>
<section id="prerrequisitos-del-curso" class="title-slide slide level1 center">
<h1>Prerrequisitos del Curso</h1>

</section>
<section id="tensores" class="slide level2 smaller">
<h2>Tensores</h2>
<blockquote>
<p>Corresponde a una generalizaci√≥n de los vectores y matrices que permite representar datos de m√∫ltiples dimensiones.</p>
</blockquote>
<div class="columns" style="font-size: 120%;">
<div class="column" style="width:30%;">
<h4 id="escalares-orden-0">Escalares (Orden 0)</h4>
<p><span class="math display">\[-1, 11.27, \pi\]</span></p>
</div><div class="column" style="width:30%;">
<h4 id="vectores-filas-orden-1">Vectores Filas (Orden 1)</h4>
<p><span class="math display">\[[1.0,-0.27, -1.22]\]</span></p>
<h4 id="vectores-columnas-orden-1">Vectores Columnas (Orden 1)</h4>
<p><span class="math display">\[\begin{bmatrix}
1 \\
-0.27\\
-1.22
\end{bmatrix}\]</span></p>
</div><div class="column" style="width:25%;">
<h4 id="matrices-orden-2">Matrices (Orden 2)</h4>
<p><span class="math display">\[\begin{bmatrix}
1.0 &amp; -0.27 &amp; 3\\
3.15 &amp; 2.02 &amp; 1.2\\
-1.22&amp; 0.55 &amp; 3.97 \\
\end{bmatrix}\]</span></p>
</div></div>
<div class="callout callout-note callout-style-simple">
<div class="callout-body">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-content">
<p>Normalmente los tensores utilizan un mismo tipo de dato: Integers o Float es lo m√°s com√∫n.</p>
</div>
</div>
</div>
</section>
<section id="tensores-1" class="slide level2 smaller">
<h2>Tensores</h2>
<div class="columns">
<div class="column" style="width:40%;">
<h4 id="tensores-orden-3">Tensores (Orden 3+)</h4>
<p><span class="math display">\[\begin{bmatrix}
    \begin{bmatrix}
        0.2 &amp; 0.1 &amp; -0.25 \\
        0.1 &amp; -1.0 &amp; 0.22\\
    \end{bmatrix} \\
    \begin{bmatrix}
        0.24 &amp; 0.1 &amp; -0.25 \\
        0.05 &amp; -0.69 &amp; 0.98
    \end{bmatrix} \\
    \begin{bmatrix}
        0.66&amp; -1.0 &amp; 0.22\\
        -0.07 &amp; -0.59 &amp; 0.99
    \end{bmatrix} \\
    \begin{bmatrix}
        0.16&amp; 1.0 &amp; 3.22\\
        9.17 &amp; 7.19 &amp; 9.99
    \end{bmatrix}
\end{bmatrix}
\]</span></p>
</div><div class="column" style="width:60%;">
<div class="callout callout-tip callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Nomenclatura</strong></p>
</div>
<div class="callout-content">
<ul>
<li><span class="math inline">\(\alpha\)</span>, <span class="math inline">\(\beta\)</span>, <span class="math inline">\(\gamma\)</span>: Min√∫sculas griegas denotan a Escalares.</li>
<li>x, y, z: Min√∫sculas latinas denotan a Vectores.</li>
<li>X, Y, Z: May√∫sculas latinas denotan a Matrices o Tensores.</li>
</ul>
</div>
</div>
</div>
<div class="callout callout-important callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Shape/Tama√±o: Tama√±o del tensor, tiene tantas dimensiones como su orden.</strong></p>
</div>
<div class="callout-content">
<ul>
<li><strong>Escalar</strong>: No tiene dimensiones.</li>
<li><strong>Vector</strong>: Tama√±o es equivalente al n√∫mero de elementos del vector. (3,)
<ul>
<li>A veces se usa la versi√≥n (1,3) para vectores filas y (3,1) para vectores columnas.</li>
</ul></li>
<li><strong>Matrices</strong>: Tama√±o es equivalente al n√∫mero de filas y columnas. Ejemplo: (3,3)</li>
<li><strong>Tensores</strong>: Tama√±o es equivalente al n√∫mero de matrices que lo componen y el n√∫mero de filas y columnas de cada una de ellas. Ejemplo: (4,2,3)</li>
</ul>
</div>
</div>
</div>
<div class="callout callout-warning no-icon callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<p><strong>Importante</strong></p>
</div>
<div class="callout-content">
<ul>
<li><p>La primera dimensi√≥n del shape se conoce como <strong>Batch Size</strong> el cual denota la cantidad de elementos de orden inferior.</p></li>
<li><p>(3, ) tenemos 3 escalares.</p></li>
<li><p>(3,2) tenemos 3 vectores filas de 2 elementos cada uno.</p></li>
<li><p>(4,2,3) tenemos 4 matrices de (2,3) cada una.</p></li>
</ul>
</div>
</div>
</div>
</div></div>
</section>
<section id="vectores-suma" class="slide level2 smaller">
<h2>Vectores: Suma</h2>
<blockquote>
<p>Corresponde a un arreglo unidimensional de n√∫meros reales. Se puede representar como fila o columna. Por convenci√≥n denotaremos <span class="math inline">\(\bar{x}\)</span> como vector columna y <span class="math inline">\(\bar{x}^T\)</span> como vector fila.</p>
</blockquote>
<div class="columns" style="font-size: 110%;">
<div class="column" style="width:50%;">
<div class="callout callout-note callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Operaci√≥n Suma</strong></p>
</div>
<div class="callout-content">
<ul>
<li>Permite sumar dos vectores de igual tama√±o dimensi√≥n por dimensi√≥n.</li>
</ul>
<p>Ej: <span class="math inline">\([7,2]^T + [2,3]^T = [9,5]^T\)</span></p>
</div>
</div>
</div>
</div><div class="column" style="width:50%;">
<div class="callout callout-tip callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Propiedades</strong></p>
</div>
<div class="callout-content">
<ul>
<li>Conmutatividad: <span class="math inline">\(\bar{x}+\bar{y} = \bar{y}+\bar{x}\)</span></li>
<li>Asociatividad: <span class="math inline">\((\bar{x}+\bar{y})+\bar{z} = \bar{x}+(\bar{y}+\bar{z})\)</span></li>
<li>Elemento Neutro: <span class="math inline">\(\bar{x} + \bar{0} = \bar{x}\)</span></li>
</ul>
</div>
</div>
</div>
</div></div>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><a href="img/clase-1/vector_sum.png" class="lightbox" data-gallery="quarto-lightbox-gallery-6"><img data-src="img/clase-1/vector_sum.png" class="quarto-figure quarto-figure-center"></a></p>
</figure>
</div>
</section>
<section id="vectores-ponderaci√≥n" class="slide level2 smaller">
<h2>Vectores: Ponderaci√≥n</h2>
<blockquote>
<p>Corresponde a un arreglo unidimensional de n√∫meros reales. Se puede representar como fila o columna. Por convenci√≥n denotaremos <span class="math inline">\(\bar{x}\)</span> como vector columna y <span class="math inline">\(\bar{x}^T\)</span> como vector fila.</p>
</blockquote>
<div class="columns" style="font-size: 110%;">
<div class="column" style="width:50%;">
<div class="callout callout-note callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Operaci√≥n Ponderaci√≥n</strong></p>
</div>
<div class="callout-content">
<ul>
<li><p>Permite multiplicar/ponderar cada dimensi√≥n del vector por un escalar.</p>
<p>Ej: <span class="math inline">\(2 \cdot [3,2]^T = [6,4]^T\)</span></p></li>
</ul>
</div>
</div>
</div>
</div><div class="column" style="width:50%;">
<div class="callout callout-tip callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Propiedades</strong></p>
</div>
<div class="callout-content">
<ul>
<li>Distributividad Escalar: <span class="math inline">\(a(\bar{x}+\bar{y}) = a\bar{x} + a\bar{y}\)</span></li>
<li>Distributividad Vectorial: <span class="math inline">\((a+b)\bar{x} = a\bar{x} + b\bar{x}\)</span></li>
<li>Elemento Neutro: <span class="math inline">\(1\cdot \bar{x} = \bar{x}\)</span></li>
<li>Compatibilidad: <span class="math inline">\(a(b\bar{x}) = (ab)\bar{x}\)</span></li>
</ul>
</div>
</div>
</div>
</div></div>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><a href="img/clase-1/vector_scaling.png" class="lightbox" data-gallery="quarto-lightbox-gallery-7"><img data-src="img/clase-1/vector_scaling.png" class="quarto-figure quarto-figure-center"></a></p>
</figure>
</div>
</section>
<section id="vectores-norma" class="slide level2 smaller">
<h2>Vectores: Norma</h2>
<div class="columns" style="font-size: 110%;">
<div class="column" style="width:50%;">
<div class="callout callout-note callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Norma (Euclideana)</strong></p>
</div>
<div class="callout-content">
<p>Para un vector <span class="math inline">\(\bar{x}=[x_1, ..., x_n] \in \mathbb{R}^n\)</span> se define la norma como:</p>
<p><span class="math display">\[||\bar{x}|| = \sqrt{\sum_{i=1}^n x_i^2}\]</span></p>
</div>
</div>
</div>
</div><div class="column" style="width:50%;">
<div class="callout callout-tip callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Propiedades</strong></p>
</div>
<div class="callout-content">
<ul>
<li>Desigualdad Triangular: <span class="math inline">\(||\bar{x}+\bar{y}|| \leq ||\bar{x}|| + ||\bar{y}||\)</span></li>
<li><span class="math inline">\(||\alpha \bar{x}= |\alpha| \cdot ||\bar{x}||\)</span></li>
<li><span class="math inline">\(||\bar{x}|| = 0 \Longleftrightarrow \bar{0}\)</span></li>
</ul>
</div>
</div>
</div>
</div></div>
<div class="columns" style="font-size: 110%;">
<div class="column" style="width:50%;">
<div class="callout callout-caution no-icon callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<p><strong>Aplicaci√≥n</strong></p>
</div>
<div class="callout-content">
<p>La norma permite calcular la distancia entre dos vectores.</p>
<p><span class="math display">\[d_{x,y} = ||\bar{x} - \bar{y}\]</span></p>
<p><strong>Tambi√©n servir√≠a para puntos. ¬øPor qu√©?</strong></p>
</div>
</div>
</div>
</div><div class="column">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><a href="img/clase-1/norm_distance.png" class="lightbox" data-gallery="quarto-lightbox-gallery-8"><img data-src="img/clase-1/norm_distance.png" class="quarto-figure quarto-figure-center" style="width:80.0%"></a></p>
</figure>
</div>
</div></div>
</section>
<section id="vectores-producto-interno-producto-punto" class="slide level2 smaller">
<h2>Vectores: Producto Interno (Producto Punto)</h2>
<div class="columns" style="font-size: 110%;">
<div class="column" style="width:50%;">
<div class="callout callout-note callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Inner Product or Dot Product</strong></p>
</div>
<div class="callout-content">
<p>El producto interno entre dos vectores en <span class="math inline">\(\mathbb{R}^n\)</span> se define como:</p>
<p><span class="math inline">\(\bar{x} = [x_1, ..., x_n]\)</span> e <span class="math inline">\(\bar{y} = [y_1, ..., y_n]\)</span></p>
<p><span class="math display">\[ \bar{x} \cdot \bar{y} = \sum_{i=1}^n x_i y_i = x_1 y_1 + ... + x_n y_n\]</span></p>
<p>A veces el producto interno se denota como <span class="math inline">\(\bar{x}^T \bar{y}\)</span> o <span class="math inline">\(\langle \bar{x}, \bar{y} \rangle\)</span>.</p>
</div>
</div>
</div>
</div><div class="column" style="width:50%;">
<div class="callout callout-tip callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Propiedades</strong></p>
</div>
<div class="callout-content">
<ul>
<li>Conmutatividad: <span class="math inline">\(\bar{x} \cdot \bar{y} = \bar{y} \cdot \bar{x}\)</span></li>
<li>Linealidad: $({x}){y} = ({x}{y})</li>
<li>Distributividad: <span class="math inline">\(\bar{x} \cdot (\bar{y} + \bar{z}) = (\bar{x} \cdot \bar{y}) + (\bar{x} \cdot \bar{z})\)</span></li>
<li><span class="math inline">\(||\bar{x}||^2 = \bar{x} \cdot \bar{x}\)</span></li>
</ul>
</div>
</div>
</div>
</div></div>
<div class="columns" style="font-size: 110%;">
<div class="column" style="width:50%;">
<div class="callout callout-caution no-icon callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<p><strong>Aplicaciones</strong></p>
</div>
<div class="callout-content">
<ul>
<li>Ortogonalidad: Dos vectores son ortogonales si su producto interno es cero.</li>
<li>Similaridad: Se puede usar el Cosine Similarity para calcular qu√© tan parecidos son dos vectores.</li>
</ul>
</div>
</div>
</div>
</div><div class="column" style="width:50%;">
<div class="callout callout-important no-icon callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<p><strong>Cosine Similarity</strong></p>
</div>
<div class="callout-content">
<p><span class="math display">\[sim(\bar{a}, \bar{b}) = \frac{\bar{a} \cdot \bar{b}}{||\bar{a}|| \cdot ||\bar{b}||}\]</span></p>
<ul>
<li>1 implica misma direcci√≥n (id√©nticos)</li>
<li>-1 implica direcciones opuestas (opuestos).</li>
<li>0 implica totalmente distintos (ortogonales).</li>
</ul>
</div>
</div>
</div>
</div></div>
</section>
<section id="vectores-otras-propiedades" class="slide level2">
<h2>Vectores: Otras Propiedades</h2>
<div class="callout callout-tip callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Combinaci√≥n Lineal</strong></p>
</div>
<div class="callout-content">
<ul>
<li>Se denomina una combinaci√≥n lineal de vectores a la suma ponderada de estos.</li>
</ul>
<p>Ej: <span class="math inline">\(\bar{w} = \alpha \cdot \bar{x} + \beta \cdot \bar{y} + \gamma \cdot \bar{z}\)</span></p>
<p><span class="math inline">\(\bar{w}\)</span> es una combinaci√≥n lineal de los vectores <span class="math inline">\(\bar{x}, \bar{y} y \bar{z}\)</span>.</p>
</div>
</div>
</div>
<div class="callout callout-note callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Independencia Lineal</strong></p>
</div>
<div class="callout-content">
<ul>
<li>Un conjunto de vectores es linealmente independiente si:</li>
</ul>
<p>$<span class="math inline">\(\alpha_1 \cdot \bar{x}_1 + \alpha_2 \cdot \bar{x}_2 + ... + \alpha_n \cdot \bar{x}_n = 0\)</span> implica que <span class="math inline">\(\alpha_i = 0\)</span> para todo <span class="math inline">\(i\)</span>.</p>
</div>
</div>
</div>
<div class="callout callout-important callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>üëÄ Ojito</strong></p>
</div>
<div class="callout-content">
<p>Hay otras propiedades sumamente importantes de vectores, por lo que coloquen atenci√≥n al curso de Algebra Lineal.</p>
</div>
</div>
</div>
</section></section>
<section>
<section id="matrices" class="title-slide slide level1 center">
<h1>Matrices</h1>

</section>
<section id="matrices-definici√≥n" class="slide level2 smaller">
<h2>Matrices: Definici√≥n</h2>
<div class="columns" style="font-size: 120%;">
<blockquote>
<p>Corresponde a un arreglo bidimensional de n√∫meros reales. Se dice que una matriz es de <span class="math inline">\(n\times m\)</span> o que es <span class="math inline">\(\mathbb{R}^{n \times m}\)</span> cuando tiene <span class="math inline">\(n\)</span> filas y <span class="math inline">\(m\)</span> columnas.</p>
</blockquote><p><span class="math display">\[A = \begin{bmatrix}
A_{1,1} &amp; \dots &amp; A_{1,m} \\
A_{2,1} &amp; \dots &amp; A_{2,m} \\
\vdots &amp; \ddots &amp; \vdots \\
A_{n, 1} &amp; \dots &amp; A_{n,m} \\
\end{bmatrix} \in \mathbb{R}^{n \times m}\]</span></p><div class="callout callout-important callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>üëÄ</strong></p>
</div>
<div class="callout-content">
<ul>
<li>Normalmente se utiliza <span class="math inline">\(m\)</span> para denotar el n√∫mero de registros y <span class="math inline">\(n\)</span> como el n√∫mero de features de un dataset tabular (o tambi√©n conocido como Dataframe).</li>
<li><span class="math inline">\(n=m\)</span> nos referimos a una matriz cuadrada.</li>
</ul>
</div>
</div>
</div>
</div>
</section>
<section id="matrices-notaci√≥n" class="slide level2 smaller">
<h2>Matrices: Notaci√≥n</h2>
<div style="font-size:110%;">
<p>Si <span class="math inline">\(A\)</span> es una matriz entonces:</p>
<ul>
<li><span class="math inline">\(A_{i,j}\)</span> corresponde al elemento en la fila <span class="math inline">\(i\)</span> y columna <span class="math inline">\(j\)</span>. Es decir, un escalar.</li>
<li><span class="math inline">\(A_{i,:}\)</span> corresponde a la fila <span class="math inline">\(i\)</span> completa. Es decir, un vector fila.</li>
<li><span class="math inline">\(A_{:,j}\)</span> corresponde a la columna <span class="math inline">\(j\)</span> completa. Es decir un vector columna.</li>
</ul>
<div class="columns">
<div class="column" style="width:50%;">
<p><span class="math display">\[A = \begin{bmatrix}
0.2 &amp; 1 &amp; -5.2 &amp; 3.1 &amp; -1.3 \\
-0.5 &amp; 10 &amp; 0 &amp; 3.1 &amp; 3 \\
2 &amp; 25 &amp; -5.2 &amp; 0 &amp; 0 \\
100 &amp; 3.4 &amp; 4.1 &amp; 0 &amp; 42
\end{bmatrix}\]</span></p>
</div><div class="column" style="width:50%;">
<div class="callout callout-important callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Importante: Recordar que los √≠ndices en Python son 0-based.</strong></p>
</div>
<div class="callout-content">
<ul>
<li><span class="math inline">\(A_{2,4} = 3.1\)</span></li>
<li><span class="math inline">\(A_{:,3} = [-5.2, 0, -5.2, 4.1]^T\)</span></li>
<li><span class="math inline">\(A_{1,:} = [0.2, 1, -5.2, 3.1, -1.3]\)</span></li>
</ul>
</div>
</div>
</div>
</div></div>
</div>
</section>
<section id="matrices-suma" class="slide level2 smaller">
<h2>Matrices: Suma</h2>
<div class="columns" style="font-size: 110%;">
<div class="column" style="width:50%;">
<div class="callout callout-note callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Operaci√≥n Suma</strong></p>
</div>
<div class="callout-content">
<ul>
<li><p>Permite sumar dos matrices elemento a elemento.</p>
<p>Ej: Sea <span class="math inline">\(A\)</span> y <span class="math inline">\(B\)</span> dos matrices:</p></li>
</ul>
<p><span class="math display">\[A = \begin{bmatrix}
A_{1,1} &amp; \dots &amp; A_{1,m} \\
A_{2,1} &amp; \dots &amp; A_{2,m} \\
\vdots &amp; \ddots &amp; \vdots \\
A_{n, 1} &amp; \dots &amp; A_{n,m} \\
\end{bmatrix} \in \mathbb{R}^{n \times m}\]</span></p>
<p><span class="math display">\[B = \begin{bmatrix}
B_{1,1} &amp; \dots &amp; B_{1,m} \\
B_{2,1} &amp; \dots &amp; B_{2,m} \\
\vdots &amp; \ddots &amp; \vdots \\
B_{n, 1} &amp; \dots &amp; B_{n,m} \\
\end{bmatrix} \in \mathbb{R}^{n \times m}\]</span></p>
</div>
</div>
</div>
</div><div class="column">
<div width="50%">
<div class="callout callout-warning no-icon callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<p><strong>Resultado</strong></p>
</div>
<div class="callout-content">
<p><span class="math display">\[A + B = \begin{bmatrix}
A_{1,1} + B_{1,1} &amp; \dots &amp; A_{1,m} + B_{1,m} \\
A_{2,1} + A_{2,1} &amp; \dots &amp; A_{2,m} + B_{2,m} \\
\vdots &amp; \ddots &amp; \vdots \\
A_{n, 1} + B_{n,1} &amp; \dots &amp; A_{n,m} + B_{n,m} \\
\end{bmatrix} \in \mathbb{R}^{n \times m}\]</span></p>
</div>
</div>
</div>
</div>
<div width="50%">
<div class="callout callout-tip callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Propiedades</strong></p>
</div>
<div class="callout-content">
<ul>
<li>Asociatividad: <span class="math inline">\((A + B) + C = A + (B + C)\)</span></li>
<li>Conmutatividad: <span class="math inline">\(A + B = B + A\)</span></li>
<li>Elemento Neutro: <span class="math inline">\(A + 0 = A\)</span></li>
<li>Elemento Inverso: <span class="math inline">\(A + (-A) = 0\)</span></li>
</ul>
</div>
</div>
</div>
</div>
</div></div>
</section>
<section id="matrices-ponderaci√≥n" class="slide level2 smaller">
<h2>Matrices: Ponderaci√≥n</h2>
<div class="columns" style="font-size: 120%;">
<div class="column" style="width:50%;">
<div class="callout callout-note callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Operaci√≥n Ponderaci√≥n</strong></p>
</div>
<div class="callout-content">
<ul>
<li><p>Permite multiplicar/ponderar cada elemento de la matriz por un escalar.</p>
<p>Ej: Sea <span class="math inline">\(A\)</span> una matriz:</p></li>
</ul>
<p><span class="math display">\[A = \begin{bmatrix}
A_{1,1} &amp; \dots &amp; A_{1,m} \\
A_{2,1} &amp; \dots &amp; A_{2,m} \\
\vdots &amp; \ddots &amp; \vdots \\
A_{n, 1} &amp; \dots &amp; A_{n,m} \\
\end{bmatrix} \in \mathbb{R}^{n \times m}\]</span></p>
<p>y <span class="math inline">\(\gamma\)</span> un escalar.</p>
</div>
</div>
</div>
</div><div class="column">
<div width="50%">
<div class="callout callout-warning no-icon callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<p><strong>Resultado</strong></p>
</div>
<div class="callout-content">
<p><span class="math display">\[\gamma \cdot A = \begin{bmatrix}
\gamma \cdot A_{1,1} &amp; \dots &amp; \gamma \cdot A_{1,m} \\
\gamma \cdot A_{2,1} &amp; \dots &amp; \gamma \cdot A_{2,m} \\
\vdots &amp; \ddots &amp; \vdots \\
\gamma \cdot A_{n, 1} &amp; \dots &amp; \gamma \cdot A_{n,m} \\
\end{bmatrix} \in \mathbb{R}^{n \times m}\]</span></p>
</div>
</div>
</div>
</div>
<div width="50%">
<div class="callout callout-tip callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Propiedades</strong></p>
</div>
<div class="callout-content">
<ul>
<li>Distibutividad Escalar: <span class="math inline">\(\gamma(A + B) = \gamma A + \gamma B\)</span></li>
<li>Distibutividad Matricial: <span class="math inline">\((\gamma + \delta) A = \gamma A + \delta A\)</span></li>
<li>Compatibilidad: <span class="math inline">\((\gamma \delta) A = \gamma (\delta A) = \delta (\gamma A)\)</span></li>
</ul>
</div>
</div>
</div>
</div>
</div></div>
</section>
<section id="transpuesta-y-reshape" class="slide level2 smaller">
<h2>Transpuesta y Reshape</h2>
<div class="columns" style="font-size: 120%;">
<div class="column" style="width:50%;">
<div class="callout callout-tip callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Transpuesta</strong></p>
</div>
<div class="callout-content">
<p>Sea:</p>
<p><span class="math display">\[A = \begin{bmatrix}
A_{1,1} &amp; \dots &amp; A_{1,m} \\
A_{2,1} &amp; \dots &amp; A_{2,m} \\
\vdots &amp; \ddots &amp; \vdots \\
A_{n, 1} &amp; \dots &amp; A_{n,m} \\
\end{bmatrix} \in \mathbb{R}^{n \times m}\]</span></p>
<p>Entonces, <span class="math inline">\(A^T\)</span> se define como:</p>
<p><span class="math display">\[A^T = \begin{bmatrix}
A_{1,1} &amp; \dots &amp; A_{m,1} \\
\vdots &amp; \ddots &amp; \vdots \\
A_{1,m} &amp; \dots &amp; A_{n,m} \\
\end{bmatrix} \in \mathbb{R}^{n \times m}\]</span></p>
<p>Es decir, intercambiamos filas por las columnas y viceversa.</p>
</div>
</div>
</div>
</div><div class="column" style="width:50%;">
<div class="callout callout-note callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Reshape</strong></p>
</div>
<div class="callout-content">
<p><span class="math display">\[B = \begin{bmatrix}
1 &amp; 3 &amp; 5 \\
1 &amp; 7 &amp; 9 \\
4 &amp; 6 &amp; 7 \\
3 &amp; 3 &amp; 5 \\
\end{bmatrix} \in \mathbb{R}^{4 \times 3}\]</span></p>
<p>Podemos hacer un reshape a (6,2)</p>
<p><span class="math display">\[B_{reshaped} = \begin{bmatrix}
1 &amp; 3 \\
5 &amp; 1 \\
7 &amp; 9 \\
4 &amp; 6 \\
7 &amp; 3 \\
3 &amp; 5
\end{bmatrix} \in \mathbb{R}^{6 \times 2}\]</span></p>
</div>
</div>
</div>
</div></div>
</section>
<section id="producto-matriz-vector-por-la-derecha" class="slide level2 smaller">
<h2>Producto Matriz-Vector (Por la derecha)</h2>
<p>A diferencia de todas las otras operaciones, el producto entre una matriz y un vector no es conmutativo.</p>
<h4 id="post-multiplicaci√≥n-multiplicaci√≥n-por-la-derecha">Post-multiplicaci√≥n (Multiplicaci√≥n por la derecha)</h4>
<div class="columns">
<div class="column" style="font-size: 110%;">
<div class="callout callout-note callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Sea</strong></p>
</div>
<div class="callout-content">
<p><span class="math display">\[\bar{y} = A \cdot \bar{x}\]</span></p>
<p><span class="math display">\[A = \begin{bmatrix}
2 &amp; 3 &amp; 0 \\
1 &amp; 0 &amp; 7
\end{bmatrix}\]</span></p>
<p><span class="math display">\[\bar{x} = \begin{bmatrix}
4 \\
2 \\
1
\end{bmatrix}\]</span></p>
</div>
</div>
</div>
</div><div class="column" style="font-size: 110%;">
<div class="callout callout-important callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Atenci√≥n</strong></p>
</div>
<div class="callout-content">
<p>La post-multiplicaci√≥n se puede ver como la combinaci√≥n lineal de las columnas de una matriz por cada elemento del vector. <span class="math display">\[
\begin{align}
\bar{y} = A \cdot \bar{x} &amp;= \begin{bmatrix}
2 \cdot 4 + 3 \cdot 2 + 0 \cdot 1 \\
1 \cdot 4 + 0 \cdot 2 + 7 \cdot 1
\end{bmatrix} \\
&amp;= 4 \cdot \begin{bmatrix}2 \\ 1\end{bmatrix} + 2 \cdot \begin{bmatrix}3 \\ 0\end{bmatrix} + 1 \cdot \begin{bmatrix}0 \\ 7\end{bmatrix} \\
&amp;= \begin{bmatrix}14 \\ 11\end{bmatrix}
\end{align}\]</span></p>
</div>
</div>
</div>
</div></div>
<div style="font-size: 120%;">
<div class="callout callout-caution no-icon callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<p><strong>üëÄ</strong></p>
</div>
<div class="callout-content">
<ul>
<li><p>La multiplicaci√≥n s√≥lo es v√°lida si la dimensi√≥n de las columnas de la matriz es igual a la dimensi√≥n del vector. El resultado siempre es un vector columna.</p></li>
<li><p><strong>La multiplicaci√≥n de una fila por una columna es equivalente al Producto Interno.</strong> Es decir, <span class="math inline">\(\bar{y}_{i,:} = A_{i,:} \cdot \bar{x}\)</span></p></li>
</ul>
</div>
</div>
</div>
</div>
</section>
<section id="producto-matriz-vector-por-la-izquierda" class="slide level2 smaller">
<h2>Producto Matriz-Vector (Por la izquierda)</h2>
<p>A diferencia de todas las otras operaciones, el producto entre una matriz y un vector no es conmutativo.</p>
<h4 id="pre-multiplicaci√≥n-multiplicaci√≥n-por-la-izquierda">Pre-multiplicaci√≥n (Multiplicaci√≥n por la izquierda)</h4>
<div class="columns">
<div class="column" style="font-size: 110%;">
<div class="callout callout-note callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Sea</strong></p>
</div>
<div class="callout-content">
<p><span class="math display">\[\bar{y}^T = \bar{x}^T \cdot A\]</span></p>
<p><span class="math display">\[A = \begin{bmatrix}
2 &amp; 3 &amp; 0 \\
1 &amp; 0 &amp; 7
\end{bmatrix}\]</span></p>
<p><span class="math display">\[\bar{x} = \begin{bmatrix}
2 &amp; 1
\end{bmatrix}\]</span></p>
</div>
</div>
</div>
</div><div class="column" style="font-size: 110%;">
<div class="callout callout-important callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Atenci√≥n</strong></p>
</div>
<div class="callout-content">
<p>La pre-multiplicaci√≥n se puede ver como la combinaci√≥n lineal de las filas de una matriz por cada elemento del vector. <span class="math display">\[
\begin{align}
\bar{y}^T = \bar{x}^T \cdot A &amp;=
\begin{bmatrix}
(2 \cdot 2 + 1 \cdot 1)  &amp; (2 \cdot 3 + 1 \cdot 0) &amp; (2 \cdot 0 + 1 \cdot 7) \\
\end{bmatrix} \\
&amp;= 2 \cdot \begin{bmatrix} 2 &amp; 3 &amp; 0\end{bmatrix} + 1 \cdot \begin{bmatrix} 1 &amp; 0 &amp; 7\end{bmatrix} \\
&amp;= \begin{bmatrix}5 &amp; 6 &amp; 7\end{bmatrix}
\end{align}
\]</span></p>
</div>
</div>
</div>
</div></div>
<div style="font-size: 130%;">
<div class="callout callout-caution no-icon callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<p><strong>üëÄ</strong></p>
</div>
<div class="callout-content">
<ul>
<li><strong>La multiplicaci√≥n s√≥lo es v√°lida si la dimensi√≥n de las filas de la matriz es igual a la dimensi√≥n del vector. El resultado siempre es un vector fila</strong></li>
</ul>
</div>
</div>
</div>
</div>
</section>
<section id="producto-matriz-matriz" class="slide level2 smaller">
<h2>Producto Matriz-Matriz</h2>
<p>Corresponde a una operaci√≥n que permite multiplicar 2 matrices si las columnas de la primera son iguales a las filas de la segunda. Una matriz de <span class="math inline">\(n \times p\)</span> multiplicada con una de <span class="math inline">\(p \times m\)</span> nos dar√° una matriz de <span class="math inline">\(n \times m\)</span>. La manera de multiplicar es tomar cada fila de la primera y multiplicarla por cada columna de la segunda.</p>
<div style="font-size: 115%;">
<div class="callout callout-important no-icon callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<p><strong>Ojito!!</strong></p>
</div>
<div class="callout-content">
<ul>
<li>La multiplicaci√≥n matricial es equivalente a <span class="math inline">\(m\)</span> post-multiplicaciones Matriz-Vector, stackeadas hacia el lado.</li>
<li>Tambi√©n se puede ver como <span class="math inline">\(n\)</span> pre-multiplicaciones Matriz-Vector, stackeadas hacia abajo.</li>
</ul>
<p><span class="math display">\[
\begin{align}
AB &amp;= \begin{bmatrix}
A_{1,1} &amp; \dots &amp; A_{1,p} \\
\vdots &amp; \ddots &amp; \vdots \\
A_{n, 1} &amp; \dots &amp; A_{n,p} \\
\end{bmatrix}
\begin{bmatrix}
B_{1,1} &amp; \dots &amp; B_{1,m} \\
\vdots &amp; \ddots &amp; \vdots \\
B_{p, 1} &amp; \dots &amp; B_{p,m} \\
\end{bmatrix} \\
&amp;= \begin{bmatrix}
| &amp; &amp;  | \\
A \cdot B_{:,1}&amp; \dots &amp;  A \cdot B_{:,m} \\
| &amp; &amp;  | \\
\end{bmatrix}\\
&amp;= \begin{bmatrix}
- &amp; A_{1,:} \cdot B &amp; - \\
&amp; \vdots &amp;  \\
- &amp; A_{n,:} \cdot B &amp; - \\
\end{bmatrix}\\
\end{align}\]</span></p>
</div>
</div>
</div>
</div>
</section>
<section id="otros-productos" class="slide level2 smaller">
<h2>Otros Productos</h2>
<div class="columns">
<div class="column" style="font-size: 120%;">
<div class="callout callout-warning callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Hadamard Product</strong></p>
</div>
<div class="callout-content">
<p>Corresponde a otra operaci√≥n que permite multiplicar 2 matrices si y s√≥lo si tienen el mismo tama√±o. La multiplicaci√≥n se realiza elemento a elemento.</p>
<p><span class="math display">\[A = \begin{bmatrix}
2 &amp; 3 &amp; 0 \\
1 &amp; 0 &amp; 7
\end{bmatrix}\]</span></p>
<p><span class="math display">\[B = \begin{bmatrix}
2 &amp; 5 &amp; 1 \\
2&amp; 3 &amp; 7
\end{bmatrix}\]</span></p>
<p><span class="math display">\[A \odot B = \begin{bmatrix} 4 &amp; 15 &amp; 0 \\ 2 &amp; 0 &amp; 49\end{bmatrix}\]</span></p>
</div>
</div>
</div>
</div><div class="column" style="font-size: 120%;">
<div class="callout callout-caution callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Outer Product (Producto Externo)</strong></p>
</div>
<div class="callout-content">
<p>Corresponde a otra operaci√≥n que permite multiplicar 2 vectores. El resultado es una matriz de tama√±o <span class="math inline">\(d1 \times d2\)</span> donde <span class="math inline">\(d1\)</span> es la dimensi√≥n del primer vector y <span class="math inline">\(d2\)</span> es la dimensi√≥n del segundo vector.</p>
<p><span class="math display">\[\bar{x} = \begin{bmatrix}
2 \\
-1 \\
3
\end{bmatrix} \, \bar{y} = \begin{bmatrix}
4 \\
1 \\
5 \\
-2
\end{bmatrix}\]</span></p>
<p><span class="math display">\[
\begin{align}
\bar{x} \otimes \bar{y} = \bar{x} \cdot \bar{y}^T &amp;= \begin{bmatrix}
2 \cdot 4 &amp; 2 \cdot 1 &amp; 2 \cdot 5 &amp; 2 \cdot -2 \\
-1 \cdot 4 &amp; -1 \cdot 1 &amp; -1 \cdot 5 &amp; -1 \cdot -2 \\
3 \cdot 4 &amp; 3 \cdot 1 &amp; 3 \cdot 5 &amp; 3 \cdot -2
\end{bmatrix} \\
&amp;= \begin{bmatrix}
8 &amp; 2 &amp; 10 &amp; -4 \\
-4 &amp; -1 &amp; -5 &amp; 2 \\
12 &amp; 3 &amp; 15 &amp; -6
\end{bmatrix}
\end{align}
\]</span></p>
</div>
</div>
</div>
</div></div>
</section>
<section id="batch-product" class="slide level2 smaller">
<h2>Batch Product</h2>
<p>Este tipo de operaci√≥n es bastante poco com√∫n en otras √°reas, pero extremadamente com√∫n en Deep Learning.</p>
<div class="callout callout-tip callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Ejemplo</strong></p>
</div>
<div class="callout-content">
<p>¬øQu√© pasa si queremos calcular la multiplicaci√≥n de un tensor de dimensiones (2, 3, 2) y otra de (2, 2, 4)? El resultado es un tensor de dimensiones (2, 3, 4).</p>
<p>Podemos interpretarlo como que se har√°n 2 multiplicaciones a matrices de (3,2) y (2,4) respectivamente (las cuales son compatibles).</p>
<p>TODO: Ejemplo num√©rico Pendiente‚Ä¶</p>
</div>
</div>
</div>
</section>
<section id="el-nacimiento-de-las-redes-neuronales" class="slide level2 smaller">
<h2>El nacimiento de las Redes Neuronales</h2>
<blockquote>
<p>Las redes neuronales artificiales (ANN), son modelos inspirados en el mecanismo cerebral de sinapsis. Su unidad m√°s b√°sica es una Neurona.</p>
</blockquote>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><a href="img/clase-1/neuron_1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-9"><img data-src="img/clase-1/neuron_1.png" class="quarto-figure quarto-figure-center"></a></p>
</figure>
</div>
</section>
<section id="el-nacimiento-de-las-redes-neuronales-1" class="slide level2 smaller">
<h2>El nacimiento de las Redes Neuronales</h2>
<blockquote>
<p>Las redes neuronales artificiales (ANN), son modelos inspirados en el mecanismo cerebral de sinapsis. Su unidad m√°s b√°sica es una Neurona.</p>
</blockquote>
<div class="columns">
<div class="column" style="width:60%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><a href="img/clase-1/neuron_2.png" class="lightbox" data-gallery="quarto-lightbox-gallery-10"><img data-src="img/clase-1/neuron_2.png" class="quarto-figure quarto-figure-center" style="width:70.0%"></a></p>
</figure>
</div>
<div class="callout callout-note callout-style-simple">
<div class="callout-body">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-content">
<p>Este tipo de nomenclatura est√° sumamente pasada de moda.</p>
</div>
</div>
</div>
</div><div class="column fragment" style="width:40%;">
<ul>
<li>Este c√°lculo se puede representar como:</li>
</ul>
<p><span class="math display">\[ y = \phi(w_1 \cdot x_1 + w_2 \cdot x_2 + ... + w_5 \cdot x_5)\]</span> <span class="math display">\[ y = \phi(w^T \cdot x)\]</span></p>
<p>donde <span class="math inline">\(w = [w_1, w_2, w_3, w_4, w_5]\)</span> y <span class="math inline">\(x = [x_1, x_2, x_3, x_4, x_5]\)</span>.</p>
<div class="fragment">
<div class="callout callout-warning callout-style-simple">
<div class="callout-body">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-content">
<ul>
<li class="fragment">¬øQu√© pasa si <span class="math inline">\(\phi(.)\)</span> vale la funci√≥n <strong><em>identidad</em></strong>?</li>
<li class="fragment">Tenemos una <strong>Regresi√≥n Lineal</strong>.</li>
</ul>
</div>
</div>
</div>
</div>
<div class="fragment">
<div class="callout callout-warning callout-style-simple">
<div class="callout-body">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-content">
<ul>
<li class="fragment">¬øQu√© pasa si <span class="math inline">\(\phi(.)\)</span> vale la funci√≥n <strong><em>sigmoide</em></strong>?</li>
<li class="fragment">Tenemos una <strong>Regresi√≥n Log√≠stica</strong>.</li>
</ul>
</div>
</div>
</div>
</div>
</div></div>
</section>
<section id="arquitectura-de-una-red" class="slide level2 smaller">
<h2>Arquitectura de una Red</h2>
<div class="columns">
<div class="column">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><a href="img/clase-1/nn_arq.png" class="lightbox" data-gallery="quarto-lightbox-gallery-11"><img data-src="img/clase-1/nn_arq.png" class="quarto-figure quarto-figure-center"></a></p>
</figure>
</div>
</div><div class="column">
<h3 id="estructura-m√°s-com√∫n">Estructura m√°s com√∫n</h3>
<h6 id="probablemente-tampoco-seguiremos-esta-nomenclatura"><em>(Probablemente tampoco seguiremos esta nomenclatura)</em></h6>
<ul>
<li>Nodos o Neuronas</li>
<li>Edges o Conexiones</li>
<li>Capas</li>
</ul>
<div class="fragment" style="font-size:150%;">
<div class="callout callout-caution callout-style-simple">
<div class="callout-body">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-content">
<p><strong><em>¬øCu√°ntas capas tiene esta red?</em></strong></p>
</div>
</div>
</div>
</div>
<div class="fragment" style="font-size:150%;">
<div class="callout callout-tip callout-style-simple">
<div class="callout-body">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-content">
<p><strong><em>Depende</em></strong></p>
</div>
</div>
</div>
</div>
</div></div>
<ul>
<li>Normalmente todas las neuronas de una capa anterior se conectan con las de una capa posterior (Hay excepciones).</li>
<li>Dependiendo de la forma en la que se conecten, cada <strong>Arquitectura</strong> recibe un nombre.</li>
</ul>
</section></section>
<section>
<section id="intuici√≥n-y-conceptos-iniciales" class="title-slide slide level1 center">
<h1>Intuici√≥n y conceptos iniciales</h1>

</section>
<section id="los-ingredientes-de-un-algoritmo-de-aprendizaje" class="slide level2 smaller">
<h2>Los Ingredientes de un Algoritmo de Aprendizaje</h2>
<dl>
<dt>Hip√≥tesis</dt>
<dd>
<blockquote>
<p>Una funci√≥n que describe como mapear inputs (features) con outputs (labels) por medio de par√°metros.</p>
</blockquote>
</dd>
<dt>Loss Function</dt>
<dd>
<blockquote>
<p>Una funci√≥n que especifica cuanta informaci√≥n se pierde. Mayor p√©rdida implica m√°s error de estimaci√≥n.</p>
</blockquote>
</dd>
<dt>M√©todo de Optimizaci√≥n</dt>
<dd>
<blockquote>
<p>Es el responsable de combinar la <code>hip√≥tesis</code> y la <code>loss function</code>. Corresponde a un procedimiento para determinar los par√°metros de la hip√≥tesis, minimizando la suma de las p√©rdidas en un set de entrenamiento.</p>
</blockquote>
</dd>
</dl>
</section>
<section id="ejemplo-softmax-regression" class="slide level2">
<h2>Ejemplo: Softmax Regression</h2>
<dl>
<dt>Softmax Regression</dt>
<dd>
<blockquote>
<p>Corresponde la versi√≥n multiclase de una Regresi√≥n Log√≠stica. Tambi√©n se le llama una <code>Shallow Network</code>.</p>
</blockquote>
</dd>
</dl>
<div class="columns">
<div class="column" style="font-size: 80%;">
<div class="callout callout-tip callout-titled callout-style-simple">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Consideremos un problema de clasificaci√≥n multiclase de <span class="math inline">\(k\)</span> clases tal que:</strong></p>
</div>
<div class="callout-content">
<ul>
<li>Datos de Entrenamiento: <span class="math inline">\(x^{(i)}, y^{(i)} \in {1,...,k}\)</span> para <span class="math inline">\(i=1,...,m\)</span>.
<ul>
<li><span class="math inline">\(n\)</span>: Es el n√∫mero de Features.</li>
<li><span class="math inline">\(m\)</span>: Es el n√∫mero de puntos en el training set.</li>
<li><span class="math inline">\(k\)</span>: Es el n√∫mero de clases del problema.</li>
</ul></li>
</ul>
</div>
</div>
</div>
<div class="callout callout-important callout-style-simple">
<div class="callout-body">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-content">
<p>Vamos a tener en total <span class="math inline">\(n \times k\)</span> par√°metros o pesos que actualizar.</p>
</div>
</div>
</div>
</div><div class="column" style="width:50%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><a href="img/clase-1/softmax_reg.png" class="lightbox" data-gallery="quarto-lightbox-gallery-12"><img data-src="img/clase-1/softmax_reg.png" class="quarto-figure quarto-figure-center"></a></p>
</figure>
</div>
</div></div>
</section>
<section id="softmax-regression-hip√≥tesis" class="slide level2">
<h2>Softmax Regression: Hip√≥tesis</h2>
<div style="font-size: 80%;">
<p>Vamos a definir una funci√≥n que mapea valores de <span class="math inline">\(x \in \mathbb{R}\)</span> a vectores de <span class="math inline">\(k\)</span> dimensiones.</p>
</div>
<p><span class="math display">\[ h: \mathbb{R}^n \rightarrow \mathbb{R}^k\]</span> <span class="math display">\[ x \rightarrow h_\theta(x) = \theta^T x\]</span></p>
<div style="font-size: 80%;">
<p>donde <span class="math inline">\(\theta \in \mathbb{R}^{n \times k}\)</span> y <span class="math inline">\(x \in \mathbb{R}^{n\times 1}\)</span></p>
</div>
<div class="callout callout-warning callout-style-simple">
<div class="callout-body">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-content">
<p>En este caso usamos una <code>hip√≥tesis lineal</code>, ya que se usa una multiplicaci√≥n matricial (o producto punto) para relacionar <span class="math inline">\(\theta\)</span> y <span class="math inline">\(x\)</span>.</p>
</div>
</div>
</div>
<div class="callout callout-note callout-style-simple">
<div class="callout-body">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-content">
<p>En este caso el output de <span class="math inline">\(h_i(x)\)</span> devolver√° la probabilidad de pertenecer a una cierta clase <span class="math inline">\(i\)</span>.</p>
</div>
</div>
</div>
<div class="fragment">
<div class="callout callout-important callout-style-simple">
<div class="callout-body">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-content">
<p><strong><em>¬øCu√°l es el tama√±o/dimensi√≥n de <span class="math inline">\(h_\theta(x)\)</span>?</em></strong></p>
</div>
</div>
</div>
</div>
</section>
<section id="notaci√≥n-matricial" class="slide level2 smaller">
<h2>Notaci√≥n Matricial</h2>
<blockquote>
<p>Una manera m√°s conveniente de escribir estas operaciones es utilizar <strong><em>(Matrix Batch Form)</em></strong>.</p>
</blockquote>
<div class="columns">
<div class="column">
<h5 id="design-matrix">Design Matrix</h5>
<p><span class="math display">\[X \in \mathbb{R}^{m \times n} = \begin{bmatrix}
&amp;-x^{(1)T}-\\
&amp; \vdots &amp; \\
&amp;-x^{(m)T}- &amp;\\
\end{bmatrix}\]</span></p>
</div><div class="column">
<h5 id="labels-vector">Labels Vector</h5>
<p><span class="math display">\[y \in {1,...,k} = \begin{bmatrix}
&amp;-y^{(1)}-\\
&amp; \vdots &amp; \\
&amp;-y^{(m)}- &amp;\\
\end{bmatrix}\]</span></p>
</div></div>
<p>La hip√≥tesis tambi√©n se puede reescribir de manera matricial como:</p>
<div class="columns">
<div class="column">
<p><span class="math display">\[h_\theta(X) = \begin{bmatrix}
&amp;-h_\theta(x^{(1)})^T-\\
&amp; \vdots &amp; \\
&amp;-h_\theta(x^{(m)})^T-\\
\end{bmatrix}\]</span></p>
</div><div class="column">
<p><span class="math display">\[h_\theta(X)= \begin{bmatrix}
&amp;-x^{(1)T} \theta-\\
&amp; \vdots &amp; \\
&amp;-x^{(m)T} \theta-\\
\end{bmatrix} = X  \theta\]</span></p>
</div></div>
<div class="fragment">
<div class="callout callout-important callout-style-simple">
<div class="callout-body">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-content">
<p>Normalmente este tipo de operaciones son las que utilizaremos para hacer nuestro c√≥digo.</p>
</div>
</div>
</div>
</div>
</section>
<section id="loss-function-softmaxcross-entropy-loss" class="slide level2 smaller">
<h2>Loss Function: Softmax/Cross-Entropy Loss</h2>
<div style="font-size: 130%;">
<div class="callout callout-warning callout-style-simple">
<div class="callout-body">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-content">
<p>La salida de nuestra <code>Shallow Network</code> retornar√° valores reales.</p>
</div>
</div>
</div>
</div>
<div style="font-size: 130%;">
<div class="callout callout-tip callout-style-simple">
<div class="callout-body">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-content">
<p>Para poder tener una mejor interpretaci√≥n del significado de cada una aplicaremos la funci√≥n <code>Softmax</code> lo cual permitir√° <em>normalizar</em> los resultados y llevar√° los resultados a una <strong><em>‚Äúdistribuci√≥n de probabilidad‚Äù</em></strong> (valores positivos que sumen 1).</p>
</div>
</div>
</div>
</div>
<div class="columns">
<div class="column" style="width:60%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><a href="img/clase-1/softmax_example.png" class="lightbox" data-gallery="quarto-lightbox-gallery-13"><img data-src="img/clase-1/softmax_example.png" class="quarto-figure quarto-figure-center"></a></p>
</figure>
</div>
</div><div class="column" style="width:40%;">
<p>Formalmente definiremos la funci√≥n Softmax como:</p>
<p><span class="math display">\[s_i = p(label = i) = \frac{exp(h_i(x))}{\sum_{j=1}^k exp(h_j(x))}\]</span></p>
<p><span class="math display">\[s = \begin{bmatrix}
&amp;s_1&amp;\\
&amp; \vdots &amp; \\
&amp;s_k&amp;\\
\end{bmatrix}\]</span></p>
</div></div>
</section>
<section id="loss-function-softmaxcross-entropy-loss-1" class="slide level2 smaller">
<h2>Loss Function: Softmax/Cross-Entropy Loss</h2>
<p>Para medir el error/p√©rdida de informaci√≥n utilizaremos el <code>Negative Log Loss</code> o <code>Cross Entropy Loss</code>.</p>
<p><span class="math display">\[l_{ce}(h(x), y) = -log\left(p(label = y)\right)\]</span></p>
<div class="fragment" style="font-size: 120%;">
<div class="callout callout-tip callout-style-simple">
<div class="callout-body">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-content">
<p>Para garantizar el √©xito de nuestro modelo, b√°sicamente queremos maximizar la probabilidad de encontrar la etiqueta correcta, es decir, que <span class="math inline">\(p(label = y)\)</span> sea lo m√°s alto posible.</p>
</div>
</div>
</div>
</div>
<div class="fragment" style="font-size: 120%;">
<div class="callout callout-caution callout-style-simple">
<div class="callout-body">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-content">
<p>Normalmente en los problemas de optimizaci√≥n no se suele maximizar sino minimizar. Minimizar el valor negativo es equivalente a maximizar. Esto ser√≠a equivalente a minimizar el error del modelo.</p>
</div>
</div>
</div>
</div>
<div class="fragment" style="font-size: 120%;">
<div class="callout callout-warning callout-style-simple">
<div class="callout-body">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-content">
<p>Finalmente por razones de estabilidad num√©rica, minimizamos el logaritmo de la probabilidad que es una t√©cnica bien conocida en Estad√≠stica.</p>
</div>
</div>
</div>
</div>
<div class="fragment">
<p><span class="math display">\[\begin{align}
l_{ce}(h(x), y) = -log\left(p(label = y)\right) &amp;= -log \left(\frac{exp(h_{(i = y)}(x))}{\sum_{j=1}^k exp(h_j(x))}\right) \\
&amp;= - h_{(i=y)}(x) + log\left(\sum_{j = 1}^k exp(h_j(x))\right)\end{align}\]</span></p>
</div>
</section>
<section id="m√©todo-de-optimizaci√≥n" class="slide level2 smaller">
<h2>M√©todo de Optimizaci√≥n</h2>
<blockquote>
<p>El √∫ltimo ingrediente de un algoritmo de aprendizaje es el m√©todo de optimizaci√≥n. Es necesario minimizar la p√©rdida promedio asociada a todos los puntos de un cierto set de entrenamiento. Para ello definimos esto formalmente como:</p>
</blockquote>
<p><span class="math display">\[\underset{\theta}{minimize} = \frac{1}{m} \sum_{i=1}^m l_{ce}(h_\theta(x^{(i)}), y^{(i)})\]</span></p>
<div class="callout callout-note callout-style-simple">
<div class="callout-body">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-content">
<p><strong><em>¬øC√≥mo encontramos los par√°metros <span class="math inline">\(\theta\)</span> que minimizan la p√©rdida de informaci√≥n/error de estimaci√≥n?</em></strong></p>
</div>
</div>
</div>
<dl>
<dt>Gradient Descent</dt>
<dd>
<blockquote>
<p>Es un m√©todo num√©rico que permite minimizar funciones movi√©ndose en direcci√≥n contraria al Gradiente. Es computacionalmente muy eficiente y f√°cil de implementar en c√≥digo.</p>
</blockquote>
</dd>
</dl>
</section>
<section id="gradient-descent" class="slide level2 smaller">
<h2>Gradient Descent</h2>
<div class="columns">
<div class="column" style="width:60%;">
<p>Se define el gradiente como la matriz que contiene las derivadas parciales de una funci√≥n <span class="math inline">\(f\)</span>. Se denota como:</p>
<p><span class="math display">\[\nabla_\theta f(\theta) \in \mathbb{R}^{n \times k} =  \begin{bmatrix}
\frac{\partial f(\theta)}{\partial \theta_{11}} &amp; \cdots &amp; \frac{\partial f(\theta)}{\partial \theta_{1k}} \\
\cdots &amp; \ddots &amp; \cdots \\
\frac{\partial f(\theta)}{\partial \theta_{n1}} &amp; \cdots &amp; \frac{\partial f(\theta)}{\partial \theta_{nk}}
\end{bmatrix}\]</span></p>
<div class="callout callout-tip callout-style-simple">
<div class="callout-body">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-content">
<p><span class="math inline">\(\theta_{ij}\)</span> corresponde al par√°metro que une el nodo/feature <span class="math inline">\(i\)</span> con el nodo/predicci√≥n <span class="math inline">\(j\)</span>.</p>
</div>
</div>
</div>
</div><div class="column" style="width:40%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><a href="img/clase-1/gradient.png" class="lightbox" data-gallery="quarto-lightbox-gallery-14"><img data-src="img/clase-1/gradient.png" class="quarto-figure quarto-figure-center"></a></p>
</figure>
</div>
</div></div>
<div style="font-size: 130%;">
<div class="callout callout-tip callout-style-simple">
<div class="callout-body">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-content">
<p>El gradiente apunta a la direcci√≥n de m√°ximo crecimiento de la funci√≥n <span class="math inline">\(f\)</span>.</p>
</div>
</div>
</div>
</div>
</section>
<section id="gradient-descent-regla-de-actualizaci√≥n" class="slide level2 smaller">
<h2>Gradient Descent: Regla de Actualizaci√≥n</h2>
<p>Para minimizar la funci√≥n, la idea es descender iterativamente por el trayecto <strong>en contra</strong> del gradiente. La regla de actualizaci√≥n se define como:</p>
<p><span class="math display">\[\theta := \theta - \alpha \nabla_\theta f(\theta) = \theta - \frac{\alpha}{m}\nabla_\theta l_{ce}(X\theta,y)\]</span></p>
<p>con <span class="math inline">\(\theta \in \mathbb{R}^{n \times k}\)</span> y <span class="math inline">\(\alpha &gt; 0\)</span> corresponde al <em>step size</em> o <code>learning rate</code>.</p>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><a href="img/clase-1/lr_effect.png" class="lightbox" data-gallery="quarto-lightbox-gallery-15"><img data-src="img/clase-1/lr_effect.png" class="quarto-figure quarto-figure-center" style="width:60.0%"></a></p>
</figure>
</div>
<div class="callout callout-tip callout-style-simple">
<div class="callout-body">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-content">
<p>En nuestro caso <span class="math inline">\(f\)</span> corresponder√° a nuestro <span class="math inline">\(l_{ce}\)</span> calculado anteriormente. El problema es, ¬øcu√°nto vale el gradiente del <code>Cross Entropy Loss</code>?</p>
</div>
</div>
</div>
</section>
<section id="calculando-el-gradiente-a-mano" class="slide level2 smaller">
<h2>Calculando el Gradiente a mano</h2>
<div style="font-size: 130%;">
<p>Simplifiquemos el problema a calcular para un s√≥lo vector <span class="math inline">\(x\)</span>.</p>
<p><span class="math display">\[\theta := \theta - \alpha \nabla_\theta l_{ce}(\theta^Tx,y) \]</span></p>
</div>
<div style="font-size: 120%;">
<div class="callout callout-warning callout-style-simple">
<div class="callout-body">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-content">
<p>¬øCu√°nto vale el Gradiente?</p>
<ul>
<li>No es tan sencillo, ya que derivamos respecto a <span class="math inline">\(\theta\)</span> que es una matriz.</li>
<li>Pero derivamos a <span class="math inline">\(\theta^T x\)</span> que es un vector.</li>
<li>Para ello, lo correcto es utilizar Calculo Diferencial Matricial, Jacobianos y Productos de Kroenecker (que probablemente no han visto en ning√∫n curso).
<ul>
<li><strong>SPOILER</strong>: Yo tampoco lo he visto en ning√∫n curso.</li>
</ul></li>
</ul>
</div>
</div>
</div>
</div>
<div class="columns fragment">
<div class="column" style="width:70%;">
<div style="font-size: 120%;">
<div class="callout callout-tip callout-style-simple">
<div class="callout-body">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-content">
<ul>
<li>Usaremos un truco (sumamente hacky üò±) que jam√°s deben revelar y que avergonzar√≠a a cualquier profesor de C√°lculo.
<ul>
<li>Pretenderemos que todos los valores son escalares y corregiremos las dimensiones al final.</li>
</ul></li>
</ul>
</div>
</div>
</div>
</div>
</div><div class="column" style="width:30%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><a href="img/clase-1/fuenzi.jpeg" class="lightbox" data-gallery="quarto-lightbox-gallery-16"><img data-src="img/clase-1/fuenzi.jpeg" class="quarto-figure quarto-figure-center" style="width:40.0%"></a></p>
</figure>
</div>
</div></div>
</section>
<section id="calculando-el-gradiente-a-mano-1" class="slide level2 smaller">
<h2>Calculando el Gradiente a mano</h2>
<blockquote>
<p>Simplifiquemos el problema pensando que calcularemos el Gradiente para un s√≥lo vector <span class="math inline">\(x\)</span>.</p>
</blockquote>
<blockquote>
<p>Es decir, <span class="math inline">\(x \in \mathbb{R}^{n\times1}\)</span>.</p>
</blockquote>
<p>Adem√°s sabemos que <span class="math inline">\(\nabla_\theta l_{ce}(\theta^Tx, y)\)</span> debe tener dimensiones <span class="math inline">\(n \times k\)</span>.</p>
<div class="fragment" style="font-size: 150%;" data-fragment-index="1">
<div class="callout callout-important callout-style-simple">
<div class="callout-body">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-content">
<p><strong><em>¬øPor qu√©?</em></strong></p>
</div>
</div>
</div>
</div>
<div class="columns">
<div class="column fragment" data-fragment-index="2">
<p><span class="math display">\[\nabla_\theta l_{ce}(\theta^T x,y) = \frac{\partial l_{ce}(\theta^T x,y)}{\partial \theta^T x} \cdot \frac{\partial \theta^Tx}{\partial \theta}\]</span></p>
</div><div class="column fragment" data-fragment-index="3">
<p><span class="math display">\[\frac{\partial l_{ce}(\theta^T x,y)}{\partial \theta^T x} = \frac{\partial l_{ce}(h_\theta(x), y)}{\partial h_\theta(x)} = \begin{bmatrix}
\frac{\partial l_{ce}(h,y)}{\partial h_1} \\
\vdots\\
\frac{\partial l_{ce}(h,y)}{\partial h_k} \\
\end{bmatrix}\]</span></p>
</div></div>
<div class="fragment" style="font-size: 130%;" data-fragment-index="4">
<div class="callout callout-tip callout-style-simple">
<div class="callout-body">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-content">
<p>Luego el gradiente de <span class="math inline">\(l_{ce}\)</span> respecto a <span class="math inline">\(h\)</span> tiene dimensiones <span class="math inline">\(k \times 1\)</span>.</p>
</div>
</div>
</div>
</div>
</section>
<section id="calculando-el-gradiente-a-mano-2" class="slide level2 smaller">
<h2>Calculando el Gradiente a mano</h2>
<p><span class="math display">\[\begin{align}
\frac{\partial l_{ce}(h,y)}{\partial h_i} &amp;= \frac{\partial }{\partial h_i}\left(-h_{(i = y)} + log \sum_{j = 1}^k exp(h_j)\right) \\
&amp;= -\frac{\partial h_{(i = y)}}{\partial h_i}+ \frac{1}{\sum_{j = 1}^k exp(h_j)} \cdot \frac{\partial}{\partial h_i}\left(\sum_{j=1}^k exp(h_j)\right) \\
&amp;= -\frac{\partial h_{(i = y)}}{\partial h_i}+ \frac{exp(h_i)}{\sum_{j = 1}^k exp(h_j)} \\
&amp;= - 1\{i=y\} + s_i = s_i - 1\{i=y\}
\end{align}
\]</span></p>
<div class="fragment">
<div class="callout callout-tip callout-style-simple">
<div class="callout-body">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-content">
<p><span class="math display">\[1\{i = y\} = \begin{cases}
1,  &amp; \text{i = y} \\
0, &amp; \text{otherwise}
\end{cases}
\]</span></p>
</div>
</div>
</div>
</div>
<div class="fragment">
<p>Finalmente en forma vectorial quedar√≠a como:</p>
<div class="columns">
<div class="column">
<p><span class="math display">\[\frac{\partial l_{ce}(\theta^T x,y)}{\partial \theta^T x} = s - e_y\]</span></p>
</div><div class="column">
<div class="callout callout-tip callout-style-simple">
<div class="callout-body">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-content">
<p>Donde <span class="math inline">\(z\)</span>, es el vector de Softmax y <span class="math inline">\(e_y\)</span> es un vector con un 1 en la posici√≥n <span class="math inline">\(y\)</span> y 0 en el resto.</p>
</div>
</div>
</div>
</div></div>
</div>
</section>
<section id="calculando-el-gradiente-a-mano-3" class="slide level2 smaller">
<h2>Calculando el Gradiente a mano</h2>
<div class="columns">
<div class="column">
<p><span class="math display">\[\nabla_\theta l_{ce}(\theta^T x,y) = \frac{\partial l_{ce}(\theta^T x,y)}{\partial \theta^T x} \cdot \frac{\partial \theta^Tx}{\partial \theta}\]</span> <span class="math display">\[\nabla_\theta l_{ce}(\theta^T x,y) = (s-e_y)\cdot x \]</span></p>
</div><div class="column fragment">
<div class="callout callout-caution callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Ojo con las dimensiones</strong></p>
</div>
<div class="callout-content">
<ul>
<li><span class="math inline">\(s-e_y \in \mathbb{R}^{k \times 1}\)</span></li>
<li><span class="math inline">\(x \in \mathbb{R}^{n \times 1}\)</span></li>
</ul>
</div>
</div>
</div>
</div></div>
<div class="fragment">
<p>Luego:</p>
<p><span class="math display">\[\nabla_\theta l_{ce}(\theta^T x,y) = x (s-e_y)^T\]</span></p>
</div>
<div class="fragment" style="font-size: 150%;">
<div class="callout callout-caution callout-style-simple">
<div class="callout-body">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-content">
<p><strong><em>¬øCu√°l es el tama√±o de <span class="math inline">\(\nabla_\theta l_{ce}(\theta^T x,y)\)</span>?</em></strong></p>
</div>
</div>
</div>
</div>
<div class="fragment" style="font-size: 150%;">
<div class="callout callout-note callout-style-simple">
<div class="callout-body">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-content">
<p><span class="math inline">\(n \times k\)</span></p>
</div>
</div>
</div>
</div>
<div class="fragment" style="font-size: 150%;">
<div class="callout callout-warning callout-style-simple">
<div class="callout-body">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-content">
<p><strong><em>¬øPor qu√©?</em></strong></p>
</div>
</div>
</div>
</div>
</section>
<section id="calculando-el-gradiente-matrix-batch-form" class="slide level2 smaller">
<h2>Calculando el Gradiente Matrix Batch Form</h2>
<h4 id="esto-ser√≠a-equivalente-a-tomar-en-consideraci√≥n-todos-los-puntos-del-training-set">Esto ser√≠a equivalente a tomar en consideraci√≥n todos los puntos del Training Set</h4>
<div class="columns">
<div class="column">
<p><span class="math display">\[\begin{align}\nabla_\theta l_{ce}(X\theta,y) &amp;= \frac{\partial l_{ce}(X\theta,y)}{\partial X\theta} \cdot \frac{\partial X\theta}{\partial \theta}\\
&amp;= (S - I_y) \cdot X \\
&amp;= X^T \cdot (S - I_y)
\end{align}\]</span></p>
<div class="callout callout-tip callout-style-simple">
<div class="callout-body">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-content">
<ul>
<li><span class="math inline">\(S\)</span> corresponde al Softmax de <span class="math inline">\(X\theta\)</span> aplicado por filas.</li>
<li><span class="math inline">\(I_y\)</span> corresponde al One Hot Encoder de las etiquetas. Filas con 1 en la etiqueta correcta y 0 en el resto.</li>
</ul>
</div>
</div>
</div>
</div><div class="column">
<div class="fragment">
<div class="callout callout-caution callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Ojo con las dimensiones</strong></p>
</div>
<div class="callout-content">
<ul>
<li><span class="math inline">\(S - I_y \in \mathbb{R}^{m \times k}\)</span></li>
<li><span class="math inline">\(X \in \mathbb{R}^{m \times n}\)</span></li>
</ul>
</div>
</div>
</div>
</div>
<div class="fragment">
<div class="callout callout-warning callout-style-simple">
<div class="callout-body">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-content">
<p><strong><em>¬øCu√°l es el tama√±o de <span class="math inline">\(\nabla_\theta l_{ce}(X\theta,y)\)</span>?</em></strong></p>
</div>
</div>
</div>
</div>
</div></div>
<div class="fragment">
<p>Finalmente la <code>Regla de Actualizaci√≥n</code> de par√°metros usando Gradient Descent queda como:</p>
<p><span class="math display">\[\theta := \theta - \frac{\alpha}{m} X^T (S - I_y)\]</span></p>
</div>
</section>
<section id="conclusiones" class="slide level2 smaller">
<h2>Conclusiones</h2>
<div class="columns">
<div class="column">
<div class="callout callout-tip callout-style-simple">
<div class="callout-body">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-content">
<ul>
<li>Acabamos de entrenar una Shallow Network, sin definir ning√∫n concepto Fancy que es propio del √°rea.</li>
<li>No hemos hablado ni de:
<ul>
<li><code>Forward Pass</code></li>
<li><code>Epochs</code></li>
<li><code>Backpropagation</code></li>
<li><code>Adam</code></li>
<li><code>Activation Functions</code></li>
<li>etc.</li>
</ul></li>
</ul>
</div>
</div>
</div>
<div class="fragment" data-fragment-index="1">
<div class="callout callout-note callout-style-simple">
<div class="callout-body">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-content">
<ul>
<li>Aplicando esta simple regla se puede obtener cerca de un 8% de error clasificando d√≠gitos en MNIST.</li>
<li>Se puede programar en pocas l√≠neas en Python.</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><a href="img/clase-1/mnist.png" class="lightbox" data-gallery="quarto-lightbox-gallery-17"><img data-src="img/clase-1/mnist.png" class="quarto-figure quarto-figure-center" style="width:30.0%"></a></p>
</figure>
</div>
</div>
</div>
</div>
</div>
</div><div class="column fragment" data-fragment-index="2">
<h4 id="pero-qu√©-pasa-con-arquitecturas-m√°s-complejas">Pero, ¬øqu√© pasa con arquitecturas m√°s complejas?</h4>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><a href="img/clase-1/nn_arq_full.png" class="lightbox" data-gallery="quarto-lightbox-gallery-18"><img data-src="img/clase-1/nn_arq_full.png" class="quarto-figure quarto-figure-center" style="width:60.0%"></a></p>
</figure>
</div>
</div></div>
</section></section>
<section id="eso-es-todo" class="title-slide slide level1 center">
<h1>¬°¬°Eso es todo!!</h1>
<div class="footer">
<p xmlns:cc="http://creativecommons.org/ns#" xmlns:dct="http://purl.org/dc/terms/">
</p><p><span property="dct:title">Tics-579 Deep Learning</span> por Alfonso Tobar-Arancibia est√° licenciado bajo <a href="http://creativecommons.org/licenses/by-nc-sa/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;">CC BY-NC-SA 4.0</a></p><a href="http://creativecommons.org/licenses/by-nc-sa/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;">
<img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/nc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/sa.svg?ref=chooser-v1"></a>
<p></p>
</div>
</section>

<section>
<section id="anexos" class="title-slide slide level1 center">
<h1>Anexos</h1>

</section>
<section id="multiplicaci√≥n-matricial" class="slide level2 smaller">
<h2>Multiplicaci√≥n Matricial</h2>
<div class="columns">
<div class="column">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><a href="img/clase-1/mat_mat_mul.png" class="lightbox" data-gallery="quarto-lightbox-gallery-19"><img data-src="img/clase-1/mat_mat_mul.png" class="quarto-figure quarto-figure-center"></a></p>
</figure>
</div>
</div><div class="column">
<ul>
<li>Donde <span class="math inline">\(B_{*,i}\)</span> corresponde a la columna <span class="math inline">\(i\)</span> de B.</li>
<li>Donde <span class="math inline">\(A_{i,*}\)</span> corresponde a la fila <span class="math inline">\(i\)</span> de A.</li>
</ul>
</div></div>


</section></section>
    </div>
  <div class="quarto-auto-generated-content" style="display: none;">
<p><img src="../logo-uai-blanco.jpeg" class="slide-logo"></p>
<div class="footer footer-default">

</div>
</div></div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="../site_libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="../site_libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="../site_libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="../site_libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="../site_libs/revealjs/plugin/reveal-chalkboard/plugin.js"></script>
  <script src="../site_libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="../site_libs/revealjs/plugin/notes/notes.js"></script>
  <script src="../site_libs/revealjs/plugin/search/search.js"></script>
  <script src="../site_libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="../site_libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': false,
'previewLinksAuto': false,
'pdfSeparateFragments': true,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'jumpToSlide': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleScrollView(event)\"><kbd>r</kbd> Scroll View Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"5\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleChalkboard(event)\"><kbd>b</kbd> Toggle Chalkboard</a></li>\n<li class=\"slide-tool-item\" data-item=\"6\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleNotesCanvas(event)\"><kbd>c</kbd> Toggle Notes Canvas</a></li>\n<li class=\"slide-tool-item\" data-item=\"7\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.downloadDrawings(event)\"><kbd>d</kbd> Download Drawings</a></li>\n<li class=\"slide-tool-item\" data-item=\"8\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'chalkboard': {"buttons":true},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: true,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c/t',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'slide',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'fast',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1366,

        height: 768,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, RevealChalkboard, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    <script id="quarto-html-after-body" type="application/javascript">
      window.document.addEventListener("DOMContentLoaded", function (event) {
        const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
        tabsets.forEach(function(tabset) {
          const tabby = new Tabby('#' + tabset.id);
        });
        const isCodeAnnotation = (el) => {
          for (const clz of el.classList) {
            if (clz.startsWith('code-annotation-')) {                     
              return true;
            }
          }
          return false;
        }
        const onCopySuccess = function(e) {
          // button target
          const button = e.trigger;
          // don't keep focus
          button.blur();
          // flash "checked"
          button.classList.add('code-copy-button-checked');
          var currentTitle = button.getAttribute("title");
          button.setAttribute("title", "Copied!");
          let tooltip;
          if (window.bootstrap) {
            button.setAttribute("data-bs-toggle", "tooltip");
            button.setAttribute("data-bs-placement", "left");
            button.setAttribute("data-bs-title", "Copied!");
            tooltip = new bootstrap.Tooltip(button, 
              { trigger: "manual", 
                customClass: "code-copy-button-tooltip",
                offset: [0, -8]});
            tooltip.show();    
          }
          setTimeout(function() {
            if (tooltip) {
              tooltip.hide();
              button.removeAttribute("data-bs-title");
              button.removeAttribute("data-bs-toggle");
              button.removeAttribute("data-bs-placement");
            }
            button.setAttribute("title", currentTitle);
            button.classList.remove('code-copy-button-checked');
          }, 1000);
          // clear code selection
          e.clearSelection();
        }
        const getTextToCopy = function(trigger) {
            const codeEl = trigger.previousElementSibling.cloneNode(true);
            for (const childEl of codeEl.children) {
              if (isCodeAnnotation(childEl)) {
                childEl.remove();
              }
            }
            return codeEl.innerText;
        }
        const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
          text: getTextToCopy
        });
        clipboard.on('success', onCopySuccess);
        if (window.document.getElementById('quarto-embedded-source-code-modal')) {
          const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
            text: getTextToCopy,
            container: window.document.getElementById('quarto-embedded-source-code-modal')
          });
          clipboardModal.on('success', onCopySuccess);
        }
          var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
          var mailtoRegex = new RegExp(/^mailto:/);
            var filterRegex = new RegExp("https:\/\/datacubeR\.github\.io\/clases_UAI\/");
          var isInternal = (href) => {
              return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
          }
          // Inspect non-navigation links and adorn them if external
         var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
          for (var i=0; i<links.length; i++) {
            const link = links[i];
            if (!isInternal(link.href)) {
              // undo the damage that might have been done by quarto-nav.js in the case of
              // links that we want to consider external
              if (link.dataset.originalHref !== undefined) {
                link.href = link.dataset.originalHref;
              }
            }
          }
        function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
          const config = {
            allowHTML: true,
            maxWidth: 500,
            delay: 100,
            arrow: false,
            appendTo: function(el) {
                return el.closest('section.slide') || el.parentElement;
            },
            interactive: true,
            interactiveBorder: 10,
            theme: 'light-border',
            placement: 'bottom-start',
          };
          if (contentFn) {
            config.content = contentFn;
          }
          if (onTriggerFn) {
            config.onTrigger = onTriggerFn;
          }
          if (onUntriggerFn) {
            config.onUntrigger = onUntriggerFn;
          }
            config['offset'] = [0,0];
            config['maxWidth'] = 700;
          window.tippy(el, config); 
        }
        const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
        for (var i=0; i<noterefs.length; i++) {
          const ref = noterefs[i];
          tippyHover(ref, function() {
            // use id or data attribute instead here
            let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
            try { href = new URL(href).hash; } catch {}
            const id = href.replace(/^#\/?/, "");
            const note = window.document.getElementById(id);
            if (note) {
              return note.innerHTML;
            } else {
              return "";
            }
          });
        }
        const findCites = (el) => {
          const parentEl = el.parentElement;
          if (parentEl) {
            const cites = parentEl.dataset.cites;
            if (cites) {
              return {
                el,
                cites: cites.split(' ')
              };
            } else {
              return findCites(el.parentElement)
            }
          } else {
            return undefined;
          }
        };
        var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
        for (var i=0; i<bibliorefs.length; i++) {
          const ref = bibliorefs[i];
          const citeInfo = findCites(ref);
          if (citeInfo) {
            tippyHover(citeInfo.el, function() {
              var popup = window.document.createElement('div');
              citeInfo.cites.forEach(function(cite) {
                var citeDiv = window.document.createElement('div');
                citeDiv.classList.add('hanging-indent');
                citeDiv.classList.add('csl-entry');
                var biblioDiv = window.document.getElementById('ref-' + cite);
                if (biblioDiv) {
                  citeDiv.innerHTML = biblioDiv.innerHTML;
                }
                popup.appendChild(citeDiv);
              });
              return popup.innerHTML;
            });
          }
        }
      });
      </script>
    <script>var lightboxQuarto = GLightbox({"closeEffect":"zoom","descPosition":"bottom","loop":false,"openEffect":"zoom","selector":".lightbox"});
    (function() {
      let previousOnload = window.onload;
      window.onload = () => {
        if (previousOnload) {
          previousOnload();
        }
        lightboxQuarto.on('slide_before_load', (data) => {
          const { slideIndex, slideNode, slideConfig, player, trigger } = data;
          const href = trigger.getAttribute('href');
          if (href !== null) {
            const imgEl = window.document.querySelector(`a[href="${href}"] img`);
            if (imgEl !== null) {
              const srcAttr = imgEl.getAttribute("src");
              if (srcAttr && srcAttr.startsWith("data:")) {
                slideConfig.href = srcAttr;
              }
            }
          } 
        });
      
        lightboxQuarto.on('slide_after_load', (data) => {
          const { slideIndex, slideNode, slideConfig, player, trigger } = data;
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(slideNode);
          }
        });
      
      };
      
    })();
              </script>
    

</body></html>