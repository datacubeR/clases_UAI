
## El nacimiento de las Redes Neuronales {.smaller}

> Las redes neuronales artificiales (ANN), son modelos inspirados en el mecanismo cerebral de sinapsis. Su unidad m치s b치sica es una Neurona. 


![](img/clase-1/neuron_1.png){.lightbox fig-align="center" width="50%"}


:::{.callout-important appearance="default"}
## Importante
Si bien los modelos est치n inspirados en el funci칩n neuronal, existe muy poca evidencia de que las neuronas de verdad efectivamente funcionen similar a una red Neuronal.
:::

## El nacimiento de las Redes Neuronales {.smaller}

> Las redes neuronales artificiales (ANN), son modelos inspirados en el mecanismo cerebral de sinapsis. Su unidad m치s b치sica es una Neurona. 


::: {.columns}
::: {.column width="60%"}
![](img/clase-1/neuron_2.png){.lightbox fig-align="center" width="70%"}


::: {.callout-note} 

:::
:::
::: {.column width="40%" .fragment}



* Este c치lculo se puede representar como: 

$$ y = \phi(w_1 \cdot x_1 + w_2 \cdot x_2 + ... + w_5 \cdot x_5)$$
$$ y = \phi(w^T \cdot x)$$

donde $w = [w_1, w_2, w_3, w_4, w_5]$ y $x = [x_1, x_2, x_3, x_4, x_5]$.

::: {.callout-warning .fragment .incremental}
* 쯈u칠 pasa si $\phi(.)$ vale la funci칩n ***identidad***?
* Tenemos una **Regresi칩n Lineal**.
:::


::: {.callout-warning .fragment .incremental}
* 쯈u칠 pasa si $\phi(.)$ vale la funci칩n ***sigmoide***?
* Tenemos una **Regresi칩n Log칤stica**.
:::
:::
::: 

## Arquitectura de una Red {.smaller}


::: {.columns}
::: {.column}
![](img/clase-1/nn_arq.png){.lightbox fig-align="center"} 
:::
::: {.column}
### Estructura m치s com칰n 
###### *(Probablemente tampoco seguiremos esta nomenclatura)*

* Nodos o Neuronas
* Edges o Conexiones
* Capas

::: {.callout-caution .fragment style="font-size:150%;"}
***쮺u치ntas capas tiene esta red?***
:::

::: {.callout-tip .fragment style="font-size:150%;"}
***Depende***
:::
:::
::: 

* Normalmente todas las neuronas de una capa anterior se conectan con las de una capa posterior (Hay excepciones). 
* Dependiendo de la forma en la que se conecten, cada **Arquitectura** recibe un nombre.

# Intuici칩n y conceptos iniciales

## Los Ingredientes de un Algoritmo de Aprendizaje {.smaller}

Hip칩tesis
: > Una funci칩n que describe como mapear inputs (features) con outputs (labels) por medio de par치metros.  

Loss Function
: > Una funci칩n que especifica cuanta informaci칩n se pierde. Mayor p칠rdida implica m치s error de estimaci칩n.

M칠todo de Optimizaci칩n
: > Es el responsable de combinar la `hip칩tesis` y la `loss function`. Corresponde a un procedimiento para determinar los par치metros de la hip칩tesis, minimizando la suma de las p칠rdidas en un set de entrenamiento. 

## Ejemplo: Softmax Regression 

Softmax Regression
: > Corresponde la versi칩n multiclase de una Regresi칩n Log칤stica. Tambi칠n se le llama una `Shallow Network`.


::: {.columns}
::: {.column width="50%" style="font-size: 80%;"}
::: {.callout-tip}
#### Consideremos un problema de clasificaci칩n multiclase de $k$ clases tal que:

* Datos de Entrenamiento: $x^{(i)}, y^{(i)} \in {1,...,k}$ para $i=1,...,m$.
    * $n$: Es el n칰mero de Features.
    * $m$: Es el n칰mero de puntos en el training set. 
    * $k$: Es el n칰mero de clases del problema.
:::

::: {.callout-important}
Vamos a tener en total $n \times k$ par치metros o pesos que actualizar.
:::
:::
::: {.column width="50%"}
![](img/clase-1/softmax_reg.png){.lightbox fig-align="center"} 
:::
::: 



## Softmax Regression: Hip칩tesis

::: {style="font-size: 80%;"}
Vamos a definir una funci칩n que mapea valores de $x \in \mathbb{R}$ a vectores de $k$ dimensiones. 
:::
$$ h: \mathbb{R}^n \rightarrow \mathbb{R}^k$$
$$ x \rightarrow h_\theta(x) = \theta^T x$$

::: {style="font-size: 80%;"}
donde $\theta \in \mathbb{R}^{n \times k}$ y $x \in \mathbb{R}^{n\times 1}$
:::

::: {.callout-warning}
En este caso usamos una `hip칩tesis lineal`, ya que se usa una multiplicaci칩n matricial (o producto punto) para relacionar $\theta$ y $x$. 
:::

::: {.callout-note}
En este caso el output de $h_i(x)$ devolver치 la probabilidad de pertenecer a una cierta clase $i$.   
:::

::: {.callout-important .fragment}
***쮺u치l es el tama침o/dimensi칩n de $h_\theta(x)$?***
:::

## Notaci칩n Matricial {.smaller}

> Una manera m치s conveniente de escribir estas operaciones es utilizar ***(Matrix Batch Form)***. 

::: {.columns}
::: {.column}
##### Design Matrix

$$X \in \mathbb{R}^{m \times n} = \begin{bmatrix}
&-x^{(1)T}-\\
& \vdots & \\
&-x^{(m)T}- &\\
\end{bmatrix}$$
:::
::: {.column}
##### Labels Vector
$$y \in {1,...,k} = \begin{bmatrix}
&-y^{(1)}-\\
& \vdots & \\
&-y^{(m)}- &\\
\end{bmatrix}$$
:::
::: 

La hip칩tesis tambi칠n se puede reescribir de manera matricial como: 

::: {.columns}
::: {.column}
$$h_\theta(X) = \begin{bmatrix}
&-h_\theta(x^{(1)})^T-\\
& \vdots & \\
&-h_\theta(x^{(m)})^T-\\
\end{bmatrix}$$
:::
::: {.column}
$$h_\theta(X)= \begin{bmatrix}
&-x^{(1)T} \theta-\\
& \vdots & \\
&-x^{(m)T} \theta-\\
\end{bmatrix} = X  \theta$$
:::
::: 

::: {.callout-important .fragment}
Normalmente este tipo de operaciones son las que utilizaremos para hacer nuestro c칩digo.
:::

## Loss Function: Softmax/Cross-Entropy Loss {.smaller}


::: {.callout-warning style="font-size: 130%;"}
La salida de nuestra `Shallow Network` retornar치 valores reales.
:::
::: {.callout-tip style="font-size: 130%;"}
Para poder tener una mejor interpretaci칩n del significado de cada una aplicaremos la funci칩n `Softmax` lo cual permitir치 *normalizar* los resultados y llevar치 los resultados a una ***"distribuci칩n de probabilidad"*** (valores positivos que sumen 1).
:::

::: {.columns}
::: {.column width="60%"}


![](img/clase-1/softmax_example.png){.lightbox fig-align="center"} 
:::
::: {.column width="40%"}


Formalmente definiremos la funci칩n Softmax como: 

$$s_i = p(label = i) = \frac{exp(h_i(x))}{\sum_{j=1}^k exp(h_j(x))}$$


$$s = \begin{bmatrix}
&s_1&\\
& \vdots & \\
&s_k&\\
\end{bmatrix}$$
:::
::: 

## Loss Function: Softmax/Cross-Entropy Loss {.smaller}

Para medir el error/p칠rdida de informaci칩n utilizaremos el `Negative Log Loss` o `Cross Entropy Loss`.

$$l_{ce}(h(x), y) = -log\left(p(label = y)\right)$$

::: {.callout-tip style="font-size: 120%;" .fragment}
Para garantizar el 칠xito de nuestro modelo, b치sicamente queremos maximizar la probabilidad de encontrar la etiqueta correcta, es decir, que $p(label = y)$ sea lo m치s alto posible.
:::
::: {.callout-caution style="font-size: 120%;" .fragment}
Normalmente en los problemas de optimizaci칩n no se suele maximizar sino minimizar. Minimizar el valor negativo es equivalente a maximizar. Esto ser칤a equivalente a minimizar el error del modelo. 
:::
::: {.callout-warning style="font-size: 120%;" .fragment}
Finalmente por razones de estabilidad num칠rica, minimizamos el logaritmo de la probabilidad que es una t칠cnica bien conocida en Estad칤stica.
:::

:::{.fragment}
$$\begin{align}
l_{ce}(h(x), y) = -log\left(p(label = y)\right) &= -log \left(\frac{exp(h_{(i = y)}(x))}{\sum_{j=1}^k exp(h_j(x))}\right) \\
&= - h_{(i=y)}(x) + log\left(\sum_{j = 1}^k exp(h_j(x))\right)\end{align}$$
:::

## M칠todo de Optimizaci칩n {.smaller}

> El 칰ltimo ingrediente de un algoritmo de aprendizaje es el m칠todo de optimizaci칩n. Es necesario minimizar la p칠rdida promedio asociada a todos los puntos de un cierto set de entrenamiento. Para ello definimos esto formalmente como:

$$\underset{\theta}{minimize} = \frac{1}{m} \sum_{i=1}^m l_{ce}(h_\theta(x^{(i)}), y^{(i)})$$


::: {.callout-note}
***쮺칩mo encontramos los par치metros $\theta$ que minimizan la p칠rdida de informaci칩n/error de estimaci칩n?***
:::

Gradient Descent
: > Es un m칠todo num칠rico que permite minimizar funciones movi칠ndose en direcci칩n contraria al Gradiente. Es computacionalmente muy eficiente y f치cil de implementar en c칩digo.

## Gradient Descent {.smaller}

::: {.columns}
::: {.column width="60%"}
Se define el gradiente como la matriz que contiene las derivadas parciales de una funci칩n $f$. Se denota como:

$$\nabla_\theta f(\theta) \in \mathbb{R}^{n \times k} =  \begin{bmatrix}
\frac{\partial f(\theta)}{\partial \theta_{11}} & \cdots & \frac{\partial f(\theta)}{\partial \theta_{1k}} \\
\cdots & \ddots & \cdots \\
\frac{\partial f(\theta)}{\partial \theta_{n1}} & \cdots & \frac{\partial f(\theta)}{\partial \theta_{nk}}
\end{bmatrix}$$

::: {.callout-tip}
$\theta_{ij}$ corresponde al par치metro que une el nodo/feature $i$ con el nodo/predicci칩n $j$.
:::
:::
::: {.column width="40%"}
![](img/clase-1/gradient.png){.lightbox fig-align="center" } 
:::
::: 


::: {.callout-tip style="font-size: 130%;"}
El gradiente apunta a la direcci칩n de m치ximo crecimiento de la funci칩n $f$. 
:::


## Gradient Descent: Regla de Actualizaci칩n {.smaller}
Para minimizar la funci칩n, la idea es descender iterativamente por el trayecto **en contra** del gradiente. La regla de actualizaci칩n se define como:

$$\theta := \theta - \alpha \nabla_\theta f(\theta) = \theta - \frac{\alpha}{m}\nabla_\theta l_{ce}(X\theta,y)$$

con $\theta \in \mathbb{R}^{n \times k}$ y $\alpha > 0$ corresponde al *step size* o `learning rate`.


![](img/clase-1/lr_effect.png){.lightbox fig-align="center" width="60%"} 

::: {.callout-tip}
En nuestro caso $f$ corresponder치 a nuestro $l_{ce}$ calculado anteriormente. El problema es, 쯖u치nto vale el gradiente del `Cross Entropy Loss`?
:::

## Calculando el Gradiente a mano {.smaller}


::: {style="font-size: 130%;"}
Simplifiquemos el problema a calcular para un s칩lo vector $x$.

$$\theta := \theta - \alpha \nabla_\theta l_{ce}(\theta^Tx,y) $$
:::

::: {.callout-warning style="font-size: 120%;"}
쮺u치nto vale el Gradiente?

* No es tan sencillo, ya que derivamos respecto a $\theta$ que es una matriz. 
* Pero derivamos a $\theta^T x$ que es un vector.
* Para ello, lo correcto es utilizar Calculo Diferencial Matricial, Jacobianos y Productos de Kroenecker (que probablemente no han visto en ning칰n curso).
  * **SPOILER**: Yo tampoco lo he visto en ning칰n curso.
:::

::: {.columns .fragment}
::: {.column width="70%"}
::: {.callout-tip style="font-size: 120%;"}
* Usaremos un truco (sumamente hacky 游땸) que jam치s deben revelar y que avergonzar칤a a cualquier profesor de C치lculo.
    * Pretenderemos que todos los valores son escalares y corregiremos las dimensiones al final.

:::
:::
::: {.column width="30%"}
![](img/clase-1/fuenzi.jpeg){.lightbox fig-align="center" width="40%"} 

:::
::: 

## Calculando el Gradiente a mano {.smaller}

> Simplifiquemos el problema pensando que calcularemos el Gradiente para un s칩lo vector $x$.

>  Es decir, $x \in \mathbb{R}^{n\times1}$.

Adem치s sabemos que $\nabla_\theta l_{ce}(\theta^Tx, y)$ debe tener dimensiones $n \times k$.

::: {.callout-important style="font-size: 150%;" .fragment fragment-index=1}
***쯇or qu칠?***
:::

::: {.columns}
::: {.column .fragment fragment-index=2}
$$\nabla_\theta l_{ce}(\theta^T x,y) = \frac{\partial l_{ce}(\theta^T x,y)}{\partial \theta^T x} \cdot \frac{\partial \theta^Tx}{\partial \theta}$$
:::
::: {.column .fragment fragment-index=3}
$$\frac{\partial l_{ce}(\theta^T x,y)}{\partial \theta^T x} = \frac{\partial l_{ce}(h_\theta(x), y)}{\partial h_\theta(x)} = \begin{bmatrix}
\frac{\partial l_{ce}(h,y)}{\partial h_1} \\
\vdots\\
\frac{\partial l_{ce}(h,y)}{\partial h_k} \\
\end{bmatrix}$$
:::
::: 

::: {.callout-tip style="font-size: 130%;" .fragment fragment-index=4}
Luego el gradiente de $l_{ce}$ respecto a $h$ tiene dimensiones $k \times 1$.
:::

## Calculando el Gradiente a mano {.smaller}

$$\begin{align}
\frac{\partial l_{ce}(h,y)}{\partial h_i} &= \frac{\partial }{\partial h_i}\left(-h_{(i = y)} + log \sum_{j = 1}^k exp(h_j)\right) \\
&= -\frac{\partial h_{(i = y)}}{\partial h_i}+ \frac{1}{\sum_{j = 1}^k exp(h_j)} \cdot \frac{\partial}{\partial h_i}\left(\sum_{j=1}^k exp(h_j)\right) \\
&= -\frac{\partial h_{(i = y)}}{\partial h_i}+ \frac{exp(h_i)}{\sum_{j = 1}^k exp(h_j)} \\
&= - 1\{i=y\} + s_i = s_i - 1\{i=y\}
\end{align}
$$

::: {.callout-tip .fragment}
$$1\{i = y\} = \begin{cases}
1,  & \text{i = y} \\
0, & \text{otherwise}
\end{cases}
$$
:::

::: {.fragment}
Finalmente en forma vectorial quedar칤a como:

::: {.columns}
::: {.column}
$$\frac{\partial l_{ce}(\theta^T x,y)}{\partial \theta^T x} = s - e_y$$
:::
::: {.column}
::: {.callout-tip}
Donde $z$, es el vector de Softmax y $e_y$ es un vector con un 1 en la posici칩n $y$ y 0 en el resto.
:::
:::
::: 
:::

## Calculando el Gradiente a mano {.smaller}

::: {.columns}
::: {.column }
$$\nabla_\theta l_{ce}(\theta^T x,y) = \frac{\partial l_{ce}(\theta^T x,y)}{\partial \theta^T x} \cdot \frac{\partial \theta^Tx}{\partial \theta}$$
$$\nabla_\theta l_{ce}(\theta^T x,y) = (s-e_y)\cdot x $$
:::

::: {.column .fragment}
::: {.callout-caution appearance="default"}
## Ojo con las dimensiones
* $s-e_y \in \mathbb{R}^{k \times 1}$
* $x \in \mathbb{R}^{n \times 1}$
:::

::: 
:::

:::{.fragment}
Luego: 

$$\nabla_\theta l_{ce}(\theta^T x,y) = x (s-e_y)^T$$
:::

::: {.callout-caution style="font-size: 150%;" .fragment}
***쮺u치l es el tama침o de $\nabla_\theta l_{ce}(\theta^T x,y)$?***
:::

::: {.callout-note style="font-size: 150%;" .fragment}
$n \times k$
:::

::: {.callout-warning style="font-size: 150%;" .fragment}
***쯇or qu칠?***
:::



## Calculando el Gradiente Matrix Batch Form {.smaller}

#### Esto ser칤a equivalente a tomar en consideraci칩n todos los puntos del Training Set

::: {.columns}
::: {.column}
$$\begin{align}\nabla_\theta l_{ce}(X\theta,y) &= \frac{\partial l_{ce}(X\theta,y)}{\partial X\theta} \cdot \frac{\partial X\theta}{\partial \theta}\\
&= (S - I_y) \cdot X \\
&= X^T \cdot (S - I_y)
\end{align}$$

::: {.callout-tip}
* $S$ corresponde al Softmax de $X\theta$ aplicado por filas.
* $I_y$ corresponde al One Hot Encoder de las etiquetas. Filas con 1 en la etiqueta correcta y 0 en el resto.
:::
:::
::: {.column}
::: {.callout-caution appearance="default" .fragment}
## Ojo con las dimensiones

* $S - I_y \in \mathbb{R}^{m \times k}$
* $X \in \mathbb{R}^{m \times n}$
:::

::: {.callout-warning .fragment}
***쮺u치l es el tama침o de $\nabla_\theta l_{ce}(X\theta,y)$?***
:::
:::
::: 



:::{.fragment}
Finalmente la `Regla de Actualizaci칩n` de par치metros usando Gradient Descent queda como:

$$\theta := \theta - \frac{\alpha}{m} X^T (S - I_y)$$
:::


## Conclusiones {.smaller}


::: {.columns}
::: {.column}

::: {.callout-tip}
* Acabamos de entrenar una Shallow Network, sin definir ning칰n concepto Fancy que es propio del 치rea.
* No hemos hablado ni de:
  * `Forward Pass`
  * `Epochs`
  * `Backpropagation`
  * `Adam`
  * `Activation Functions`
  * etc.

::: 
::: {.callout-note .fragment fragment-index=1}
* Aplicando esta simple regla se puede obtener cerca de un 8% de error clasificando d칤gitos en MNIST.
* Se puede programar en pocas l칤neas en Python.

![](img/clase-1/mnist.png){.lightbox fig-align="center" width="30%"} 
:::
:::

::: {.column .fragment fragment-index=2}
#### Pero, 쯤u칠 pasa con arquitecturas m치s complejas?

![](img/clase-1/nn_arq_full.png){.lightbox fig-align="center" width="60%"} 
:::
::: 



M치s info legacy que tiene que ir entrando en pr칩ximas clases.

# Problemas de una Hip칩tesis Lineal

## Clase anterior {.smaller}

> La Regresi칩n Softmax es capaz de generar separaciones lineales para m치s de dos clases para cualquier punto $x \in \mathbb{R}^{1 \times n}$:

::: {.columns}
::: {.column width="70%" }

<br>

:::{style="font-size: 130%;"}
$h_\theta(x) = \theta^T x$, tal que $\theta \in \mathbb{R}^{n \times k}$.
:::

<br>

::: {.callout-caution style="font-size: 130%;"}
Esta hip칩tesis es bastante limitada, y existen muchos problemas que no podr치n solucionarse con este tipo de soluci칩n.
:::

:::
::: {.column width="30%"}
![](img/clase-2/softmax_viz.png){.lightbox}
:::
::: 

## Limitaciones de una Hip칩tesis Lineal {.smaller}

> Es claro que un problema como el que se muestra ac치 no podr치 ser resuelto mediante un clasificador lineal (hip칩tesis lineal). 

::: {.columns}
::: {.column width="70%"}

::: {.callout-warning appearance="default" style="font-size: 120%;"}
## 쮺칩mo se resuelve este tipo de problemas?

* Creando nuevas features que permitan predecir problemas `no-lineales`. 
:::

::: {style="font-size: 130%;"}
$$h_\theta(x) = \theta^T \phi(x)$$
:::

tal que $\theta \in \mathbb{R}^{n \times k}$ y $\phi(x): \mathbb{R}^n \rightarrow \mathbb{R}^d$ con $d > n$.

::: {.callout-tip style="font-size: 130%;" .fragment}
* B치sicamente $\phi(.)$ es la manera matem치tica de denotar la creaci칩n de m치s features que permiten resolver el problema.
:::

::: {.callout-important style="font-size: 130%;" .fragment}
SVM es un algoritmo que hace esto de manera autom치tica utilizando el famoso `Kernel Trick`, donde $\phi(.)$ es conocido como el Kernel.
:::
:::
::: {.column width="30%"}
![](img/clase-2/non_linear_prob.png){.lightbox}
:::
::: 

## Diferencias entre ML y DL {.smaller}

![](img/clase-2/ml-dl.jpeg){.lightbox fig-align="center"}

> La diferencia principal entre el `Machine Learning` y el `Deep Learning` es la manera en la que se crean las features.

::: {.callout-important .fragment}
* Normalmente el Machine Learning est치 enfocado en que manualmente se generen features.
* Deep Learning busca que el Algoritmo busque esas features. El 칠nfasis est치 en buscar la `Arquitectura` adecuada.

:::

## 쮺칩mo creamos features de manera autom치tica? {.smaller}

::: {.columns}
::: {.column}
Una primera idea ser칤a crearlas de manera lineal:

$$\phi(x) = W^T x$$

donde $W \in \mathbb{R}^{n \times d}$.

:::
::: {.column .fragment}

![](img/clase-2/multilayer_softmax.png){.lightbox fig-align="center" width="60%"}
:::
::: 

::: {.columns .fragment}
::: {.column }
En este caso nuestra hip칩tesis queda como:
$$ h_\theta(x) = \theta^T \phi(x) = \theta^T W^T x = \tilde{\theta}^T x$$

::: {.callout-caution .fragment}
Lamentablemente este approach **no funciona**, ya que $\tilde{\theta}^T$ es s칩lo otra matriz que genera dos transformaciones simult치neas, pero que en este caso llevar치 de $n$ a $k$ de manera directa.
:::
:::

::: {.column}

::: {.callout-warning appearance="default"}
## Ojo con las dimensiones.
* $W^t$ tiene dimensi칩n $d \times n$.
* Sabemos que $h_\theta(x)$ tiene que devolver $k$ outputs. Por lo tanto, $\theta^T$ tiene que tener dimensiones $k \times d$. 
* $x$ es un vector con $n$ features por lo tanto es de dimensi칩n $n \times 1$.
* Eso har치 que $h_\theta(x)$ sea de tama침o $k \times 1$.
:::
:::
:::

## 쮼ntonces c칩mo? {.smaller}

::: {.columns}
::: {.column}
Vamos a utilizar funciones no lineales. **Cualquiera sirve** tal que:

$$\phi(x) = \sigma(W^Tx)$$

donde $W \in \mathbb{R}^{n \times d}$ y $\sigma: \mathbb{R}^d \rightarrow \mathbb{R}^d$, es decir, $\sigma$ es una funci칩n escalar.
:::
::: {.column .fragment}
![](img/clase-2/mlp.png){.lightbox fig-align="center" width="60%"}
:::
::: 

:::{.fragment}
De este modo nuestra hip칩tesis quedar칤a como:

$$h_\theta(x) = \theta^T \sigma(W^T x) \neq \tilde{\theta}^T x$$
:::

::: {.callout-important style="font-size: 130%;" .fragment} 
Estamos aplicando una `transformaci칩n no-lineal` a la `transformaci칩n lineal` de $x$ con $W$. 
:::

::: {.callout-tip style="font-size: 130%;" .fragment}
Normalmente escogeremos `funciones no-lineales` que sean diferenciables para poder actualizar $\theta$ y $W$. 

Esto es lo que llamaremos el ***entrenamiento de una red neuronal***.
:::

## Activation Functions {.smaller}

:::: {.columns}
::: {.column width="60%"}
> Definiremos las funciones de activaci칩n como funciones no-lineales que se aplican a la salida de cada capa para evitar la `composici칩n` de dos trasnformaciones lineales consecutivas. 

::: {.callout-important}
Esta es la **칰nica** manera de transformar hip칩tesis lineales en hip칩tesis no lineales. 
:::
:::

::: {.column width="40%"}
![](img/clase-2/activation_functions.png){.lightbox fig-align="center" width="80%"} 
:::
::::


::: {.columns}
::: {.column}
::: {.callout-note appearance="default"}
#### Funciones Cl치sicas
* ***Sigmoide***
* ***ReLU***
* ***Tanh***
* ***Softmax***
:::
:::

::: {.column}
::: {.callout-tip appearance="default"}
#### Funciones m치s modernas
* Swish
* GELU
* ELU
:::
:::
::: 


## 2-Layer non-linear Softmax Regression {.smaller}

::: {.columns}
::: {.column}
$$h_\theta(x) = W_2^T \phi(x) = W_2^T \sigma(W_1^T x)$$

donde $\theta=\{W_1 \in \mathbb{R}^{n \times d}, W_2 \in \mathbb{R}^{d \times k}\}$

::: {.callout-caution}
* Podemos pensar que $W_1 \in \mathbb{R}^{n \times d}$ es aquella matriz que lleva a un vector $x$ de $n$ a $d$ dimensiones.
* De la misma forma, $W_2 \in \mathbb{R}^{d \times k}$ es aquella matriz que lleva a un vector $x$ de $d$ a $k$ dimensiones/salidas.
:::

:::
::: {.column}
![](img/clase-2/mlp.png){.lightbox fig-align="center" width="60%"} 
:::
::: 

::: {.columns}
::: {.column}
#### Matrix Batch Form

$$h_\theta(X) = \sigma(XW_1)W_2$$
:::
::: {.column}
#### Update Rule

$$W_1 := W_1 - \frac{\alpha}{m} \nabla_{W_1} l_{ce}(h_\theta(X),y)$$
$$W_2 := W_2 - \frac{\alpha}{m} \nabla_{W_2} l_{ce}(h_\theta(X),y)$$
:::
::: 

## C치lculo de Gradientes {.smaller}

::: {.columns}
::: {.column}
::: {.callout-tip appearance="default"}
#### Gradiente de $W_1$


$$\begin{align} \nabla_{W_1} &= \frac{\partial l_{ce}(h_\theta(X),y)}{\partial \sigma(XW_1)} \cdot \frac{\partial h_\theta(X)}{\partial \sigma(XW_1)} \cdot \frac{\partial \sigma(XW_1)}{\partial XW_1} \cdot \frac{\partial XW_1}{\partial W_1} \\
&= (Z-I_y)_{m \times k} \cdot (W_{2})_{d \times k}  \cdot \sigma'(XW_1)_{m \times d} \cdot X_{m \times n}
\end{align}$$

Luego, corrigiendo por dimensiones obtenemos que
$$\nabla_{W_1} \in \mathbb{R}^{n \times d} = X^T_{n \times m} \left[\sigma'(XW_1) \odot (Z-I_y)W_2^T \right]_{m \times d}$$

:::
:::
::: {.column}
::: {.callout-note appearance="default"}
#### Gradiente de $W_2$


$$\begin{align} \nabla_{W_2} &= \frac{\partial l_{ce}(h_\theta(X),y)}{\partial h_\theta(X)} \cdot \frac{\partial h_\theta(X)}{\partial W_2}\\
&= (Z-I_y)_{m\times k} \cdot \sigma(XW_1)_{m \times d}
\end{align}$$

Luego, corrigiendo por dimensiones obtenemos que
$$\nabla_{W_2} \in \mathbb{R}^{d \times k} = \sigma(XW_1)^T_{d \times m}(Z - I_y)_{m \times k}$$

:::
:::
::: 

::: {.callout-important}
* $\odot$ representa el producto Hadamard entre dos matrices. Esto es, multiplicaci칩n elemento a elemento.
* $\sigma'(.)$ representa la derivada de la funci칩n de activaci칩n $\sigma(.)$

:::

# Nuestra Primera Red Neuronal

## Definiciones {.smaller}


![](img/clase-2/formal_nn.png){.lightbox fig-align="center" width="80%"}  


::: {.columns}
::: {.column width="25%"}
::: {.callout-warning appearance="default" style="font-size: 75%;" }
## Inputs
$$Z_1 = X$$
:::
:::
::: {.column width="25%"}
::: {.callout-tip appearance="default" style="font-size: 75%;" }
## Intermediate Outputs
$$Z_{i+1} = \sigma_i(Z_iW_i), i=1,...,L$$
$$Z_i \in \mathbb{R}^{m \times n_i}$$
:::
:::
::: {.column width="25%"}
::: {.callout-important appearance="default" style="font-size: 75%;" }
## Output (Head)
$$h_\theta(X) = Z_{L+1}$$
:::
:::
::: {.column width="25%"}
::: {.callout appearance="default" style="font-size: 75%;"}
## Par치metros
$$\theta = \left[W_1,..., W_L\right]$$
$$ W_i \in \mathbb{R}^{n_i \times n_{i+1}}$$

:::
:::
::: 
::: {.callout-caution .fragment}
* Las salidas intermedias (intermediate outputs) son las mal llamadas hidden layers. Esta red cuenta con $L$ hidden layers $W$.
:::


## Definiciones {.smaller}

::: {.callout-note appearance="default"}
## Red Neuronal
Vamos a definir como ***Red Neuronal*** un tipo particular de hip칩tesis que consiste en:  

* Multiples capas que permiten cambiar de dimensi칩n.
* Funciones de activaci칩n no-lineales y diferenciables que permiten ***desacoplar*** transformaciones lineales.
* Un set de par치metros optimizables, que permiten reducir una `Loss Function`.
:::

::: {.callout-caution}
Si bien estas redes toman inspiraci칩n de la bi칩log칤a, poco o nada tienen que ver con neuronas reales.
:::

::: {.callout-warning}
T칠rminos como `Neural Network`, `Deep Networks`, `Deep Learning`, son ampliamente usados y algunas veces usados para diferenciar el tama침o de distintas arquitecturas. 

Nosotros los vamos a usar ***pr치cticamente*** como sin칩nimos.
:::

#### Update Rule

$$W_i := W_i - \frac{\alpha}{m} \nabla_{W_i} l(h_\theta(X),y)$$


## C치lculo de Gradientes de una Red Neuronal {.smaller}

$$\nabla_{W_i} l(Z_{L+1},y) = \underbrace{\frac{\partial l(Z_{L+1},i)}{\partial Z_{L+1}} \cdot \frac{\partial Z_{{L+1}}}{\partial Z_L} \cdot \frac{\partial Z_L}{\partial Z_{L-1}}...\cdot \frac{\partial Z_{i+2}}{\partial Z_{i+1}}}_{G_{i+1} = \frac{\partial l(Z_{L+1},y)}{\partial Z_{i+1}}}\cdot \frac{\partial Z_{i+1}}{\partial W_i}$$

::: {.callout-important appearance="default"}
## **Gradiente Entrante (Incoming Backward Gradient)**

* Vamos a definir el **Gradiente Entrante** hasta antes de la capa $i$ ***(desde la salida en direcci칩n a la entrada)*** como:
$$\begin{align}G_i &= G_{i+1} \cdot \frac{\partial Z_{i + 1}}{\partial Z_i} \\
&= G_{i+1} \cdot \frac{\partial \sigma_i(Z_i W_i)}{\partial Z_i W_i} \cdot \frac{\partial Z_i W_i}{\partial Z_i}_{} \\
&= (G_{i+1})_{m \times n_{i+1}} \cdot \sigma'(Z_i W_i)_{m \times n_{i + 1}} \cdot (W_i)_{n_i \times n_{i+1}}
\end{align}$$
:::

Luego,
$$ G_i \in \mathbb{R}^{m \times n_i} = \left[ G_{i+1} \odot \sigma_i'(Z_i W_i)\right] W_i^T$$

## C치lculo de Gradientes de una Red Neuronal {.smaller}

$$\begin{align}\nabla_{W_i} l(Z_{L+1},y) &= G_{i+1} \cdot \frac{\partial Z_{i+1}}{\partial W_i} \\
&= G_{i+1} \cdot \frac{\partial \sigma_i'(Z_i W_i)}{\partial Z_i W_i} \cdot \frac{\partial Z_i W_i}{\partial W_i} \\
&= (G_{i+1})_{m \times n_{i+1}} \cdot \sigma'(Z_i W_i)_{m \times n_{i+1}} \cdot (Z_i)_{m \times n_i}
\end{align}$$

<br>

::: {.callout-important style="font-size: 130%;"}

Luego el Gradiente de cualquier `Loss Function` con respecto a un set de par치metros $W_i$ se escribe como:

$$\nabla_{W_i}l(Z_{L+1}, y) = Z_i^T \left[G_{i+1} \odot \sigma'(Z_i W_i)\right]$$
:::

## Forward y Backward Passes {.smaller}

Backpropagation
: Corresponde al Algoritmo con el cu치l calcularemos los Gradientes de una Red Neuronal. Es un nombre `muy fancy` para calcular la `Regla de la Cadena` de manera eficiente aplicando `caching` de los resultados intermedios. 


::: {style="font-size: 90%;"}
#### Forward Pass
1. Inicializar $Z_1 = X$.
2. Iterar calculando: $Z_i = \sigma_i(Z_i W_i), i=1,...,L$.

#### Backward Pass
3. Inicializar $G_{L+1} = \nabla_{Z_{L+1}}l(Z_{L+1},y) = S-I_y$ (Este ejemplo es s칩lo el caso de `Cross Entropy` como `Loss Function`).
4. Iterar calculando: $G_i = \left[G_{i+1} \odot \sigma_i'(Z_i W_i)\right]W_i^T, i=L,...,1$

#### Update Rule
5. Calcular Gradientes para poder aplicar el `Update Rule`. 

$$W_i := W_i - \frac{\alpha}{m}\nabla_{W_i}l(Z_{L+1},y) = W_i - \frac{\alpha}{m} Z_i^T\left[G_{i+1} \odot \sigma'(Z_i W_i)\right]$$
:::

## Conceptos Cl치sicos del Entrenamiento de una NN {.smaller}

![](img/clase-2/formal_nn.png){.lightbox fig-align="center" width="60%"}  

::: {.callout-note}
* Definiremos una `Epoch` como el n칰mero de veces que repetiremos el Algoritmo de Backpropagation con todos los datos de Entrenamiento. El n칰mero de `epochs` de entrenamiento ser치 un hiperpar치metro de un modelo.
* Definiremos el `learning rate` como un hiperpar치metro que controlar치 el aprendizaje del modelo. 
* Definiremos este tipo de redes neuronales como `Feed Forward Networks` o ***FFN*** aunque en la pr치ctica tienen una peque침a modificaci칩n que veremos en la siguiente clase.
:::

::: {.callout-important}
Este tipo de redes es muy utilizada y recibe diversos nombres:

* Fully Connected Layers
* Dense Layers: Proviene de la nomenclatura utilizada por Tensorflow.
* Linear Layers: Proviene de la nomenclatura utilizada por Pytorch, pero **no es del todo** correcto.
* **MLP** o Multilayer Perceptron.
:::
