---
title: "TICS-579-Deep Learning"
subtitle: "Clase 2: Introducción a las Redes Neuronales y formalidades"
author: Alfonso Tobar-Arancibia
institute: <alfonso.tobar.a@edu.uai.cl>
format:
  revealjs: 
    width: 1366
    height: 768
    theme: simple
    slide-number: true
    controls: true
    controls-layout: edges
    controls-back-arrows: faded
    transition: slide
    transition-speed: fast
    chalkboard: true
    callout-appearance: simple
    logo: ../logo-uai-blanco.jpeg
    css: ../logo.css
    code-copy: true
    highlight-style: arrow
    pdf-separate-fragments: true
---

# Problemas de una Hipótesis Lineal

## Clase anterior {.smaller}

> La Regresión Softmax es capaz de generar separaciones lineales para más de dos clases para cualquier punto $x \in \mathbb{R}^{1 \times n}$:

::: {.columns}
::: {.column width="70%" }

<br>

:::{style="font-size: 130%;"}
$h_\theta(x) = \theta^T x$, tal que $\theta \in \mathbb{R}^{n \times k}$.
:::

<br>

::: {.callout-caution style="font-size: 130%;"}
Esta hipótesis es bastante limitada, y existen muchos problemas que no podrán solucionarse con este tipo de solución.
:::

:::
::: {.column width="30%"}
![](img/clase-2/softmax_viz.png){.lightbox}
:::
::: 

## Limitaciones de una Hipótesis Lineal {.smaller}

> Es claro que un problema como el que se muestra acá no podrá ser resuelto mediante un clasificador lineal (hipótesis lineal). 

::: {.columns}
::: {.column width="70%"}

::: {.callout-warning appearance="default" style="font-size: 120%;"}
## ¿Cómo se resuelve este tipo de problemas?

* Creando nuevas features que permitan predecir problemas `no-lineales`. 
:::

::: {style="font-size: 130%;"}
$$h_\theta(x) = \theta^T \phi(x)$$
:::

tal que $\theta \in \mathbb{R}^{n \times k}$ y $\phi(x): \mathbb{R}^n \rightarrow \mathbb{R}^d$ con $d > n$.

::: {.callout-tip style="font-size: 130%;" .fragment}
* Básicamente $\phi(.)$ es la manera matemática de denotar la creación de más features que permiten resolver el problema.
:::

::: {.callout-important style="font-size: 130%;" .fragment}
SVM es un algoritmo que hace esto de manera automática utilizando el famoso `Kernel Trick`, donde $\phi(.)$ es conocido como el Kernel.
:::
:::
::: {.column width="30%"}
![](img/clase-2/non_linear_prob.png){.lightbox}
:::
::: 

## Diferencias entre ML y DL {.smaller}

![](img/clase-2/ml-dl.jpeg){.lightbox fig-align="center"}

> La diferencia principal entre el `Machine Learning` y el `Deep Learning` es la manera en la que se crean las features.

::: {.callout-important .fragment}
* Normalmente el Machine Learning está enfocado en que manualmente se generen features.
* Deep Learning busca que el Algoritmo busque esas features. El énfasis está en buscar la `Arquitectura` adecuada.

:::

## ¿Cómo creamos features de manera automática? {.smaller}

::: {.columns}
::: {.column}
Una primera idea sería crearlas de manera lineal:

$$\phi(x) = W^T x$$

donde $W \in \mathbb{R}^{n \times d}$.

:::
::: {.column .fragment}

![](img/clase-2/multilayer_softmax.png){.lightbox fig-align="center" width="60%"}
:::
::: 

::: {.columns .fragment}
::: {.column }
En este caso nuestra hipótesis queda como:
$$ h_\theta(x) = \theta^T \phi(x) = \theta^T W^T x = \tilde{\theta}^T x$$

::: {.callout-caution .fragment}
Lamentablemente este approach **no funciona**, ya que $\tilde{\theta}^T$ es sólo otra matriz que genera dos transformaciones simultáneas, pero que en este caso llevará de $n$ a $k$ de manera directa.
:::
:::

::: {.column}

::: {.callout-warning appearance="default"}
## Ojo con las dimensiones.
* $W^t$ tiene dimensión $d \times n$.
* Sabemos que $h_\theta(x)$ tiene que devolver $k$ outputs. Por lo tanto, $\theta^T$ tiene que tener dimensiones $k \times d$. 
* $x$ es un vector con $n$ features por lo tanto es de dimensión $n \times 1$.
* Eso hará que $h_\theta(x)$ sea de tamaño $k \times 1$.
:::
:::
:::

## ¿Entonces cómo? {.smaller}

::: {.columns}
::: {.column}
Vamos a utilizar funciones no lineales. **Cualquiera sirve** tal que:

$$\phi(x) = \sigma(W^Tx)$$

donde $W \in \mathbb{R}^{n \times d}$ y $\sigma: \mathbb{R}^d \rightarrow \mathbb{R}^d$, es decir, $\sigma$ es una función escalar.
:::
::: {.column .fragment}
![](img/clase-2/mlp.png){.lightbox fig-align="center" width="60%"}
:::
::: 

:::{.fragment}
De este modo nuestra hipótesis quedaría como:

$$h_\theta(x) = \theta^T \sigma(W^T x) \neq \tilde{\theta}^T x$$
:::

::: {.callout-important style="font-size: 130%;" .fragment} 
Estamos aplicando una `transformación no-lineal` a la `transformación lineal` de $x$ con $W$. 
:::

::: {.callout-tip style="font-size: 130%;" .fragment}
Normalmente escogeremos `funciones no-lineales` que sean diferenciables para poder actualizar $\theta$ y $W$. 

Esto es lo que llamaremos el ***entrenamiento de una red neuronal***.
:::

## Activation Functions {.smaller}

:::: {.columns}
::: {.column width="60%"}
> Definiremos las funciones de activación como funciones no-lineales que se aplican a la salida de cada capa para evitar la `composición` de dos trasnformaciones lineales consecutivas. 

::: {.callout-important}
Esta es la **única** manera de transformar hipótesis lineales en hipótesis no lineales. 
:::
:::

::: {.column width="40%"}
![](img/clase-2/activation_functions.png){.lightbox fig-align="center" width="80%"} 
:::
::::


::: {.columns}
::: {.column}
::: {.callout-note appearance="default"}
#### Funciones Clásicas
* ***Sigmoide***
* ***ReLU***
* ***Tanh***
* ***Softmax***
:::
:::

::: {.column}
::: {.callout-tip appearance="default"}
#### Funciones más modernas
* Swish
* GELU
* ELU
:::
:::
::: 

## Activation Functions

---

## 2-Layer non-linear Softmax Regression {.smaller}

::: {.columns}
::: {.column}
$$h_\theta(x) = W_2^T \phi(x) = W_2^T \sigma(W_1^T x)$$

donde $\theta=\{W_1 \in \mathbb{R}^{n \times d}, W_2 \in \mathbb{R}^{d \times k}\}$

::: {.callout-caution}
* Podemos pensar que $W_1 \in \mathbb{R}^{n \times d}$ es aquella matriz que lleva a un vector $x$ de $n$ a $d$ dimensiones.
* De la misma forma, $W_2 \in \mathbb{R}^{d \times k}$ es aquella matriz que lleva a un vector $x$ de $d$ a $k$ dimensiones/salidas.
:::

:::
::: {.column}
![](img/clase-2/mlp.png){.lightbox fig-align="center" width="60%"} 
:::
::: 

::: {.columns}
::: {.column}
#### Matrix Batch Form

$$h_\theta(X) = \sigma(XW_1)W_2$$
:::
::: {.column}
#### Update Rule

$$W_1 := W_1 - \frac{\alpha}{m} \nabla_{W_1} l_{ce}(h_\theta(X),y)$$
$$W_2 := W_2 - \frac{\alpha}{m} \nabla_{W_2} l_{ce}(h_\theta(X),y)$$
:::
::: 

## Cálculo de Gradientes {.smaller}

::: {.columns}
::: {.column}
::: {.callout-tip appearance="default"}
#### Gradiente de $W_1$


$$\begin{align} \nabla_{W_1} &= \frac{\partial l_{ce}(h_\theta(X),y)}{\partial \sigma(XW_1)} \cdot \frac{\partial h_\theta(X)}{\partial \sigma(XW_1)} \cdot \frac{\partial \sigma(XW_1)}{\partial XW_1} \cdot \frac{\partial XW_1}{\partial W_1} \\
&= (Z-I_y)_{m \times k} \cdot (W_{2})_{d \times k}  \cdot \sigma'(XW_1)_{m \times d} \cdot X_{m \times n}
\end{align}$$

Luego, corrigiendo por dimensiones obtenemos que
$$\nabla_{W_1} \in \mathbb{R}^{n \times d} = X^T_{n \times m} \left[\sigma'(XW_1) \odot (Z-I_y)W_2^T \right]_{m \times d}$$

:::
:::
::: {.column}
::: {.callout-note appearance="default"}
#### Gradiente de $W_2$


$$\begin{align} \nabla_{W_2} &= \frac{\partial l_{ce}(h_\theta(X),y)}{\partial h_\theta(X)} \cdot \frac{\partial h_\theta(X)}{\partial W_2}\\
&= (Z-I_y)_{m\times k} \cdot \sigma(XW_1)_{m \times d}
\end{align}$$

Luego, corrigiendo por dimensiones obtenemos que
$$\nabla_{W_2} \in \mathbb{R}^{d \times k} = \sigma(XW_1)^T_{d \times m}(Z - I_y)_{m \times k}$$

:::
:::
::: 

::: {.callout-important}
* $\odot$ representa el producto Hadamard entre dos matrices. Esto es, multiplicación elemento a elemento.
* $\sigma'(.)$ representa la derivada de la función de activación $\sigma(.)$

:::

# Nuestra Primera Red Neuronal

## Definiciones {.smaller}


![](img/clase-2/formal_nn.png){.lightbox fig-align="center" width="80%"}  


::: {.columns}
::: {.column width="25%"}
::: {.callout-warning appearance="default" style="font-size: 75%;" }
## Inputs
$$Z_1 = X$$
:::
:::
::: {.column width="25%"}
::: {.callout-tip appearance="default" style="font-size: 75%;" }
## Intermediate Outputs
$$Z_{i+1} = \sigma_i(Z_iW_i), i=1,...,L$$
$$Z_i \in \mathbb{R}^{m \times n_i}$$
:::
:::
::: {.column width="25%"}
::: {.callout-important appearance="default" style="font-size: 75%;" }
## Output (Head)
$$h_\theta(X) = Z_{L+1}$$
:::
:::
::: {.column width="25%"}
::: {.callout appearance="default" style="font-size: 75%;"}
## Parámetros
$$\theta = \left[W_1,..., W_L\right]$$
$$ W_i \in \mathbb{R}^{n_i \times n_{i+1}}$$

:::
:::
::: 
::: {.callout-caution .fragment}
* Las salidas intermedias (intermediate outputs) son las mal llamadas hidden layers. Esta red cuenta con $L$ hidden layers $W$.
:::


## Definiciones {.smaller}

::: {.callout-note appearance="default"}
## Red Neuronal
Vamos a definir como ***Red Neuronal*** un tipo particular de hipótesis que consiste en:  

* Multiples capas que permiten cambiar de dimensión.
* Funciones de activación no-lineales y diferenciables que permiten ***desacoplar*** transformaciones lineales.
* Un set de parámetros optimizables, que permiten reducir una `Loss Function`.
:::

::: {.callout-caution}
Si bien estas redes toman inspiración de la biólogía, poco o nada tienen que ver con neuronas reales.
:::

::: {.callout-warning}
Términos como `Neural Network`, `Deep Networks`, `Deep Learning`, son ampliamente usados y algunas veces usados para diferenciar el tamaño de distintas arquitecturas. 

Nosotros los vamos a usar ***prácticamente*** como sinónimos.
:::

#### Update Rule

$$W_i := W_i - \frac{\alpha}{m} \nabla_{W_i} l(h_\theta(X),y)$$


## Cálculo de Gradientes de una Red Neuronal {.smaller}

$$\nabla_{W_i} l(Z_{L+1},y) = \underbrace{\frac{\partial l(Z_{L+1},i)}{\partial Z_{L+1}} \cdot \frac{\partial Z_{{L+1}}}{\partial Z_L} \cdot \frac{\partial Z_L}{\partial Z_{L-1}}...\cdot \frac{\partial Z_{i+2}}{\partial Z_{i+1}}}_{G_{i+1} = \frac{\partial l(Z_{L+1},y)}{\partial Z_{i+1}}}\cdot \frac{\partial Z_{i+1}}{\partial W_i}$$

::: {.callout-important appearance="default"}
## **Gradiente Entrante (Incoming Backward Gradient)**

* Vamos a definir el **Gradiente Entrante** hasta antes de la capa $i$ ***(desde la salida en dirección a la entrada)*** como:
$$\begin{align}G_i &= G_{i+1} \cdot \frac{\partial Z_{i + 1}}{\partial Z_i} \\
&= G_{i+1} \cdot \frac{\partial \sigma_i(Z_i W_i)}{\partial Z_i W_i} \cdot \frac{\partial Z_i W_i}{\partial Z_i}_{} \\
&= (G_{i+1})_{m \times n_{i+1}} \cdot \sigma'(Z_i W_i)_{m \times n_{i + 1}} \cdot (W_i)_{n_i \times n_{i+1}}
\end{align}$$
:::

Luego,
$$ G_i \in \mathbb{R}^{m \times n_i} = \left[ G_{i+1} \odot \sigma_i'(Z_i W_i)\right] W_i^T$$

## Cálculo de Gradientes de una Red Neuronal {.smaller}

$$\begin{align}\nabla_{W_i} l(Z_{L+1},y) &= G_{i+1} \cdot \frac{\partial Z_{i+1}}{\partial W_i} \\
&= G_{i+1} \cdot \frac{\partial \sigma_i'(Z_i W_i)}{\partial Z_i W_i} \cdot \frac{\partial Z_i W_i}{\partial W_i} \\
&= (G_{i+1})_{m \times n_{i+1}} \cdot \sigma'(Z_i W_i)_{m \times n_{i+1}} \cdot (Z_i)_{m \times n_i}
\end{align}$$

<br>

::: {.callout-important style="font-size: 130%;"}

Luego el Gradiente de cualquier `Loss Function` con respecto a un set de parámetros $W_i$ se escribe como:

$$\nabla_{W_i}l(Z_{L+1}, y) = Z_i^T \left[G_{i+1} \odot \sigma'(Z_i W_i)\right]$$
:::

## Forward y Backward Passes {.smaller}

Backpropagation
: Corresponde al Algoritmo con el cuál calcularemos los Gradientes de una Red Neuronal. Es un nombre `muy fancy` para calcular la `Regla de la Cadena` de manera eficiente aplicando `caching` de los resultados intermedios. 


::: {style="font-size: 90%;"}
#### Forward Pass
1. Inicializar $Z_1 = X$.
2. Iterar calculando: $Z_i = \sigma_i(Z_i W_i), i=1,...,L$.

#### Backward Pass
3. Inicializar $G_{L+1} = \nabla_{Z_{L+1}}l(Z_{L+1},y) = S-I_y$ (Este ejemplo es sólo el caso de `Cross Entropy` como `Loss Function`).
4. Iterar calculando: $G_i = \left[G_{i+1} \odot \sigma_i'(Z_i W_i)\right]W_i^T$

#### Update Rule
5. Calcular Gradientes para poder aplicar el `Update Rule`. 

$$W_i := W_i - \frac{\alpha}{m}\nabla_{W_i}l(Z_{L+1},y) = Z_i^T\left[G_{i+1} \odot \sigma'(Z_i W_i)\right]$$
:::

## Conceptos Clásicos del Entrenamiento de una NN {.smaller}

![](img/clase-2/formal_nn.png){.lightbox fig-align="center" width="60%"}  

::: {.callout-note}
* Definiremos una `Epoch` como el número de veces que repetiremos el Algoritmo de Backpropagation con todos los datos de Entrenamiento. El número de `epochs` de entrenamiento será un hiperparámetro de un modelo.
* Definiremos el `learning rate` como un hiperparámetro que controlará el aprendizaje del modelo. 
* Definiremos este tipo de redes neuronales como `Feed Forward Networks` o ***FFN*** aunque en la práctica tienen una pequeña modificación que veremos en la siguiente clase.
:::

::: {.callout-important}
Este tipo de redes es muy utilizada y recibe diversos nombres:

* Fully Connected Layers
* Dense Layers: Proviene de la nomenclatura utilizada por Tensorflow.
* Linear Layers: Proviene de la nomenclatura utilizada por Pytorch, pero **no es del todo** correcto.
* **MLP** o Multilayer Perceptron.
:::


# See ya later, aligator!!

::: {.footer}
<p xmlns:cc="http://creativecommons.org/ns#" xmlns:dct="http://purl.org/dc/terms/"><span property="dct:title">Tics-579 Deep Learning</span> por Alfonso Tobar-Arancibia está licenciado bajo <a href="http://creativecommons.org/licenses/by-nc-sa/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;">CC BY-NC-SA 4.0

<img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/nc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/sa.svg?ref=chooser-v1"></a></p>
:::