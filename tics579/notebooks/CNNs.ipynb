{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Generación de los Datos"
      ],
      "metadata": {
        "id": "LUho7vxLXQmL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "torch.manual_seed(42)\n",
        "\n",
        "X = torch.randint(1, 10, (1, 1, 6, 6)).float()\n",
        "print(\"=\"*60)\n",
        "print(\"X shape:\", X.shape)\n",
        "print(\"Una Imagen, de 1 canal de tamaño 6x6\")\n",
        "print(\"=\"*60)\n",
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mznFQqT1bx0T",
        "outputId": "16e58f10-d1ec-462b-8c39-76dbfa9d00fb"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "X shape: torch.Size([1, 1, 6, 6])\n",
            "Una Imagen, de 1 canal de tamaño 6x6\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[7., 6., 8., 5., 1., 3.],\n",
              "          [8., 6., 5., 3., 5., 5.],\n",
              "          [9., 1., 1., 5., 3., 5.],\n",
              "          [4., 5., 5., 9., 2., 6.],\n",
              "          [9., 5., 3., 1., 2., 2.],\n",
              "          [4., 4., 8., 8., 9., 8.]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=\"*60)\n",
        "print(\"Hiperparámetros de la Convolución\")\n",
        "C_out = 2\n",
        "N, C_in, H, W = X.shape\n",
        "kH, kW = (3,3)\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(f\"Número de Feature Maps (C_out): {C_out}\")\n",
        "print(f\"Tamaño del Kernel de la Convolución: {kH,kW}\")\n"
      ],
      "metadata": {
        "id": "H1i_WQyDrBvN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "450b7c08-e3d5-4b4a-d354-89cb0e3e3735"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "Hiperparámetros de la Convolución\n",
            "============================================================\n",
            "Número de Feature Maps (C_out): 2\n",
            "Tamaño del Kernel de la Convolución: (3, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=\"*60)\n",
        "print(\"Parámetros de la convolución: \")\n",
        "print(\"Se va a aplicar 2 filtros de tamaño 3x3 y un bias para cada filtro\")\n",
        "print(\"=\"*60)\n",
        "given_w = torch.randint(-1,2, (C_out, C_in, kH,kW)).float()\n",
        "given_bias = torch.tensor([1.,1.]) # (2,)\n",
        "print(\"W_conv: \", end=\"\")\n",
        "print(given_w)\n",
        "print(\"=\"*60)\n",
        "print(\"bias_conv: \", end=\"\")\n",
        "print(given_bias)\n",
        "print(\"=\"*60)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vnj4bqHFYWwy",
        "outputId": "bb883890-4b8a-47d5-d032-3168be3d6894"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "Parámetros de la convolución: \n",
            "Se va a aplicar 2 filtros de tamaño 3x3 y un bias para cada filtro\n",
            "============================================================\n",
            "W_conv: tensor([[[[ 1.,  1.,  0.],\n",
            "          [-1.,  1., -1.],\n",
            "          [ 0., -1., -1.]]],\n",
            "\n",
            "\n",
            "        [[[ 1.,  1.,  0.],\n",
            "          [-1.,  1., -1.],\n",
            "          [-1.,  0., -1.]]]])\n",
            "============================================================\n",
            "bias_conv: tensor([1., 1.])\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pytorch `nn.Module`"
      ],
      "metadata": {
        "id": "Fnkw-vVQcPik"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=\"*60)\n",
        "print(\"Definición del Modelo en Pytorch utilizando nn.Module\")\n",
        "print(\"=\"*60)\n",
        "class Conv(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv2d(in_channels=1, out_channels=2, kernel_size=3, bias=True)\n",
        "        self.conv.weight.data = given_w\n",
        "        self.conv.bias.data = given_bias\n",
        "        self.max_pool = nn.MaxPool2d(kernel_size=2, return_indices=True)\n",
        "        self.fc = nn.Linear(8, 1)\n",
        "        nn.init.ones_(self.fc.weight)\n",
        "        nn.init.ones_(self.fc.bias)\n",
        "        self.flatten = nn.Flatten()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        print(x)\n",
        "        x, self.indices = self.max_pool(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "model = Conv()\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "y = torch.zeros([N,1])\n",
        "\n",
        "# Forward con PyTorch (referencia)\n",
        "logits = model(X)\n",
        "loss = criterion(logits, y)\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"y: \", end=\"\")\n",
        "print(y)\n",
        "print(\"=\"*60)\n",
        "print(f\"Loss obtenido: {loss}\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Logits: {logits}\")\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "phMREQIdcBeV",
        "outputId": "ac17b5c4-3682-4974-821a-198060d9128e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "Definición del Modelo en Pytorch utilizando nn.Module\n",
            "============================================================\n",
            "tensor([[[[  5.,   5.,  -1.,  -4.],\n",
            "          [ -4.,  -7.,  -1.,  -6.],\n",
            "          [ -1., -10.,   6.,  -8.],\n",
            "          [ -9.,  -8.,  -6.,  -6.]],\n",
            "\n",
            "         [[ -3.,   5.,   3.,  -6.],\n",
            "          [ -3.,  -7.,   3., -13.],\n",
            "          [ -5., -12.,   4.,  -7.],\n",
            "          [ -9.,  -4.,  -6.,  -5.]]]], grad_fn=<ConvolutionBackward0>)\n",
            "============================================================\n",
            "y: tensor([[0.]])\n",
            "============================================================\n",
            "Loss obtenido: 18.0\n",
            "============================================================\n",
            "Logits: tensor([[18.]], grad_fn=<AddmmBackward0>)\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Forward Pass Manual"
      ],
      "metadata": {
        "id": "CgpExX91cUl_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_out(X, k_size=(3,3), stride=1, dilation=1, padding=0):\n",
        "  kH, kW = k_size\n",
        "  N, in_channels, H_in, W_in = X.shape\n",
        "  out_H = np.floor((H_in +2*padding-dilation*(kH-1)-1)/stride + 1)\n",
        "  out_W = np.floor((W_in +2*padding-dilation*(kW-1)-1)/stride + 1)\n",
        "  return int(out_H), int(out_W)\n",
        "\n",
        "H_out, W_out = calculate_out(X, k_size = (kH,kW))\n",
        "print(\"=\"*60)\n",
        "print(f\"Tamaño resultante post-convolución: {H_out, W_out}\")\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QT6hmi6Yce6x",
        "outputId": "83b9ede2-97ec-4359-ece5-8fe3d7d207a3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "Tamaño resultante post-convolución: (4, 4)\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=\"*60)\n",
        "print(\"Implementación básica de la Convolución: Muy Ineficiente\")\n",
        "print(\"=\"*60)\n",
        "O = torch.zeros((N, C_out, H_out, W_out))\n",
        "for n in range(N):\n",
        "    for co in range(C_out):\n",
        "        for i in range(H_out):\n",
        "            for j in range(W_out):\n",
        "                patch = X[n, :, i:i+kH, j:j+kW]       # submatriz de tamaño kH x kW\n",
        "                O[n, co, i, j] = (patch * given_w[co]).sum() + given_bias[co]\n",
        "\n",
        "\n",
        "print(\"O:\", end=\"\")\n",
        "print(O)\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FNRuvowSkQ0g",
        "outputId": "0de9993a-b03d-4db0-9a7f-611fb826ac94"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "Implementación básica de la Convolución: Muy Ineficiente\n",
            "============================================================\n",
            "O:tensor([[[[  5.,   5.,  -1.,  -4.],\n",
            "          [ -4.,  -7.,  -1.,  -6.],\n",
            "          [ -1., -10.,   6.,  -8.],\n",
            "          [ -9.,  -8.,  -6.,  -6.]],\n",
            "\n",
            "         [[ -3.,   5.,   3.,  -6.],\n",
            "          [ -3.,  -7.,   3., -13.],\n",
            "          [ -5., -12.,   4.,  -7.],\n",
            "          [ -9.,  -4.,  -6.,  -5.]]]])\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# im2col: Convierte ventanas deslizantes en columnas\n",
        "print(\"=\"*60)\n",
        "print(\"Implementación Algoritmo im2col: \")\n",
        "print(\"=\"*60)\n",
        "X_col = F.unfold(X, kernel_size=(kH, kW))  # (1, 9, 16) (N,kH*kW,n_patches)\n",
        "print(f\"Cada columna es una ventana 3x3 aplanada\")\n",
        "print(f\"Tenemos 16 patches (4x4 posiciones de salida) para una imagen\")\n",
        "print(\"X_col: \", end=\"\")\n",
        "print(X_col)\n",
        "print(\"=\"*60)\n",
        "print(f\"X_col shape: {X_col.shape}\")\n",
        "print(\"=\"*60)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7bBzncqacQLE",
        "outputId": "9e6b2301-6612-4e91-adf1-3483f2b511a0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "Implementación Algoritmo im2col: \n",
            "============================================================\n",
            "Cada columna es una ventana 3x3 aplanada\n",
            "Tenemos 16 patches (4x4 posiciones de salida) para una imagen\n",
            "X_col: tensor([[[7., 6., 8., 5., 8., 6., 5., 3., 9., 1., 1., 5., 4., 5., 5., 9.],\n",
            "         [6., 8., 5., 1., 6., 5., 3., 5., 1., 1., 5., 3., 5., 5., 9., 2.],\n",
            "         [8., 5., 1., 3., 5., 3., 5., 5., 1., 5., 3., 5., 5., 9., 2., 6.],\n",
            "         [8., 6., 5., 3., 9., 1., 1., 5., 4., 5., 5., 9., 9., 5., 3., 1.],\n",
            "         [6., 5., 3., 5., 1., 1., 5., 3., 5., 5., 9., 2., 5., 3., 1., 2.],\n",
            "         [5., 3., 5., 5., 1., 5., 3., 5., 5., 9., 2., 6., 3., 1., 2., 2.],\n",
            "         [9., 1., 1., 5., 4., 5., 5., 9., 9., 5., 3., 1., 4., 4., 8., 8.],\n",
            "         [1., 1., 5., 3., 5., 5., 9., 2., 5., 3., 1., 2., 4., 8., 8., 9.],\n",
            "         [1., 5., 3., 5., 5., 9., 2., 6., 3., 1., 2., 2., 8., 8., 9., 8.]]])\n",
            "============================================================\n",
            "X_col shape: torch.Size([1, 9, 16])\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=\"*60)\n",
        "print(\"Implementación de la Convolución utilizando im2col:\")\n",
        "print(\"=\"*60)\n",
        "# Reshape de pesos\n",
        "\n",
        "W_row = given_w.reshape(C_out, -1)  # (2, 9)\n",
        "print(f\"Cada fila es un filtro 3x3 aplanado\")\n",
        "print(f\"W_row shape: {W_row.shape}\")\n",
        "print(\"W_row: \", end=\"\")\n",
        "print(W_row)\n",
        "print(\"=\"*60)\n",
        "\n",
        "\n",
        "# Multiplicación matricial y corregimos dimensiones...\n",
        "H_col = W_row @ X_col + given_bias.reshape(-1, 1)  # (1,2,16) # (N, C_out, n_patches)\n",
        "_, _, n_patches = H_col.shape\n",
        "H = H_col.reshape(N, C_out, H_out, W_out)  # (1, 2, 4, 4)\n",
        "print(f\"H shape: {H.shape}\")\n",
        "print(\"=\"*60)\n",
        "print(\"Corresponde a un imagen de 2 Feature Maps de Salida.\")\n",
        "print(\"Cada Feature Map es de 4x4\")\n",
        "print(\"=\"*60)\n",
        "print(\"H: \", end=\"\")\n",
        "print(H)\n",
        "print(\"=\"*60)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BaOoAk2odjkh",
        "outputId": "3f173e8a-a9ac-4971-91fa-6dde5655cd6c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "Implementación de la Convolución utilizando im2col:\n",
            "============================================================\n",
            "Cada fila es un filtro 3x3 aplanado\n",
            "W_row shape: torch.Size([2, 9])\n",
            "W_row: tensor([[ 1.,  1.,  0., -1.,  1., -1.,  0., -1., -1.],\n",
            "        [ 1.,  1.,  0., -1.,  1., -1., -1.,  0., -1.]])\n",
            "============================================================\n",
            "H shape: torch.Size([1, 2, 4, 4])\n",
            "============================================================\n",
            "Corresponde a un imagen de 2 Feature Maps de Salida.\n",
            "Cada Feature Map es de 4x4\n",
            "============================================================\n",
            "H: tensor([[[[  5.,   5.,  -1.,  -4.],\n",
            "          [ -4.,  -7.,  -1.,  -6.],\n",
            "          [ -1., -10.,   6.,  -8.],\n",
            "          [ -9.,  -8.,  -6.,  -6.]],\n",
            "\n",
            "         [[ -3.,   5.,   3.,  -6.],\n",
            "          [ -3.,  -7.,   3., -13.],\n",
            "          [ -5., -12.,   4.,  -7.],\n",
            "          [ -9.,  -4.,  -6.,  -5.]]]])\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "H_pool, W_pool = calculate_out(H, k_size=(2,2),stride=2)\n",
        "print(\"=\"*60)\n",
        "print(f\"Tamaño resultante post-pooling: {H_pool, W_pool}\")\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "id": "3yVvUc_eF4Ya",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a11d228-e6b0-4837-ca7f-c6f0c74b6d33"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "Tamaño resultante post-pooling: (2, 2)\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=\"*60)\n",
        "print(\"Forward Pass Pooling usando im2col: \")\n",
        "print(\"=\"*60)\n",
        "pool_size = 2\n",
        "\n",
        "h_col = F.unfold(H, kernel_size=pool_size, stride=pool_size)  # (1, 8, 4)\n",
        "print(f\"Shape h_col: {h_col.shape}\")\n",
        "print(\"=\"*60)\n",
        "print(\"h_col: \", end=\"\")\n",
        "print(h_col)\n",
        "print(\"=\"*60)\n",
        "h_col_reshaped = h_col.view(N, C_out, pool_size*pool_size, -1)  # (1, 2, 4, 4)\n",
        "print(f\"Shape h_col_reshaped: {h_col_reshaped.shape}\")\n",
        "print(\"=\"*60)\n",
        "print(h_col_reshaped)\n",
        "print(\"=\"*60)\n",
        "M_flat, pool_indices = h_col_reshaped.max(dim=2)\n",
        "print(\"=\"*60)\n",
        "print(\"M_flat: \", end=\"\")\n",
        "print(M_flat)\n",
        "print(\"=\"*60)\n",
        "M = M_flat.reshape(N, C_out, H_pool, W_pool)\n",
        "print(\"Reconstrucción a Feature Map\")\n",
        "print(\"M: \", end=\"\")\n",
        "print(M)\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PuEoAGaBhDyH",
        "outputId": "0e68810c-2470-44e7-9703-4fd83f7c27aa"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "Forward Pass Pooling usando im2col: \n",
            "============================================================\n",
            "Shape h_col: torch.Size([1, 8, 4])\n",
            "============================================================\n",
            "h_col: tensor([[[  5.,  -1.,  -1.,   6.],\n",
            "         [  5.,  -4., -10.,  -8.],\n",
            "         [ -4.,  -1.,  -9.,  -6.],\n",
            "         [ -7.,  -6.,  -8.,  -6.],\n",
            "         [ -3.,   3.,  -5.,   4.],\n",
            "         [  5.,  -6., -12.,  -7.],\n",
            "         [ -3.,   3.,  -9.,  -6.],\n",
            "         [ -7., -13.,  -4.,  -5.]]])\n",
            "============================================================\n",
            "Shape h_col_reshaped: torch.Size([1, 2, 4, 4])\n",
            "============================================================\n",
            "tensor([[[[  5.,  -1.,  -1.,   6.],\n",
            "          [  5.,  -4., -10.,  -8.],\n",
            "          [ -4.,  -1.,  -9.,  -6.],\n",
            "          [ -7.,  -6.,  -8.,  -6.]],\n",
            "\n",
            "         [[ -3.,   3.,  -5.,   4.],\n",
            "          [  5.,  -6., -12.,  -7.],\n",
            "          [ -3.,   3.,  -9.,  -6.],\n",
            "          [ -7., -13.,  -4.,  -5.]]]])\n",
            "============================================================\n",
            "============================================================\n",
            "M_flat: tensor([[[ 5., -1., -1.,  6.],\n",
            "         [ 5.,  3., -4.,  4.]]])\n",
            "============================================================\n",
            "Reconstrucción a Feature Map\n",
            "M: tensor([[[[ 5., -1.],\n",
            "          [-1.,  6.]],\n",
            "\n",
            "         [[ 5.,  3.],\n",
            "          [-4.,  4.]]]])\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=\"*60)\n",
        "print(\"Flatten\")\n",
        "print(\"=\"*60)\n",
        "f = M.view(N, -1)  # (1, 8)\n",
        "print(f\"Shape post-Flatten: {f.shape}\")\n",
        "\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"Feed Forward\")\n",
        "print(\"=\"*60)\n",
        "print(\"Parámetros: \")\n",
        "print(\"W_fc: \", end=\"\")\n",
        "W_fc = torch.ones(8, 1)\n",
        "print(W_fc)\n",
        "b_fc = torch.ones(1)\n",
        "print(\"=\"*60)\n",
        "print(\"b_fc: \", end=\"\")\n",
        "print(b_fc)\n",
        "Z = f @ W_fc + b_fc\n",
        "print(\"=\"*60)\n",
        "print(\"Logits: \", end=\"\")\n",
        "print(Z)\n",
        "print(\"=\"*60)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GUVMJ49QbPnk",
        "outputId": "e01fbf2b-07ef-40fe-b457-f9a316744df2"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "Flatten\n",
            "============================================================\n",
            "Shape post-Flatten: torch.Size([1, 8])\n",
            "============================================================\n",
            "Feed Forward\n",
            "============================================================\n",
            "Parámetros: \n",
            "W_fc: tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]])\n",
            "============================================================\n",
            "b_fc: tensor([1.])\n",
            "============================================================\n",
            "Logits: tensor([[18.]])\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Backward Pass Manual"
      ],
      "metadata": {
        "id": "Q34SeL-BdS6A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=\"*60)\n",
        "print(\"Debido a que partimos derivando desde atrás, \\nlas derivadas son muy sencillas y se realizan de forma idéntica a lo visto en clases\")\n",
        "print(\"Sólo nos interesa calcular las derivadas respecto a W_conv que son parámetros que no conocemos...\")\n",
        "print(\"=\"*60)\n",
        "print(\"Derivada del BCEwithLogitLoss: \")\n",
        "dZ = torch.sigmoid(Z) - y  # (1, 1)\n",
        "print(\"dZ: \", dZ)\n",
        "print(\"=\"*60)\n",
        "print(\"Derivada hasta f\")\n",
        "df = dZ @ W_fc.T           # (1, 8)\n",
        "print(\"df: \", df)\n",
        "print(\"=\"*60)\n",
        "print(\"El gradiente hasta M es el inverso del Flatten, es decir recobramos la forma original\")\n",
        "\n",
        "dM = df.reshape(N, C_out, pool_size, pool_size)\n",
        "print(\"dM: \", dM)\n",
        "print(f\"Shape de dM: {dM.shape}\")\n",
        "print(\"Una imagen de 2 canales de tamaño 2x2\")\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AWltbky2iYtW",
        "outputId": "a3b89670-36b0-420a-c9e1-dc143de1dead"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "Debido a que partimos derivando desde atrás, \n",
            "las derivadas son muy sencillas y se realizan de forma idéntica a lo visto en clases\n",
            "Sólo nos interesa calcular las derivadas respecto a W_conv que son parámetros que no conocemos...\n",
            "============================================================\n",
            "Derivada del BCEwithLogitLoss: \n",
            "dZ:  tensor([[1.]])\n",
            "============================================================\n",
            "Derivada hasta f\n",
            "df:  tensor([[1., 1., 1., 1., 1., 1., 1., 1.]])\n",
            "============================================================\n",
            "El gradiente hasta M es el inverso del Flatten, es decir recobramos la forma original\n",
            "dM:  tensor([[[[1., 1.],\n",
            "          [1., 1.]],\n",
            "\n",
            "         [[1., 1.],\n",
            "          [1., 1.]]]])\n",
            "Shape de dM: torch.Size([1, 2, 2, 2])\n",
            "Una imagen de 2 canales de tamaño 2x2\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=\"*60)\n",
        "print(\"Gradiente del Pooling hasta h_col\")\n",
        "dh_col = torch.zeros_like(h_col_reshaped)\n",
        "dh_col.scatter_(2, pool_indices.unsqueeze(2), dM.reshape(N, C_out, 1, -1))\n",
        "print(\"=\"*60)\n",
        "print(\"h_col:\", h_col_reshaped)\n",
        "print(\"=\"*60)\n",
        "print(\"Se puede notar que el gradiente del Max Pooling coloca un 1 en la fila de cada columna en la que se encontró el máximo y cero en otro caso\")\n",
        "print(\"Para poder restaurar esta información fue necesario guardar los índices del Máximo en el Forward Pass..\")\n",
        "print(\"dh_col: \", dh_col)\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A3qKpJvDe1Xa",
        "outputId": "43b4493e-24d0-43aa-d0df-98cf894dca0a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "Gradiente del Pooling hasta h_col\n",
            "============================================================\n",
            "h_col: tensor([[[[  5.,  -1.,  -1.,   6.],\n",
            "          [  5.,  -4., -10.,  -8.],\n",
            "          [ -4.,  -1.,  -9.,  -6.],\n",
            "          [ -7.,  -6.,  -8.,  -6.]],\n",
            "\n",
            "         [[ -3.,   3.,  -5.,   4.],\n",
            "          [  5.,  -6., -12.,  -7.],\n",
            "          [ -3.,   3.,  -9.,  -6.],\n",
            "          [ -7., -13.,  -4.,  -5.]]]])\n",
            "============================================================\n",
            "Se puede notar que el gradiente del Max Pooling coloca un 1 en la fila de cada columna en la que se encontró el máximo y cero en otro caso\n",
            "Para poder restaurar esta información fue necesario guardar los índices del Máximo en el Forward Pass..\n",
            "dh_col:  tensor([[[[1., 1., 1., 1.],\n",
            "          [0., 0., 0., 0.],\n",
            "          [0., 0., 0., 0.],\n",
            "          [0., 0., 0., 0.]],\n",
            "\n",
            "         [[0., 1., 0., 1.],\n",
            "          [1., 0., 0., 0.],\n",
            "          [0., 0., 0., 0.],\n",
            "          [0., 0., 1., 0.]]]])\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=\"*60)\n",
        "print(\"Gradiente hasta H\")\n",
        "print(\"Debido a que pasamos de h_col a H, es necesario calcular el Gradiente el im2col\")\n",
        "print(\"El gradiente es el Algoritmo inverso: col2im\")\n",
        "print(\"=\"*60)\n",
        "print(\"Primero debemos juntar los canales, que es lo que es pera de resultado el im2col\")\n",
        "dh_col_flat = dh_col.reshape(N, C_out * 4, -1)\n",
        "print(dh_col_flat)\n",
        "print(\"=\"*60)\n",
        "print(\"Aplicamos col2im: \")\n",
        "print(\"Acá debemos reconstruir utilizando el Kernel y el Stride utilizado (Los del Pooling)\")\n",
        "print(\"Luego debemos ingresar el tamaño resultante, que sería el de la entrada al Pooling (Salida de la Convolución)\")\n",
        "dH = F.fold(dh_col_flat, output_size=(H_out, W_out), kernel_size=2, stride=2)\n",
        "print(\"dH\", dH)\n",
        "print(\"=\"*60)\n",
        "print(f\"Shape dH: {dH.shape}\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "dH_col = dH.view(N, C_out, -1)  # (N, C_out, num_patches)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZzX1JGpgNNr",
        "outputId": "8035025b-bfaa-4b93-ce2f-69d795ed662b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "Gradiente hasta H\n",
            "Debido a que pasamos de h_col a H, es necesario calcular el Gradiente el im2col\n",
            "El gradiente es el Algoritmo inverso: col2im\n",
            "============================================================\n",
            "Primero debemos juntar los canales, que es lo que es pera de resultado el im2col\n",
            "tensor([[[1., 1., 1., 1.],\n",
            "         [0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0.],\n",
            "         [0., 1., 0., 1.],\n",
            "         [1., 0., 0., 0.],\n",
            "         [0., 0., 0., 0.],\n",
            "         [0., 0., 1., 0.]]])\n",
            "============================================================\n",
            "Aplicamos col2im: \n",
            "Acá debemos reconstruir utilizando el Kernel y el Stride utilizado (Los del Pooling)\n",
            "Luego debemos ingresar el tamaño resultante, que sería el de la entrada al Pooling (Salida de la Convolución)\n",
            "dH tensor([[[[1., 0., 1., 0.],\n",
            "          [0., 0., 0., 0.],\n",
            "          [1., 0., 1., 0.],\n",
            "          [0., 0., 0., 0.]],\n",
            "\n",
            "         [[0., 1., 1., 0.],\n",
            "          [0., 0., 0., 0.],\n",
            "          [0., 0., 1., 0.],\n",
            "          [0., 1., 0., 0.]]]])\n",
            "============================================================\n",
            "Shape dH: torch.Size([1, 2, 4, 4])\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=\"*60)\n",
        "print(\"El gradiente de W_conv es similar al de una Linear Layer pero con un truquito de shapes para poder hacer multiplicaciones válidas...\")\n",
        "print(\"=\"*60)\n",
        "dH_reshaped = dH.permute(1,0,2,3).reshape(C_out, -1) # (C_out, N*n_patches)\n",
        "X_reshaped = X_col.reshape(C_in*kH*kW,-1) # (C_in*kH*kW, N*n_patches)\n",
        "print(\"=\"*60)\n",
        "dW_conv_flat = dH_reshaped @ X_reshaped.T  # (C_out, C_in*kH*kW)\n",
        "print(\"dW_conv_flat: \", dW_conv_flat)\n",
        "print(\"=\"*60)\n",
        "dW_conv = dW_conv_flat.reshape(C_out, C_in, kH, kW)\n",
        "print(\"dW_conv: \", dW_conv)\n",
        "print(\"=\"*60)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SYGnsaa9i0UW",
        "outputId": "2c781f25-03cf-4f4d-c469-f038746e773c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "El gradiente de W_conv es similar al de una Linear Layer pero con un truquito de shapes para poder hacer multiplicaciones válidas...\n",
            "============================================================\n",
            "============================================================\n",
            "dW_conv_flat:  tensor([[25., 17., 13., 22., 23., 17., 22., 12.,  9.],\n",
            "        [20., 23., 18., 21., 20., 11.,  9., 15., 18.]])\n",
            "============================================================\n",
            "dW_conv:  tensor([[[[25., 17., 13.],\n",
            "          [22., 23., 17.],\n",
            "          [22., 12.,  9.]]],\n",
            "\n",
            "\n",
            "        [[[20., 23., 18.],\n",
            "          [21., 20., 11.],\n",
            "          [ 9., 15., 18.]]]])\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=\"*60)\n",
        "print(\"El Gradiente del Bias: \")\n",
        "print(\"=\"*60)\n",
        "dBias_conv = torch.ones(n_patches)@dH_col.transpose(-1,-2)\n",
        "print(\"dbias_conv: \", dBias_conv)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MkhkfWHZjMZ8",
        "outputId": "fb616b0d-85a3-412d-9e17-6d6625c79642"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "El Gradiente del Bias: \n",
            "============================================================\n",
            "dbias_conv:  tensor([[4., 4.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gradientes calculados con Pytorch `nn.Module`"
      ],
      "metadata": {
        "id": "79YoeeRImi9j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss.backward()\n",
        "print(\"=\"*60)\n",
        "print(\"Gradientes Calculados utilizando nn.Module\")\n",
        "print(\"=\"*60)\n",
        "print(\"dW_conv_pytorch: \",  model.conv.weight.grad)\n",
        "print(\"=\"*60)\n",
        "print(\"dbias_conv_pytorch: \",  model.conv.bias.grad)\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vRWUQsXjmbLD",
        "outputId": "315e551f-ed50-4cab-d69c-296949562323"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "Gradientes Calculados utilizando nn.Module\n",
            "============================================================\n",
            "dW_conv_pytorch:  tensor([[[[25., 17., 13.],\n",
            "          [22., 23., 17.],\n",
            "          [22., 12.,  9.]]],\n",
            "\n",
            "\n",
            "        [[[20., 23., 18.],\n",
            "          [21., 20., 11.],\n",
            "          [ 9., 15., 18.]]]])\n",
            "============================================================\n",
            "dbias_conv_pytorch:  tensor([4., 4.])\n",
            "============================================================\n"
          ]
        }
      ]
    }
  ]
}