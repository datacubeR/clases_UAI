<!DOCTYPE html>
<html lang="en"><head>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-html/tabby.min.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/light-border.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-37eea08aefeeee20ff55810ff984fec1.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/quarto-contrib/glightbox/glightbox.min.js"></script>
<link href="../site_libs/quarto-contrib/glightbox/glightbox.min.css" rel="stylesheet">
<link href="../site_libs/quarto-contrib/glightbox/lightbox.css" rel="stylesheet"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.7.32">

  <meta name="author" content="Alfonso Tobar-Arancibia">
  <title>Clases UAI ‚Äì TICS-579-Deep Learning</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="../site_libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="../site_libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
  </style>
  <link rel="stylesheet" href="../site_libs/revealjs/dist/theme/quarto-673c2e7d040da7fd4b9d655d29f657a0.css">
  <link rel="stylesheet" href="../logo.css">
  <link href="../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="../site_libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="../site_libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="../site_libs/revealjs/plugin/reveal-chalkboard/font-awesome/css/all.css" rel="stylesheet">
  <link href="../site_libs/revealjs/plugin/reveal-chalkboard/style.css" rel="stylesheet">
  <link href="../site_libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
</head>
<body class="quarto-light">
  <div class="reveal">
    <div class="slides">

<section id="title-slide" class="quarto-title-block center">
  <h1 class="title">TICS-579-Deep Learning</h1>
  <p class="subtitle">Clase 3: Feed Forward Networks</p>

<div class="quarto-title-authors">
<div class="quarto-title-author">
<div class="quarto-title-author-name">
Alfonso Tobar-Arancibia 
</div>
        <p class="quarto-title-affiliation">
            <a href="mailto:alfonso.tobar.a@edu.uai.cl" class="email">alfonso.tobar.a@edu.uai.cl</a>
          </p>
    </div>
</div>

</section>
<section>
<section id="feed-forward-networks" class="title-slide slide level1 center">
<h1>Feed Forward Networks</h1>

</section>
<section id="feed-forward-networks-1" class="slide level2 smaller">
<h2>Feed Forward Networks</h2>
<blockquote>
<p>Son redes neuronales que se caracterizan por tener una arquitectura en la que la informaci√≥n fluye en una sola direcci√≥n, desde las entradas hasta las salidas. En general todas las neuronas de una capa est√°n conectadas a todas las neuronas de la siguiente capa, sin ciclos ni conexiones recurrentes.</p>
</blockquote>
<dl>
<dt>Teorema de aproximaci√≥n Universal</dt>
<dd>
<blockquote>
<p>Una red neuronal feedforward con al menos una capa oculta y un n√∫mero finito de neuronas, usando funciones de activaci√≥n no lineales (como sigmoide, tanh o ReLU), puede aproximar cualquier funci√≥n continua definida en un conjunto compacto (acotado y cerrado) de <span class="math inline">\(\mathbb{R}^n\)</span> a cualquier nivel de precisi√≥n, siempre que se utilicen suficientes neuronas y se ajusten adecuadamente los pesos y sesgos.</p>
</blockquote>
</dd>
</dl>
<div class="callout callout-important callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Importante</strong></p>
</div>
<div class="callout-content">
<ul>
<li>El teorema dice que es posible encontrar aproximar cualquier funci√≥n.</li>
<li>El teorema no dice ni c√≥mo se hace ni los recursos necesarios para hacerlo (N√∫mero de Neuronas, capas, Hiperpar√°metros, etc.).</li>
</ul>
</div>
</div>
</div>
<div class="callout callout-tip callout-style-simple">
<div class="callout-body">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-content">
<ul>
<li>B√°sicamente nos est√°n diciendo que tienes la mejor herramienta que existe, pero es tu responsabilidad saber c√≥mo utilizarla y qu√© recursos necesitas para lograrlo.</li>
</ul>
</div>
</div>
</div>
</section>
<section id="feed-forward-networks-ffn" class="slide level2 smaller">
<h2>Feed Forward Networks (FFN)</h2>
<div class="callout callout-important callout-style-simple">
<div class="callout-body">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-content">
<p>Este tipo de Redes tiene distintos nombres que son usados de manera intercambiable:</p>
<ul>
<li>Capas Lineales: Probablemente por su denominaci√≥n en Pytorch.</li>
<li>Capas/Redes Densas: Probablemente por su denominaci√≥n en Tensorflow.</li>
<li>Multilayer Perceptron: O tambi√©n conocido como MLP, debido a que es la generalizaci√≥n del Perceptr√≥n, la primera propuesta de Redes Neuronales de Rosenblatt en 1958.</li>
<li>Projection Layers: Probablemente por su denominaci√≥n en algunos papers. Se usa en el contexto de proyectar de <span class="math inline">\(n\)</span> dimensiones a <span class="math inline">\(d\)</span> dimensiones.</li>
</ul>
</div>
</div>
</div>
<div class="columns">
<div class="column">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><a href="img/clase-1/nn_arq.png" class="lightbox" data-gallery="quarto-lightbox-gallery-1"><img data-src="img/clase-1/nn_arq.png" class="quarto-figure quarto-figure-center" style="width:60.0%"></a></p>
</figure>
</div>
</div><div class="column">
<p>De ahora en adelante utilizaremos las siguiente notaci√≥n para referirnos a una Red Neuronal Feed Forward:</p>
<p><span class="math display">\[h_\theta(X) = \sigma_s(Z)\]</span></p>
<div class="callout callout-warning no-icon callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<p><strong>Logits</strong></p>
</div>
<div class="callout-content">
<p>Definiremos <span class="math inline">\(Z=\phi_L(X) W_{L+1} + b_{L+1}^T\)</span> como Logits y corresponden a las activaciones de la √∫ltima capa antes de aplicar la funci√≥n de activaci√≥n de salida <span class="math inline">\(\sigma_s(.)\)</span>.</p>
</div>
</div>
</div>
</div></div>
</section>
<section id="hiperpar√°metros-de-una-red-neuronal" class="slide level2 smaller">
<h2>Hiperpar√°metros de una Red Neuronal</h2>
<dl>
<dt>Hiperpar√°metros</dt>
<dd>
<blockquote>
<p>Son las configuraciones externas que no se aprenden durante el entrenamiento, sino que se definen antes de entrenar el modelo y controlan su comportamiento y rendimiento.</p>
</blockquote>
</dd>
</dl>
<div style="font-size: 120%;">
<div class="callout callout-caution no-icon callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<p><strong>ü§ì Hiperpar√°metros de una Red Neuronal</strong></p>
</div>
<div class="callout-content">
<ul>
<li><strong><em>Learning Rate</em></strong> (Karpathy Constant: 3e-4), valores entre [1e-5, 1e-1] son comunes.</li>
<li><strong>N√∫mero de Capas</strong> y sus respectivas dimensiones (Para Pesos/Weights y Sesgos/Biases).</li>
<li><strong>Funciones de Activaci√≥n</strong> para cada capa.</li>
<li><strong>Funci√≥n de P√©rdida</strong> (Loss Function) a utilizar.</li>
<li><strong>Optimizador</strong> a utilizar.</li>
<li><strong>Punto de Partida</strong> de los Par√°metros (Inicializaci√≥n de Pesos y Sesgos).</li>
<li>¬øCu√°nto tiempo debo entrenar mi modelo? <strong><em>¬øC√≥mo sabemos si es que convergi√≥ o no?</em></strong></li>
</ul>
</div>
</div>
</div>
</div>
</section>
<section id="output-de-una-red-neuronal" class="slide level2 smaller">
<h2>Output de una Red Neuronal</h2>
<blockquote>
<p>En el aprendizaje supervisado se abordan principalmente dos tipos de problemas: clasificaci√≥n y regresi√≥n. Seg√∫n el tipo de problema, la hip√≥tesis debe adoptar una forma distinta en la capa de salida.</p>
</blockquote>
<div style="font-size: 120%;">
<div class="callout callout-important no-icon callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<p><strong>‚ö†Ô∏è Dimensi√≥n de Salida</strong></p>
</div>
<div class="callout-content">
<p>Est√° definida por el n√∫mero de valores a predecir para cada observaci√≥n. Denominaremos <span class="math inline">\(k\)</span> como la dimensi√≥n de salida.</p>
<p>Para una red de dos capas:</p>
<p><span class="math display">\[\phi_0(X) = X\]</span> <span class="math display">\[\phi_1(X) = \sigma_1(W_1 \cdot \phi_0(X) + \bar{b_1}^T)\]</span> <span class="math display">\[\phi_2(X) = \sigma_2(W_2 \cdot \phi_1(X) + \bar{b_2}^T)\]</span></p>
<p>Donde <span class="math inline">\(W_1 \in \mathbb{R}^{n \times d_1}\)</span> y <span class="math inline">\(W_2 \in \mathbb{R}^{d_1 \times k}\)</span> y <span class="math inline">\(b_1 \in \mathbb{R}^{d_1}\)</span> y <span class="math inline">\(b_2 \in \mathbb{R}^{k}\)</span>.</p>
</div>
</div>
</div>
</div>
<div style="font-size: 120%;">
<div class="callout callout-note no-icon callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<p><strong>‚úÖ Activaci√≥n de la Salida</strong></p>
</div>
<div class="callout-content">
<p>Seg√∫n el tipo de problema, la capa de salida puede necesitar una funci√≥n de activaci√≥n particular que ajuste los resultados al formato correcto. En este sentido, <span class="math inline">\(\sigma_2\)</span> estar√° determinada por la naturaleza del problema a resolver.</p>
</div>
</div>
</div>
</div>
</section>
<section id="consejos-para-el-output-de-una-red" class="slide level2 smaller">
<h2>Consejos para el Output de una Red</h2>
<div class="columns">
<div class="column">
<div class="callout callout-note no-icon callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<p><strong>Clasificaci√≥n Binaria</strong></p>
</div>
<div class="callout-content">
<p>El approach m√°s com√∫n utiliza <span class="math inline">\(k=1\)</span> con una <strong><em>Sigmoide</em></strong> para calcular la probabilidad de la clase 1. Otros approach utilizan <span class="math inline">\(k=2\)</span> para calcular la probabilidad de ambas clases (Activando con <strong><em>Softmax</em></strong>).</p>
</div>
</div>
</div>
<div class="callout callout-warning no-icon callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<p><strong>Clasificaci√≥n Multiclase</strong></p>
</div>
<div class="callout-content">
<p>Utiliza <span class="math inline">\(k=C\)</span> donde C es el n√∫mero de clases a clasificar. Se usa una funci√≥n <strong><em>Softmax</em></strong> para transformar el output en una distribuci√≥n de probabilidades.</p>
</div>
</div>
</div>
<div class="callout callout-important no-icon callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<p><strong>Clasificaci√≥n Multilabel</strong></p>
</div>
<div class="callout-content">
<p>Se requiere un <span class="math inline">\(k=C\)</span> donde C es el n√∫mero de clases a clasificar. Se usa una funci√≥n <strong><em>Sigmoide</em></strong> para transformar cada clase en probabilidades.</p>
</div>
</div>
</div>
</div><div class="column">
<div class="callout callout-caution no-icon callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<p><strong>Regresi√≥n Simple</strong></p>
</div>
<div class="callout-content">
<p>Se requiere un <span class="math inline">\(k=1\)</span>. T√≠picamente no requiere de funciones adicionales aunque a veces se agregan funciones para acotar la salida.</p>
</div>
</div>
</div>
<div class="callout callout-tip no-icon callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<p><strong>Regresi√≥n Multiple</strong></p>
</div>
<div class="callout-content">
<p>Se requiere un <span class="math inline">\(k=V\)</span> con V el n√∫mero de valores a predecir. Se deben tener las mismas consideraciones para acotar la salida.</p>
</div>
</div>
</div>
</div></div>
<div class="fragment">
<div class="callout callout-none no-icon callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<p><strong>üëÄ Muy Importante</strong></p>
</div>
<div class="callout-content">
<p>En la mayor√≠a de las implementaciones en C√≥digo la activaci√≥n de la salida va embebida en la Loss Function. Por lo tanto, no es necesario aplicar una funci√≥n de activaci√≥n expl√≠cita en la capa de salida. Aunque s√≠ deben aplicarse al momento de la <strong><em>Predicci√≥n del modelo</em></strong>.</p>
</div>
</div>
</div>
</div>
</section>
<section id="funciones-de-activaci√≥n" class="slide level2 smaller">
<h2>Funciones de Activaci√≥n</h2>
<dl>
<dt>Activation Functions</dt>
<dd>
Corresponden a las funciones que agregar√°n caracter√≠sticas no lineales a cada activaci√≥n, impidiendo la composici√≥n de transformaciones Affine.
</dd>
</dl>
<div class="callout callout-tip no-icon callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<p><strong>ü§ì Convenci√≥n para C√≥digo</strong></p>
</div>
<div class="callout-content">
<p>En Pytorch, nunca aplicaremos una funci√≥n de activaci√≥n a la capa de salida.</p>
</div>
</div>
</div>
<div class="callout callout-warning callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Cuidado</strong></p>
</div>
<div class="callout-content">
<p>Otros frameworks como Tensorflow, Keras, etc. utilizan una convenci√≥n distinta y aplican funciones de activaci√≥n a la capa de salida.</p>
</div>
</div>
</div>
<div class="callout callout-note no-icon callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<p><strong>¬øPuedo aplicar distintas Funciones de Activaci√≥n a cada Neurona?</strong></p>
</div>
<div class="callout-content">
<p>Puedo, pero no se hace. Complicar√≠a much√≠simo la implementaci√≥n.</p>
</div>
</div>
</div>
<p><a href="https://pytorch.org/docs/stable/nn.html#non-linear-activations-weighted-sum-nonlinearity">Activation Functions in Pytorch</a>.</p>
</section>
<section id="funciones-de-activaci√≥n-1" class="slide level2 smaller">
<h2>Funciones de Activaci√≥n</h2>
<h3 id="sigmoide">Sigmoide</h3>
<div class="columns">
<div class="column" style="width:60%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><a href="img/clase-1/sigmoid.png" class="lightbox" data-gallery="quarto-lightbox-gallery-2"><img data-src="img/clase-1/sigmoid.png" class="quarto-figure quarto-figure-center" style="width:80.0%"></a></p>
</figure>
</div>
</div><div class="column" style="width:40%;">
<div style="font-size: 120%;">
<div class="callout callout-tip no-icon callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<p><strong>Definici√≥n</strong></p>
</div>
<div class="callout-content">
<p><span class="math display">\[\sigma(z) = \frac{1}{1 + e^{-z}}\]</span></p>
</div>
</div>
</div>
</div>
<div class="callout callout-warning no-icon callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<p><strong>Propiedades</strong></p>
</div>
<div class="callout-content">
<ul>
<li>Acota la salida entre 0 y 1.</li>
<li>Su derivada es <span class="math inline">\(\sigma'(z) = \sigma(z)(1 - \sigma(z))\)</span>.</li>
<li>Su gradiente es general es muy peque√±o, lo que lleva a problemas de <strong><em>Vanishing Gradient</em></strong>.</li>
<li>Su principal uso es en la capa de salida para problemas de clasificaci√≥n binaria y Clasificaci√≥n Multilabel.</li>
</ul>
</div>
</div>
</div>
</div></div>
</section>
<section id="funciones-de-activaci√≥n-2" class="slide level2 smaller">
<h2>Funciones de Activaci√≥n</h2>
<h3 id="softmax">Softmax</h3>
<div class="columns">
<div class="column" style="width:60%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><a href="img/clase-3/softmax.png" class="lightbox" data-gallery="quarto-lightbox-gallery-3"><img data-src="img/clase-3/softmax.png" class="quarto-figure quarto-figure-center" style="width:80.0%"></a></p>
</figure>
</div>
</div><div class="column" style="width:40%;">
<div style="font-size: 120%;">
<div class="callout callout-tip no-icon callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<p><strong>Definici√≥n</strong></p>
</div>
<div class="callout-content">
<p><span class="math display">\[S_i(z) = \frac{e^{z_i}}{\sum_{j=1}^k e^{z_j}}\]</span></p>
</div>
</div>
</div>
</div>
<div class="callout callout-warning no-icon callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<p><strong>Propiedades</strong></p>
</div>
<div class="callout-content">
<ul>
<li>Transofrma un vector en una distribuci√≥n de probabilidad.</li>
<li>Su principal uso es en la capa de salida para problemas de clasificaci√≥n multiclase. Es por lejos la funci√≥n de activaci√≥n m√°s utilizada en la salida, pero en casos m√°s avanzados tambi√©n en Mecanismos de Atenci√≥n.</li>
</ul>
</div>
</div>
</div>
</div></div>
</section>
<section id="funciones-de-activaci√≥n-3" class="slide level2 smaller">
<h2>Funciones de Activaci√≥n</h2>
<h3 id="tanh">Tanh</h3>
<div class="columns">
<div class="column" style="width:60%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><a href="img/clase-3/tanh.jpg" class="lightbox" data-gallery="quarto-lightbox-gallery-4"><img data-src="img/clase-3/tanh.jpg" class="quarto-figure quarto-figure-center" style="width:80.0%"></a></p>
</figure>
</div>
</div><div class="column" style="width:40%;">
<div style="font-size: 120%;">
<div class="callout callout-tip no-icon callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<p><strong>Definici√≥n</strong></p>
</div>
<div class="callout-content">
<p><span class="math display">\[Tanh(z) = \frac{e^z - e^{-z}}{e^z + e^{-z}}\]</span></p>
</div>
</div>
</div>
</div>
<div class="callout callout-warning no-icon callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<p><strong>Propiedades</strong></p>
</div>
<div class="callout-content">
<ul>
<li>Acota su salida entre -1 y 1.</li>
<li>Su derivada es <span class="math inline">\(Tanh'(z) = 1 - Tanh^2(z)\)</span>.</li>
<li>Su gradiente normalmente es m√°s grande que el de la Sigmoide, pero a√∫n as√≠ puede llevar a problemas de <strong><em>Vanishing Gradient</em></strong>.</li>
<li>A pesar de estar un poco en desuso, tiene un rol protag√≥nico en las <code>Redes Recurrentes</code> (RNNs).</li>
</ul>
</div>
</div>
</div>
</div></div>
</section>
<section id="funciones-de-activaci√≥n-4" class="slide level2 smaller">
<h2>Funciones de Activaci√≥n</h2>
<h3 id="relu-rectified-linear-unit">ReLU (Rectified Linear Unit)</h3>
<div class="columns">
<div class="column" style="width:60%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><a href="img/clase-3/relu.png" class="lightbox" data-gallery="quarto-lightbox-gallery-5"><img data-src="img/clase-3/relu.png" class="quarto-figure quarto-figure-center" style="width:80.0%"></a></p>
</figure>
</div>
</div><div class="column" style="width:40%;">
<div style="font-size: 120%;">
<div class="callout callout-tip no-icon callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<p><strong>Definici√≥n</strong></p>
</div>
<div class="callout-content">
<p><span class="math display">\[ReLU(z) = max(0, z)\]</span></p>
</div>
</div>
</div>
</div>
<div class="callout callout-warning no-icon callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<p><strong>Propiedades</strong></p>
</div>
<div class="callout-content">
<ul>
<li>Acota su salida entre 0 e <span class="math inline">\(\infty\)</span>.</li>
<li>Su derivada es <span class="math inline">\(ReLU'(z) = \begin{cases}
1,  &amp; \text{if $z \ge$ 0} \\
0 &amp; \text{if $z &lt; 0$}
\end{cases}\)</span></li>
<li>Es la funci√≥n de activaci√≥n m√°s utilizada en la actualidad, principalmente en las capas ocultas de las Redes Neuronales.</li>
<li>Se hizo extremadamente popular por su simplicidad y efectividad en <code>Redes Convolucionales</code> (CNNs).</li>
</ul>
</div>
</div>
</div>
</div></div>
</section>
<section id="funciones-de-activaci√≥n-modernas" class="slide level2 smaller">
<h2>Funciones de Activaci√≥n Modernas</h2>
<div class="columns">
<div class="column">
<h3 id="leaky-relu">Leaky ReLU</h3>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><a href="img/clase-3/leaky_relu.png" class="lightbox" data-gallery="quarto-lightbox-gallery-6"><img data-src="img/clase-3/leaky_relu.png" class="quarto-figure quarto-figure-center" style="width:60.0%"></a></p>
</figure>
</div>
<p><span class="math display">\[g(z) = max(0.1z, z)\]</span></p>
</div><div class="column">
<h3 id="parametrized-relu-prelu">Parametrized ReLU (PReLU)</h3>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><a href="img/clase-3/prelu.png" class="lightbox" data-gallery="quarto-lightbox-gallery-7"><img data-src="img/clase-3/prelu.png" class="quarto-figure quarto-figure-center" style="width:60.0%"></a></p>
</figure>
</div>
<p><span class="math display">\[g(z) = max(az, z)\]</span></p>
</div></div>
</section>
<section id="funciones-de-activaci√≥n-5" class="slide level2 smaller">
<h2>Funciones de Activaci√≥n</h2>
<div class="columns">
<div class="column">
<h3 id="elu">ELU</h3>
<p><a href="img/clase-3/elu.png" class="lightbox" data-gallery="quarto-lightbox-gallery-8"><img data-src="img/clase-3/elu.png" class="quarto-figure quarto-figure-center" style="width:60.0%"></a> <span class="math inline">\(g(z) =
\begin{cases}
z,  &amp; \text{if $z \ge$ 0} \\[2ex]
\alpha(e^{z}-1), &amp; \text{if $z &lt; 0$}
\end{cases}\)</span></p>
</div><div class="column">
<h3 id="gelu">GELU</h3>
<p><a href="img/clase-3/gelu.png" class="lightbox" data-gallery="quarto-lightbox-gallery-9"><img data-src="img/clase-3/gelu.png" class="quarto-figure quarto-figure-center" style="width:60.0%"></a> <span class="math display">\[\begin{align} g(z) &amp;= z \cdot \Phi(z) \\
g(z)&amp;= 0.5 \cdot z \cdot \left(1 + Tanh\left(\sqrt{2/\pi}\right) \cdot \left(z + 0.044715 \cdot z^3\right)\right)\end{align}\]</span></p>
</div></div>
</section>
<section id="funciones-de-activaci√≥n-6" class="slide level2 smaller">
<h2>Funciones de Activaci√≥n</h2>
<div class="columns">
<div class="column">
<h3 id="selu">SELU</h3>
<p><a href="img/clase-3/selu.png" class="lightbox" data-gallery="quarto-lightbox-gallery-10"><img data-src="img/clase-3/selu.png" class="quarto-figure quarto-figure-center" style="width:60.0%"></a> <span class="math display">\[ g(z) = scale \cdot (max(0,z) + min(0,\alpha(e^z - 1)))\]</span></p>
<p>con <span class="math inline">\(\alpha=1.6732632423543772848170429916717\)</span> y <span class="math inline">\(scale = 1.0507009873554804934193349852946\)</span></p>
</div><div class="column">
<h3 id="swish">Swish</h3>
<p><a href="img/clase-3/swish.png" class="lightbox" data-gallery="quarto-lightbox-gallery-11"><img data-src="img/clase-3/swish.png" class="quarto-figure quarto-figure-center" style="width:60.0%"></a> <span class="math display">\[g(z) = z \cdot sigmoid(z)\]</span></p>
</div></div>
</section>
<section id="loss-functions-clasificaci√≥n" class="slide level2 smaller">
<h2>Loss Functions: Clasificaci√≥n</h2>
<blockquote>
<p>Son las encargadas de medir el error entre la predicci√≥n del modelo y el valor real. En general, se busca minimizar la Loss Function durante el entrenamiento del modelo.</p>
</blockquote>
<div style="font-size: 120%;">
<div class="callout callout-note no-icon callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<p><strong>Clasificaci√≥n Binaria: Binary Cross Entropy</strong></p>
</div>
<div class="callout-content">
<p><span class="math display">\[BCE(Z) = - \frac{1}{m}\left[y^T log(\sigma(Z)) + (1-y)^T log(1-\sigma(Z))\right]\]</span></p>
<p>Donde <span class="math inline">\(Z\)</span> corresponden a los Logits del Modelo.</p>
</div>
</div>
</div>
</div>
<div class="callout callout-important callout-style-simple">
<div class="callout-body">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-content">
<p>En Pytorch esta funci√≥n se llama <code>BCEWithLogitsLoss</code>.</p>
</div>
</div>
</div>
<div style="font-size: 120%;">
<div class="callout callout-warning no-icon callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<p><strong>ü§ì Logits</strong></p>
</div>
<div class="callout-content">
<p>Se refiere a las activaciones finales del modelo antes de aplicar la funci√≥n de activaci√≥n.</p>
</div>
</div>
</div>
</div>
<div class="callout callout-important callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>üëä Clasificaci√≥n Multilabel: BCEWithLogitsLoss</strong></p>
</div>
<div class="callout-content">
<p>En Pytorch se suele utilizar <code>BCEWithLogitsLoss</code> ya que combina una sigmoide a cada activaci√≥n de la salida.</p>
</div>
</div>
</div>
</section>
<section id="loss-functions-clasificaci√≥n-1" class="slide level2 smaller">
<h2>Loss Functions: Clasificaci√≥n</h2>
<div style="font-size: 120%;">
<div class="callout callout-note no-icon callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<p><strong>Clasificaci√≥n Multiclase: CrossEntropy</strong></p>
</div>
<div class="callout-content">
<p><span class="math display">\[CE(Z)= -\frac{1}{m}Tr(Y^T Log(\hat{Y}))\]</span></p>
<p>Donde <span class="math inline">\(Tr(.)\)</span> es la traza de una matriz e <span class="math inline">\(Y \in \{0,1\}^{m \times k}\)</span> es la codificaci√≥n One-Hot de las etiquetas e <span class="math inline">\(\hat{Y} = Softmax(Z)\)</span>, donde <span class="math inline">\(Z\)</span> son los Logits del modelo.</p>
</div>
</div>
</div>
</div>
<div style="font-size: 120%;">
<div class="callout callout-tip no-icon callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<p><strong>ü§ì Traza (<span class="math inline">\(Tr(.)\)</span>)</strong></p>
</div>
<div class="callout-content">
<p>Corresponde a la suma de los elementos de la diagonal principal de una matriz.</p>
</div>
</div>
</div>
</div>
<div style="font-size: 120%;">
<div class="callout callout-warning no-icon callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<p><strong>Derivada</strong></p>
</div>
<div class="callout-content">
<p><span class="math display">\[\frac{\partial CE(X)}{\partial Z} = \frac{1}{m}\left(\hat{Y} - Y\right)\]</span></p>
</div>
</div>
</div>
</div>
<div class="callout callout-tip callout-style-simple">
<div class="callout-body">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-content">
<p>En Pytorch se suele utilizar <code>CrossEntropyLoss</code> ya que combina aplica una funci√≥n Softmax a la capa de salida adem√°s de ser una clase numericamente m√°s estable.</p>
</div>
</div>
</div>
</section>
<section id="ejemplo-de-cross-entropy-loss" class="slide level2">
<h2>Ejemplo de Cross Entropy Loss</h2>
<p>TODO:</p>
</section>
<section id="loss-functions-regresi√≥n" class="slide level2 smaller">
<h2>Loss Functions: Regresi√≥n</h2>
<div style="font-size: 120%;">
<div class="callout callout-note no-icon callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<p><strong>Regresi√≥n: Mean Squared Error (MSELoss)</strong></p>
</div>
<div class="callout-content">
<p><span class="math display">\[MSE(Z) = \frac{1}{m}||Z - \bar{y}||^2\]</span></p>
<p>Donde <span class="math inline">\(||.||\)</span> corresponde a la norma Euclideana e <span class="math inline">\(\bar{y} \in \mathbb{R}^{m \times 1}\)</span>.</p>
</div>
</div>
</div>
</div>
<div style="font-size: 120%;">
<div class="callout callout-warning no-icon callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<p><strong>Derivada</strong></p>
</div>
<div class="callout-content">
<p><span class="math display">\[\frac{\partial MSE(Z)}{\partial Z} = \frac{2}{m}(Z - \bar{y})\]</span></p>
</div>
</div>
</div>
</div>
</section>
<section id="loss-functions-regresi√≥n-1" class="slide level2 smaller">
<h2>Loss Functions: Regresi√≥n</h2>
<div style="font-size: 120%;">
<div class="callout callout-note no-icon callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<p><strong>Regresi√≥n: Mean Absolute Error (L1Loss)</strong></p>
</div>
<div class="callout-content">
<p><span class="math display">\[L1Loss(Z) = \frac{1}{m}|Z - \bar{y}|\]</span></p>
<p>Donde <span class="math inline">\(||.||\)</span> corresponde a la norma Euclideana y <span class="math inline">\(\bar{y} \in \mathbb{R}^{m \times 1}\)</span>.</p>
</div>
</div>
</div>
</div>
<div style="font-size: 120%;">
<div class="callout callout-warning no-icon callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<p><strong>Derivada</strong></p>
</div>
<div class="callout-content">
<p><span class="math display">\[\frac{\partial L1Loss(Z)}{\partial Z} = \frac{1}{m}sign(Z-\bar{y})\]</span></p>
<p><span class="math display">\[\operatorname{sign}(z) =
\begin{cases}
+1 &amp; \text{si  z &gt; 0},\\[2mm]
0 &amp; \text{si z = 0},\\[1mm]
-1 &amp; \text{si z &lt; 0}
\end{cases}\]</span></p>
</div>
</div>
</div>
</div>
</section>
<section id="optimizers-gradient-descent" class="slide level2 smaller">
<h2>Optimizers: Gradient Descent</h2>
<div style="font-size: 80%;">
<blockquote>
<p>Gradient Descent corresponde al algoritmo de Optimizaci√≥n m√°s popular, pero no necesariamente el m√°s eficiente. Distintas variantes han ido apareciendo para ir mejorando eventuales deficiencias de la proposici√≥n inicial.</p>
</blockquote>
</div>
<div class="callout callout-warning no-icon callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<p><strong>Epochs</strong></p>
</div>
<div class="callout-content">
<p>Corresponden a la cantidad de iteraciones que se realizan a la Update Rule para que el modelo se optimize.</p>
</div>
</div>
</div>
<div style="font-size: 120%;">
<div class="callout callout-note no-icon callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<p><strong>Standard Gradient Descent</strong></p>
</div>
<div class="callout-content">
<p><span class="math display">\[\theta := \theta - \frac{\alpha}{m}\nabla_\theta L\]</span></p>
</div>
</div>
</div>
</div>
<div class="callout callout-caution callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Importante</strong></p>
</div>
<div class="callout-content">
<ul>
<li>En Deep Learning, los conjuntos de datos suelen ser tan grandes que calcular el gradiente sobre todos ellos es inviable por memoria y tiempo de c√≥mputo.</li>
<li>Adicionalmente no basta con calcular el gradiente una vez, sino que se debe hacer varias veces seg√∫n el n√∫mero de Epochs definido.</li>
<li>Practicar Standard Gradient Descent en la pr√°ctica es muy poco com√∫n, ya que no es eficiente.</li>
</ul>
</div>
</div>
</div>
</section>
<section id="minibatch-gradient-descent" class="slide level2 smaller">
<h2>Minibatch Gradient Descent</h2>
<div class="callout callout-important callout-style-simple">
<div class="callout-body">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-content">
<p>Los <code>minibatches</code> permiten estimar el gradiente con un subconjunto de datos, manteniendo la direcci√≥n correcta para actualizar los par√°metros de manera m√°s eficiente. Se realiza en un subconjunto de <span class="math inline">\(B\)</span> datos donde <span class="math inline">\(B &lt;&lt; m\)</span>.</p>
</div>
</div>
</div>
<p><span class="math display">\[\theta := \theta - \frac{\alpha}{B}\nabla_\theta L\]</span></p>
<div class="callout callout-warning no-icon callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<p><strong>üëÄ Importante</strong></p>
</div>
<div class="callout-content">
<ul>
<li><span class="math inline">\(X \in \mathbb{R}^{B \times n}\)</span> e <span class="math inline">\(y \in \mathbb{R}^{B \times 1}\)</span> son versiones reducidas de los datos totales. Se deben hacer suficientes <code>minibatches</code> para utilizar todos los datos. El minibatch se implementa en Pytorch utilizando el <code>DataLoader</code>. Cada actualizaci√≥n de par√°metros ahora se le denomina <code>step</code>.</li>
<li>Cuando todos los <code>minibatches</code> han sido utilizados, se dice que se ha completado una <code>epoch</code>.</li>
<li>Es com√∫n utilizar un <code>minibatch</code> de tama√±o 32, 64, 128, etc.</li>
<li>A veces se deshecha el √∫ltimo <code>minibatch</code> (remanente) si no tiene el tama√±o completo para evitar problemas de estabilidad de gradientes.</li>
</ul>
</div>
</div>
</div>
<div class="callout callout-tip no-icon callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<p><strong>Pros</strong></p>
</div>
<div class="callout-content">
<ul>
<li>Permite optimizar utilizando menos recursos computacionales.</li>
<li>Al actualizar los par√°metros de manera m√°s frecuente, se puede converger m√°s r√°pido.</li>
</ul>
</div>
</div>
</div>
<div class="callout callout-important no-icon callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<p><strong>Contras</strong></p>
</div>
<div class="callout-content">
<ul>
<li>Si <span class="math inline">\(B\)</span> es muy peque√±o, el gradiente puede ser muy ruidoso y no converger.</li>
<li>El entrenamiento toma m√°s tiempo que el Standard Gradient Descent.</li>
</ul>
</div>
</div>
</div>
</section>
<section id="sgd-with-momentum" class="slide level2 smaller">
<h2>SGD with Momentum</h2>
<div class="columns">
<div class="column" style="font-size: 90%;">
<h4 id="update-rule">Update Rule</h4>
<p><span class="math display">\[\theta_{t+1} = \theta_t - \alpha v_{t + 1}\]</span> <span class="math display">\[v_{t+1} = \beta v_{t} + (1-\beta) \nabla_\theta L(\theta_{t+1})\]</span></p>
<p>donde <span class="math inline">\(0&lt;\beta&lt;1\)</span>, pero normalmente <span class="math inline">\(\beta=0.9\)</span>.</p>
</div><div class="column">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><a href="img/clase-3/momentum_update.png" class="lightbox" data-gallery="quarto-lightbox-gallery-12"><img data-src="img/clase-3/momentum_update.png" class="quarto-figure quarto-figure-center" style="width:45.0%"></a></p>
</figure>
</div>
</div></div>
<div class="callout callout-note no-icon callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<p><strong>‚òùÔ∏è Intuici√≥n</strong></p>
</div>
<div class="callout-content">
<ul>
<li>Este c√°lculo se denomina un Exponential Moving Average de los Gradientes. Y se puede interpretar como una especie de velocidad del gradiente. Su objetivo es ponderar con un cierto porcentaje el gradiente actual y el gradiente anterior.</li>
<li><span class="math inline">\(v_{0} = 0\)</span></li>
</ul>
</div>
</div>
</div>
<p><span class="math display">\[\begin{align} v_{t+1}&amp;=(1-\beta)\nabla_\theta L(\theta_{t}) + \beta v_t \\
v_{t+1}&amp;=(1-\beta)\nabla_\theta L(\theta_{t}) + \beta \left[(1-\beta) \nabla_\theta L(\theta_{t-1}) + \beta v_{t-1}\right] \\
v_{t+1}&amp;=(1-\beta)\nabla_\theta L(\theta_{t}) + \beta (1-\beta) \nabla_\theta L(\theta_{t-1}) + \beta^2 (1-\beta) \nabla_\theta L(\theta_{t-2})... \\
\end{align}\]</span></p>
</section>
<section id="sgd-with-nesterov-momentum" class="slide level2 smaller">
<h2>SGD with Nesterov Momentum</h2>
<div class="columns">
<div class="column">
<p><span class="math display">\[\theta_{t+1} = \theta_t - \alpha u_{t + 1}\]</span> <span class="math display">\[v_{t + 1} = \beta v_t + (1-\beta) \nabla_\theta f(\theta_{t+1} + \beta v_t)\]</span></p>
<p>donde <span class="math inline">\(0&lt;\beta&lt;1\)</span>, pero normalmente <span class="math inline">\(\beta=0.9\)</span>.</p>
</div><div class="column">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><a href="img/clase-3/nesterov_update.png" class="lightbox" data-gallery="quarto-lightbox-gallery-13"><img data-src="img/clase-3/nesterov_update.png" class="quarto-figure quarto-figure-center" style="width:50.0%"></a></p>
</figure>
</div>
</div></div>
<div class="callout callout-note no-icon callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<p><strong>‚òùÔ∏è Intuici√≥n</strong></p>
</div>
<div class="callout-content">
<p>El m√©todo de Nesterov ‚Äúmira hacia adelante‚Äù en la direcci√≥n del momentum antes de calcular el gradiente, lo que le da una correcci√≥n m√°s precisa y evita en parte el sobrepaso de m√≠nimos. En este caso <span class="math inline">\(\theta_{t+1} + \beta v_t\)</span> es el punto ‚Äúfuturo‚Äù para calcular el gradiente.</p>
</div>
</div>
</div>
</section>
<section id="efecto-del-momentum-en-el-update-rule" class="slide level2 smaller">
<h2>Efecto del Momentum en el Update Rule</h2>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><a href="img/clase-3/momentum_effect.png" class="lightbox" data-gallery="quarto-lightbox-gallery-14"><img data-src="img/clase-3/momentum_effect.png" class="quarto-figure quarto-figure-center"></a></p>
</figure>
</div>
<div class="callout callout-note no-icon callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<p><strong>‚òùÔ∏è Intuici√≥n</strong></p>
</div>
<div class="callout-content">
<ul>
<li>El SGD tiende a ser m√°s oscilante.</li>
<li>El SGD con Momentum tiende a ser m√°s suave y r√°pido debido a la inercia recibida por el t√©rmino de momentum.</li>
</ul>
</div>
</div>
</div>
</section>
<section id="m√©todos-adaptativos-adagrad" class="slide level2 smaller">
<h2>M√©todos Adaptativos: Adagrad</h2>
<div class="callout callout-note no-icon callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<p><strong>‚òùÔ∏è Intuici√≥n</strong></p>
</div>
<div class="callout-content">
<p>¬øQu√© tal, si el learning rate se va adaptando en el tiempo y deja de ser est√°tica?</p>
</div>
</div>
</div>
<p><span class="math display">\[r_{t+1} = r_t + \nabla_\theta f(\theta_t)^2\]</span> <span class="math display">\[\theta_{t+1} = \theta_t - \frac{\alpha}{\sqrt{r_{t+1}}}\nabla_\theta f(\theta_t)\]</span></p>
<div class="callout callout-warning no-icon callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<p><strong>Efecto</strong></p>
</div>
<div class="callout-content">
<ul>
<li>Par√°metros con gradientes grandes <span class="math inline">\(\rightarrow\)</span> tasa de aprendizaje disminuye m√°s r√°pido.</li>
<li>Par√°metros con gradientes peque√±os <span class="math inline">\(\rightarrow\)</span> tasa de aprendizaje se mantiene m√°s alta.</li>
</ul>
</div>
</div>
</div>
<div class="callout callout-tip no-icon callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<p><strong>Pros</strong></p>
</div>
<div class="callout-content">
<ul>
<li>Util cuando hay par√°metros que se actualizan con distinta frecuencia.</li>
<li>Acelera la convergencia en direcciones poco exploradas.</li>
</ul>
</div>
</div>
</div>
<div class="callout callout-important no-icon callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<p><strong>Contras</strong></p>
</div>
<div class="callout-content">
<ul>
<li>Como el denominador acumula gradientes al cuadrado, la tasa de aprendizaje puede llegar a volverse muy peque√±a <span class="math inline">\(\rightarrow\)</span> el entrenamiento se <strong><em>‚Äúfrena‚Äù</em></strong> antes de llegar al √≥ptimo.</li>
</ul>
</div>
</div>
</div>
</section>
<section id="m√©todos-adaptativos-rmsprop" class="slide level2 smaller">
<h2>M√©todos Adaptativos: RMSProp</h2>
<div class="callout callout-note no-icon callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<p><strong>‚òùÔ∏è Intuici√≥n</strong></p>
</div>
<div class="callout-content">
<ul>
<li>Normalizar por el Exponential Moving Average de los Gradientes al cuadrado para controlar el efecto de reducci√≥n del learning rate.</li>
</ul>
</div>
</div>
</div>
<p><span class="math display">\[s_{t+1} = \beta r_t + (1-\beta) \nabla_\theta f(\theta_t)^2\]</span> <span class="math display">\[\theta_{t+1} = \theta_t - \frac{\alpha}{\sqrt{s_{t+1}}}\nabla_\theta f(\theta_t)\]</span></p>
<div class="callout callout-tip no-icon callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<p><strong>Pros</strong></p>
</div>
<div class="callout-content">
<ul>
<li>Normalizaci√≥n adaptativa: cada par√°metro tiene su propia tasa de aprendizaje ajustada din√°micamente.</li>
<li>A diferencia de Adagrad, el denominador no crece indefinidamente porque el promedio exponencial ‚Äúolvida‚Äù gradientes antiguos. Esto permite seguir aprendiendo incluso despu√©s de muchos pasos.</li>
</ul>
</div>
</div>
</div>
<div class="callout callout-important no-icon callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<p><strong>Contras</strong></p>
</div>
<div class="callout-content">
<ul>
<li>Depende mucho de la elecci√≥n de su hiperpar√°metro <span class="math inline">\(\beta\)</span></li>
</ul>
</div>
</div>
</div>
</section>
<section id="m√©todos-adaptativos-adam" class="slide level2 smaller">
<h2>M√©todos Adaptativos: Adam</h2>
<div class="callout callout-note no-icon callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<p><strong>‚òùÔ∏è Intuici√≥n</strong></p>
</div>
<div class="callout-content">
<p>Se mantiene el Exponential Moving average para: Los gradientes (como utilizando momentum), los gradientes al cuadrado (como RMSprop).</p>
</div>
</div>
</div>
<div class="columns">
<div class="column">
<p><span class="math display">\[v_{t+1} = \beta_1 v_t + (1-\beta_1) \nabla_\theta f(\theta_t)\]</span> <span class="math display">\[s_{t+1} = \beta_2 s_t + (1-\beta_2) \nabla_\theta f(\theta_t)^2\]</span> <span class="math display">\[\theta_{t+1} = \theta_t - \frac{\alpha}{\sqrt{s'_{t+1}}} v'_{t+1}\]</span></p>
</div><div class="column">
<h5 id="correcciones-iniciales">Correcciones Iniciales</h5>
<p><span class="math display">\[v'_{t+1} = \frac{v_{t+1}}{1-\beta_1^{t+1}}\]</span> <span class="math display">\[s'_{t+1} = \frac{s_{t+1}}{1-\beta_2^{t+1}}\]</span></p>
</div></div>
<div class="callout callout-tip no-icon callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<p><strong>Pros</strong></p>
</div>
<div class="callout-content">
<ul>
<li>Combina momentum + RMSprop + correcci√≥n <span class="math inline">\(\rightarrow\)</span> r√°pido, estable.</li>
<li>Es por lejos el optimizador m√°s usado.</li>
</ul>
</div>
</div>
</div>
<div class="callout callout-important no-icon callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<p><strong>Contras</strong></p>
</div>
<div class="callout-content">
<ul>
<li>Sensible a la elecci√≥n de sus hiperpar√°metros <span class="math inline">\(\beta_1\)</span> y <span class="math inline">\(\beta_2\)</span>. Pytorch utiliza 0.9 y 0.999 como valores de <span class="math inline">\(\beta_1\)</span> y <span class="math inline">\(\beta_2\)</span> respectivamente.</li>
</ul>
</div>
</div>
</div>
</section></section>
<section id="eso-es-todo-amigos" class="title-slide slide level1 center">
<h1>üëä Eso es todo amigos</h1>
<div class="footer">
<p xmlns:cc="http://creativecommons.org/ns#" xmlns:dct="http://purl.org/dc/terms/">
</p><p><span property="dct:title">Tics-579 Deep Learning</span> por Alfonso Tobar-Arancibia est√° licenciado bajo <a href="http://creativecommons.org/licenses/by-nc-sa/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;">CC BY-NC-SA 4.0</a></p><a href="http://creativecommons.org/licenses/by-nc-sa/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;">
<img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/nc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/sa.svg?ref=chooser-v1"></a>
<p></p>
</div>


</section>
    </div>
  <div class="quarto-auto-generated-content" style="display: none;">
<p><img src="../logo-uai-blanco.jpeg" class="slide-logo"></p>
<div class="footer footer-default">

</div>
</div></div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="../site_libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="../site_libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="../site_libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="../site_libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="../site_libs/revealjs/plugin/reveal-chalkboard/plugin.js"></script>
  <script src="../site_libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="../site_libs/revealjs/plugin/notes/notes.js"></script>
  <script src="../site_libs/revealjs/plugin/search/search.js"></script>
  <script src="../site_libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="../site_libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': false,
'previewLinksAuto': false,
'pdfSeparateFragments': true,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'jumpToSlide': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleScrollView(event)\"><kbd>r</kbd> Scroll View Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"5\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleChalkboard(event)\"><kbd>b</kbd> Toggle Chalkboard</a></li>\n<li class=\"slide-tool-item\" data-item=\"6\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleNotesCanvas(event)\"><kbd>c</kbd> Toggle Notes Canvas</a></li>\n<li class=\"slide-tool-item\" data-item=\"7\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.downloadDrawings(event)\"><kbd>d</kbd> Download Drawings</a></li>\n<li class=\"slide-tool-item\" data-item=\"8\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'chalkboard': {"buttons":true},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: true,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c/t',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'slide',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'fast',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1366,

        height: 768,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, RevealChalkboard, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    <script id="quarto-html-after-body" type="application/javascript">
      window.document.addEventListener("DOMContentLoaded", function (event) {
        const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
        tabsets.forEach(function(tabset) {
          const tabby = new Tabby('#' + tabset.id);
        });
        const isCodeAnnotation = (el) => {
          for (const clz of el.classList) {
            if (clz.startsWith('code-annotation-')) {                     
              return true;
            }
          }
          return false;
        }
        const onCopySuccess = function(e) {
          // button target
          const button = e.trigger;
          // don't keep focus
          button.blur();
          // flash "checked"
          button.classList.add('code-copy-button-checked');
          var currentTitle = button.getAttribute("title");
          button.setAttribute("title", "Copied!");
          let tooltip;
          if (window.bootstrap) {
            button.setAttribute("data-bs-toggle", "tooltip");
            button.setAttribute("data-bs-placement", "left");
            button.setAttribute("data-bs-title", "Copied!");
            tooltip = new bootstrap.Tooltip(button, 
              { trigger: "manual", 
                customClass: "code-copy-button-tooltip",
                offset: [0, -8]});
            tooltip.show();    
          }
          setTimeout(function() {
            if (tooltip) {
              tooltip.hide();
              button.removeAttribute("data-bs-title");
              button.removeAttribute("data-bs-toggle");
              button.removeAttribute("data-bs-placement");
            }
            button.setAttribute("title", currentTitle);
            button.classList.remove('code-copy-button-checked');
          }, 1000);
          // clear code selection
          e.clearSelection();
        }
        const getTextToCopy = function(trigger) {
            const codeEl = trigger.previousElementSibling.cloneNode(true);
            for (const childEl of codeEl.children) {
              if (isCodeAnnotation(childEl)) {
                childEl.remove();
              }
            }
            return codeEl.innerText;
        }
        const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
          text: getTextToCopy
        });
        clipboard.on('success', onCopySuccess);
        if (window.document.getElementById('quarto-embedded-source-code-modal')) {
          const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
            text: getTextToCopy,
            container: window.document.getElementById('quarto-embedded-source-code-modal')
          });
          clipboardModal.on('success', onCopySuccess);
        }
          var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
          var mailtoRegex = new RegExp(/^mailto:/);
            var filterRegex = new RegExp("https:\/\/datacubeR\.github\.io\/clases_UAI\/");
          var isInternal = (href) => {
              return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
          }
          // Inspect non-navigation links and adorn them if external
         var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
          for (var i=0; i<links.length; i++) {
            const link = links[i];
            if (!isInternal(link.href)) {
              // undo the damage that might have been done by quarto-nav.js in the case of
              // links that we want to consider external
              if (link.dataset.originalHref !== undefined) {
                link.href = link.dataset.originalHref;
              }
            }
          }
        function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
          const config = {
            allowHTML: true,
            maxWidth: 500,
            delay: 100,
            arrow: false,
            appendTo: function(el) {
                return el.closest('section.slide') || el.parentElement;
            },
            interactive: true,
            interactiveBorder: 10,
            theme: 'light-border',
            placement: 'bottom-start',
          };
          if (contentFn) {
            config.content = contentFn;
          }
          if (onTriggerFn) {
            config.onTrigger = onTriggerFn;
          }
          if (onUntriggerFn) {
            config.onUntrigger = onUntriggerFn;
          }
            config['offset'] = [0,0];
            config['maxWidth'] = 700;
          window.tippy(el, config); 
        }
        const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
        for (var i=0; i<noterefs.length; i++) {
          const ref = noterefs[i];
          tippyHover(ref, function() {
            // use id or data attribute instead here
            let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
            try { href = new URL(href).hash; } catch {}
            const id = href.replace(/^#\/?/, "");
            const note = window.document.getElementById(id);
            if (note) {
              return note.innerHTML;
            } else {
              return "";
            }
          });
        }
        const findCites = (el) => {
          const parentEl = el.parentElement;
          if (parentEl) {
            const cites = parentEl.dataset.cites;
            if (cites) {
              return {
                el,
                cites: cites.split(' ')
              };
            } else {
              return findCites(el.parentElement)
            }
          } else {
            return undefined;
          }
        };
        var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
        for (var i=0; i<bibliorefs.length; i++) {
          const ref = bibliorefs[i];
          const citeInfo = findCites(ref);
          if (citeInfo) {
            tippyHover(citeInfo.el, function() {
              var popup = window.document.createElement('div');
              citeInfo.cites.forEach(function(cite) {
                var citeDiv = window.document.createElement('div');
                citeDiv.classList.add('hanging-indent');
                citeDiv.classList.add('csl-entry');
                var biblioDiv = window.document.getElementById('ref-' + cite);
                if (biblioDiv) {
                  citeDiv.innerHTML = biblioDiv.innerHTML;
                }
                popup.appendChild(citeDiv);
              });
              return popup.innerHTML;
            });
          }
        }
      });
      </script>
    <script>var lightboxQuarto = GLightbox({"closeEffect":"zoom","descPosition":"bottom","loop":false,"openEffect":"zoom","selector":".lightbox"});
    (function() {
      let previousOnload = window.onload;
      window.onload = () => {
        if (previousOnload) {
          previousOnload();
        }
        lightboxQuarto.on('slide_before_load', (data) => {
          const { slideIndex, slideNode, slideConfig, player, trigger } = data;
          const href = trigger.getAttribute('href');
          if (href !== null) {
            const imgEl = window.document.querySelector(`a[href="${href}"] img`);
            if (imgEl !== null) {
              const srcAttr = imgEl.getAttribute("src");
              if (srcAttr && srcAttr.startsWith("data:")) {
                slideConfig.href = srcAttr;
              }
            }
          } 
        });
      
        lightboxQuarto.on('slide_after_load', (data) => {
          const { slideIndex, slideNode, slideConfig, player, trigger } = data;
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(slideNode);
          }
        });
      
      };
      
    })();
              </script>
    

</body></html>