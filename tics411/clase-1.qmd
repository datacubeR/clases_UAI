---
title: "TICS-411 Minería de Datos"
subtitle: "Clase 1: Calidad de los Datos y Feature Engineering"
author: Alfonso Tobar-Arancibia
institute: <alfonso.tobar.a@edu.uai.cl>
format:
  revealjs: 
    width: 1366
    height: 768
    theme: simple
    slide-number: true
    controls: true
    controls-layout: edges
    controls-back-arrows: faded
    transition: slide
    transition-speed: fast
    chalkboard: true
    callout-appearance: simple
    logo: ../logo.jpg
    css: ../logo.css
    code-copy: true
    highlight-style: arrow
---

# Datos Tabulares 

## Tipos de Datos: Datos Tabulares {.smaller}

![](img/clase-0/tab_data.png){fig-align="center" .lightbox}

::: {.callout-tip}
* Filas: Observaciones, registros, instancias. (Normalmente independientes).
* Columnas: Variables, Atributos, Features.
:::
::: {.callout-note}
* Probablemente el tipo de datos más amigable.
* Requiere conocimiento de negocio (**Domain Knowledge**)
:::

::: {.callout-warning}
* Es un % bajísimo del total de datos existentes en el Mundo.
* Distintos tipos, por lo que normalmente requiere de algún tipo de **preprocesamiento**.
:::

## Data Types: Numéricos {.smaller}

Numéricos
: > Valores a los que se les puede aplicar alguna operación matemática. 


::: {.callout-tip }
* Discretas: Número finito o contable de valores. Integers (Enteros). Ej: `Número de Hijos`, `Cantidad de Productos`, `Edad`.
* Continuas: Existen infinitos puntos entre dos puntos. Floats (punto flotando o decimales). Ej. `Temperatura`, `Peso`.
:::

![](img/clase-1/cont_vs_disc.jpg){fig-align="center" .lightbox width="50%"}

## Data Types: Categóricos {.smaller}

Categóricos
: > Datos que representan una categoría. 

::: {.callout-tip}
* Nominales: Sólo nombres que no representan ningún orden. Ej: `Nacionalidad`, `género`, `ocupación`. 
* Ordinales: Que tienen un orden o jerarquía inherente. Ej: `Nivel de Escolaridad`, `tamaño`. 
:::

![](img/clase-1/nom_vs_ord.png){fig-align="center" .lightbox width="50%"}

::: {.callout-caution .fragment}
No todas las operaciones matemáticas son aplicables. Ej: Media, Mediana, Sumas, Restas, etc.
:::

## Data Types: Otros {.smaller}

Strings
: > Datos de texto, los cuales podrían eventualmente ser tratados y representar algo. Ej: `Rescatar comunas de una dirección`, `rescatar sexo desde el nombre`, etc.

Fechas
: > Datos tipo fecha, los cuales podrían eventualmente ser tratados y representar variables de algún tipo. Ej: `Rescatar Años`, `meses`, `días`, `semanas`, `trimestres (quarters)`, etc. 

Datos Geográficos
: > Datos que representan la ubicación geográfica de un elemento. Ej: `Latitud`, `Longitud`, `Coordenadas`.

::: {.callout-important .fragment}
Sin importar el tipo de dato el mayor problema es su **calidad**. 
:::

# Calidad de los Datos

## Calidad de los Datos: Ruido {.smaller}

Ruido
: Corresponde al error y extrema variabilidad en la medición en los datos. Este error puede ser aleatorio o sistemático. 

<br>

::: {.columns}
::: {.column }
![](img/clase-1/noise.png){width="75%" .lightbox fig-align="center"}
:::
::: {.column .fragment}
![](img/clase-1/signal.png){.lightbox fig-align="center"}
:::
::: 

::: {.callout-tip .fragment}
Se le llama `Señal` a la tendencia principal y representa la información significativa y valiosa de los datos.
:::



## Calidad de los Datos: Outliers {.smaller}

Outliers
: Son datos considerablemente diferentes a la mayoría del dataset. Dependiendo del caso pueden indicar casos `"interesantes"` o `errores de medición`. 


![](img/clase-1/outliers.png){.lightbox fig-align="center"}

::: {.callout-note}
* Es importante notar que dependiendo del caso puede ser una buena idea deshacerse de ellos. **¿En qué casos podría no ser necesario eliminarlos?**
:::

## Calidad de los Datos: Valores Faltantes {.smaller}

Missing Values
: > Son valores que por alguna razón no están presentes.

::: {.incremental}
* **Missing at Random (MAR)**: Son valores que no están presentes por causas que no se pueden controlar. **Ej**: No se registró, no se preguntó, fallas en el sistema de recolección de datos, etc.

* **Informative Missing**: Es un valor no aplicable. **Ej**: Sueldo en niños, Precio de la entrada de un concierto si es que **NO** compró entrada. 
:::

![](img/clase-1/na.jpg){fig-align="center" .lightbox width="70%" .fragment}



## Calidad de los Datos: Datos Duplicados {.smaller}

Duplicates
: Se refiere a registros que pueden estar total o parcialmente duplicados.


![](img/clase-1/dups.png){.lightbox fig-align="center"}

::: {.callout-warning}
Esto genera problemas en la confiabilidad de los datos. **¿Cuál es el registro correcto?**

**Ej**: Caso particular de una Jooycar (una startup de seguros). 
:::

## Calidad de los Datos: Dominio del Problema {.smaller}

![](img/clase-1/domain.png){.lightbox fig-align="center"}

:::::: {.callout-caution .fragment}
* Por lejos el problema de calidad más difícil de encontrar.
* Se requiere experiencia y conocimiento profundo del negocio para detectarlo.

**Ej**: Caso de Super Avances en Cencosud. 
:::

# Feature Engineering

## Feature Engineering 

Feature Engineering
: > También conocida como Ingeniería de Atributos, es el `arte` de trabajar las `features` existentes para *limpiar* o *corregir* variables existentes o *crear* nuevas variables.

Preprocesamiento
: > Se refiere al proceso de preparación de los datos para su ingreso a un modelo. En una primera parte puede incluir limpieza de datos corruptos, redundantes y/o irrelevantes. Por otra parte, también hace referencia a la transformación de datos para que puedan ser consumidos por un algoritmo.  

## Feature Engineering {.smaller}

* No existe un procedimiento estándar. 
* Revisar los datos y ver potenciales errores que puedan afectar el funcionamiento de un modelo. 

![](img/clase-1/cleaning.png){.lightbox fig-align="center" width="80%"}

## Preprocesamiento: Valores Faltantes {.smaller}

> Imputación: Se refiere al proceso de rellenar datos faltantes.

::: {.columns}
::: {.column}
![](img/clase-1/impute.jpeg){.lightbox fig-align="center"}
:::
::: {.column}
![](img/clase-1/mean_median.png){.lightbox fig-align="center"}
:::
::: 

::: {.callout-note .fragment}
Dependiendo del nivel de valores faltantes, es necesario evaluar la eliminación de registros o atributos completos de ser necesario. 
:::

## Preprocesamiento: Manejo de Outliers {.smaller}

Capping
: Se refiere al proceso de acotar un atributo eliminando los valores extremos o atípicos (outliers). 

::: {.columns}
::: {.column}
![](img/clase-1/winsorizer.jpg){.lightbox fig-align="center" width="80%"}
:::
::: {.column .fragment}
::: {.callout-note}
Al igual que en el caso anterior, es necesario evaluar la eliminación de registros si es que representan valores atípicos.
:::
:::
::: 

## Preprocesamiento: Manejo de Variables Categóricas {.smaller}

> La mayoría de los modelos no tienen la capacidad de poder lidiar con variables categóricas por lo que deben ser transformadas en una representación numérica antes de ingresar a un modelo. 


::: {.columns}
::: {.column width="70%" .fragment}
![One Hot Encoder](img/clase-1/ohe.png){.lightbox width="200%"} 
:::
::: {.column width="30%" .fragment}
![Ordinal Encoder](img/clase-1/ordinal.png){.lightbox} 
:::
::: 

::: {.callout-note .fragment}
* `One Hot Encoder` suele dar mejores resultados en modelos lineales modelos que dependan de distancias.
* `Ordinal Encoder` suele dar mejores resultados en modelos de árbol. 
:::

::: {.fragment}
#### ¿Son necesarias todas las columnas en un One Hot Encoder?
:::

## Preprocesamiento: Escalamiento {.smaller}

> El `escalamiento` se refiere al proceso de llevar distintas variables a una misma escala.


::: {.columns}
::: {.column width="60%"}
![](img/clase-1/scaling.png){.lightbox fig-align="center"} 

* Evitar que la escala de una "sobre-importancia" a una cierta variable.
* Permitir una mejor convergencia de los algoritmos. 
:::
::: {.column .fragment width="40%"}

#### StandardScaler (Normalización)
$$x_j=\frac{x_j-\mu_x}{\sigma_x}$$

::: {.callout-important}
* Este proceso fuerza (en la medida de lo posible) a tener media 0 y std 1. 
* Notar que $\sigma_x$ hace referencia a la varianza poblacional.

:::

#### MinMax Scaler
$$x_j=\frac{x_j-min(x_j)}{max(x_j)-min(x_j)}$$

::: {.callout-important}
Este proceso fuerza a los datos a distribuirse entre 0 y 1. 
:::

:::

::: 


## Preprocesamiento: Escalamiento {.smaller}

![](img/clase-1/df_scale.png){.lightbox fig-align="center" }

::: {.callout-note .fragment fragment-index=1}
* **Media**: 0.75
* **Std**: 3.1875
* **Min**: -2
* **Max**: 3
:::

::: {.callout-important .fragment fragment-index=2}
* **Centering (Centrado)**: Se le llama a la diferencia entre la variable y su media.
* **Scaling (Escalado)**: Se le llama al cuociente entre la variable y su Desviación Estándar.
* **StandardScaler (Normalización)**: Es Centrado y Escalado. 
:::


## Creación de Variables {.smaller}

Combinación
: > Combinar 2 o más variables. Ej: Calcular el área de un sitio a partir del ancho y largo. 

Transformación
: > Aplicar una operación a una variable. Ej: El logaritmo de las ganancias.

::: {.columns}
::: {.column}
Discretización (Binning)
: > Generar categorías a partir de una variable continua. 
:::
::: {.column .fragment}
![](img/clase-1/binning.png){fig-align="center" .lightbox width="35%"}
:::
::: 


## Creación de Variables

Ratios
: Es una medida que expresa la relación entre dos cantidades. Ej: Puntos por partido, cantidad de transacciones por mes, etc.

Agregación
: Agregar o agrupar información resumida de ciertas variables. Ej: Promedio de tiempo en aprobar un tipo de crédito. 

## Selección de Variables {.smaller}
> Se refiere al proceso de eliminar variables que pueden ser irrelevantes o poco significativas. 

![](img/clase-1/f_sel.png){.lightbox fig-align="center" width="40%"}

::: {.callout-tip}
* Procesos Manuales. 
* Procesos Automáticos:
  * PCA (Principal Component Analysis).
  * Recursive Feature Elimination. 
  * Recursive Feature Addition. 
  * Eliminación mediante alguna medida. 
:::

# Medidas

## Medidas {.smaller}

> Son métricas que permiten cuantificar la relación existente entre dos o más objetos.

![](img/clase-1/medidas_.png){.lightbox fig-align="center"}


## Medidas: Similaridad

![](img/clase-1/simil.png){.lightbox fig-align="center"}

## Medidas: Similaridad Nominal

:::: {.columns}
::: {.column width="60%" style="text-align: center;"}
* Disimilaridad: 
$$D =
\begin{cases}
0,  & \text{if $p=q$} \\[2ex]
1, & \text{if $p\neq q$}
\end{cases}
$$
:::
::: {.column width="40%" style="text-align: center;"}
* Similaridad:  
$$S =
\begin{cases}
1,  & \text{if $p=q$} \\[2ex]
0, & \text{if $p\neq q$}
\end{cases}
$$
:::
::::

<br>

::: {.columns .fragment}
::: {.column}
![](img/clase-1/s_nom.png){fig-align="center" .lightbox}
:::
::: {.column}
$$S(p,q) = 0$$
$$D(p,q) = 1$$
:::
::: 

## Medidas: Similaridad Ordinal

:::: {.columns}
::: {.column style="text-align: center;"}
* Disimilaridad: 
$$D = \frac{|p-q|}{n-1}$$
:::
::: {.column style="text-align: center;"}
* Similaridad:  
$$S = 1 - \frac{|p-q|}{n-1}$$
:::
::::

::: {.columns .fragment}
::: {.column}
![](img/clase-1/s_ord.png){fig-align="center" .lightbox}
:::
::: {.column}
$$S(p,q) = 1 - \frac{5 - 4}{6 - 1} = 0.8$$
:::
::: 

## Medidas: Similaridad Intervalo o Ratio {.smaller}

:::: {.columns}
::: {.column style="text-align: center;"}
* Disimilaridad: 
$$D = |p-q|$$
:::

::: {.column style="text-align: center;"}
* Similaridad:  
$$S = -D$$
$$S = \frac{1}{1+D}$$
$$S = 1 - \frac{d - min_d}{max_d - min_d}$$
:::
::::

::: {.fragment}
Sea $p=35 °C$ y $q = 40 °C$. Luego: 

$$ S(p,q) = -5$$
$$S(p,q) = \frac{1}{1 + 5} = 0.17$$
:::

## Medidas: Similaridad Datos Categóricos {.smaller}

> Sea `p` y `q` vectores de dimensión $m$ con *sólo atributos categóricos*. Para calcular la similaridad entre vectores se usa lo siguiente: 

$$Sim(p,q) = \sum_{i=1}^m S(p_i,q_i)$$

<br>

::: {.columns}

::: {.column width="30%"}

* Overlap: 
$$S(p_{a_i}, q_{a_i}) =
\begin{cases}
1,  & \text{if $p_{a_i} = q_{a_i}$} \\[2ex]
0, & \text{if $p_i\neq q_i$}
\end{cases}
$$

:::

::: {.column width="40%"}

* Frecuencia de Ocurrencia Inversa
$$S(p_i, q_i) = \frac{1}{p_k(p_i)^2}$$
:::

::: {.column width="30%"}

* Medida de Goodall

$$S(p_i, q_i) = 1 - p_k(p_i)^2$$
:::
::: 

::: {.callout-important}

* $p_k()$ se refiere a la probabilidad de ocurrencia del atributo k.
* Todas estas medidas son 0 si $p_i \neq q_i$
:::


## Medidas: Similaridad Datos Categóricos {.smaller}

![](img/clase-1/datos_cat.png){.lightbox fig-align="center" }


::: {.notes}

![](img/clase-1/sim_cat_1.png){.lightbox fig-align="center" width="70%"}

![](img/clase-1/simil_calc.png){.lightbox fig-align="center" width="70%"}
:::

#### ¿Cuánto vale la similaridad entre los siguientes registros?

* 1-4
* 2-5
* 7-8

## Medidas: Similaridad Datos Binarios {.smaller}

> Sea `p` y `q` vectores de dimensión $m$ con *sólo atributos binarios*. Para calcular la similaridad entre vectores se usa lo siguiente: 

::: {.columns}
::: {.column}
$$SMC = \frac{M_{00} + M_{11}}{M_{00} + M_{01} + M_{10} + M_{11}}$$ 

* Simple Matching Coefficient =  Número de Coincidencias / Total de Atributos
:::
::: {.column}
$$JC = \frac{M_{11}}{M_{01} + M_{10} + M_{11}}$$

* Jaccard Coefficient = Número de Coincidencias 11 / Número de Atributos distintos de Ceros.
:::
::: 

<br>

![](img/clase-1/sim_bin.png){.lightbox fig-align="center"}

## Medidas: Similaridad Datos Binarios {.smaller}

| name | $a_1$ | $a_2$ | $a_3$ |$a_4$ | $a_5$ | $a_6$ |$a_7$ | $a_8$ | $a_9$ |$a_{10}$ | 
|:----:|:----:|:----:|:----:|:----:|:----:|:----:|:----:|:----:|:----:|:----:|
|p_i|1|0|0|0|0|0|0|0|0|0|
|q_i|0|0|0|0|0|0|1|0|0|1|

<br>

:::: {.columns}
::: {.column width="50%"}
$$SMC = \frac{M_{00} + M_{11}}{M_{00} + M_{01} + M_{10} + M_{11}} = $$ 
$$JC = \frac{M_{11}}{M_{01} + M_{10} + M_{11}} = $$ 
:::

::: {.column width="50%"}
::: {.fragment fragment-index=1}
$$\frac{7 + 0}{7 + 2 + 1 + 0} = 0.7$$ 
:::

::: {.fragment fragment-index=2}
$$\frac{0}{2 + 1 + 0} = 0$$
:::
::: 
::::

## Medidas: Similaridad (Distancia Coseno) {.smaller}

> Sean $d_1$ y $d_2$ dos vectores. La distancia coseno se calcula como:

$$cos(d_1, d_2) = \frac{d_1 \cdot d_2}{||d_1||||d_2||}$$


| name | $a_1$ | $a_2$ | $a_3$ |$a_4$ | $a_5$ | $a_6$ |$a_7$ | $a_8$ | $a_9$ |$a_{10}$ | 
|:----:|:----:|:----:|:----:|:----:|:----:|:----:|:----:|:----:|:----:|:----:|
|d_1|3|2|0|5|0|0|0|2|0|0|
|d_2|1|0|0|0|0|0|1|1|0|2|
|d_3|6|4|0|10|0|0|0|4|0|0|

::: {.columns}
::: {.column width="30%" .fragment}
$$d_1 \cdot d_2 = 5$$
$$d_1 \cdot d_3 = 84$$
:::
::: {.column width="40%" .fragment}
$$||d_1|| = \sqrt{42} = 6.481$$
$$||d_2|| = \sqrt{6} = 2.449$$
$$||d_3|| = \sqrt{168} = 12.962$$
:::
::: {.column width="30%" .fragment}
$$cos(d_1, d_2) = 0.3150$$
$$cos(d_1, d_3) = 0.9999$$
:::
::: 

# Distancias

## Distancias {.smaller}

> Una métrica o función de distancia es una función que define una distancia para cada par de elementos de un conjunto. 
> Sean dos puntos `x` e `y`, una métrica o función de distancia debe satisfacer las siguientes condiciones: 

* No Negatividad: 
  * $d(x,y) = \ge 0$
* Identidad:
  * $d(x,y) = 0 \Leftrightarrow x = y$ 
* Simetría:
  * $d(x,y) = d(y,x)$
* Desigualdad Triangular:
  * $d(x,z) \le d(x,y) + d(y,z)$

## Distancias: Distancia Minkowski {.smaller}

$$d(p,q) = \left(\sum_{k=1}^m |p_k - q_k|^r\right)^{1/r}$$

::: {.columns}
::: {.column}
![](img/clase-1/data_dist.png){.lightbox fig-align="center" width="50%"}
:::
::: {.column}
* $r=1 \rightarrow$ Distancia Manhattan (L1).
* $r=2 \rightarrow$ Distancia Euclideana (L2).
* $r=\infty \rightarrow$ Distancia Chebyshev (L$\infty$).
  $$D_{ch}(p,q) = \underset{k}{max} |p_k - q_k|$$

::: {.callout-note}
**Resolvamos en [Colab](https://colab.research.google.com/?hl=es)**
:::
:::
::: 

:::::: {.callout-important}
* Se denomina `Matriz de Distancias` a la Matriz que contiene la distancia $d(p_i,p_j)$ en la coordenada $i,j$.
:::

## Distancias: Distancia Minkowski (Resultados)

![](img/clase-1/results_dist.png){.lightbox width="30%" fig-align="center"}

## Distancias: Distancia Mahalanobis {.smaller}

$$d(p,q) = \sqrt{(p-q)^T \Sigma^{-1}(p-q)}$$

donde $\Sigma$ es la `Matriz de Covarianza` de los datos de entrada.

$$cov(x,y) = \frac{1}{n-1}\sum_{i = 1}^n (x_i - \bar{x})(y_i - \bar{y})$$

* Para 2 variables p y q: 

$$\Sigma = \begin{bmatrix}
cov(p,p) & cov(p,q) \\
cov(q,p) & cov(q,q)
\end{bmatrix}
$$

#### Ejercicio: Supongamos las siguientes escalas de notas. Calcular la distancia entre la nota (1.0 y 7.0)

* test #1: 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0, 5.5, 6.0, 6.5, 7.0
* test #2: 1.0, 3.5, 3.6, 3.7, 3.8, 3.9, 4.0, 4.1, 4.2, 4.3, 4.4, 4.5, 7.0


## Distancias: Distancia Mahalanobis (Resultados) {.smaller}

::: {.columns}
::: {.column}
![](img/clase-1/mah_dist.png){.lightbox}
:::
::: {.column .incremental}

<br>

* test #1: $d(7.0,1.0) = \sqrt{(7-1)\frac{1}{3.79}(7-1)} = 3.08$
* test #2: $d(7.0,1.0) = \sqrt{(7-1)\frac{1}{1.59}(7-1)} = 4.76$
:::
::: 

::: {.callout-important .fragment}
* Es importante notar que la correlación existente entre los datos `influye en la distancia`. 
:::

## Correlación {.smaller}

> La correlación mide la relación lineal entre 2 atributos.

:::: {.columns}
::: {.column}
Correlación Poblacional
: $$\rho(X,Y) = corr(X,Y) = \frac{cov(X,Y)}{\sigma_X\sigma_Y}$$
:::
::: {.column}
Correlación Muestral o Pearson
: $$r(X,Y) = \frac{\sum_{i=1}^n (x_i - \bar{x})(y_i-\bar{y})}{S_xS_y}$$
:::
::::

![](img/clase-1/corr_examples.png){.lightbox fig-align="center" width="60%"}


## Correlación {.smaller}
![](img/clase-1/cage_corr.png){.lightbox fig-align="center" width="80%"}


::: {.callout-note .fragment}
* Es importante recalcar que `Causalidad` **no es igual** a `Correlación`.
* La `Correlación` no se ve afectada por la escala de los datos. 
:::


# Preguntas para terminar

* ¿En qué se diferencia un estimador muestral de uno poblacional?
* ¿Cuándo es preferible utilizar la Distancia de Mahalanobis?
* ¿Cuál es la diferencia entre Covarianza y Correlación?


# Danke Schön

::: {.footer}
<p xmlns:cc="http://creativecommons.org/ns#" xmlns:dct="http://purl.org/dc/terms/"><span property="dct:title">Tics-411 Minería de Datos</span> está licenciado bajo <a href="http://creativecommons.org/licenses/by-nc-sa/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;">CC BY-NC-SA 4.0

<img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/nc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/sa.svg?ref=chooser-v1"></a></p>
:::
