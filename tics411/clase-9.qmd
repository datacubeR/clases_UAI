---
title: "TICS-411 Minería de Datos"
subtitle: "Clase 8: Evaluación de Modelos"
author: Alfonso Tobar-Arancibia
institute: <alfonso.tobar.a@edu.uai.cl>
format:
  revealjs: 
    width: 1366
    height: 768
    theme: simple
    slide-number: true
    controls: true
    controls-layout: edges
    controls-back-arrows: faded
    transition: slide
    transition-speed: fast
    chalkboard: true
    callout-appearance: simple
    logo: ../logo.jpg
    css: ../logo.css
    code-copy: true
    highlight-style: arrow
    pdf-separate-fragments: true
---


# Evaluación de Modelos Supervisados 

## Evaluación {.smaller}

> La evaluación de modelos supervisados es fundamental. De no hacerlo de forma correcta podemos quedarnos con una idea muy equivocada del rendimiento del modelo.

* Esto es importante ya que un modelo con un rendimiento incorrecto puede entregar predicciones completamente inútiles. 

Cross Validation (Validación Cruzada)
: > Se debe evaluar el rendimiento de un modelo en un `dataset diferente` al que fue entrenado. Esta es la única manera en la que se puede medir el poder de generalización.

Generalización
: > Corresponde a la habilidad de un modelo de adaptarse apropiadamente a datos no vistos previamente. 

::: {.callout-important}
Para esto se asume que todos los datos son i.i.d (`idependent and identically distributed`). De no lograr esto, lograr buenos rendimientos es más difícil.
:::

## Intuición

::: {.fragment}
* Si tengo que estudiar para una prueba. Y sólo les entrego una pregunta para estudiar y no tiene respuesta.
    Ej: Calcule el coeficiente de Silueta.
* Qué pasa si ahora les doy la respuesta. 
* Qu









## Introducción al Aprendizaje Supervisado

Los modelos Predictivos/Supervisados tienen la capacidad de predecir valores en datos no vistos.

Aprenden mediante un `train_set` y evalúan su performance utilizando un `test_set`.

2 Tipos: 

* Clasificación 
* Regresión

## Definiciones

Features
Labels o Etiquetas

## Ejemplo Clasificación

> Queremos generar un algoritmo de aprendizaje tal que dado un cierto set de datos predigamos si es que a un niño se le dará o no permiso para jugar.

::: {.callout-tip}
Problema de Clasificación Binaria.
:::

::: {.columns}
::: {.column width="70%"}
![](img/clase-8/dataset_sunny.png){.lightbox fig-align="center" width="80%"}
:::
::: {.column width="30%"}
::: {.callout-important}
* Llamaremos Features a la `Matriz` variables que intentarán predecir la etiqueta (con título morado). 
* Llamaremos etiquetas al `vector` de valores a predecir (en azul). 
:::
:::
::: 

## Definiciones 

$$h_\theta(X) = f(X, \theta)$$


::: {.callout-tip}
* A $h_\theta(\cdot)$ la denominaremos `hipótesis` o simplemente `modelo`.
* $X$ será nuestro set de `features` ($n\times m$ donde $n$ es el número de observaciones y $m$ el número de features).  
* Cada fila de $X$ corresponde a un vector $x_i$ que representa una observación de nuestro set de features. 
* $\theta$ corresponde a los parámetros del modelo *(existen modelos paramétricos y no paramétricos)*. 
* Cada `algoritmo` tendrá su propio mapeo $f(\cdot)$ para tratar de *predecir* una etiqueta. 
:::

::: {.callout-note appearance="default"}

## Tipos de Hipótesis

* Si $h_\theta(X)$ devuelve valores discretos (o categóricos) hablaremos de un modelo de `Clasificación`. 
* Si $h_\theta(X)$ devuelve valores continuos hablaremos de un modelo de `Regresión`. 
:::

## Definiciones {.smaller}

::: {.callout-tip appearance="default"}
## Clasificación:
  * **Binaria**: La Clasificación es dicotómica, Perro o Gato, Sí o No, 1 o 0, Clase Positiva o Negativa.
  * **Multiclase**: La clasificación puede tener más de 2 clases, pero sólo una es posible.
    * Ej: Perro, Gato o Canario; 0, 1, 2, 3, 4.
  * **Multilabel**: La clasificación puede tener más de 2 clases, y más de una es posible a la vez.
    * Ej: Categorías de Libro: Puede ser Romance y Drama, Películas: Fantasía, Animación y Acción.
:::

::: {.callout-note appearance="default"}
##### Regresión:
  * **Simple**: Predigo sólo un valor. Ej: Predecir la Temperatura.
  * **Multiple**: Predigo varios valores continuos a la vez. 
    * Ej: Modelo para intentar estimar Temperatura y Humedad a la vez.
  * **Forecast**: Donde se utilizan valores pasados para estimar valores futuros.
    * Dadas mis ganancias pasadas, estimar las futuras. 
:::

## Clasificación: Intuición {.smaller}

![](img/clase-8/clf_ex.png){.lightbox fig-align="center" width="60%"}

> Supongamos el siguiente problema de clasificación. Tenemos un algoritmo, que dadas las variables `Largo` y `Peso` sean capaces de predecir si es que un Pez es una *Reineta* o una *Sardina*.

## Clasificación: Intuición 

![](img/clase-8/clf_1.png){.lightbox fig-align="center" width="60%"}

::: {.callout-tip}
Queremos encontrar una `Regla de Decisión` (Decision Rule) que permita clasificar correctamente un punto nuevo.
:::

## K-Nearest Neighbors {.smaller}

> El modelo de vecinos más cercanos, o KNN por sus siglas en Inglés es un modelo basado en `distancias`. Su `regla de decisión` se basa en imitar el comportamiento de sus $K$ vecinos más cercanos por votación (para clasificación) o la media (para regresión).

::: {.callout-tip}
K es un `hiperparámetro` de este modelo. 
:::

::: {.columns}
::: {.column}
![](img/clase-8/knn_ex.png){.lightbox fig-align="center" width="60%"}
:::
::: {.column}
* Supongamos $K = 3$.
* Es decir, tomaremos los 3 vecinos más cercanos. 

::: {.callout-note}
En general es una buena idea elegir vecinos impares. **¿Por qué?**
:::
:::
::: 


## KNN: Paso 1 (Training Time)

Training Time
: Corresponde al periodo donde el modelo aprende de los datos. Toma un patrón y ese modelo es utilizado para predecir. 

::: {.callout-important}
En el caso de un KNN **NO HAY APRENDIZAJE** en esta etapa.
:::

## KNN: Paso 2 (Test Time) {.smaller}

Inference Time
: Corresponde al periodo donde el modelo debe emitir una predicción. 

En este caso, KNN calcula las distancias del punto a predecir (en verde) a todos los otros puntos existentes (proceso caro). 

::: {.columns}
::: {.column width="40%"}
![](img/clase-8/knn_ex.png){.lightbox fig-align="center" width="90%"}
:::
::: {.column width="30%"}
![](img/clase-8/knn_dist.png){.lightbox fig-align="center" width="90%"}
:::
::: {.column width="30%"}
![](img/clase-8/ord_dist_knn.png){.lightbox fig-align="center" width="100%"}
:::
::: 

::: {.callout-note}
* La predicción corresponderá a la etiqueta mayoritaria por `votacioń`

::: {.callout-note}
* La predicción corresponderá a la etiqueta mayoritaria por `votacioń`. 
* **¿Cuál sería una buena estrategia de predicción para un modelo de Regresión?**
:::
:::

## Fronteras de Decisión

![](img/clase-8/frontera_decision.png){.lightbox fig-align="center" width="40%"}

::: {.callout-note}
* Implicitamente, todo modelo de Machine Learning generará lo que se llama una Frontera de Decisión. 
* Si un punto no visto cae dentro de su frontera entonces se le asigna dicha etiqueta.
:::

## Implementación Clasificación en Scikit-Learn

```{.python code-line-numbers="|1|3-4|6-7|"}
from sklearn.neighbors import KNeighborsClassifier

knn_clf = KNeighborsClasifier(n_neighbors = 5, metric="minkowski", p=2, n_jobs=-1)
knn_clf.fit(X, y)

# Predicción...
y_pred = knn_clf.predict(X)
```
::: {style="font-size: 75%;"}

* **n_neighbors**: $K$ número de vecinos a utilizar. Por defecto 5.
* **metric**: Métrica de distancia. Por defecto "Minkowski". 
* **p**: Potencia de Minkowski: $p=1$, Manhattan, $p=2$ Euclideana. Por defecto $p=2$.
* **n_jobs**: Corresponde a un parámetro interno para poder paralelizar los cálculos. Se recomienda utilizar -1 para utilizar todos sus cores. 
:::

## Implementación Regresión en Scikit-Learn

```{.python code-line-numbers="|1|3-4|6-7|"}
from sklearn.neighbors import KNeighborsRegressor

knn_clf = KNeighborsRegressor(n_neighbors = 5, metric="minkowski", p=2, n_jobs=-1)
knn_clf.fit(X, y)

# Predicción...
y_pred = knn_clf.predict(X)
```
::: {style="font-size: 75%;"}

* **n_neighbors**: $K$ número de vecinos a utilizar. Por defecto 5.
* **metric**: Métrica de distancia. Por defecto "Minkowski". 
* **p**: Potencia de Minkowski: $p=1$, Manhattan, $p=2$ Euclideana. Por defecto $p=2$.
* **n_jobs**: Corresponde a un parámetro interno para poder paralelizar los cálculos. Se recomienda utilizar -1 para utilizar todos sus cores. 
:::

::: {.callout-caution}
¿Cómo se encuentran las predicciones en un modelo de **Regresión**?
:::

## KNN: Detalles Técnicos

::: {.callout-note appearance="default"}
## Fortalezas
* Modelo muy simple de implementar y entender. 
* Muy eficiente en el aprendizaje.
:::

::: {.callout-warning appearance="default"}
## Debilidades

* Inferencia ineficiente.
* `Curse of Dimensionality`: A medida que el número de dimensiones del problema crece, se requiere un incremento exponencial en la cantidad de datos para asegurar que existen suficientes vecinos cercanos para cualquier punto.

:::

# Saionara!


::: {.footer}
<p xmlns:cc="http://creativecommons.org/ns#" xmlns:dct="http://purl.org/dc/terms/"><span property="dct:title">Tics-411 Minería de Datos</span> está licenciado bajo <a href="http://creativecommons.org/licenses/by-nc-sa/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;">CC BY-NC-SA 4.0

<img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/nc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/sa.svg?ref=chooser-v1"></a></p>
:::