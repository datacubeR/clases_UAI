---
title: "TICS-411 Miner√≠a de Datos"
subtitle: "Clase 5: DBSCAN"
author: Alfonso Tobar-Arancibia
institute: <alfonso.tobar.a@edu.uai.cl>
format:
  revealjs: 
    width: 1366
    height: 768
    theme: simple
    slide-number: true
    controls: true
    controls-layout: edges
    controls-back-arrows: faded
    transition: slide
    transition-speed: fast
    chalkboard: true
    callout-appearance: simple
    logo: ../logo.jpg
    css: ../logo.css
    code-copy: true
    highlight-style: arrow
---


# Clustering por Densidad

## Clustering: Densidad

> Se basan en la idea de continuar el crecimiento de un cluster a medida que la densidad (n√∫mero de objetos o puntos) en el vecindario sobrepase alg√∫n umbral.

![](img/clase-3/densidad.png){.lightbox fig-align="center" }

::: {.callout-note}
En nuestro caso utilizaremos **DBSCAN** (Density-Based Spatial Clustering Applications with Noise). 
:::

## DBSCAN: Definiciones {.smaller}

::: {.callout-note appearance="default"}
## Hiperpar√°metros del Modelo
* `eps`: Radio de an√°lisis
* `MinPts`: Corresponde al m√≠nimo de puntos necesarios en un Radio `eps`. 

:::
::: {.columns}
::: {.column}
Densidad
: > Densidad es el n√∫mero de puntos dentro del radio `eps`. 

Core Point/Punto Central
: > Un punto central/core es aquel que tiene al menos `MinPts` puntos dentro de la esfera definida por `eps` (se incluye √©l mismo).

:::
::: {.column}
Border Point/Punto Borde
: > Un punto de borde tiene menos puntos que `MinPts` del `eps`, pero est√° dentro de la esfera de un punto central.

Noise Point/Punto Ruido
: > Un punto de ruido es todo aquel que no es punto central ni de borde.
:::
::: 

## DBSCAN: Algoritmo categorizaci√≥n de puntos {.smaller}

> Primeramente se aplica un algoritmo para categorizar cada punto de acuerdo a las definiciones anteriores.

* Para cada punto en el espacio: 
  * Calcular su densidad en EPS y aplicar el siguiente algoritmo:

![](img/clase-5/dbscan_algo.png){.lightbox fig-align="center" width="50%"}

## Ejemplo: Iteraci√≥n 1


::: {.columns}
::: {.column}

::: {.r-stack}
![](img/clase-5/ejemplo.png){.lightbox fig-align="center" .fragment fragment-index=1}

![](img/clase-5/ejemplo_1.png){.lightbox fig-align="center" .fragment fragment-index=2}

![](img/clase-5/ejemplo_2.png){.lightbox fig-align="center" .fragment fragment-index=3}
:::
:::

::: {.column}

![](img/clase-5/iter_1.png){.lightbox fig-align="center" .fragment fragment-index=2}

::: {.callout-note .fragment fragment-index=3}
Este punto corresponde a un **Core Point**.
:::
:::
::: 

## Ejemplo: Iteraci√≥n 2

::: {.columns}
::: {.column}

::: {.r-stack}
![](img/clase-5/border_1.png){.lightbox fig-align="center" }

![](img/clase-5/border_2.png){.lightbox fig-align="center" .fragment fragment-index=1}

:::
:::

::: {.column}

![](img/clase-5/border_algo.png){.lightbox fig-align="center" }

::: {.callout-note .fragment fragment-index=1}
Este punto corresponde a un **Border Point**.
:::
:::
::: 

## Ejemplo: Iteraci√≥n 3

::: {.columns}
::: {.column}

::: {.r-stack}
![](img/clase-5/noise_1.png){.lightbox fig-align="center" }

![](img/clase-5/noise_2.png){.lightbox fig-align="center" .fragment fragment-index=1}

:::
:::

::: {.column}

![](img/clase-5/noise_algo.png){.lightbox fig-align="center" }

::: {.callout-note .fragment fragment-index=1}
Este punto corresponde a un **Noise Point**.
:::
:::
::: 

## Ejemplo: Iteraci√≥n Final

![](img/clase-5/iter_final.png){.lightbox fig-align="center" }

::: {.callout-important}
Ahora, **¬øC√≥mo definimos que partes son clusters o no?**
:::

## Algoritmo de Clustering

Se aplica el siguiente algoritmo para calcular clusterings.

::: {.callout-important}
Antes de aplicar se desechan los Noise Points ya que no ser√°n considerados. **(Veremos luego que ocurre con estos puntos)**.
:::

```{.python code-line-numbers="|1|2|3-5|6|7-8|"}
label=0
for punto_c in corePoints:
    if punto_c no tiene etiqueta:
        label += 1
        punto_c = label
    for point_eps dentro de eps:
        if punto_eps no tiene etiqueta:
            punto_eps = label
```

## Iteraci√≥n 1

::: {.columns}
::: {.column}
:::{.r-stack}

![](img/clase-5/c1_0.png){.lightbox fig-align="center"}

![](img/clase-5/c1.png){.lightbox fig-align="center" .fragment fragment-index=1}

![](img/clase-5/c1_1.png){.lightbox fig-align="center" .fragment fragment-index=2}
:::
:::
::: {.column}

::: {.r-stack}
:::{.fragment .fade-in-then-out fragment-index=1 }
```{.python code-line-numbers="2-5"}
label=0
for punto_c in corePoints:
    if punto_c no tiene etiqueta:
        label += 1
        punto_c = label
    for point_eps dentro de eps:
        if punto_eps no tiene etiqueta:
            punto_eps = label
```
:::

:::{.fragment fragment-index=2 }
```{.python code-line-numbers="6-8"}
label=0
for punto_c in corePoints:
    if punto_c no tiene etiqueta:
        label += 1
        punto_c = label
    for point_eps dentro de eps:
        if punto_eps no tiene etiqueta:
            punto_eps = label
```
:::
:::

::: {.callout-note .fragment fragment-index=3}
Todos los puntos cercanos a un Core reciben la misma etiqueta.
:::

:::
::: 

## Iteraci√≥n 2

::: {.columns}
::: {.column}
:::{.r-stack}

![](img/clase-5/c2_0.png){.lightbox fig-align="center"}

![](img/clase-5/c2.png){.lightbox fig-align="center" .fragment fragment-index=1}

![](img/clase-5/c2_1.png){.lightbox fig-align="center" .fragment fragment-index=2}
:::
:::
::: {.column}

::: {.r-stack}
:::{.fragment .fade-in-then-out fragment-index=1 }
```{.python code-line-numbers="2-5"}
label=0
for punto_c in corePoints:
    if punto_c no tiene etiqueta:
        label += 1
        punto_c = label
    for point_eps dentro de eps:
        if punto_eps no tiene etiqueta:
            punto_eps = label
```
:::

:::{.fragment fragment-index=2 }
```{.python code-line-numbers="6-8"}
## label ya est√° en 1
for punto_c in corePoints:
    if punto_c no tiene etiqueta:
        label += 1
        punto_c = label
    for point_eps dentro de eps:
        if punto_eps no tiene etiqueta:
            punto_eps = label
```
:::
:::

::: {.callout-note .fragment fragment-index=3}
En este caso obtuvimos 2 clusters, e indirectamente un 3er de puntos ruido. 
:::

:::
::: 

## DBSCAN

![](img/clase-5/dbscan.png){.lightbox fig-align="center"}

::: {.callout-caution .fragment}
**¬øSer√≠a posible replicar un proceso de Clustering similar utilizando K-Means?** **¬øPor qu√©?**
:::


## DBSCAN: Detalles T√©cnicos

::: {.callout-note appearance="default"}
## Fortalezas
* Resistente al ruido.
* Puede lidiar con clusters de diferentes formas y tama√±os.
* No es necesario especificar cu√°ntos clusters encontrar.
:::

::: {.callout-warning appearance="default"}
## Debilidades

* Algoritmo de alta complejidad computacional que puede llegar $O(n^2)$ en el peor caso.
* Se ve afectado por densidad de los datos y por datos con una alta dimensionalidad.
* Su √≥ptimo resultado depende espec√≠ficamente de sus Hiperpar√°metros.
* No puede generalizar en datos no usados en entrenamiento. 
:::

## ¬øC√≥mo encontrar los Hiperpar√°metros?

::: {.columns}
::: {.column width="70%"}
::: {.callout-tip appearance="default"}
## minPts
Para datasets multidimensionales grandes, la regla es:

$$minPts \ge dim + 1$$
:::

::: {.callout-note appearance="default"}
## Otras recomendaciones:

* Para dos dimensiones: $minPts=4$ (Ester et al., 1996)
* Para m√°s de 2 dimensiones: $minPts = 2 \cdot dim$ (Sander et al., 1998)
:::
:::
::: {.column width="30%"}
<br>
<br>
<br>

![](img/clase-5/hp.png){.lightbox fig-align="center" width="80%"}
:::
::: 

## ¬øC√≥mo encontrar los Hiperpar√°metros? {.smaller}

> Para encontrar EPS se suele utilizar el m√©todo de Vecinos m√°s cercanos. 

::: {.columns}
::: {.column}
#### Idea

* La distancia de los puntos dentro de un cluster a su k-√©simo vecino deber√≠an ser similares. 

* Luego, los puntos at√≠picos (o ruidosos) tienen el k-√©simo vecino a una mayor distancia. 

::: {.callout-tip}
üí° Podemos plotear la distancia ordenada de cada punto a su k-√©simo vecino y seleccionar un `eps` cercano al crecimiento exponencial (codo). 
:::
:::
::: {.column}
![](img/clase-5/codo_dbscan.png){.lightbox fig-align="center"}
:::
::: 


## Implementaci√≥n en Scikit-Learn


```{.python code-line-numbers="|1|3|5-6|"}
from sklearn.cluster import DBSCAN

dbs = DBSCAN(min_samples = 5, eps = 0.5, metric = "euclidean")

## Se entrena y se genera la predicci√≥n
dbs.fit_predict(X)
```

::: {.columns style="font-size: 70%;"}
* **min_samples**: Corresponde a minPts. Por defecto 5.
* **eps**: Corresponde al radio de la esfera en la que se buscan los puntos cercanos. Por defecto 0.5.
*  **metric**: Corresponde a la distancia utilizada para medir la distancia. Permite todas las distancias mencionadas [ac√°](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise_distances.html#sklearn.metrics.pairwise_distances).

* `.fit_predict()`: Entrenar√° el modelo en los datos suministrados e inmediatamente genera el cluster asociado a cada elemento. Adicionalmente los puntos ruidosos se etiquetar√°n como -1. 
:::

üëÄ Veamos un ejemplo.  



# It's over!!

::: {.footer}
<p xmlns:cc="http://creativecommons.org/ns#" xmlns:dct="http://purl.org/dc/terms/"><span property="dct:title">Tics-411 Miner√≠a de Datos</span> est√° licenciado bajo <a href="http://creativecommons.org/licenses/by-nc-sa/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;">CC BY-NC-SA 4.0

<img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/nc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/sa.svg?ref=chooser-v1"></a></p>
:::