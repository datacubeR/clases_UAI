[
  {
    "objectID": "tics411-labs.html",
    "href": "tics411-labs.html",
    "title": "Prácticos",
    "section": "",
    "text": "Práctico\nColab\n\n\n\n\nPreprocesamiento\n\n\n\nEDA\n\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Notebooks"
    ]
  },
  {
    "objectID": "tics411/clase-3.html#definiciones",
    "href": "tics411/clase-3.html#definiciones",
    "title": "TICS-411 Minería de Datos",
    "section": "Definiciones",
    "text": "Definiciones\n\nAprendizaje No supervisado\n\n\nEs un tipo de aprendizaje que no requiere de etiquetas (las respuestas correctas) para poder aprender.\n\n\n\n\n\n\n\n\n\nEn nuestro caso nos enfocaremos en un caso particular de Modelación Descriptiva llamada Clustering.\n\n\n\n\nClustering\n\n\nConsiste en agrupar los datos en un menor número de entidades/grupos. A estos grupos se les conoce como clusters y pueden ser agrupados de manera global, o modelando las principales características de los datos."
  },
  {
    "objectID": "tics411/clase-3.html#intuición",
    "href": "tics411/clase-3.html#intuición",
    "title": "TICS-411 Minería de Datos",
    "section": "Intuición",
    "text": "Intuición\n¿Cuántos clusters se pueden apreciar?"
  },
  {
    "objectID": "tics411/clase-3.html#clustering-introducción",
    "href": "tics411/clase-3.html#clustering-introducción",
    "title": "TICS-411 Minería de Datos",
    "section": "Clustering: Introducción",
    "text": "Clustering: Introducción\n\n\n\n\n\n\n\nClustering: Consiste en buscar grupos de objetos tales que la similaridad intra-grupo sea alta, mientras que la similaridad inter-grupos sea baja. Normalmente la distancia es usada para determinar qué tan similares son estos grupos."
  },
  {
    "objectID": "tics411/clase-3.html#clustering-evaluación",
    "href": "tics411/clase-3.html#clustering-evaluación",
    "title": "TICS-411 Minería de Datos",
    "section": "Clustering: Evaluación",
    "text": "Clustering: Evaluación\n\n\n\n\n\n\n\nEvaluar el nivel del éxito o logro del Clustering es complicado. ¿Por qué?"
  },
  {
    "objectID": "tics411/clase-3.html#clustering-tipos",
    "href": "tics411/clase-3.html#clustering-tipos",
    "title": "TICS-411 Minería de Datos",
    "section": "Clustering: Tipos",
    "text": "Clustering: Tipos"
  },
  {
    "objectID": "tics411/clase-3.html#clustering-tipos-1",
    "href": "tics411/clase-3.html#clustering-tipos-1",
    "title": "TICS-411 Minería de Datos",
    "section": "Clustering: Tipos",
    "text": "Clustering: Tipos"
  },
  {
    "objectID": "tics411/clase-3.html#clustering-partición",
    "href": "tics411/clase-3.html#clustering-partición",
    "title": "TICS-411 Minería de Datos",
    "section": "Clustering: Partición",
    "text": "Clustering: Partición\n\nLos datos son separados en K clusters, donde cada punto pertenece exclusivamente a un único cluster."
  },
  {
    "objectID": "tics411/clase-3.html#clustering-densidad",
    "href": "tics411/clase-3.html#clustering-densidad",
    "title": "TICS-411 Minería de Datos",
    "section": "Clustering: Densidad",
    "text": "Clustering: Densidad\n\nSe basan en la idea de continuar el crecimiento de un cluster a medida que la densidad (número de objetos o puntos) en el vecindario sobrepase algún umbral."
  },
  {
    "objectID": "tics411/clase-3.html#clustering-jerarquía",
    "href": "tics411/clase-3.html#clustering-jerarquía",
    "title": "TICS-411 Minería de Datos",
    "section": "Clustering: Jerarquía",
    "text": "Clustering: Jerarquía\n\nLos algoritmos basados en jerarquía pueden seguir 2 estrategias:\n\n\n**Aglomerativos*n: Comienzan con cada objeto como un grupo (bottom-up). Estos grupos se van combinando sucesivamente a través de una métrica de similaridad. Para n objetos se realizan n-1 uniones.\nDivisionales: Comienzan con un solo gran cluster (bottom-down). Posteriormente este mega-cluster es dividido sucesivamente de acuerdo a una métrica de similaridad."
  },
  {
    "objectID": "tics411/clase-3.html#clustering-probabilístico",
    "href": "tics411/clase-3.html#clustering-probabilístico",
    "title": "TICS-411 Minería de Datos",
    "section": "Clustering: Probabilístico",
    "text": "Clustering: Probabilístico\nSe ajusta cada punto a una distribución de probabilidades que indica cuál es la probabilidad de pertenencia a dicho cluster."
  },
  {
    "objectID": "tics411/clase-3.html#partición",
    "href": "tics411/clase-3.html#partición",
    "title": "TICS-411 Minería de Datos",
    "section": "Partición",
    "text": "Partición\n\nLos datos son separados en K Clusters, donde cada punto pertenece exclusivamente a un único cluster.\n\n\n\n\n\n\n\n\nCluster Compactos: Minimizar la distancia intra-cluster (within cluster).\nClusters bien separados: Maximizar la distancia inter-cluster (between cluster).\n\n\n\n\n\\[ Score (C,D) = f(wc(C),bc(C))\\]\nEl puntaje/score mide la calidad del clustering \\(C\\) para el Dataset \\(D\\)."
  },
  {
    "objectID": "tics411/clase-3.html#score",
    "href": "tics411/clase-3.html#score",
    "title": "TICS-411 Minería de Datos",
    "section": "Score",
    "text": "Score\n\\[ Score (C,D) = f(wc(C),bc(C))\\]\n\n\n\n\nDistancia Between-Cluster: \\[bc(C) = \\sum_{1 \\le j \\le k \\le K} d(r_j, r_k)\\]\n\ndonde \\(r_k\\) representa el centro del cluster \\(k\\): \\[r_k = \\frac{1}{n_k} \\sum_{x_i \\in C_k} x_i\\]\n\n\nDistancia Within-Cluster: \\[wc(C) = \\sum_{k=1}^K \\sum_{x_i \\in C_k} d(x_i, r_k)\\]\n\n\n\n\n\n\n\n\n\n\n\nDistancia entre los centros de cada cluster.\n\n\n\n\n\n\n\n\n\n\nDistancia entre todos los puntos del cluster y su respectivo centro."
  },
  {
    "objectID": "tics411/clase-3.html#k-means",
    "href": "tics411/clase-3.html#k-means",
    "title": "TICS-411 Minería de Datos",
    "section": "K-Means",
    "text": "K-Means\n\nK-Means\n\n\nDado un número de clusters \\(K\\) (determinado por el usuario), cada cluster es asociado a un centro (centroide). Luego, cada punto es asociado al cluster con el centroide más cercano.\n\n\n\n\n\n\n\n\n\n\n\nNormalmente se utiliza la Distancia Euclideana como medida de similaridad.\n\n\nSe seleccionan \\(K\\) puntos como centroides iniciales.\nRepite:\n\nForma K clusters asignando todos los puntos al centroide más cercano.\nRecalcula el centroide para cada clase como la media de todos los puntos de dicho cluster.\n\n\n\nSe repite este procedimiento por un número finito de iteraciones o hasta que los centroides no cambien."
  },
  {
    "objectID": "tics411/clase-3.html#k-means-ejemplo",
    "href": "tics411/clase-3.html#k-means-ejemplo",
    "title": "TICS-411 Minería de Datos",
    "section": "K-Means: Ejemplo",
    "text": "K-Means: Ejemplo\nResolvamos el siguiente ejemplo.\nSupongamos que tenemos tipos de manzana, y cada una de ellas tiene 2 atributos (features). Agrupemos estos objetos en 2 grupos de manzanas basados en sus características."
  },
  {
    "objectID": "tics411/clase-3.html#k-means-ejemplo-1",
    "href": "tics411/clase-3.html#k-means-ejemplo-1",
    "title": "TICS-411 Minería de Datos",
    "section": "K-Means: Ejemplo",
    "text": "K-Means: Ejemplo\n1era Iteración\n\n\n\n\nDefinamos los centroides. \\[C_1 = (1,1)\\] \\[C_2 = (2,1)\\]\n\n\n\n\nCalculemos la Matriz de Distancias:\n\n\n\n\\[D^1 = \\begin{bmatrix}\n0 & 1 & 3.61 & 5\\\\\n1 & 0 & 2.83 & 4.24\n\\end{bmatrix}\\]\n\n\n\nCalculemos la Matriz de Pertenencia \\(G\\):\n\n\n\n\\[G^1 = \\begin{bmatrix}\n1 & 0 & 0 & 0 \\\\\n0 & 1 & 1 & 1\n\\end{bmatrix}\\]\n\n\n\n\n\n\n\n\nLos nuevos centroides son: \\[C_1 = (1,1)\\] \\[C_2 = (\\frac{11}{3}, \\frac{8}{3})\\]"
  },
  {
    "objectID": "tics411/clase-3.html#k-means-ejemplo-2",
    "href": "tics411/clase-3.html#k-means-ejemplo-2",
    "title": "TICS-411 Minería de Datos",
    "section": "K-Means: Ejemplo",
    "text": "K-Means: Ejemplo\n2da Iteración\n\n\n\n\nLos nuevos centroides son:\n\n\\[C_1 = (1,1)\\] \\[C_2 = (\\frac{11}{3}, \\frac{8}{3})\\]\n\n\n\nCalculemos la Matriz de Distancias:\n\n\n\n\\[D^1 = \\begin{bmatrix}\n0 & 1 & 3.61 & 5\\\\\n3.14 & 2.26 & 0.47 & 1.89\n\\end{bmatrix}\\]\n\n\n\nCalculemos la Matriz de Pertenencia \\(G\\):\n\n\n\n\\[G^1 = \\begin{bmatrix}\n1 & 1 & 0 & 0 \\\\\n0 & 0 & 1 & 1\n\\end{bmatrix}\\]\n\n\n\n\n\n\n\n\nLos nuevos centroides son: \\[C_1 = (1,1)\\] \\[C_2 = (\\frac{9}{2}, \\frac{7}{2})\\]"
  },
  {
    "objectID": "tics411/clase-3.html#k-means-ejemplo-3",
    "href": "tics411/clase-3.html#k-means-ejemplo-3",
    "title": "TICS-411 Minería de Datos",
    "section": "K-Means: Ejemplo",
    "text": "K-Means: Ejemplo\n\n\n\n\n\n\n\n\n\n\n\n\nSi seguimos iterando notaremos que ya no hay cambios en los clusters. El algoritmo converge.\nEste es el resultado de usar \\(K=2\\). Utilizar otro valor de \\(K\\) entregará valores distintos.\n¿Es este el número de clusters óptimos?"
  },
  {
    "objectID": "tics411/clase-3.html#k-means-número-de-clusters-óptimos",
    "href": "tics411/clase-3.html#k-means-número-de-clusters-óptimos",
    "title": "TICS-411 Minería de Datos",
    "section": "K-Means: Número de Clusters Óptimos",
    "text": "K-Means: Número de Clusters Óptimos\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSiempre es posible encontrar el número de clusters indicados.\nEntonces,\n\n¿Cómo debería escoger el valor de \\(K\\)?"
  },
  {
    "objectID": "tics411/clase-3.html#k-means-número-de-clusters-óptimos-1",
    "href": "tics411/clase-3.html#k-means-número-de-clusters-óptimos-1",
    "title": "TICS-411 Minería de Datos",
    "section": "K-Means: Número de Clusters Óptimos",
    "text": "K-Means: Número de Clusters Óptimos\n\nCurva del Codo\n\nEs una heurísitca en la cual gráfica el valor de una métrica de distancia (e.g. within distance) para distintos valores de \\(K\\). El valor óptimo de \\(K\\) será el codo de la curva, que es el valor donde se estabiliza la métrica.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEste valor del codo muchas veces es subjetivo y distintas apreciaciones pueden llegar a distintos \\(K\\) óptimos.\n\n\n\n\n\n\n\n\n\n\n\n\nEventualmente otras métricas distintas al within distance podrían también ser usadas."
  },
  {
    "objectID": "tics411/clase-3.html#k-means-detalles-técnicos",
    "href": "tics411/clase-3.html#k-means-detalles-técnicos",
    "title": "TICS-411 Minería de Datos",
    "section": "K-Means: Detalles Técnicos",
    "text": "K-Means: Detalles Técnicos\n\n\n\n\n\n\nFortalezas\n\n\n\nAlgoritmo relativamente eficiente (existen muy buenas implementaciones). \\(O(k \\cdot n \\cdot i)\\). Donde \\(k\\) es el número de clusters, \\(n\\) el número de puntos, e \\(i\\) el número de iteraciones.\nEncuentra clusters esféricos.\n\n\n\n\n\n\n\n\n\n\nDebilidades\n\n\n\nSensible al punto de inicio.\nSolo se puede aplicar cuando el promedio es calculable.\nSe requiere definir K a priori (K es un hiperparámetro).\nSuceptible al ruido."
  },
  {
    "objectID": "tics411/clase-1.html#tenemos-posible-ayudante-pero-tenemos-un-problema-de-horario.",
    "href": "tics411/clase-1.html#tenemos-posible-ayudante-pero-tenemos-un-problema-de-horario.",
    "title": "TICS-411 Minería de Datos",
    "section": "Tenemos (posible) ayudante, pero tenemos un problema de horario.",
    "text": "Tenemos (posible) ayudante, pero tenemos un problema de horario.\n\nHorario Actual: Viernes 20:00 a 21:10 hrs.\nHorario Propuesto: Lunes 11:45 a 12:55 hrs.\n\n\n\nTenemos pruebas:\n\nPrueba 1: Martes 30 de Abril 18:30 a 21:00\nPrueba 2: Martes 11 de Julio 18:30 a 21:00"
  },
  {
    "objectID": "tics411/clase-1.html#tipos-de-datos-datos-tabulares",
    "href": "tics411/clase-1.html#tipos-de-datos-datos-tabulares",
    "title": "TICS-411 Minería de Datos",
    "section": "Tipos de Datos: Datos Tabulares",
    "text": "Tipos de Datos: Datos Tabulares\n\n\n\n\n\n\n\n\n\n\n\n\nFilas: Observaciones, registros, instancias. (Normalmente independientes).\nColumnas: Variables, Atributos, Features.\n\n\n\n\n\n\n\n\n\n\n\nProbablemente el tipo de datos más amigable.\nRequiere conocimiento de negocio (Domain Knowledge)\n\n\n\n\n\n\n\n\n\n\n\nEs un % bajísimo del total de datos existentes en el Mundo.\nDistintos tipos, por lo que normalmente requiere de algún tipo de preprocesamiento."
  },
  {
    "objectID": "tics411/clase-1.html#data-types-numéricos",
    "href": "tics411/clase-1.html#data-types-numéricos",
    "title": "TICS-411 Minería de Datos",
    "section": "Data Types: Numéricos",
    "text": "Data Types: Numéricos\n\nNuméricos\n\n\nValores a los que se les puede aplicar alguna operación matemática.\n\n\n\n\n\n\n\n\n\n\nDiscretas: Número finito o contable de valores. Integers (Enteros). Ej: Número de Hijos, Cantidad de Productos, Edad.\nContinuas: Existen infinitos puntos entre dos puntos. Floats (punto flotando o decimales). Ej. Temperatura, Peso."
  },
  {
    "objectID": "tics411/clase-1.html#data-types-categóricos",
    "href": "tics411/clase-1.html#data-types-categóricos",
    "title": "TICS-411 Minería de Datos",
    "section": "Data Types: Categóricos",
    "text": "Data Types: Categóricos\n\nCategóricos\n\n\nDatos que representan una categoría.\n\n\n\n\n\n\n\n\n\n\nNominales: Sólo nombres que no representan ningún orden. Ej: Nacionalidad, género, ocupación.\nOrdinales: Que tienen un orden o jerarquía inherente. Ej: Nivel de Escolaridad, tamaño.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo todas las operaciones matemáticas son aplicables. Ej: Media, Mediana, Sumas, Restas, etc."
  },
  {
    "objectID": "tics411/clase-1.html#data-types-otros",
    "href": "tics411/clase-1.html#data-types-otros",
    "title": "TICS-411 Minería de Datos",
    "section": "Data Types: Otros",
    "text": "Data Types: Otros\n\nStrings\n\n\nDatos de texto, los cuales podrían eventualmente ser tratados y representar algo. Ej: Rescatar comunas de una dirección, rescatar sexo desde el nombre, etc.\n\n\nFechas\n\n\nDatos tipo fecha, los cuales podrían eventualmente ser tratados y representar variables de algún tipo. Ej: Rescatar Años, meses, días, semanas, trimestres (quarters), etc.\n\n\nDatos Geográficos\n\n\nDatos que representan la ubicación geográfica de un elemento. Ej: Latitud, Longitud, Coordenadas.\n\n\n\n\n\n\n\n\n\n\nSin importar el tipo de dato el mayor problema es su calidad."
  },
  {
    "objectID": "tics411/clase-1.html#calidad-de-los-datos-ruido",
    "href": "tics411/clase-1.html#calidad-de-los-datos-ruido",
    "title": "TICS-411 Minería de Datos",
    "section": "Calidad de los Datos: Ruido",
    "text": "Calidad de los Datos: Ruido\n\nRuido\n\nCorresponde al error y extrema variabilidad en la medición en los datos. Este error puede ser aleatorio o sistemático.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSe le llama Señal a la tendencia principal y representa la información significativa y valiosa de los datos."
  },
  {
    "objectID": "tics411/clase-1.html#calidad-de-los-datos-outliers",
    "href": "tics411/clase-1.html#calidad-de-los-datos-outliers",
    "title": "TICS-411 Minería de Datos",
    "section": "Calidad de los Datos: Outliers",
    "text": "Calidad de los Datos: Outliers\n\nOutliers\n\nSon datos considerablemente diferentes a la mayoría del dataset. Dependiendo del caso pueden indicar casos \"interesantes\" o errores de medición.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEs importante notar que dependiendo del caso puede ser una buena idea deshacerse de ellos. ¿En qué casos podría no ser necesario eliminarlos?"
  },
  {
    "objectID": "tics411/clase-1.html#calidad-de-los-datos-valores-faltantes",
    "href": "tics411/clase-1.html#calidad-de-los-datos-valores-faltantes",
    "title": "TICS-411 Minería de Datos",
    "section": "Calidad de los Datos: Valores Faltantes",
    "text": "Calidad de los Datos: Valores Faltantes\n\nMissing Values\n\n\nSon valores que por alguna razón no están presentes.\n\n\n\n\n\nMissing at Random (MAR): Son valores que no están presentes por causas que no se pueden controlar. Ej: No se registró, no se preguntó, fallas en el sistema de recolección de datos, etc.\nInformative Missing: Es un valor no aplicable. Ej: Sueldo en niños, Precio de la entrada de un concierto si es que NO compró entrada."
  },
  {
    "objectID": "tics411/clase-1.html#calidad-de-los-datos-datos-duplicados",
    "href": "tics411/clase-1.html#calidad-de-los-datos-datos-duplicados",
    "title": "TICS-411 Minería de Datos",
    "section": "Calidad de los Datos: Datos Duplicados",
    "text": "Calidad de los Datos: Datos Duplicados\n\nDuplicates\n\nSe refiere a registros que pueden estar total o parcialmente duplicados.\n\n\n\n\n\n\n\n\n\n\n\n\n\nEsto genera problemas en la confiabilidad de los datos. ¿Cuál es el registro correcto?\nEj: Caso particular de una Jooycar (una startup de seguros)."
  },
  {
    "objectID": "tics411/clase-1.html#calidad-de-los-datos-dominio-del-problema",
    "href": "tics411/clase-1.html#calidad-de-los-datos-dominio-del-problema",
    "title": "TICS-411 Minería de Datos",
    "section": "Calidad de los Datos: Dominio del Problema",
    "text": "Calidad de los Datos: Dominio del Problema\n\n\n\n\n\n\n\n\n\n\n\n\n\nPor lejos el problema de calidad más difícil de encontrar.\nSe requiere experiencia y conocimiento profundo del negocio para detectarlo.\n\nEj: Caso de Super Avances en Cencosud."
  },
  {
    "objectID": "tics411/clase-1.html#feature-engineering-1",
    "href": "tics411/clase-1.html#feature-engineering-1",
    "title": "TICS-411 Minería de Datos",
    "section": "Feature Engineering",
    "text": "Feature Engineering\n\nFeature Engineering\n\n\nTambién conocida como Ingeniería de Atributos, es el arte de trabajar las features existentes para limpiar o corregir variables existentes o crear nuevas variables.\n\n\nPreprocesamiento\n\n\nSe refiere al proceso de preparación de los datos para su ingreso a un modelo. En una primera parte puede incluir limpieza de datos corruptos, redundantes y/o irrelevantes. Por otra parte, también hace referencia a la transformación de datos para que puedan ser consumidos por un algoritmo."
  },
  {
    "objectID": "tics411/clase-1.html#feature-engineering-2",
    "href": "tics411/clase-1.html#feature-engineering-2",
    "title": "TICS-411 Minería de Datos",
    "section": "Feature Engineering",
    "text": "Feature Engineering\n\nNo existe un procedimiento estándar.\nRevisar los datos y ver potenciales errores que puedan afectar el funcionamiento de un modelo."
  },
  {
    "objectID": "tics411/clase-1.html#preprocesamiento-valores-faltantes",
    "href": "tics411/clase-1.html#preprocesamiento-valores-faltantes",
    "title": "TICS-411 Minería de Datos",
    "section": "Preprocesamiento: Valores Faltantes",
    "text": "Preprocesamiento: Valores Faltantes\n\nImputación: Se refiere al proceso de rellenar datos faltantes.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDependiendo del nivel de valores faltantes, es necesario evaluar la eliminación de registros o atributos completos de ser necesario."
  },
  {
    "objectID": "tics411/clase-1.html#preprocesamiento-manejo-de-outliers",
    "href": "tics411/clase-1.html#preprocesamiento-manejo-de-outliers",
    "title": "TICS-411 Minería de Datos",
    "section": "Preprocesamiento: Manejo de Outliers",
    "text": "Preprocesamiento: Manejo de Outliers\n\nCapping\n\nSe refiere al proceso de acotar un atributo eliminando los valores extremos o atípicos (outliers).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAl igual que en el caso anterior, es necesario evaluar la eliminación de registros si es que representan valores atípicos."
  },
  {
    "objectID": "tics411/clase-1.html#preprocesamiento-manejo-de-variables-categóricas",
    "href": "tics411/clase-1.html#preprocesamiento-manejo-de-variables-categóricas",
    "title": "TICS-411 Minería de Datos",
    "section": "Preprocesamiento: Manejo de Variables Categóricas",
    "text": "Preprocesamiento: Manejo de Variables Categóricas\n\nLa mayoría de los modelos no tienen la capacidad de poder lidiar con variables categóricas por lo que deben ser transformadas en una representación numérica antes de ingresar a un modelo.\n\n\n\n\n\n\nOne Hot Encoder\n\n\n\n\n\n\nOrdinal Encoder\n\n\n\n\n\n\n\n\n\n\n\n\nOne Hot Encoder suele dar mejores resultados en modelos lineales modelos que dependan de distancias.\nOrdinal Encoder suele dar mejores resultados en modelos de árbol.\n\n\n\n\n\n\n\n¿Son necesarias todas las columnas en un One Hot Encoder?"
  },
  {
    "objectID": "tics411/clase-1.html#preprocesamiento-escalamiento",
    "href": "tics411/clase-1.html#preprocesamiento-escalamiento",
    "title": "TICS-411 Minería de Datos",
    "section": "Preprocesamiento: Escalamiento",
    "text": "Preprocesamiento: Escalamiento\n\nEl escalamiento se refiere al proceso de llevar distintas variables a una misma escala.\n\n\n\n\n\n\n\n\n\nEvitar que la escala de una “sobre-importancia” a una cierta variable.\nPermitir una mejor convergencia de los algoritmos.\n\n\n\nStandardScaler (Normalización)\n\\[x_j=\\frac{x_j-\\mu_x}{\\sigma_x}\\]\n\n\n\n\n\n\n\nEste proceso fuerza (en la medida de lo posible) a tener media 0 y std 1.\nNotar que \\(\\sigma_x\\) hace referencia a la varianza poblacional.\n\n\n\n\nMinMax Scaler\n\\[x_j=\\frac{x_j-min(x_j)}{max(x_j)-min(x_j)}\\]\n\n\n\n\n\n\nEste proceso fuerza a los datos a distribuirse entre 0 y 1."
  },
  {
    "objectID": "tics411/clase-1.html#preprocesamiento-escalamiento-1",
    "href": "tics411/clase-1.html#preprocesamiento-escalamiento-1",
    "title": "TICS-411 Minería de Datos",
    "section": "Preprocesamiento: Escalamiento",
    "text": "Preprocesamiento: Escalamiento\n\n\n\n\n\n\n\n\n\n\n\n\n\nMedia: 0.75\nStd: 3.1875\nMin: -2\nMax: 3\n\n\n\n\n\n\n\n\n\n\n\n\n\nCentering (Centrado): Se le llama a la diferencia entre la variable y su media.\nScaling (Escalado): Se le llama al cuociente entre la variable y su Desviación Estándar.\nStandardScaler (Normalización): Es Centrado y Escalado."
  },
  {
    "objectID": "tics411/clase-1.html#creación-de-variables",
    "href": "tics411/clase-1.html#creación-de-variables",
    "title": "TICS-411 Minería de Datos",
    "section": "Creación de Variables",
    "text": "Creación de Variables\n\nCombinación\n\n\nCombinar 2 o más variables. Ej: Calcular el área de un sitio a partir del ancho y largo.\n\n\nTransformación\n\n\nAplicar una operación a una variable. Ej: El logaritmo de las ganancias.\n\n\n\n\n\n\nDiscretización (Binning)\n\n\nGenerar categorías a partir de una variable continua."
  },
  {
    "objectID": "tics411/clase-1.html#creación-de-variables-1",
    "href": "tics411/clase-1.html#creación-de-variables-1",
    "title": "TICS-411 Minería de Datos",
    "section": "Creación de Variables",
    "text": "Creación de Variables\n\nRatios\n\nEs una medida que expresa la relación entre dos cantidades. Ej: Puntos por partido, cantidad de transacciones por mes, etc.\n\nAgregación\n\nAgregar o agrupar información resumida de ciertas variables. Ej: Promedio de tiempo en aprobar un tipo de crédito."
  },
  {
    "objectID": "tics411/clase-1.html#selección-de-variables",
    "href": "tics411/clase-1.html#selección-de-variables",
    "title": "TICS-411 Minería de Datos",
    "section": "Selección de Variables",
    "text": "Selección de Variables\n\nSe refiere al proceso de eliminar variables que pueden ser irrelevantes o poco significativas.\n\n\n\n\n\n\n\n\n\n\n\n\n\nProcesos Manuales.\nProcesos Automáticos:\n\nPCA (Principal Component Analysis).\nRecursive Feature Elimination.\nRecursive Feature Addition.\nEliminación mediante alguna medida."
  },
  {
    "objectID": "tics411/clase-1.html#medidas-1",
    "href": "tics411/clase-1.html#medidas-1",
    "title": "TICS-411 Minería de Datos",
    "section": "Medidas",
    "text": "Medidas\n\nSon métricas que permiten cuantificar la relación existente entre dos o más objetos."
  },
  {
    "objectID": "tics411/clase-1.html#medidas-similaridad",
    "href": "tics411/clase-1.html#medidas-similaridad",
    "title": "TICS-411 Minería de Datos",
    "section": "Medidas: Similaridad",
    "text": "Medidas: Similaridad"
  },
  {
    "objectID": "tics411/clase-1.html#medidas-similaridad-nominal",
    "href": "tics411/clase-1.html#medidas-similaridad-nominal",
    "title": "TICS-411 Minería de Datos",
    "section": "Medidas: Similaridad Nominal",
    "text": "Medidas: Similaridad Nominal\n\n\n\nDisimilaridad: \\[D =\n\\begin{cases}\n0,  & \\text{if $p=q$} \\\\[2ex]\n1, & \\text{if $p\\neq q$}\n\\end{cases}\n\\]\n\n\n\nSimilaridad:\n\\[S =\n\\begin{cases}\n1,  & \\text{if $p=q$} \\\\[2ex]\n0, & \\text{if $p\\neq q$}\n\\end{cases}\n\\]\n\n\n\n\n\n\n\n\n\n\n\n\n\\[S(p,q) = 0\\] \\[D(p,q) = 1\\]"
  },
  {
    "objectID": "tics411/clase-1.html#medidas-similaridad-ordinal",
    "href": "tics411/clase-1.html#medidas-similaridad-ordinal",
    "title": "TICS-411 Minería de Datos",
    "section": "Medidas: Similaridad Ordinal",
    "text": "Medidas: Similaridad Ordinal\n\n\n\nDisimilaridad: \\[D = \\frac{|p-q|}{n}\\]\n\n\n\nSimilaridad:\n\\[S = 1 - \\frac{|p-q|}{n}\\]\n\n\n\n\n\n\n\n\n\n\n\n\\[S(p,q) = 1 - \\frac{5 - 4}{5} = 0.8\\]"
  },
  {
    "objectID": "tics411/clase-1.html#medidas-similaridad-intervalo-o-ratio",
    "href": "tics411/clase-1.html#medidas-similaridad-intervalo-o-ratio",
    "title": "TICS-411 Minería de Datos",
    "section": "Medidas: Similaridad Intervalo o Ratio",
    "text": "Medidas: Similaridad Intervalo o Ratio\n\n\n\nDisimilaridad: \\[D = |p-q|\\]\n\n\n\nSimilaridad:\n\\[S = -D\\] \\[S = \\frac{1}{1+D}\\]\n\n\n\n\nSea \\(p=35 °C\\) y \\(q = 40 °C\\). Luego:\n\\[ S(p,q) = -5\\] \\[S(p,q) = \\frac{1}{1 + 5} = 0.17\\]"
  },
  {
    "objectID": "tics411/clase-1.html#medidas-similaridad-datos-categóricos",
    "href": "tics411/clase-1.html#medidas-similaridad-datos-categóricos",
    "title": "TICS-411 Minería de Datos",
    "section": "Medidas: Similaridad Datos Categóricos",
    "text": "Medidas: Similaridad Datos Categóricos\n\nSea p y q vectores de dimensión \\(m\\) con sólo atributos categóricos. Para calcular la similaridad entre vectores se usa lo siguiente:\n\n\\[Sim(p,q) = \\sum_{i=1}^m S(p_i,q_i)\\]\n\n\n\n\nOverlap: \\[S(p_{a_i}, q_{a_i}) =\n\\begin{cases}\n1,  & \\text{if $p_{a_i} = q_{a_i}$} \\\\[2ex]\n0, & \\text{if $p_i\\neq q_i$}\n\\end{cases}\n\\]\n\n\n\nFrecuencia de Ocurrencia Inversa \\[S(p_i, q_i) = \\frac{1}{p_k(p_i)^2}\\]\n\n\n\nMedida de Goodall\n\n\\[S(p_i, q_i) = 1 - p_k(p_i)^2\\]\n\n\n\n\n\n\n\n\n\n\\(p_k()\\) se refiere a la probabilidad de ocurrencia del atributo k.\nTodas estas medidas son 0 si \\(p_i \\neq q_i\\)"
  },
  {
    "objectID": "tics411/clase-1.html#medidas-similaridad-datos-categóricos-1",
    "href": "tics411/clase-1.html#medidas-similaridad-datos-categóricos-1",
    "title": "TICS-411 Minería de Datos",
    "section": "Medidas: Similaridad Datos Categóricos",
    "text": "Medidas: Similaridad Datos Categóricos\n\n\n\n\n\nEjercicio Propuesto: ¿Cuánto vale la similaridad entre los siguientes registros?\n\n1-4\n2-5\n7-8"
  },
  {
    "objectID": "tics411/clase-1.html#medidas-similaridad-datos-binarios",
    "href": "tics411/clase-1.html#medidas-similaridad-datos-binarios",
    "title": "TICS-411 Minería de Datos",
    "section": "Medidas: Similaridad Datos Binarios",
    "text": "Medidas: Similaridad Datos Binarios\n\nSea p y q vectores de dimensión \\(m\\) con sólo atributos binarios. Para calcular la similaridad entre vectores se usa lo siguiente:\n\n\n\n\\[SMC = \\frac{M_{00} + M_{11}}{M_{00} + M_{01} + M_{10} + M_{11}}\\]\n\nSimple Matching Coefficient = Número de Coincidencias / Total de Atributos\n\n\n\\[JC = \\frac{M_{11}}{M_{01} + M_{10} + M_{11}}\\]\n\nJaccard Coefficient = Número de Coincidencias 11 / Número de Atributos distintos de Ceros."
  },
  {
    "objectID": "tics411/clase-1.html#medidas-similaridad-datos-binarios-1",
    "href": "tics411/clase-1.html#medidas-similaridad-datos-binarios-1",
    "title": "TICS-411 Minería de Datos",
    "section": "Medidas: Similaridad Datos Binarios",
    "text": "Medidas: Similaridad Datos Binarios\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nname\n\\(a_1\\)\n\\(a_2\\)\n\\(a_3\\)\n\\(a_4\\)\n\\(a_5\\)\n\\(a_6\\)\n\\(a_7\\)\n\\(a_8\\)\n\\(a_9\\)\n\\(a_{10}\\)\n\n\n\n\np_i\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\nq_i\n0\n0\n0\n0\n0\n0\n1\n0\n0\n1\n\n\n\n\n\n\n\\[SMC = \\frac{M_{00} + M_{11}}{M_{00} + M_{01} + M_{10} + M_{11}} = \\] \\[JC = \\frac{M_{11}}{M_{01} + M_{10} + M_{11}} = \\]\n\n\n\\[\\frac{7 + 0}{7 + 2 + 1 + 0} = 0.7\\]\n\n\n\\[\\frac{0}{2 + 1 + 0} = 0\\]"
  },
  {
    "objectID": "tics411/clase-1.html#medidas-similaridad-distancia-coseno",
    "href": "tics411/clase-1.html#medidas-similaridad-distancia-coseno",
    "title": "TICS-411 Minería de Datos",
    "section": "Medidas: Similaridad (Distancia Coseno)",
    "text": "Medidas: Similaridad (Distancia Coseno)\n\nSean \\(d_1\\) y \\(d_2\\) dos vectores. La distancia coseno se calcula como:\n\n\\[cos(d_1, d_2) = \\frac{d_1 \\cdot d_2}{||d_1||||d_2||}\\]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nname\n\\(a_1\\)\n\\(a_2\\)\n\\(a_3\\)\n\\(a_4\\)\n\\(a_5\\)\n\\(a_6\\)\n\\(a_7\\)\n\\(a_8\\)\n\\(a_9\\)\n\\(a_{10}\\)\n\n\n\n\nd_1\n3\n2\n0\n5\n0\n0\n0\n2\n0\n0\n\n\nd_2\n1\n0\n0\n0\n0\n0\n1\n1\n0\n2\n\n\nd_3\n6\n4\n0\n10\n0\n0\n0\n4\n0\n0\n\n\n\nEjercicio Propuesto: ¿Cuánto vale \\(cos(d_1,d_2)\\) y \\(cos(d_1,d_3)\\)?"
  },
  {
    "objectID": "tics411/clase-1.html#distancias-1",
    "href": "tics411/clase-1.html#distancias-1",
    "title": "TICS-411 Minería de Datos",
    "section": "Distancias",
    "text": "Distancias\n\nUna métrica o función de distancia es una función que define una distancia para cada par de elementos de un conjunto. Sean dos puntos x e y, una métrica o función de distancia debe satisfacer las siguientes condiciones:\n\n\nNo Negatividad:\n\n\\(d(x,y) = \\ge 0\\)\n\nIdentidad:\n\n\\(d(x,y) = 0 \\Leftrightarrow x = y\\)\n\nSimetría:\n\n\\(d(x,y) = d(y,x)\\)\n\nDesigualdad Triangular:\n\n\\(d(x,z) \\le d(x,y) + d(y,z)\\)"
  },
  {
    "objectID": "tics411/clase-1.html#distancias-distancia-minkowski",
    "href": "tics411/clase-1.html#distancias-distancia-minkowski",
    "title": "TICS-411 Minería de Datos",
    "section": "Distancias: Distancia Minkowski",
    "text": "Distancias: Distancia Minkowski\n\\[d(p,q) = \\left(\\sum_{k=1}^m |p_k - q_k|^r\\right)^{1/r}\\]\n\n\n\n\n\n\n\n\n\n\\(r=1 \\rightarrow\\) Distancia Manhattan (L1).\n\\(r=2 \\rightarrow\\) Distancia Euclideana (L2).\n\\(r=\\infty \\rightarrow\\) Distancia Chebyshev (L\\(\\infty\\)). \\[D_{ch}(p,q) = \\underset{k}{max} |p_k - q_k|\\]\n\n\n\n\n\n\n\nResolvamos en Colab\n\n\n\n\n\n\n\n\n\n\n\n\nSe denomina Matriz de Distancias a la Matriz que contiene la distancia \\(d(p_i,p_j)\\) en la coordenada \\(i,j\\)."
  },
  {
    "objectID": "tics411/clase-1.html#distancias-distancia-minkowski-resultados",
    "href": "tics411/clase-1.html#distancias-distancia-minkowski-resultados",
    "title": "TICS-411 Minería de Datos",
    "section": "Distancias: Distancia Minkowski (Resultados)",
    "text": "Distancias: Distancia Minkowski (Resultados)"
  },
  {
    "objectID": "tics411/clase-1.html#distancias-distancia-mahalanobis",
    "href": "tics411/clase-1.html#distancias-distancia-mahalanobis",
    "title": "TICS-411 Minería de Datos",
    "section": "Distancias: Distancia Mahalanobis",
    "text": "Distancias: Distancia Mahalanobis\n\\[d(p,q) = \\sqrt{(p-q)^T \\Sigma^{-1}(p-q)}\\]\ndonde \\(\\Sigma\\) es la Matriz de Covarianza de los datos de entrada.\n\\[cov(x,y) = \\frac{1}{n-1}\\sum_{i = 1}^n (x_i - \\bar{x})(y_i - \\bar{y})\\]\n\nPara 2 variables p y q:\n\n\\[\\Sigma = \\begin{bmatrix}\ncov(p,p) & cov(p,q) \\\\\ncov(q,p) & cov(q,q)\n\\end{bmatrix}\n\\]\nEjercicio: Supongamos las siguientes escalas de notas. Calcular la distancia entre la nota (1.0 y 7.0)\n\ntest #1: 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0, 5.5, 6.0, 6.5, 7.0\ntest #2: 1.0, 3.5, 3.6, 3.7, 3.8, 3.9, 4.0, 4.1, 4.2, 4.3, 4.4, 4.5, 7.0"
  },
  {
    "objectID": "tics411/clase-1.html#distancias-distancia-mahalanobis-resultados",
    "href": "tics411/clase-1.html#distancias-distancia-mahalanobis-resultados",
    "title": "TICS-411 Minería de Datos",
    "section": "Distancias: Distancia Mahalanobis (Resultados)",
    "text": "Distancias: Distancia Mahalanobis (Resultados)\n\n\n\n\n\n\ntest #1: \\(d(7.0,1.0) = \\sqrt{(7-1)\\frac{1}{3.79}(7-1)} = 3.08\\)\ntest #2: \\(d(7.0,1.0) = \\sqrt{(7-1)\\frac{1}{1.59}(7-1)} = 4.76\\)\n\n\n\n\n\n\n\n\n\n\n\nEs importante notar que la correlación existente entre los datos influye en la distancia."
  },
  {
    "objectID": "tics411/clase-1.html#correlación",
    "href": "tics411/clase-1.html#correlación",
    "title": "TICS-411 Minería de Datos",
    "section": "Correlación",
    "text": "Correlación\n\nLa correlación mide la relación lineal entre 2 atributos.\n\n\n\n\nCorrelación Poblacional\n\n\\[\\rho(X,Y) = corr(X,Y) = \\frac{cov(X,Y)}{\\sigma_X\\sigma_Y}\\]\n\n\n\n\nCorrelación Muestral o Pearson\n\n\\[r(X,Y) = \\frac{\\sum_{i=1}^n (x_i - \\bar{x})(y_i-\\bar{y})}{S_xS_y}\\]"
  },
  {
    "objectID": "tics411/clase-1.html#correlación-1",
    "href": "tics411/clase-1.html#correlación-1",
    "title": "TICS-411 Minería de Datos",
    "section": "Correlación",
    "text": "Correlación\n\n\n\n\n\n\n\n\n\n\n\n\n\nEs importante recalcar que Causalidad no es igual a Correlación.\nLa Correlación no se ve afectada por la escala de los datos."
  },
  {
    "objectID": "tics411/clase-1.html#medidas-similaridad-datos-categóricos-2",
    "href": "tics411/clase-1.html#medidas-similaridad-datos-categóricos-2",
    "title": "TICS-411 Minería de Datos",
    "section": "Medidas: Similaridad Datos Categóricos",
    "text": "Medidas: Similaridad Datos Categóricos"
  },
  {
    "objectID": "tics411/clase-1.html#medidas-similaridad-distancia-coseno-1",
    "href": "tics411/clase-1.html#medidas-similaridad-distancia-coseno-1",
    "title": "TICS-411 Minería de Datos",
    "section": "Medidas: Similaridad (Distancia Coseno)",
    "text": "Medidas: Similaridad (Distancia Coseno)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nname\n\\(a_1\\)\n\\(a_2\\)\n\\(a_3\\)\n\\(a_4\\)\n\\(a_5\\)\n\\(a_6\\)\n\\(a_7\\)\n\\(a_8\\)\n\\(a_9\\)\n\\(a_{10}\\)\n\n\n\n\nd_1\n3\n2\n0\n5\n0\n0\n0\n2\n0\n0\n\n\nd_2\n1\n0\n0\n0\n0\n0\n1\n1\n0\n2\n\n\nd_3\n6\n4\n0\n10\n0\n0\n0\n4\n0\n0\n\n\n\n\\[d_1 \\cdot d_2 = 5\\] \\[d_1 \\cdot d_3 = 84\\]\n\\[||d_1|| = \\sqrt{42} = 6.481\\] \\[||d_2|| = \\sqrt{6} = 2.449\\] \\[||d_3|| = \\sqrt{168} = 12.962\\]\n\\[cos(d_1, d_2) = 0.3150\\] \\[cos(d_1, d_3) = 0.9999\\]\n\n\n\n\n\n\n\n\nOne Hot Encoder\nOrdinal Encoder"
  },
  {
    "objectID": "tics411/notebooks/viz.html",
    "href": "tics411/notebooks/viz.html",
    "title": "Clases UAI",
    "section": "",
    "text": "import matplotlib.pyplot as plt\nimport numpy as np\n\na = np.array([4.5, 4, 4.1, 1, 2.3, 2.2, 2.4, 5, 5.5, 6.2, 6, 6, 6, 6])\nb = np.append(a, a + 1)\n\nfig = plt.figure(figsize=(20, 6))\nax = fig.subplot_mosaic(\"ABC\")\nax[\"A\"].hist(b, bins=5)\nax[\"A\"].set_title(\"Bins 5\")\nax[\"A\"].set_xlabel(\"Notas\")\nax[\"A\"].set_ylabel(\"Número de Estudiantes\")\nax[\"B\"].hist(b, bins=15)\nax[\"B\"].set_title(\"Bins 15\")\nax[\"B\"].set_xlabel(\"Notas\")\nax[\"C\"].hist(b, bins=30)\nax[\"C\"].set_title(\"Bins 30\")\nax[\"C\"].set_xlabel(\"Notas\")\nplt.show()\n\n\n\n\n\n\n\n\n\nfrom sklearn.neighbors import KernelDensity\n\n\nkd_gauss = KernelDensity(kernel=\"epanechnikov\")\nkd_gauss.fit(b[:, np.newaxis])\nx_grid = np.linspace(1, 6, 1000)\nb_gauss = np.exp(kd_gauss.score_samples(x_grid[:, np.newaxis]))\nplt.hist(b)\nplt.plot(b_gauss)\n\n\n\n\n\n\n\n\n\nfrom scipy.stats import norm\n\nnp.random.seed(0)\nx_grid = np.linspace(-4.5, 3.5, 1000)\nx = np.concatenate([norm(-1, 1.0).rvs(400), norm(1, 0.3).rvs(100)])\n\n\ndef kde_sklearn(x, x_grid, bandwidth=0.2, **kwargs):\n    \"\"\"Kernel Density Estimation with Scikit-learn\"\"\"\n    kde_skl = KernelDensity(bandwidth=bandwidth, **kwargs)\n    kde_skl.fit(x[:, np.newaxis])\n    # score_samples() returns the log-likelihood of the samples\n    log_pdf = kde_skl.score_samples(x_grid[:, np.newaxis])\n    return np.exp(log_pdf)\n\n\npdf = kde_sklearn(x, x_grid, bandwidth=0.2)\n\nplt.hist(x)\nplt.plot(x_grid, pdf)\n\n\n\n\n\n\n\n\n\nn = 100\nnp.random.seed(123)\nmuestra_1 = np.random.normal(loc=1, scale=0.5, size=int(n * 0.75))\nmuestra_2 = np.random.normal(loc=-1, scale=0.5, size=int(n * 0.25))\ndatos = np.hstack((muestra_1, muestra_2)) + 3\n\nX_grid = np.linspace(0, 7, 200)\n\nmodelo_kde = KernelDensity(kernel=\"tophat\", bandwidth=0.2)\nmodelo_kde.fit(datos.reshape(-1, 1))\n\nlog_densidad_pred = modelo_kde.score_samples(X_grid.reshape((-1, 1)))\n# Se aplica el exponente para deshacer el logaritmo\ndensidad_pred_tophat = np.exp(log_densidad_pred)\n\n\nn = 100\nnp.random.seed(123)\nmuestra_1 = np.random.normal(loc=1, scale=0.5, size=int(n * 0.75))\nmuestra_2 = np.random.normal(loc=-1, scale=0.5, size=int(n * 0.25))\ndatos = np.hstack((muestra_1, muestra_2)) + 3\n\nX_grid = np.linspace(0, 7, 200)\n\nmodelo_kde = KernelDensity(kernel=\"gaussian\", bandwidth=0.2)\nmodelo_kde.fit(datos.reshape(-1, 1))\n\nlog_densidad_pred = modelo_kde.score_samples(X_grid.reshape((-1, 1)))\n# Se aplica el exponente para deshacer el logaritmo\ndensidad_pred_gaussian = np.exp(log_densidad_pred)\n\n\nn = 100\nnp.random.seed(123)\nmuestra_1 = np.random.normal(loc=1, scale=0.5, size=int(n * 0.75))\nmuestra_2 = np.random.normal(loc=-1, scale=0.5, size=int(n * 0.25))\ndatos = np.hstack((muestra_1, muestra_2)) + 3\n\nX_grid = np.linspace(0, 7, 200)\n\nmodelo_kde = KernelDensity(kernel=\"epanechnikov\", bandwidth=0.2)\nmodelo_kde.fit(datos.reshape(-1, 1))\n\nlog_densidad_pred = modelo_kde.score_samples(X_grid.reshape((-1, 1)))\n# Se aplica el exponente para deshacer el logaritmo\ndensidad_pred_epa = np.exp(log_densidad_pred)\n\n\nfig = plt.figure(figsize=(20, 6))\nax = fig.subplot_mosaic(\"ABC\")\nax[\"A\"].hist(datos, bins=30, density=True, color=\"#3182bd\", alpha=0.5)\nax[\"A\"].plot(X_grid, densidad_pred_tophat, color=\"red\", label=\"predicción\")\nax[\"A\"].set_title(\"Kernel Uniforme/Tophat h=0.2\")\n\nax[\"B\"].hist(datos, bins=30, density=True, color=\"#3182bd\", alpha=0.5)\nax[\"B\"].plot(X_grid, densidad_pred_gaussian, color=\"red\", label=\"predicción\")\nax[\"B\"].set_title(\"Kernel Gaussiano h=0.2\")\n\nax[\"C\"].hist(datos, bins=30, density=True, color=\"#3182bd\", alpha=0.5)\nax[\"C\"].plot(X_grid, densidad_pred_epa, color=\"red\", label=\"predicción\")\nax[\"C\"].set_title(\"Kernel Epanechnikov h=0.2\")\n\nText(0.5, 1.0, 'Kernel Epanechnikov h=0.2')\n\n\n\n\n\n\n\n\n\n\nn = 1000\nnp.random.seed(123)\nmuestra_1 = np.random.normal(loc=1, scale=0.5, size=int(n * 0.75))\nmuestra_2 = np.random.normal(loc=-1, scale=0.5, size=int(n * 0.25))\ndatos = np.hstack((muestra_1, muestra_2))\n\nX_grid = np.linspace(-3, 4, 1000)\n\nmodelo_kde = KernelDensity(kernel=\"linear\", bandwidth=1)\nmodelo_kde.fit(datos.reshape(-1, 1))\n\nlog_densidad_pred = modelo_kde.score_samples(X_grid.reshape((-1, 1)))\n# Se aplica el exponente para deshacer el logaritmo\ndensidad_pred = np.exp(log_densidad_pred)\n\nfig, ax = plt.subplots(figsize=(7, 4))\nax.hist(datos, bins=30, density=True, color=\"#3182bd\", alpha=0.5)\nax.plot(X_grid, densidad_pred, color=\"red\", label=\"predicción\")\n\n\n\n\n\n\n\n\n\nimport seaborn as sns\n\ntitanic_df = sns.load_dataset(\"titanic\")\ntitanic_df[\"embarked\"].value_counts().plot(\n    kind=\"bar\", rot=0, title=\"Personas embarcadas por puerto del Titanic\"\n)\n\n\n\n\n\n\n\n\n\ntitanic_df.dtypes\n\nsurvived          int64\npclass            int64\nsex              object\nage             float64\nsibsp             int64\nparch             int64\nfare            float64\nembarked         object\nclass          category\nwho              object\nadult_male         bool\ndeck           category\nembark_town      object\nalive            object\nalone              bool\ndtype: object\n\n\n\ng = sns.catplot(\n    data=titanic_df, y=\"fare\", x=\"pclass\", kind=\"bar\", errorbar=None, hue=\"sex\"\n)\ng.figure.suptitle(\"Tarifa Promedio de Pasajeros del Titanic\\n por Clase y Sexo.\")\n\n\n\n\n\n\n\n\n\ndata = titanic_df[[\"age\", \"fare\"]].melt(value_vars=[\"age\", \"fare\"])\ndata\n\n\n\n\n\n\n\n\n\nvariable\nvalue\n\n\n\n\n0\nage\n22.00\n\n\n1\nage\n38.00\n\n\n2\nage\n26.00\n\n\n3\nage\n35.00\n\n\n4\nage\n35.00\n\n\n...\n...\n...\n\n\n1777\nfare\n13.00\n\n\n1778\nfare\n30.00\n\n\n1779\nfare\n23.45\n\n\n1780\nfare\n30.00\n\n\n1781\nfare\n7.75\n\n\n\n\n1782 rows × 2 columns\n\n\n\n\n\nsns.catplot(\n    kind=\"box\", x=\"variable\", y=\"value\", data=data, height=6, aspect=0.5, hue=\"variable\"\n)\n\n\n\n\n\n\n\n\n\niris_df = sns.load_dataset(\"iris\")\niris_df\n\n\n\n\n\n\n\n\n\nsepal_length\nsepal_width\npetal_length\npetal_width\nspecies\n\n\n\n\n0\n5.1\n3.5\n1.4\n0.2\nsetosa\n\n\n1\n4.9\n3.0\n1.4\n0.2\nsetosa\n\n\n2\n4.7\n3.2\n1.3\n0.2\nsetosa\n\n\n3\n4.6\n3.1\n1.5\n0.2\nsetosa\n\n\n4\n5.0\n3.6\n1.4\n0.2\nsetosa\n\n\n...\n...\n...\n...\n...\n...\n\n\n145\n6.7\n3.0\n5.2\n2.3\nvirginica\n\n\n146\n6.3\n2.5\n5.0\n1.9\nvirginica\n\n\n147\n6.5\n3.0\n5.2\n2.0\nvirginica\n\n\n148\n6.2\n3.4\n5.4\n2.3\nvirginica\n\n\n149\n5.9\n3.0\n5.1\n1.8\nvirginica\n\n\n\n\n150 rows × 5 columns\n\n\n\n\n\ndata = iris_df.melt(\n    value_vars=[\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\"]\n)\ndata\n\n\n\n\n\n\n\n\n\nvariable\nvalue\n\n\n\n\n0\nsepal_length\n5.1\n\n\n1\nsepal_length\n4.9\n\n\n2\nsepal_length\n4.7\n\n\n3\nsepal_length\n4.6\n\n\n4\nsepal_length\n5.0\n\n\n...\n...\n...\n\n\n595\npetal_width\n2.3\n\n\n596\npetal_width\n1.9\n\n\n597\npetal_width\n2.0\n\n\n598\npetal_width\n2.3\n\n\n599\npetal_width\n1.8\n\n\n\n\n600 rows × 2 columns\n\n\n\n\n\ng = sns.catplot(x=\"variable\", y=\"value\", kind=\"box\", hue=\"variable\", data=data)\ng.figure.suptitle(\"Distribución de Medidas de Flores\")\ng._legend.remove()\ng.set(xlabel=None)\ng.set(ylabel=None)\n\n\n\n\n\n\n\n\n\nplt.scatter(iris_df.sepal_length, iris_df.petal_length)\nplt.title(\"Relación entre Largo del Sépalo y del Pétalo\")\nplt.xlabel(\"Largo del Sépalo\")\nplt.ylabel(\"Largo del Pétalo\")\n\nText(0, 0.5, 'Largo del Pétalo')\n\n\n\n\n\n\n\n\n\n\nanscombe = sns.load_dataset(\"anscombe\")\n\nfig = plt.figure(figsize=(10, 9))\nax = fig.subplot_mosaic(\n    \"\"\"AB\n                        CD\"\"\"\n)\nsns.regplot(data=anscombe.query(\"dataset == 'I'\"), x=\"x\", y=\"y\", ax=ax[\"A\"], ci=None)\nsns.regplot(data=anscombe.query(\"dataset == 'II'\"), x=\"x\", y=\"y\", ax=ax[\"B\"], ci=None)\nsns.regplot(data=anscombe.query(\"dataset == 'III'\"), x=\"x\", y=\"y\", ax=ax[\"C\"], ci=None)\nsns.regplot(data=anscombe.query(\"dataset == 'IV'\"), x=\"x\", y=\"y\", ax=ax[\"D\"], ci=None)\nplt.suptitle(\"Cuarteto de Anscombe\")\n\nText(0.5, 0.98, 'Cuarteto de Anscombe')\n\n\n\n\n\n\n\n\n\n\nimport seaborn as sns\n\niris_df = sns.load_dataset(\"iris\")\niris_df\n\n\n\n\n\n\n\n\n\nsepal_length\nsepal_width\npetal_length\npetal_width\nspecies\n\n\n\n\n0\n5.1\n3.5\n1.4\n0.2\nsetosa\n\n\n1\n4.9\n3.0\n1.4\n0.2\nsetosa\n\n\n2\n4.7\n3.2\n1.3\n0.2\nsetosa\n\n\n3\n4.6\n3.1\n1.5\n0.2\nsetosa\n\n\n4\n5.0\n3.6\n1.4\n0.2\nsetosa\n\n\n...\n...\n...\n...\n...\n...\n\n\n145\n6.7\n3.0\n5.2\n2.3\nvirginica\n\n\n146\n6.3\n2.5\n5.0\n1.9\nvirginica\n\n\n147\n6.5\n3.0\n5.2\n2.0\nvirginica\n\n\n148\n6.2\n3.4\n5.4\n2.3\nvirginica\n\n\n149\n5.9\n3.0\n5.1\n1.8\nvirginica\n\n\n\n\n150 rows × 5 columns\n\n\n\n\n\nfrom sklearn.decomposition import PCA\nimport matplotlib.pyplot as plt\n\npca = PCA(n_components=2)\ndata = pca.fit_transform(iris_df.drop(columns=\"species\"))\nx, y = data[:,0], data[:,1]\n\nplt.scatter(x, y);\n\n\n\n\n\n\n\n\n\nc = iris_df.species.astype(\"category\").cat.codes\nplt.scatter(x,y, c = c)\nplt.title(\"3 Clusters\");\n\n\n\n\n\n\n\n\n\nc_prima = (c == 0).astype(\"int64\")\nplt.scatter(x,y, c= c_prima)\nplt.title(\"2 Clusters\")\n\nText(0.5, 1.0, '2 Clusters')\n\n\n\n\n\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "tics411/notebooks/distancia.html",
    "href": "tics411/notebooks/distancia.html",
    "title": "Clases UAI",
    "section": "",
    "text": "import pandas as pd\nimport numpy as np\n\ndf = pd.DataFrame(dict(x=[0, 2, 3, 5], y=[2, 0, 1, 1]))\n\ndf\n\n\n\n\n\n\n\n\n\nx\ny\n\n\n\n\n0\n0\n2\n\n\n1\n2\n0\n\n\n2\n3\n1\n\n\n3\n5\n1\n\n\n\n\n\n\n\n\n\ndef distancia_l1(p1, p2):\n    x1 = p1[\"x\"]\n    x2 = p2[\"x\"]\n    y1 = p1[\"y\"]\n    y2 = p2[\"y\"]\n\n    return np.abs(x1 - x2) + np.abs(y1 - y2)\n\n\ndef distancia_l2(p1, p2):\n    x1 = p1[\"x\"]\n    x2 = p2[\"x\"]\n    y1 = p1[\"y\"]\n    y2 = p2[\"y\"]\n    return np.sqrt((x1 - x2) ** 2 + (y1 - y2) ** 2)\n\n\ndef distancia_linf(p1, p2):\n    x1 = p1[\"x\"]\n    x2 = p2[\"x\"]\n    y1 = p1[\"y\"]\n    y2 = p2[\"y\"]\n    d_x = np.abs(x1 - x2)\n    d_y = np.abs(y1 - y2)\n    return np.max([d_x, d_y])\n\n\ndef calculate_matrix(distance, n_puntos):\n    m = np.zeros((n_puntos, n_puntos))\n    for i in range(n_puntos):\n        for j in range(n_puntos):\n            m[i, j] = distance(df.iloc[i], df.iloc[j])\n\n    return m\n\n\nm_m = calculate_matrix(distancia_l1, 4)\nm_e = calculate_matrix(distancia_l2, 4)\nm_c = calculate_matrix(distancia_linf, 4)\n\n\nm_m\n\narray([[0., 4., 4., 6.],\n       [4., 0., 2., 4.],\n       [4., 2., 0., 2.],\n       [6., 4., 2., 0.]])\n\n\n\nm_e\n\narray([[0.        , 2.82842712, 3.16227766, 5.09901951],\n       [2.82842712, 0.        , 1.41421356, 3.16227766],\n       [3.16227766, 1.41421356, 0.        , 2.        ],\n       [5.09901951, 3.16227766, 2.        , 0.        ]])\n\n\n\nm_c\n\narray([[0., 2., 3., 5.],\n       [2., 0., 1., 3.],\n       [3., 1., 0., 2.],\n       [5., 3., 2., 0.]])\n\n\n\na = pd.Series(\n    [1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0, 5.5, 6.0, 6.5, 7.0]\n)\nb = pd.Series(\n    [1.0, 3.5, 3.6, 3.7, 3.8, 3.9, 4.0, 4.1, 4.2, 4.3, 4.4, 4.5, 7.0]\n)\n\na.var(ddof=0)  # Varianza Poblacional\n\n3.5\n\n\n\na.var(ddof=1)  # Varianza Muestral\n\n3.7916666666666665\n\n\n\nb.var(ddof=1)\n\n1.5916666666666668\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "tics411/notebooks/02-EDA-solved.html",
    "href": "tics411/notebooks/02-EDA-solved.html",
    "title": "Medidas de Tendencia Central",
    "section": "",
    "text": "import seaborn as sns\nimport matplotlib.pyplot as plt\n\niris_df = sns.load_dataset(\"iris\")\ntitanic_df = sns.load_dataset(\"titanic\")\nts_df = sns.load_dataset(\"dowjones\")\niris_df\n\n\n\n\n\n\n\n\n\nsepal_length\nsepal_width\npetal_length\npetal_width\nspecies\n\n\n\n\n0\n5.1\n3.5\n1.4\n0.2\nsetosa\n\n\n1\n4.9\n3.0\n1.4\n0.2\nsetosa\n\n\n2\n4.7\n3.2\n1.3\n0.2\nsetosa\n\n\n3\n4.6\n3.1\n1.5\n0.2\nsetosa\n\n\n4\n5.0\n3.6\n1.4\n0.2\nsetosa\n\n\n...\n...\n...\n...\n...\n...\n\n\n145\n6.7\n3.0\n5.2\n2.3\nvirginica\n\n\n146\n6.3\n2.5\n5.0\n1.9\nvirginica\n\n\n147\n6.5\n3.0\n5.2\n2.0\nvirginica\n\n\n148\n6.2\n3.4\n5.4\n2.3\nvirginica\n\n\n149\n5.9\n3.0\n5.1\n1.8\nvirginica\n\n\n\n\n150 rows × 5 columns"
  },
  {
    "objectID": "tics411/notebooks/02-EDA-solved.html#medidas-de-tendencia-central",
    "href": "tics411/notebooks/02-EDA-solved.html#medidas-de-tendencia-central",
    "title": "Medidas de Tendencia Central",
    "section": "Medidas de Tendencia Central",
    "text": "Medidas de Tendencia Central\n\nprint(f\"Promedio de Ancho de Petalo {iris_df['sepal_width'].mean()}\")\nprint(f\"Mediana de Largo de Petalo {iris_df['sepal_length'].median()}\")\n\nPromedio de Ancho de Petalo 3.0573333333333337\nMediana de Largo de Petalo 5.8\n\n\n\nprint(f\"Moda de Especies: \")\niris_df[\"species\"].mode()\n\nModa de Especies: \n\n\n0        setosa\n1    versicolor\n2     virginica\nName: species, dtype: object\n\n\n\np25 = iris_df[\"sepal_width\"].quantile(q=0.25)\np50 = iris_df[\"sepal_width\"].quantile(q=0.50)\np75 = iris_df[\"sepal_width\"].quantile(q=0.75)\niris_df[\"sepal_width\"].median(), p25, p50, p75\n\n(3.0, 2.8, 3.0, 3.3)"
  },
  {
    "objectID": "tics411/notebooks/02-EDA-solved.html#medidas-de-dispersión",
    "href": "tics411/notebooks/02-EDA-solved.html#medidas-de-dispersión",
    "title": "Medidas de Tendencia Central",
    "section": "Medidas de Dispersión",
    "text": "Medidas de Dispersión\n\n# Mostrar error en caso de no usar numeric_only\niris_df.var(numeric_only=True, ddof=0)\n\nsepal_length    0.681122\nsepal_width     0.188713\npetal_length    3.095503\npetal_width     0.577133\ndtype: float64\n\n\n\niris_df.var(numeric_only=True, ddof=1)\n\nsepal_length    0.685694\nsepal_width     0.189979\npetal_length    3.116278\npetal_width     0.581006\ndtype: float64\n\n\n\niris_df.std(numeric_only=True, ddof=1)\n\nsepal_length    0.828066\nsepal_width     0.435866\npetal_length    1.765298\npetal_width     0.762238\ndtype: float64\n\n\n\n# Mostrar cómo se construye esta función...\ndef calculate_quantiles(column):\n    quantiles = iris_df.quantile([0.25, 0.75], numeric_only=True)\n    iqr_sl = quantiles.loc[0.75, column] - quantiles.loc[0.25, column]\n    return iqr_sl\n\n\ncalculate_quantiles(\"sepal_length\")\ncalculate_quantiles(\"petal_width\")\n\n1.5\n\n\n\niris_df.skew(numeric_only=True)\n\nsepal_length    0.314911\nsepal_width     0.318966\npetal_length   -0.274884\npetal_width    -0.102967\ndtype: float64\n\n\n\nCuando hacemos visualizaciones tenemos 2 formas de hacerlas: * Usar Pandas directamente y/o Matplotlib: Buena documentación, gráficos bonitos. * Usar Seaborn: Documentación Complicada, fácil para descubrir insights."
  },
  {
    "objectID": "tics411/notebooks/02-EDA-solved.html#visualizaciones-pandas",
    "href": "tics411/notebooks/02-EDA-solved.html#visualizaciones-pandas",
    "title": "Medidas de Tendencia Central",
    "section": "Visualizaciones: Pandas",
    "text": "Visualizaciones: Pandas\n\nHistogramas\n\niris_df.hist(figsize=(20, 6), bins=30, edgecolor=\"black\", grid=False)\nplt.tight_layout()\n\n\n\n\n\n\n\n\n\niris_df.plot(\n    kind=\"hist\", alpha=0.5, bins=30, figsize=(20, 6), edgecolor=\"black\"\n)\n# Notar que este genera todos los histogramas super puestos...\n\n\n\n\n\n\n\n\n\n\nBarplots\n\ntitanic_df[\"sex\"].value_counts().plot(\n    kind=\"bar\",\n    figsize=(5, 6),\n    title=\"Número de Pasajeros por Sexo...\",\n    edgecolor=\"black\",\n)\n\n\n\n\n\n\n\n\n\nPara este tipo de gráficas se requiere entender el concepto de agrupación…\n\n\n## Gráficar varias dimensiones\ntitanic_df.groupby(\"pclass\")[[\"age\", \"fare\"]].mean().plot(\n    kind=\"bar\", edgecolor=\"black\", title=\"Edad y Tarifa por cada Clase\"\n)\n\n\n\n\n\n\n\n\n\niris_df.groupby(\"species\").mean().plot(kind=\"bar\", edgecolor=\"black\")"
  },
  {
    "objectID": "tics411/notebooks/02-EDA-solved.html#boxplots",
    "href": "tics411/notebooks/02-EDA-solved.html#boxplots",
    "title": "Medidas de Tendencia Central",
    "section": "Boxplots",
    "text": "Boxplots\n\niris_df.drop(columns=\"species\").plot(kind=\"box\")\n\n\n\n\n\n\n\n\n\nPuntos\n\niris_df.plot(\n    x=\"petal_length\",\n    y=\"petal_width\",\n    kind=\"scatter\",\n    title=\"Largo de Pétalo vs Ancho de Pétalo\",\n    xlabel=\"Largo\",\n    ylabel=\"Ancho\",\n)\n\n\n\n\n\n\n\n\n\nts_df.plot(x=\"Date\", y=\"Price\", title=\"Evolución del Dow Jones\")\n\n\n\n\n\n\n\n\n\nfrom scipy.stats import norm\n\nts_df[\"AA\"] = ts_df[\"Price\"] + norm.rvs(size=649) * 55 + 1000\nts_df[\"BB\"] = -norm.rvs(size=649) * 55\n\nts_df.set_index(\"Date\").plot(title=\"Comparación distintas Tendencias\")\n\n\n\n\n\n\n\n\n\nfig = plt.figure(figsize=(20, 10))\nax = fig.subplot_mosaic(\n    \"\"\"AAA\n       BCC\"\"\"\n)\n\niris_df.drop(columns=\"species\").plot(\n    kind=\"box\", ax=ax[\"C\"], title=\"Distribución de Datos por Variable\"\n)\niris_df.plot(\n    x=\"petal_length\",\n    y=\"petal_width\",\n    kind=\"scatter\",\n    title=\"Largo de Pétalo vs Ancho de Pétalo\",\n    xlabel=\"Largo\",\n    ylabel=\"Ancho\",\n    ax=ax[\"B\"],\n)\niris_df.groupby(\"species\").mean().plot(\n    kind=\"bar\",\n    edgecolor=\"black\",\n    ax=ax[\"A\"],\n    rot=0,\n    title=\"Valores promedio por Especie\",\n)\nplt.suptitle(\"Súper Título\", fontsize=20)\n\nText(0.5, 0.98, 'Súper Título')"
  },
  {
    "objectID": "tics411/notebooks/02-EDA-solved.html#seaborn",
    "href": "tics411/notebooks/02-EDA-solved.html#seaborn",
    "title": "Medidas de Tendencia Central",
    "section": "Seaborn",
    "text": "Seaborn\n\nsns.catplot(kind=\"count\", data=titanic_df, y=\"embark_town\")\nplt.title(\"Pasajeros por Puerto\")\nsns.catplot(kind=\"count\", data=titanic_df, x=\"pclass\")\nplt.title(\"Pasajeros por Clase\")\n\nText(0.5, 1.0, 'Pasajeros por Clase')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEn el caso de querer entender los colores de Seaborn ver acá\n\n\n# Agrupar por ambos casos\nsns.catplot(\n    kind=\"count\", y=\"sex\", hue=\"pclass\", data=titanic_df, palette=\"Set1\"\n)\n\n\n\n\n\n\n\n\n\n## Barplot\nimport numpy as np\n\nsns.catplot(\n    kind=\"bar\",\n    x=\"sex\",\n    y=\"fare\",\n    data=titanic_df,\n    estimator=np.median,\n    errorbar=None,\n    hue=\"embark_town\",\n    col=\"pclass\",\n)\n\n\n\n\n\n\n\n\n\nHistogramas\n\nsns.displot(x=\"fare\", data=titanic_df, kind=\"kde\", height=4, aspect=6)\n\n\n\n\n\n\n\n\n\nsns.displot(x=\"fare\", data=titanic_df, height=4, aspect=6)\n\n\n\n\n\n\n\n\n\nsns.displot(x=\"fare\", data=titanic_df, kde=True, height=4, aspect=6)\n\n\n\n\n\n\n\n\n\nsns.relplot(\n    kind=\"scatter\", x=\"age\", y=\"fare\", data=titanic_df, hue=\"pclass\"\n)\n\n\n\n\n\n\n\n\n\nsns.relplot(x=\"Date\", y=\"Price\", data=ts_df, kind=\"line\")\nplt.title(\"Precio del Dow Jones\")\n\nText(0.5, 1.0, 'Precio del Dow Jones')\n\n\n\n\n\n\n\n\n\n\nnew_data = ts_df.melt(\n    id_vars=[\"Date\"],\n    value_vars=[\"AA\", \"BB\"],\n    var_name=\"Tipo\",\n    value_name=\"stock_price\",\n)\nnew_data\n\n\n\n\n\n\n\n\n\nDate\nTipo\nstock_price\n\n\n\n\n0\n1914-12-01\nAA\n1108.502557\n\n\n1\n1915-01-01\nAA\n1047.266778\n\n\n2\n1915-02-01\nAA\n962.881350\n\n\n3\n1915-03-01\nAA\n1087.728331\n\n\n4\n1915-04-01\nAA\n981.036020\n\n\n...\n...\n...\n...\n\n\n1293\n1968-08-01\nBB\n36.633113\n\n\n1294\n1968-09-01\nBB\n40.238166\n\n\n1295\n1968-10-01\nBB\n61.388597\n\n\n1296\n1968-11-01\nBB\n-16.274181\n\n\n1297\n1968-12-01\nBB\n-43.500801\n\n\n\n\n1298 rows × 3 columns\n\n\n\n\n\nsns.relplot(\n    kind=\"line\", y=\"stock_price\", x=\"Date\", data=new_data, hue=\"Tipo\"\n)\n\n\n\n\n\n\n\n\n\nsns.relplot(\n    kind=\"scatter\",\n    x=\"age\",\n    y=\"fare\",\n    data=titanic_df,\n    col=\"alone\",\n    hue=\"survived\",\n)\n\n\n\n\n\n\n\n\n\n# Esto es un insight... Los hombres solos sobrevivieron muchísimo más...\nsns.catplot(\n    kind=\"count\", x=\"sex\", hue=\"survived\", data=titanic_df, col=\"alone\"\n)\n\n\n\n\n\n\n\n\n\nEl contra de estos gráficos en Seaborn es que no permiten agregarse a un Layout Mosaic."
  },
  {
    "objectID": "tics411/clase-0.html#quién-soy",
    "href": "tics411/clase-0.html#quién-soy",
    "title": "TICS-411 Minería de Datos",
    "section": "¿Quién soy?",
    "text": "¿Quién soy?\n\n\n\n\n\n\n\nAlfonso Tobar-Arancibia, estudié Ingeniería Civil pero llevo 9 años trabajando como:\n\nData Analyst.\nData Scientist.\nML Engineer.\nData Engineer.\n\nTerminando mi Msc. y empezando mi PhD en la UAI.\nMe gusta mucho programar (en vivo).\nContribuyo a HuggingFace y Feature Engine.\nHe ganado 2 competencias de Machine Learning.\nPubliqué mi primer paper el año pasado sobre Hate Speech en Español.\nJuego Tenis de Mesa, hago Agility con mi perrita Kira y escribo en mi Blog."
  },
  {
    "objectID": "tics411/clase-0.html#objetivos-del-curso",
    "href": "tics411/clase-0.html#objetivos-del-curso",
    "title": "TICS-411 Minería de Datos",
    "section": "Objetivos del Curso",
    "text": "Objetivos del Curso\n\n\n\n\n\n\nIdentificar Elementos Claves del Machine Learning (Terminología, Nomenclatura, Intuición).\nEntender como interactúan los algoritmos más importantes.\nAprender a seleccionar el mejor Algoritmo para el Problema.\nEjecutar y aplicar algoritmos clásicos de Machine Learning.\nEvaluar el desempeño esperado del Modelo."
  },
  {
    "objectID": "tics411/clase-0.html#tópicos",
    "href": "tics411/clase-0.html#tópicos",
    "title": "TICS-411 Minería de Datos",
    "section": "Tópicos",
    "text": "Tópicos\n\n\n\n\n\n\n\nIntroducción a la Minería de Datos\nAnálisis Exploratorio de Datos (EDA)\nModelos No Supervisados/Descriptivos\nModelos Supervisados/Predictivos\n\n\n\n\n\n\nModelos no Supervisados\n\nK-Means\nHierarchical Clustering\nDBScan\nApriori\n\n\nModelos Supervisados\n\nKNN\nÁrboles de Decisión\nNaive Bayes\nRegresión Logística"
  },
  {
    "objectID": "tics411/clase-0.html#sobre-las-clases",
    "href": "tics411/clase-0.html#sobre-las-clases",
    "title": "TICS-411 Minería de Datos",
    "section": "Sobre las clases",
    "text": "Sobre las clases\n\n\nClases presenciales, con participación activa de los estudiantes.\nEs un curso coordinado.\nCanal oficial será Webcursos.\nMucha terminología y material de estudio será en Inglés.\nHorario: Jueves.\n\n15:30 a 16:40 (Cátedra)\n17:00 a 18:10 (Práctico)\nIdealmente!!\n\nAsistencia es voluntaria, pero altamente recomendada."
  },
  {
    "objectID": "tics411/clase-0.html#materiales-de-clases",
    "href": "tics411/clase-0.html#materiales-de-clases",
    "title": "TICS-411 Minería de Datos",
    "section": "Materiales de Clases",
    "text": "Materiales de Clases\n\nDiapositivas\nPrácticos\n\n\n\n\n\n\n\n\nSlides interactivas (Código se puede copiar e imágenes se pueden ver en grande).\nSe puede buscar contenido en las diapositivas mediante un buscador.\nSe dejarán copias en PDF en Webcursos (levemente distintas).\n\n\n\n\n\n\n\n\n\n\nSe espera que los estudiantes dominen las siguientes tecnologías:\n\nPython\nGoogle Colab\nPandas/Numpy\nScikit-Learn (Se enseñará a lo largo del curso)."
  },
  {
    "objectID": "tics411/clase-0.html#material-complementario",
    "href": "tics411/clase-0.html#material-complementario",
    "title": "TICS-411 Minería de Datos",
    "section": "Material Complementario",
    "text": "Material Complementario\n\n\n\n\n\n\nCurso de Scikit-Learn \n\nTutorial Colab\nAgregar Datos Externos a Colab"
  },
  {
    "objectID": "tics411/clase-0.html#evaluación",
    "href": "tics411/clase-0.html#evaluación",
    "title": "TICS-411 Minería de Datos",
    "section": "Evaluación",
    "text": "Evaluación\n\n\n\n\n\n\n\nDos Evaluaciones Escritas (P1, P2) coordinadas y cuatro tareas prácticas en parejas (T1, T2, T3, T4) \\[NP = 0.35 \\cdot P1 + 0.35 \\cdot P2 + 0.3 \\cdot \\bar{T}\\] \\[ \\bar{T} = (T1 + T2 + T3 + T4)/4 \\]\n\n\n\n\n\n\n\n\n\n\nSi NP &gt; 5\n\n\n\\[NF = NP\\]\n\n\n\n\n\n\n\n\n\nEn caso contrario:\n\n\n\\[NF = 0.7 \\cdot NP + 0.3 \\cdot E\\]"
  },
  {
    "objectID": "tics411/clase-0.html#ayudantías",
    "href": "tics411/clase-0.html#ayudantías",
    "title": "TICS-411 Minería de Datos",
    "section": "Ayudantías",
    "text": "Ayudantías\nAyudante: TBD\nemail: TBD\n\n\n\n\n\n\n\nLas ayudantías serán en la manera que sean necesarias.\nEstarán enfocadas principalmente en aplicaciones y código."
  },
  {
    "objectID": "tics411/clase-0.html#revolución-de-los-datos",
    "href": "tics411/clase-0.html#revolución-de-los-datos",
    "title": "TICS-411 Minería de Datos",
    "section": "Revolución de los Datos",
    "text": "Revolución de los Datos\n\n\n\n\n\n\n\nHablar de los distintos tipos de Datos.\nTodo es datos, y está lleno de ellos en Internet y el mundo."
  },
  {
    "objectID": "tics411/clase-0.html#nace-el-data-science-ciencia-de-datos",
    "href": "tics411/clase-0.html#nace-el-data-science-ciencia-de-datos",
    "title": "TICS-411 Minería de Datos",
    "section": "Nace el Data Science (Ciencia de Datos)",
    "text": "Nace el Data Science (Ciencia de Datos)\n\n\n\n\n\n\n\nExplicar las distintas etapas. Qué son cada uno de ellos.\nExplicar que no estoy de acuerdo con todas las definiciones."
  },
  {
    "objectID": "tics411/clase-0.html#cómo-aprovechar-la-información-que-tenemos",
    "href": "tics411/clase-0.html#cómo-aprovechar-la-información-que-tenemos",
    "title": "TICS-411 Minería de Datos",
    "section": "¿Cómo aprovechar la información que tenemos?",
    "text": "¿Cómo aprovechar la información que tenemos?\n\n\nData Mining (Minería de Datos)\n\n\n“The process of identifying valid, novel, potentially useful, and ultimately understandable patterns in data.” (Fayyad, Piatetsky-Shapiro & Smith 1996)\n\n\n\n\n\n\nMachine Learning (Aprendizaje Automático)\n\n\n“A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P, if its performance at tasks in T, as measured by P, improves with experience E.” (Mitchell, 2006)\n\n\n\n\n\n\nExplicar que estos son dos tipos de Approaches con el que hoy en día se enfrentan los datos.\nEl primero más enfocado en un análisis manual.\nEl segundo en un enfoque más automático."
  },
  {
    "objectID": "tics411/clase-0.html#tipos-de-datos",
    "href": "tics411/clase-0.html#tipos-de-datos",
    "title": "TICS-411 Minería de Datos",
    "section": "Tipos de Datos",
    "text": "Tipos de Datos\n\n\n\n\n\nDatos Estructurados\n\n\n\n\n\nDatos No Estructurados"
  },
  {
    "objectID": "tics411/clase-0.html#tipos-de-datos-datos-tabulares",
    "href": "tics411/clase-0.html#tipos-de-datos-datos-tabulares",
    "title": "TICS-411 Minería de Datos",
    "section": "Tipos de Datos: Datos Tabulares",
    "text": "Tipos de Datos: Datos Tabulares\n\n\n\n\n\n\n\n\n\n\n\n\nFilas: Observaciones, instancias, registros. (Normalmente independientes).\nColumnas: Variables, Atributos, Features.\n\n\n\n\n\n\n\n\n\n\n\nProbablemente el tipo de datos más amigable.\nRequiere conocimiento de negocio (Domain Knowledge)\n\n\n\n\n\n\n\n\n\n\n\nEs un % bajísimo del total de datos existentes en el Mundo. También el que más disponible está en las empresas.\nDistintos data types, por lo que normalmente requiere de algún tipo de preprocesamiento."
  },
  {
    "objectID": "tics411/clase-0.html#tipos-de-datos-series-de-tiempo",
    "href": "tics411/clase-0.html#tipos-de-datos-series-de-tiempo",
    "title": "TICS-411 Minería de Datos",
    "section": "Tipos de Datos: Series de Tiempo",
    "text": "Tipos de Datos: Series de Tiempo\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFilas: Instancias temporales (Normalmente interdependientes).\nColumnas: Variables, Atributos, Features (Univariada o Multivariada).\n\n\n\n\n\n\n\n\n\n\n\nEs un % bajísimo del total de datos existentes en el Mundo.\nPropiedad temporal requiere preprocesamiento y modelos especiales."
  },
  {
    "objectID": "tics411/clase-0.html#tipos-de-datos-imágenes",
    "href": "tics411/clase-0.html#tipos-de-datos-imágenes",
    "title": "TICS-411 Minería de Datos",
    "section": "Tipos de Datos: Imágenes",
    "text": "Tipos de Datos: Imágenes\n\n\n\n\n\n\n\n\n\n\n\n\n\nEste es el tipo de Datos que disparó la Inteligencia Artificial.\n¿Cuántos computadores para identificar un Gato? 16,000\n\n\n\n\n\n\n\n\n\n\n\n\n\nExplicar el concepto de Tensor, extensión de las matrices. Diferencia entre Grayscale y RGB."
  },
  {
    "objectID": "tics411/clase-0.html#tipos-de-datos-texto-libre",
    "href": "tics411/clase-0.html#tipos-de-datos-texto-libre",
    "title": "TICS-411 Minería de Datos",
    "section": "Tipos de Datos: Texto Libre",
    "text": "Tipos de Datos: Texto Libre\n\n\n\n\n\n\n\n\n\n\n\n\nDatos Masivos.\nDificiles de lidiar ya que deben ser llevarse a una representación numérica.\nAlto nivel de Sesgo y Subjetividad.\n\n\n\n\n\n\n\n\n\n\n\nGracias a este tipo de datos se han producido los avances más increíbles del último tiempo: Transformers"
  },
  {
    "objectID": "tics411/clase-0.html#tipos-de-datos-videos",
    "href": "tics411/clase-0.html#tipos-de-datos-videos",
    "title": "TICS-411 Minería de Datos",
    "section": "Tipos de Datos: Videos",
    "text": "Tipos de Datos: Videos\n\n\n\n\n\n\n\n\nLos videos no son más que arreglos de imágenes.\nSon un tipo de dato muy pesado y difícil de lidiar.\nRequiere alto poder de Procesamiento."
  },
  {
    "objectID": "tics411/clase-0.html#tipos-de-aprendizaje",
    "href": "tics411/clase-0.html#tipos-de-aprendizaje",
    "title": "TICS-411 Minería de Datos",
    "section": "Tipos de Aprendizaje",
    "text": "Tipos de Aprendizaje"
  },
  {
    "objectID": "tics411/clase-0.html#reinforcement-learning",
    "href": "tics411/clase-0.html#reinforcement-learning",
    "title": "TICS-411 Minería de Datos",
    "section": "Reinforcement Learning",
    "text": "Reinforcement Learning\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEn este tipo de aprendizaje se enseña por refuerzo. Es decir se da una recompensa si el sistema aprende lo que queremos.\n\n\n\n\n\n\n\n\n\n\n\nSi el premio es mayor, se pueden obtener aprendizajes mayores.\n\n\n\n\n\n\n\n\n\n\n\nUn ejemplo de esto es AlphaTensor en el cual un modelo aprendió una nueva manera de multiplicar matrices que es más eficiente.\n\n\n\n\n\n\n\n\n\n\n\nOtro ejemplo es AlphaFold donde el modelo aprendió/descubrió cómo se doblan las proteínas cuando se vuelven aminoácidos."
  },
  {
    "objectID": "tics411/clase-0.html#problemas-supervisados-regresión-y-clasificación",
    "href": "tics411/clase-0.html#problemas-supervisados-regresión-y-clasificación",
    "title": "TICS-411 Minería de Datos",
    "section": "Problemas Supervisados: Regresión y Clasificación",
    "text": "Problemas Supervisados: Regresión y Clasificación\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRegresión: Se busca estimar un valor continuo.\n\n(Estimar el valor de una casa).\n\nClasificación: Se busca encontrar una categoría o un valor discreto.\n\n(Clasificar una imagen como Perro o Gato).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPara entrenar este tipo de modelos se necesitan etiquetas, es decir, la respuesta esperada del modelo.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAmbos ejemplos se pueden realizar utilizando Largo (Eje Y) y Peso (Eje X)."
  },
  {
    "objectID": "tics411/clase-0.html#clustering",
    "href": "tics411/clase-0.html#clustering",
    "title": "TICS-411 Minería de Datos",
    "section": "Clustering",
    "text": "Clustering\n\n\n\n\n\n\n\n\n\n\n\n\n\nClusters: Una categoría en la que sus componentes son similares. Los clusters normalmente no tienen un nombre propio, sino que uno les asigna uno.\nTambién se les llama segmentos. No usar la palabra clase.\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo requiere de etiquetas, por lo tanto, no es posible evaluar su desempeño de manera 100% acertada."
  },
  {
    "objectID": "tics411/clase-0.html#reducción-de-dimensionalidad",
    "href": "tics411/clase-0.html#reducción-de-dimensionalidad",
    "title": "TICS-411 Minería de Datos",
    "section": "Reducción de Dimensionalidad",
    "text": "Reducción de Dimensionalidad\n\n\n\n\n\n\n\n\n\n\n\n\nReducción de la Dimensionalidad: Eliminar complejidad sin perder información clave para poder entender su comportamiento."
  },
  {
    "objectID": "tics411/clase-0.html#nuestro-sistema-de-ml",
    "href": "tics411/clase-0.html#nuestro-sistema-de-ml",
    "title": "TICS-411 Minería de Datos",
    "section": "Nuestro Sistema de ML",
    "text": "Nuestro Sistema de ML\nCreemos un Sistema de ML que sea capaz de ver una imágen y pronunciar correctamente el uso de la letra C.\n\n\n\n\n\n\nVamos a Entrenar un Modelo."
  },
  {
    "objectID": "tics411/clase-0.html#nuestro-sistema-de-ml-entrenamiento",
    "href": "tics411/clase-0.html#nuestro-sistema-de-ml-entrenamiento",
    "title": "TICS-411 Minería de Datos",
    "section": "Nuestro Sistema de ML: Entrenamiento",
    "text": "Nuestro Sistema de ML: Entrenamiento\n\n\n\n\n\n\nKasa\n\n\n\n\n\n\n\nKokodrilo\n\n\n\n\n\n\n\nKubo\n\n\n\n\n\n\n\n\n\n\n\n\n¿Qué patrones está aprendiendo el modelo?\n\n\n\n\n\nEntrenamiento\n\n\nEs el proceso en el cuál se permite al modelo aprender. En este proceso se le entregan ejemplos (Train Set) para que el modelo de manera autónoma pueda aprender patrones que le permitan resolver la tarea dada."
  },
  {
    "objectID": "tics411/clase-0.html#nuestro-sistema-de-ml-inferencia",
    "href": "tics411/clase-0.html#nuestro-sistema-de-ml-inferencia",
    "title": "TICS-411 Minería de Datos",
    "section": "Nuestro Sistema de ML: Inferencia",
    "text": "Nuestro Sistema de ML: Inferencia\n\nInferencia/Predicción\n\n\nSe refiere al proceso en el que el modelo tiene que demostrar cuál sería su decisión de acuerdo a los patrones aprendidos en el proceso de entrenamiento. Los ejemplos en los que se prueba se le denomina Test Set.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nKollar\n\n\nKonejo\n\n\nKukillo\n\n\nBikikleta\n\n\n\n\n\nGeneralización\n\n\nSe le llama generalización a la capacidad del modelo de aplicar lo aprendido de manera correcta en ejemplos no vistos."
  },
  {
    "objectID": "tics411/clase-0.html#nuestro-sistema-de-ml-nuevas-instancias-de-entrenamiento",
    "href": "tics411/clase-0.html#nuestro-sistema-de-ml-nuevas-instancias-de-entrenamiento",
    "title": "TICS-411 Minería de Datos",
    "section": "Nuestro Sistema de ML: Nuevas instancias de Entrenamiento",
    "text": "Nuestro Sistema de ML: Nuevas instancias de Entrenamiento\n\n\n\n\n\n\nKuchillo\n\n\n\n\n\n\n\nChokolate\n\n\n\n\n\n\n\nSinsel\n\n\n\n\n\n\n\n\n\n\n\n\nNo es bueno entrenar con las mismas instancias de de Test, es decir, con las cuales se evalúa el modelo. ¿Por qué?\n\n\n\n\n\nMencionar el caso de error de ImageNet."
  },
  {
    "objectID": "tics411/clase-0.html#nuestro-sistema-de-ml-reevaluemos-nuestro-modelo",
    "href": "tics411/clase-0.html#nuestro-sistema-de-ml-reevaluemos-nuestro-modelo",
    "title": "TICS-411 Minería de Datos",
    "section": "Nuestro Sistema de ML: Reevaluemos nuestro Modelo",
    "text": "Nuestro Sistema de ML: Reevaluemos nuestro Modelo\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nKollar\n\n\nKonejo\n\n\nKuchillo\n\n\nBisikleta\n\n\n\n\n\nEvaluación\n\n\nUtilizar una métrica que permita ponerle nota al modelo.\n\n\n\n\n\n\n1er Modelo: 2 correctas de 4, es decir 50%.\n\n\n\n\n2do Modelo: 4 correctas de 4, es decir 100%."
  },
  {
    "objectID": "tics411/clase-0.html#problemas-del-aprendizaje",
    "href": "tics411/clase-0.html#problemas-del-aprendizaje",
    "title": "TICS-411 Minería de Datos",
    "section": "Problemas del Aprendizaje",
    "text": "Problemas del Aprendizaje\n\nSupongamos que queremos utilizar nuestro modelo para pronunciar palabras en otro idioma (otro Test Set).\n¿Qué problemas podemos encontrar?\n\n\n\n\nStomach \\(\\rightarrow\\) Stomak\nArcher \\(\\rightarrow\\) Archer\nChurch \\(\\rightarrow\\) Churk\n\nChurch.\n\nArcheology \\(\\rightarrow\\) Archeology\n\nArkeology.\n\nChicago \\(\\rightarrow\\) Chicago\n\nShicago.\n\nMuscle \\(\\rightarrow\\) Muskle\n\nMus_le.\n\nIch mag Schweinefleisch \\(\\rightarrow\\) Ich mag Schweinefleisk.\n\nIj mag Shvaineflaish.\n\n\n\n\n\n\n\n\n\n\nClaramente tenemos un problema. ¿A qué se debe esto?"
  },
  {
    "objectID": "tics411/clase-0.html#problemas-del-aprendizaje-definiciones",
    "href": "tics411/clase-0.html#problemas-del-aprendizaje-definiciones",
    "title": "TICS-411 Minería de Datos",
    "section": "Problemas del Aprendizaje: Definiciones",
    "text": "Problemas del Aprendizaje: Definiciones\n\nOverfitting (Sobreajuste)\n\n\nSe refiere a cuando un modelo no es capaz de generalizar de manera correcta, porque se ajusta demasiado bien (llegando a memorizar) a los datos de entrenamiento. ¿Cómo se puede mitigar este problema?\n\n\n\n\n\n\n\n\n\n\nSe le tiende a llamar sobreentrenamiento, pero no es del todo correcto para el caso de modelos de Machine Learning. Lo más correcto es que el sobreentrenamiento provoca overfitting.\n\n\n\n\n\nMostrar ejemplos en Pizarra de manera gráfica. Ejemplos típicos de Excel.\n\n\n\nUnderfitting (Subajuste)\n\n\nSe refiere a cuando un modelo no es capaz de generalizar de manera correcta, pero a diferencia del overfitting no se ha ajustado correctamente a los datos. ¿Cómo se vería el underfitting en nuestro ejemplo?"
  },
  {
    "objectID": "tics411/clase-0.html#etapas-del-modelamiento-crisp-dm",
    "href": "tics411/clase-0.html#etapas-del-modelamiento-crisp-dm",
    "title": "TICS-411 Minería de Datos",
    "section": "Etapas del Modelamiento: Crisp-DM",
    "text": "Etapas del Modelamiento: Crisp-DM"
  },
  {
    "objectID": "tics411/clase-0.html#etapas-del-modelamiento-kdd",
    "href": "tics411/clase-0.html#etapas-del-modelamiento-kdd",
    "title": "TICS-411 Minería de Datos",
    "section": "Etapas del Modelamiento: KDD",
    "text": "Etapas del Modelamiento: KDD"
  },
  {
    "objectID": "tics411/clase-0.html#etapas-del-modelamiento-semma",
    "href": "tics411/clase-0.html#etapas-del-modelamiento-semma",
    "title": "TICS-411 Minería de Datos",
    "section": "Etapas del Modelamiento: Semma",
    "text": "Etapas del Modelamiento: Semma"
  },
  {
    "objectID": "tics411/clase-0.html#etapas-del-modelamiento-metodología-propia",
    "href": "tics411/clase-0.html#etapas-del-modelamiento-metodología-propia",
    "title": "TICS-411 Minería de Datos",
    "section": "Etapas del Modelamiento: Metodología Propia",
    "text": "Etapas del Modelamiento: Metodología Propia"
  },
  {
    "objectID": "tics411/clase-2.html#eda",
    "href": "tics411/clase-2.html#eda",
    "title": "TICS-411 Minería de Datos",
    "section": "EDA",
    "text": "EDA\n\nEl Analisis Exploratorio de Datos (EDA, por sus siglas en inglés) es procedimiento en el cual se analiza un dataset para explorar sus características principales.\n\n\nSu objetivo principal es poder familiarizarse con los datos además de encontrar potenciales problemas en su calidad.\nPrincipalmente hace uso de técnicas de manipulación de datos y visualizaciones.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLos hallazgos importantes dentro del proceso se les denomina insights.\n\n\n\n\n\n\n\n\n\nEl uso de visualizaciones inadecuadas podría llevar a conclusiones erróneas.\n\n\n\n\n\n\n\n\n\n\nSummary.\nVisualización."
  },
  {
    "objectID": "tics411/clase-2.html#medidas-de-tendencia-central",
    "href": "tics411/clase-2.html#medidas-de-tendencia-central",
    "title": "TICS-411 Minería de Datos",
    "section": "Medidas de Tendencia Central",
    "text": "Medidas de Tendencia Central"
  },
  {
    "objectID": "tics411/clase-2.html#medidas-de-dispersión-y-asimetría",
    "href": "tics411/clase-2.html#medidas-de-dispersión-y-asimetría",
    "title": "TICS-411 Minería de Datos",
    "section": "Medidas de Dispersión y Asimetría",
    "text": "Medidas de Dispersión y Asimetría"
  },
  {
    "objectID": "tics411/clase-2.html#eda-visualización",
    "href": "tics411/clase-2.html#eda-visualización",
    "title": "TICS-411 Minería de Datos",
    "section": "EDA: Visualización",
    "text": "EDA: Visualización\n\nLa visualización de datos es la presentación de datos en forma gráfica. Permite ver los análisis de modo que los responsables a cargo pueden comprender conceptos complejos.\n\n\nGracias a la evoluación del cerebro humano somos capaces de detectar patrones complejos en la naturaleza a partir de la Visión.\n\n\n\n\n\n\n\n\nPuede ser difícil de aplicar si el tamaño de los datos es grande (sea en instancias o atributos). Por ejemplo, si los datos están en 4 dimensiones.\n\n\n\n\n\n\n\n\n\n\n\n\nSe suelen resumir los datos en estadísticas simples.\nGraficar datos en 1D, 2D y 3D (evitar dentro de lo posible).\nLa visualización debe ser comprensible ojalá sin ninguna explicación.\n\n\n\n\n\n\n\n\n\n\n\n\nEn caso de datos de alta dimensionalidad puede ser una buena idea reducir dimensiones mediante técnicas como:\n\nPCA\nUMAP\netc."
  },
  {
    "objectID": "tics411/clase-2.html#caso-de-visualización",
    "href": "tics411/clase-2.html#caso-de-visualización",
    "title": "TICS-411 Minería de Datos",
    "section": "Caso de Visualización",
    "text": "Caso de Visualización\n\n\n\n\n\n\n\nFiguras\nEscala de Colores.\nTamaño de los puntos.\nDemasiada información en un sólo gráfico.\nNo se entiende el mensaje."
  },
  {
    "objectID": "tics411/clase-2.html#canales-visuales",
    "href": "tics411/clase-2.html#canales-visuales",
    "title": "TICS-411 Minería de Datos",
    "section": "Canales Visuales",
    "text": "Canales Visuales\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSe les llama canales visuales a elementos visuales que pueden expresarse para poder expresar información (Clase Visualizacion Andreas Mueller).\nLa idea es poder mapear valores a cada uno de estos canales a valores.\n\n\n\n\n\n\n\n\n\n\n\nNo todos los canales son igual de útiles ni fáciles de entender."
  },
  {
    "objectID": "tics411/clase-2.html#visualizaciones-distribuciones",
    "href": "tics411/clase-2.html#visualizaciones-distribuciones",
    "title": "TICS-411 Minería de Datos",
    "section": "Visualizaciones: Distribuciones",
    "text": "Visualizaciones: Distribuciones\n\nHistograma\n\n\nEl histograma permite visualizar distribuciones univariadas acumulando los datos en rangos de igual tamaño (bins).\n\n\n\n\nPermite visualizar el centro, la extensión, la asimetría y outliers.\n\n\n\n\n\n\n\n\nEl histograma puede ser “engañoso” para conjuntos de datos pequeños.\nLa visualización puede resultar de manera muy distintas dependiendo del número de bins."
  },
  {
    "objectID": "tics411/clase-2.html#visualizaciones-distribuciones-1",
    "href": "tics411/clase-2.html#visualizaciones-distribuciones-1",
    "title": "TICS-411 Minería de Datos",
    "section": "Visualizaciones: Distribuciones",
    "text": "Visualizaciones: Distribuciones\n\nKernel Density\n\n\nCorresponde a un suavizamiento de un Histograma en el cuál se usa un Kernel (función no negativa que suma 1 y tiene media 0) para agrupar los puntos vecinos.\n\n\n\n\n\nLa función estimada es:\n\\[f(x) = \\frac{1}{n} = \\sum_{i=1}^n K \\left(\\frac{x - x(i)}{h}\\right)\\]\n\n\\(K(u)\\) es el Kernel.\n\\(h\\) es el ancho de banda."
  },
  {
    "objectID": "tics411/clase-2.html#visualizaciones-distribuciones-2",
    "href": "tics411/clase-2.html#visualizaciones-distribuciones-2",
    "title": "TICS-411 Minería de Datos",
    "section": "Visualizaciones: Distribuciones",
    "text": "Visualizaciones: Distribuciones\n\nBoxplot (Caja y Bigotes)\n\nEs un tipo de gráfico que muestra la distribución de manera univariada.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTiene la capacidad de mostrar varias distribuciones a la vez.\nAdemás presenta estadísticos de interés: Mediana, IQR y outliers.\nLos puntos fuera de los bigotes son considerados Outliers.\n\n\n\n\n\n\n\n\n\n\n\n\n\nLos bigotes pueden representar:\n\nMínimo y Máximo. (En este caso no hay outliers).\n\\(\\mu \\pm 3\\sigma\\)\nPercentiles 5 y 95.\nOtros valores."
  },
  {
    "objectID": "tics411/clase-2.html#visualizaciones-barras",
    "href": "tics411/clase-2.html#visualizaciones-barras",
    "title": "TICS-411 Minería de Datos",
    "section": "Visualizaciones: Barras",
    "text": "Visualizaciones: Barras\n\nBar Plot\n\n\nLa altura de la barra (normalmente Eje y) representa una cantidad asociada a una categoría (normalmente Eje x).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOtras convenciones llaman a este gráfico Column Plot, mientras que el Bar Plot tiene las barras de manera horizontal."
  },
  {
    "objectID": "tics411/clase-2.html#visualizaciones-puntos",
    "href": "tics411/clase-2.html#visualizaciones-puntos",
    "title": "TICS-411 Minería de Datos",
    "section": "Visualizaciones: Puntos",
    "text": "Visualizaciones: Puntos\n\nScatter\n\n\nGráfico empleado para mostrar distribución de datos bivariados\n\n\n\n\nMuestra la relación entre una variable independiente (Eje X) y una variable dependiente (Eje Y).\nPermite mostrar relaciones lineales o no-lineales.\nCorrelaciones.\nOutliers."
  },
  {
    "objectID": "tics411/clase-2.html#visualizaciones-líneas",
    "href": "tics411/clase-2.html#visualizaciones-líneas",
    "title": "TICS-411 Minería de Datos",
    "section": "Visualizaciones: Líneas",
    "text": "Visualizaciones: Líneas\n\nLineplot\n\n\nGráfico empleado para visualizar tendencias y su evolución en el tiempo.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSi bien es posible utilizarlo para gráficar dos medidas continuas, las buenas prácticas indican que el eje X siempre debería contener una componente temporal."
  },
  {
    "objectID": "tics411/clase-2.html#estadísticos-vs-visualizaciones",
    "href": "tics411/clase-2.html#estadísticos-vs-visualizaciones",
    "title": "TICS-411 Minería de Datos",
    "section": "Estadísticos vs Visualizaciones",
    "text": "Estadísticos vs Visualizaciones"
  },
  {
    "objectID": "tics411/clase-2.html#otras-visualizaciones",
    "href": "tics411/clase-2.html#otras-visualizaciones",
    "title": "TICS-411 Minería de Datos",
    "section": "¿Otras Visualizaciones?",
    "text": "¿Otras Visualizaciones?"
  },
  {
    "objectID": "tics411/notebooks/01-Preprocesamiento.html",
    "href": "tics411/notebooks/01-Preprocesamiento.html",
    "title": "Clases UAI",
    "section": "",
    "text": "# %%capture\n#!pip install feature_engine\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nfrom sklearn import set_config\n\nset_config(transform_output=\"pandas\")\n\ndf = sns.load_dataset(\"titanic\")\ndf"
  },
  {
    "objectID": "tics411/notebooks/01-Preprocesamiento.html#valores-faltantes",
    "href": "tics411/notebooks/01-Preprocesamiento.html#valores-faltantes",
    "title": "Clases UAI",
    "section": "Valores Faltantes",
    "text": "Valores Faltantes\n\ndf.isnull().sum()\n\n\n### Pandas\n# Veamos cuánto vale el promedio de Edad de los pasajeros del Titanic.\nmedia = df[\"age\"].mean()\nmediana = df[\"age\"].median()\nprint(f\"Promedio de Edad: {media}\")\nprint(f'Promedio de Edad con Imputación con Ceros: {df[\"age\"].fillna(0).mean()}')\nprint(f'Promedio de Edad con Imputación por Media: {df[\"age\"].fillna(media).mean()}')\nprint(\n    f'Promedio de Edad con Imputación por Mediana: {df[\"age\"].fillna(mediana).mean()}'\n)\n\n\nfrom sklearn.impute import SimpleImputer\n\nsc = SimpleImputer(strategy=\"mean\")\ndata_imputed = sc.fit_transform(df[[\"age\"]])  # Ojo con el doble []\ndata_imputed.isnull().sum()\n\n\nmode = df[\"embark_town\"].mode()[0]  # Hablar del tipo de datos que es la Moda.\ndf[\"embark_town\"].fillna(mode).isnull().sum()"
  },
  {
    "objectID": "tics411/notebooks/01-Preprocesamiento.html#outliers",
    "href": "tics411/notebooks/01-Preprocesamiento.html#outliers",
    "title": "Clases UAI",
    "section": "Outliers",
    "text": "Outliers\n\nprint(f\"Promedio de Tarifas: {df.fare.mean()}\")\ndf[\"fare\"].agg([\"min\", \"max\"])\n\n\nlower: Define la cota inferior.\nupper: Define la cota superior.\n\n\nclipped_data = df[[\"fare\"]].clip(lower=10, upper=50)\nclipped_data.agg([\"min\", \"max\"])\n\n\ndf[[\"fare\"]]\n\n\nclipped_data\n\n\nfrom feature_engine.outliers import ArbitraryOutlierCapper, Winsorizer\n\ncapper = ArbitraryOutlierCapper(\n    max_capping_dict=dict(fare=50), min_capping_dict=dict(fare=10)\n)\ncapper.fit_transform(df[[\"fare\"]])\n\n\ncapping_method: Define la Estragegia a utilizar para el Winsorizer. Ver Docs.\n\n\nwin = Winsorizer(capping_method=\"gaussian\")\nwin.fit_transform(df[[\"fare\"]])"
  },
  {
    "objectID": "tics411/notebooks/01-Preprocesamiento.html#variables-categóricas",
    "href": "tics411/notebooks/01-Preprocesamiento.html#variables-categóricas",
    "title": "Clases UAI",
    "section": "Variables Categóricas",
    "text": "Variables Categóricas\n\ndrop_first: Si es True se elimina la primera categoría.\n\n\npd.get_dummies(df[\"embark_town\"], drop_first=False)\n\n\npd.get_dummies(\n    df[\"embark_town\"], drop_first=True\n)  # No considera los Nulos como otra categoría...\n\n\nsort: Usar True ya que coloca las categorías en orden. Además de esta manera se comporta igual que OrdinalEncoder de Scikit-Learn.\n\n\npd.DataFrame(pd.factorize(df[\"embark_town\"], sort=True)[0], columns=[\"new_column\"])\n\n\nsparse_output: Se debe fijar como False para poder ver el output como Pandas\ndrop: Se debe colocar \"first\" o el nombre de una sóla categoría a eliminar.\n\n\nfrom sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n\nohe = OneHotEncoder(drop=\"first\", sparse_output=False)\nohe.fit_transform(df[[\"embark_town\"]])\n\n\nohe = OneHotEncoder(\n    drop=[\"Queenstown\"], sparse_output=False\n)  # También se puede colocar np.nan.\nohe.fit_transform(df[[\"embark_town\"]])\n\n\noe = OrdinalEncoder()\noe.fit_transform(df[[\"embark_town\"]])"
  },
  {
    "objectID": "tics411/notebooks/01-Preprocesamiento.html#escalamiento",
    "href": "tics411/notebooks/01-Preprocesamiento.html#escalamiento",
    "title": "Clases UAI",
    "section": "Escalamiento",
    "text": "Escalamiento\n\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\n\nsc = StandardScaler()\ndata = sc.fit_transform(df[[\"fare\"]])\ndata.agg([\"mean\", \"std\"])\n\n\nmms = MinMaxScaler()\nmms.fit_transform(df[[\"fare\"]]).agg([\"min\", \"max\"])"
  },
  {
    "objectID": "tics411/notebooks/kmeans.html",
    "href": "tics411/notebooks/kmeans.html",
    "title": "Clases UAI",
    "section": "",
    "text": "import numpy as np\n\n## Primera fila son coordenadas X\n## Segunda fila son coordenadas Y\n## Cada columna es el punto.\npuntos = np.array([[1,2,4,5], [1,1,3,4]])\npuntos\n\nc_1 = np.array([1,1])\nc_2 = np.array([2,1])\n\n\nimport matplotlib.pyplot as plt\ndef plot_clusters(puntos, c_1, c_2, c = None):\n    plt.scatter(puntos[0], puntos[1], s = 500, c = c)\n    plt.scatter(c_1[0], c_1[1], marker = \"^\", label = \"Centroide Cluster 1\", edgecolors=\"k\", s = 200, color = \"orange\")\n    plt.scatter(c_2[0], c_2[1], marker = \"^\", label = \"Centroide Cluster 2\", edgecolors=\"k\", s=200, c = \"green\")\n    plt.grid(alpha=0.5)\n    plt.legend();\n\nplot_clusters(puntos, c_1, c_2)\n\n\n\n\n\n\n\n\n\ndef distancia(p0,p1): \n    x0 = p0[0]\n    x1 = p1[0]\n    y0 = p0[1]\n    y1 = p1[1]\n    return np.sqrt((x1-x0)**2 + (y1-y0)**2)\n\n\ndef calculate_distances(puntos, c_1, c_2):\n\n    distancia_mat = np.zeros((2,4))\n    distancia_mat\n\n    for i in range(4):\n        p = puntos[:,i]\n        distancia_mat[0,i] = distancia(p, c_1)\n        distancia_mat[1,i] = distancia(p, c_2)\n\n    return distancia_mat\n\ndistancia_mat = calculate_distances(puntos, c_1, c_2)\ndistancia_mat\n\narray([[0.        , 1.        , 3.60555128, 5.        ],\n       [1.        , 0.        , 2.82842712, 4.24264069]])\n\n\n\ndef calculate_clusters(distancia_mat):\n    min_distancia_mat = np.min(distancia_mat, axis = 0)\n    min_distancia_mat\n\n    clusters = (distancia_mat == min_distancia_mat)\n    return clusters\n\nclusters = calculate_clusters(distancia_mat)\nclusters\n\n## Solo el punto 1 pertenece al cluster 1, todo el resto al cluster 2\n\narray([[ True, False, False, False],\n       [False,  True,  True,  True]])\n\n\n\ndef calculate_centroids(clusters):\n    c_1 = puntos[:,clusters[0]].mean(axis = 1)\n    c_2 = puntos[:,clusters[1]].mean(axis = 1)\n\n    return c_1, c_2\n\nc_1, c_2 = calculate_centroids(clusters)\nc_1, c_2\n\n(array([1., 1.]), array([3.66666667, 2.66666667]))\n\n\n\nplot_clusters(puntos, c_1, c_2, c = [\"red\",\"blue\", \"blue\", \"blue\"])\n\n\n\n\n\n\n\n\n\ndistancia_mat = calculate_distances(puntos, c_1, c_2)\nclusters = calculate_clusters(distancia_mat)\nc_1, c_2 = calculate_centroids(clusters)\nclusters\n\narray([[ True,  True, False, False],\n       [False, False,  True,  True]])\n\n\n\nc_1, c_2\n\n(array([1.5, 1. ]), array([4.5, 3.5]))\n\n\n\nplot_clusters(puntos, c_1, c_2, c = [\"red\",\"red\", \"blue\", \"blue\"])\n\n\n\n\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "tics411/notebooks/02-EDA.html",
    "href": "tics411/notebooks/02-EDA.html",
    "title": "Medidas de Tendencia Central",
    "section": "",
    "text": "import seaborn as sns\nimport matplotlib.pyplot as plt\n\niris_df = sns.load_dataset(\"iris\")\ntitanic_df = sns.load_dataset(\"titanic\")\nts_df = sns.load_dataset(\"dowjones\")\niris_df"
  },
  {
    "objectID": "tics411/notebooks/02-EDA.html#medidas-de-tendencia-central",
    "href": "tics411/notebooks/02-EDA.html#medidas-de-tendencia-central",
    "title": "Medidas de Tendencia Central",
    "section": "Medidas de Tendencia Central",
    "text": "Medidas de Tendencia Central\n\nprint(f\"Promedio de Ancho de Petalo {iris_df['sepal_width'].mean()}\")\nprint(f\"Mediana de Largo de Petalo {iris_df['sepal_length'].median()}\")\n\n\nprint(f\"Moda de Especies: \")\niris_df[\"species\"].mode()\n\n\np25 = iris_df[\"sepal_width\"].quantile(q=0.25)\np50 = iris_df[\"sepal_width\"].quantile(q=0.50)\np75 = iris_df[\"sepal_width\"].quantile(q=0.75)\niris_df[\"sepal_width\"].median(), p25, p50, p75"
  },
  {
    "objectID": "tics411/notebooks/02-EDA.html#medidas-de-dispersión",
    "href": "tics411/notebooks/02-EDA.html#medidas-de-dispersión",
    "title": "Medidas de Tendencia Central",
    "section": "Medidas de Dispersión",
    "text": "Medidas de Dispersión\n\n# Mostrar error en caso de no usar numeric_only\niris_df.var(numeric_only=True, ddof=0)\n\n\niris_df.var(numeric_only=True, ddof=1)\n\n\niris_df.std(numeric_only=True, ddof=1)\n\n\n# Mostrar cómo se construye esta función...\ndef calculate_quantiles(column):\n    quantiles = iris_df.quantile([0.25, 0.75], numeric_only=True)\n    iqr_sl = quantiles.loc[0.75, column] - quantiles.loc[0.25, column]\n    return iqr_sl\n\n\ncalculate_quantiles(\"sepal_length\")\ncalculate_quantiles(\"petal_width\")\n\n\niris_df.skew(numeric_only=True)\n\n\nCuando hacemos visualizaciones tenemos 2 formas de hacerlas: * Usar Pandas directamente y/o Matplotlib: Buena documentación, gráficos bonitos. * Usar Seaborn: Documentación Complicada, fácil para descubrir insights."
  },
  {
    "objectID": "tics411/notebooks/02-EDA.html#visualizaciones-pandas",
    "href": "tics411/notebooks/02-EDA.html#visualizaciones-pandas",
    "title": "Medidas de Tendencia Central",
    "section": "Visualizaciones: Pandas",
    "text": "Visualizaciones: Pandas\n\nHistogramas\n\niris_df.hist(figsize=(20, 6), bins=30, edgecolor=\"black\", grid=False)\nplt.tight_layout()\n\n\niris_df.plot(\n    kind=\"hist\", alpha=0.5, bins=30, figsize=(20, 6), edgecolor=\"black\"\n)\n# Notar que este genera todos los histogramas super puestos...\n\n\n\nBarplots\n\ntitanic_df[\"sex\"].value_counts().plot(\n    kind=\"bar\",\n    figsize=(5, 6),\n    title=\"Número de Pasajeros por Sexo...\",\n    edgecolor=\"black\",\n)\n\n\nPara este tipo de gráficas se requiere entender el concepto de agrupación…\n\n\n## Gráficar varias dimensiones\ntitanic_df.groupby(\"pclass\")[[\"age\", \"fare\"]].mean().plot(\n    kind=\"bar\", edgecolor=\"black\", title=\"Edad y Tarifa por cada Clase\"\n)\n\n\niris_df.groupby(\"species\").mean().plot(kind=\"bar\", edgecolor=\"black\")"
  },
  {
    "objectID": "tics411/notebooks/02-EDA.html#boxplots",
    "href": "tics411/notebooks/02-EDA.html#boxplots",
    "title": "Medidas de Tendencia Central",
    "section": "Boxplots",
    "text": "Boxplots\n\niris_df.drop(columns=\"species\").plot(kind=\"box\")\n\n\nPuntos\n\niris_df.plot(\n    x=\"petal_length\",\n    y=\"petal_width\",\n    kind=\"scatter\",\n    title=\"Largo de Pétalo vs Ancho de Pétalo\",\n    xlabel=\"Largo\",\n    ylabel=\"Ancho\",\n)\n\n\nts_df.plot(x=\"Date\", y=\"Price\", title=\"Evolución del Dow Jones\")\n\n\nfrom scipy.stats import norm\n\nts_df[\"AA\"] = ts_df[\"Price\"] + norm.rvs(size=649) * 55 + 1000\nts_df[\"BB\"] = -norm.rvs(size=649) * 55\n\nts_df.set_index(\"Date\").plot(title=\"Comparación distintas Tendencias\")\n\n\nfig = plt.figure(figsize=(20, 10))\nax = fig.subplot_mosaic(\n    \"\"\"AAA\n       BCC\"\"\"\n)\n\niris_df.drop(columns=\"species\").plot(\n    kind=\"box\", ax=ax[\"C\"], title=\"Distribución de Datos por Variable\"\n)\niris_df.plot(\n    x=\"petal_length\",\n    y=\"petal_width\",\n    kind=\"scatter\",\n    title=\"Largo de Pétalo vs Ancho de Pétalo\",\n    xlabel=\"Largo\",\n    ylabel=\"Ancho\",\n    ax=ax[\"B\"],\n)\niris_df.groupby(\"species\").mean().plot(\n    kind=\"bar\",\n    edgecolor=\"black\",\n    ax=ax[\"A\"],\n    rot=0,\n    title=\"Valores promedio por Especie\",\n)\nplt.suptitle(\"Súper Título\", fontsize=20)"
  },
  {
    "objectID": "tics411/notebooks/02-EDA.html#seaborn",
    "href": "tics411/notebooks/02-EDA.html#seaborn",
    "title": "Medidas de Tendencia Central",
    "section": "Seaborn",
    "text": "Seaborn\n\nsns.catplot(kind=\"count\", data=titanic_df, y=\"embark_town\")\nplt.title(\"Pasajeros por Puerto\")\nsns.catplot(kind=\"count\", data=titanic_df, x=\"pclass\")\nplt.title(\"Pasajeros por Clase\")\n\n\nEn el caso de querer entender los colores de Seaborn ver acá\n\n\n# Agrupar por ambos casos\nsns.catplot(\n    kind=\"count\", y=\"sex\", hue=\"pclass\", data=titanic_df, palette=\"Set1\"\n)\n\n\n## Barplot\nimport numpy as np\n\nsns.catplot(\n    kind=\"bar\",\n    x=\"sex\",\n    y=\"fare\",\n    data=titanic_df,\n    estimator=np.median,\n    errorbar=None,\n    hue=\"embark_town\",\n    col=\"pclass\",\n)\n\n\nHistogramas\n\nsns.displot(x=\"fare\", data=titanic_df, kind=\"kde\", height=4, aspect=6)\n\n\nsns.displot(x=\"fare\", data=titanic_df, height=4, aspect=6)\n\n\nsns.displot(x=\"fare\", data=titanic_df, kde=True, height=4, aspect=6)"
  },
  {
    "objectID": "tics411/notebooks/02-EDA.html#lineplots",
    "href": "tics411/notebooks/02-EDA.html#lineplots",
    "title": "Medidas de Tendencia Central",
    "section": "Lineplots",
    "text": "Lineplots\n\nsns.relplot(\n    kind=\"scatter\", x=\"age\", y=\"fare\", data=titanic_df, hue=\"pclass\"\n)\n\n\nsns.relplot(x=\"Date\", y=\"Price\", data=ts_df, kind=\"line\")\nplt.title(\"Precio del Dow Jones\")\n\n\nnew_data = ts_df.melt(\n    id_vars=[\"Date\"],\n    value_vars=[\"AA\", \"BB\"],\n    var_name=\"Tipo\",\n    value_name=\"stock_price\",\n)\nnew_data\n\n\nsns.relplot(\n    kind=\"line\", y=\"stock_price\", x=\"Date\", data=new_data, hue=\"Tipo\"\n)\n\n\nsns.relplot(\n    kind=\"scatter\",\n    x=\"age\",\n    y=\"fare\",\n    data=titanic_df,\n    col=\"alone\",\n    hue=\"survived\",\n)\n\n\n# Esto es un insight... Los hombres solos sobrevivieron muchísimo más...\nsns.catplot(\n    kind=\"count\", x=\"sex\", hue=\"survived\", data=titanic_df, col=\"alone\"\n)\n\n\nEl contra de estos gráficos en Seaborn es que no permiten agregarse a un Layout Mosaic."
  },
  {
    "objectID": "tics411/lab-0.html#qué-es-scikit-learn",
    "href": "tics411/lab-0.html#qué-es-scikit-learn",
    "title": "TICS-411 Minería de Datos",
    "section": "¿Qué es Scikit-Learn?",
    "text": "¿Qué es Scikit-Learn?\n\n\n\n\n\nScikit-Learn (sklearn para los amigos) es una librería creada por David Cournapeau, como un Google Summer Code Project y luego Matthieu Brucher en su tesis.\nEn 2010 queda a cargo de INRIA y tiene un ciclo de actualización de 3 meses.\nEs la librería más famosa y poderosa para hacer Machine Learning hoy en día.\nSu API es tan famosa, que hoy se sabe que una librería es de calidad si sigue los estándares implementados por Scikit-Learn.\nPara que un algoritmo sea parte de Scikit-Learn debe poseer 3 años desde su publicación y 200+ citaciones mostrando su utilidad y amplio uso (ver acá).\nAdemás es una librería que obliga a que sus algoritmos tengan la capacidad de generalizar."
  },
  {
    "objectID": "tics411/lab-0.html#diseño",
    "href": "tics411/lab-0.html#diseño",
    "title": "TICS-411 Minería de Datos",
    "section": "Diseño",
    "text": "Diseño\n\nScikit-Learn sigue un patrón de Programación Orientada a Objetos (POO) basado en clases.\n\n\n\n\n\n\n\n\nEn programación, una clase es un objeto que internamente contiene estados que pueden ir cambiando en el tiempo.\n\nUna clase posee:\n\nMétodos: Funciones que cambian el comportamiento de la clase.\nAtributos: Datos propios de la clase.\n\n\n\n\n\n\n\nScikit-Learn sigue el siguiente estándar:\n\nTodas las Clases se escriben en CamelCase: Ej: KMeans,LogisticRegression, StandardScaler.\nLas clases en Scikit-Learn pueden representar algoritmos, o etapas de un preprocesamiento.\n\nLos algoritmos se denominan Estimators.\nLos preprocesamientos se denominan Transformers.\n\nLas funciones se escriben como snake_case y permiten realizar algunas operaciones básicas en el proceso de modelamiento. Ej: train_test_split(), cross_val_score().\nNormalmente se utilizan letras mayúsculas para denotar Matrices o DataFrames, mientras que las letras minúsculas denotan Vectores o Series."
  },
  {
    "objectID": "tics411/lab-0.html#estimadores-no-supervisados",
    "href": "tics411/lab-0.html#estimadores-no-supervisados",
    "title": "TICS-411 Minería de Datos",
    "section": "Estimadores No supervisados",
    "text": "Estimadores No supervisados\nfrom sklearn.sub_modulo import Estimator \nmodel = Estimator(hp1=v1, hp2=v2,...) \nmodel.fit(X) \n\ny_pred = model.predict(X) \n\n## Opcionalmente se puede entrenar y predecir a la vez.\nmodel.fit_predict(X) \n\n\nL1. Importar la clase a utilizar.\nL2. Instanciar el modelo y sus hiperparámetros.\nL3. Entrenar o ajustar el modelo (Requiere sólo de X).\nL5. Predecir. Los modelos de clasificación tienen la capacidad de generar probabilidades.\nL7-8. Este tipo de modelos permite entrenar y predecir en un sólo paso."
  },
  {
    "objectID": "tics411/lab-0.html#estimadores-predictivos",
    "href": "tics411/lab-0.html#estimadores-predictivos",
    "title": "TICS-411 Minería de Datos",
    "section": "Estimadores Predictivos",
    "text": "Estimadores Predictivos\nfrom sklearn.sub_modulo import Estimator \nmodel = Estimator(hp1=v1, hp2=v2,...) \nmodel.fit(X_train, y_train) \n\ny_pred = model.predict(X_test) \ny_pred_proba = model.predict_proba(X_test)\n\nmodel.score(X_test,y_test) \n\n\nL1. Importar la clase a utilizar.\nL2. Instanciar el modelo y sus hiperparámetros.\nL3. Entrenar o ajustar el modelo (Ojo, requiere de X e y).\nL5–6. Predecir en datos nuevos. (Algunos modelos pueden predecir probabilidades).\nL8. Evaluar el modelo en los datos nuevos."
  },
  {
    "objectID": "tics411/lab-0.html#output-de-un-modelo",
    "href": "tics411/lab-0.html#output-de-un-modelo",
    "title": "TICS-411 Minería de Datos",
    "section": "Output de un Modelo",
    "text": "Output de un Modelo\n\nLos modelos no entregan directamente un output sino que los dejan almacenados en su interior como un estado.\nLos Estimators tienen dos estados:\n\nNot Fitted: Modelo antes de ser entrenado\nFitted: Una vez que el modelo ya está entrenado. (Después de aplicar .fit())\n\n\n\n\n\n\n\n\n\nMuchos modelos pueden entregar información sólo luego de ser entrenados (su atributo termina con un _).\nEj: model.coef_, model.intercept_.\n\n\n\n\n\n\n\n\n\n\n\nEl modelo es una herramienta a la cual le entregamos datos (Input), y nos devuelve datos (Predicciones)."
  },
  {
    "objectID": "tics411/lab-0.html#transformers",
    "href": "tics411/lab-0.html#transformers",
    "title": "TICS-411 Minería de Datos",
    "section": "Transformers",
    "text": "Transformers\n\n\n\n\n\n\n\n\nA diferencia de los Estimators, los Transformers no son modelos.\nSu input y su output son datos.\nAlgunos Transformers permiten escalar los datos, transformar categorías en números, rellenar valores faltantes. (Veremos más acerca de esto en los Preprocesamiento).\n\n\n\n\n\n\nfrom sklearn.preprocessing import Transformer \ntr = Transformer(hp1=v1, hp2=v2,...) \ntr.fit(X) \n\nX_new = tr.transform(X) \n\n## Opcionalmente\nX_new = tr.fit_transform(X) \n\nL1. Importar la clase a utilizar (en este caso del submodulo preprocessing, aunque pueden haber otros como impute).\nL2. Instanciar el Transformer y sus hiperparámetros.\nL3. Entrenar o ajustar el Transformer.\nL5. Transformar los datos.\nL7-8. Adicionalmente se puede entrenar y transformar los datos en un sólo paso."
  },
  {
    "objectID": "tics411/lab-0.html#pipelines",
    "href": "tics411/lab-0.html#pipelines",
    "title": "TICS-411 Minería de Datos",
    "section": "Pipelines",
    "text": "Pipelines\n\nEn ocasiones un Dataset requiere más de un preprocesamiento.\nEstas Transformaciones normalmente se hacen en serie de manera consecutiva.\n\n\n\n\n\n\n\n\n\n\n\n\n\nEl Estimator es opcional, es decir, el Pipeline puede ser para combinar sólo Transformers o Transformers + un Estimator.\n\n\n\n\n\n\n\n\n\n\nUn Pipeline puede tener sólo un Estimator."
  },
  {
    "objectID": "tics411/lab-0.html#pipelines-código",
    "href": "tics411/lab-0.html#pipelines-código",
    "title": "TICS-411 Minería de Datos",
    "section": "Pipelines: Código",
    "text": "Pipelines: Código\nfrom sklearn.tree import DecisionTreeClassifier \nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder \nfrom sklearn.pipeline import Pipeline \n\npipe = Pipeline(steps=[ \n    (\"ohe\", OneHotEncoder()),\n    (\"sc\", StandardScaler()),\n    (\"model\", DecisionTreeClassifier())\n])\n\npipe.fit(X_train, y_train) \ny_pred = pipe.predict(X_test) \n\npipe.score(X_test, y_test) \n\nL1-2. Importo mi modelo y mis preprocesamientos\nL3. Importo el Pipeline.\nL5-9. Instancio un Pipeline.\nL11. Entreno el Pipeline.\nL12. Predigo utilizando el Pipeline entrenado.\nL14. Evalúo el modelo en datos no vistos."
  },
  {
    "objectID": "tics411/lab-0.html#documentación",
    "href": "tics411/lab-0.html#documentación",
    "title": "TICS-411 Minería de Datos",
    "section": "Documentación",
    "text": "Documentación\n\nProbablemente Scikit-Learn tenga una de las mejores documentaciones existentes.\n\n\nVeamos el caso de la Documentación del One Hot Encoder"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Alfonso Tobar",
    "section": "",
    "text": "LinkedIn\n  \n  \n    \n     Github\n  \n  \n    \n     datacuber.cl\n  \n\n      \nSoy Alfonso y he trabajado como Científico de Datos por los últimos 9 años. Además me gusta el Machine Learning Competitivo y hasta el momento he ganado 2 competencias.\nActualmente me encuentro a punto de terminar mi Msc. y además comencé a cursar mi PhD. en Data Science. Mis intereses de investigación tienen que ver con Machine Learning y Deep Learning enfocándome principalmente en la aplicación de Transformers.\nEn mi tiempo libre practico Tenis de Mesa y escribo sobre Machine Learning en mi blog: datacuber.cl.\n\n\nUniversidad Adolfo Ibañez, Viña del Mar | PhD. in Data Science | 2023 - 2026\nUniversidad Adolfo Ibañez, Viña del Mar | Msc. in Data Science | 2022 - 2023\nUniversidad Técnica Federico Santa María | Ingeniería Civil | 2005 - 2013\nPuedes ver más detalles de mi carrera acá.\n\n\n\n\nHate Speech Recognition in Chilean Tweets"
  },
  {
    "objectID": "index.html#educación",
    "href": "index.html#educación",
    "title": "Alfonso Tobar",
    "section": "",
    "text": "Universidad Adolfo Ibañez, Viña del Mar | PhD. in Data Science | 2023 - 2026\nUniversidad Adolfo Ibañez, Viña del Mar | Msc. in Data Science | 2022 - 2023\nUniversidad Técnica Federico Santa María | Ingeniería Civil | 2005 - 2013\nPuedes ver más detalles de mi carrera acá."
  },
  {
    "objectID": "index.html#publicaciones",
    "href": "index.html#publicaciones",
    "title": "Alfonso Tobar",
    "section": "",
    "text": "Hate Speech Recognition in Chilean Tweets"
  },
  {
    "objectID": "tics411.html",
    "href": "tics411.html",
    "title": "Diapositivas",
    "section": "",
    "text": "Clase 0\n\n\nPresentación del Curso\n\n\n\nMar 7, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nClase 1\n\n\nCalidad de los Datos y Feature Engineering\n\n\n\nMar 21, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nClase 2\n\n\nExploratory Data Analysis (EDA)\n\n\n\nMar 21, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nClase Bonus\n\n\nIntroducción a Scikit-Learn\n\n\n\nMar 21, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nClase 3\n\n\nModelación Descriptiva y K-Means\n\n\n\nMar 28, 2024\n\n\n\n\n\n\n\n\nNo matching items\n\n Back to top",
    "crumbs": [
      "Diapositivas del Curso"
    ]
  }
]