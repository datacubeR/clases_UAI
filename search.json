[
  {
    "objectID": "charlas.html",
    "href": "charlas.html",
    "title": "Charlas",
    "section": "",
    "text": "Hate Speech UAI\n\n\nPresentación del HateStack\n\n\n\nMay 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\nLike a Needle in the HateStack\n\n\nPresentación final para la Datatón 2022\n\n\n\nOct 10, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\nRFM-Superlag\n\n\nPresentación Final del Desafío Itaú-Binnario\n\n\n\nDec 5, 2020\n\n\n\n\n\n\nNo matching items\n Back to top"
  },
  {
    "objectID": "tics411/lab-0.html#qué-es-scikit-learn",
    "href": "tics411/lab-0.html#qué-es-scikit-learn",
    "title": "TICS-411 Minería de Datos",
    "section": "¿Qué es Scikit-Learn?",
    "text": "¿Qué es Scikit-Learn?\n\n\n\n\n\nScikit-Learn (sklearn para los amigos) es una librería creada por David Cournapeau, como un Google Summer Code Project y luego Matthieu Brucher en su tesis.\nEn 2010 queda a cargo de INRIA y tiene un ciclo de actualización de 3 meses.\nEs la librería más famosa y poderosa para hacer Machine Learning hoy en día.\nSu API es tan famosa, que hoy se sabe que una librería es de calidad si sigue los estándares implementados por Scikit-Learn.\nPara que un algoritmo sea parte de Scikit-Learn debe poseer 3 años desde su publicación y 200+ citaciones mostrando su utilidad y amplio uso (ver acá).\nAdemás es una librería que obliga a que sus algoritmos tengan la capacidad de generalizar."
  },
  {
    "objectID": "tics411/lab-0.html#diseño",
    "href": "tics411/lab-0.html#diseño",
    "title": "TICS-411 Minería de Datos",
    "section": "Diseño",
    "text": "Diseño\n\nScikit-Learn sigue un patrón de Programación Orientada a Objetos (POO) basado en clases.\n\n\n\n\n\n\n\n\nEn programación, una clase es un objeto que internamente contiene estados que pueden ir cambiando en el tiempo.\n\nUna clase posee:\n\nMétodos: Funciones que cambian el comportamiento de la clase.\nAtributos: Datos propios de la clase.\n\n\n\n\n\n\n\nScikit-Learn sigue el siguiente estándar:\n\nTodas las Clases se escriben en CamelCase: Ej: KMeans,LogisticRegression, StandardScaler.\nLas clases en Scikit-Learn pueden representar algoritmos, o etapas de un preprocesamiento.\n\nLos algoritmos se denominan Estimators.\nLos preprocesamientos se denominan Transformers.\n\nLas funciones se escriben como snake_case y permiten realizar algunas operaciones básicas en el proceso de modelamiento. Ej: train_test_split(), cross_val_score().\nNormalmente se utilizan letras mayúsculas para denotar Matrices o DataFrames, mientras que las letras minúsculas denotan Vectores o Series."
  },
  {
    "objectID": "tics411/lab-0.html#estimadores-no-supervisados",
    "href": "tics411/lab-0.html#estimadores-no-supervisados",
    "title": "TICS-411 Minería de Datos",
    "section": "Estimadores No supervisados",
    "text": "Estimadores No supervisados\nfrom sklearn.sub_modulo import Estimator \nmodel = Estimator(hp1=v1, hp2=v2,...) \nmodel.fit(X) \n\ny_pred = model.predict(X) \n\n## Opcionalmente se puede entrenar y predecir a la vez.\nmodel.fit_predict(X) \n\n\nL1. Importar la clase a utilizar.\nL2. Instanciar el modelo y sus hiperparámetros.\nL3. Entrenar o ajustar el modelo (Requiere sólo de X).\nL5. Predecir. Los modelos de clasificación tienen la capacidad de generar probabilidades.\nL7-8. Este tipo de modelos permite entrenar y predecir en un sólo paso."
  },
  {
    "objectID": "tics411/lab-0.html#estimadores-predictivos",
    "href": "tics411/lab-0.html#estimadores-predictivos",
    "title": "TICS-411 Minería de Datos",
    "section": "Estimadores Predictivos",
    "text": "Estimadores Predictivos\nfrom sklearn.sub_modulo import Estimator \nmodel = Estimator(hp1=v1, hp2=v2,...) \nmodel.fit(X_train, y_train) \n\ny_pred = model.predict(X_test) \ny_pred_proba = model.predict_proba(X_test)\n\nmodel.score(X_test,y_test) \n\n\nL1. Importar la clase a utilizar.\nL2. Instanciar el modelo y sus hiperparámetros.\nL3. Entrenar o ajustar el modelo (Ojo, requiere de X e y).\nL5–6. Predecir en datos nuevos. (Algunos modelos pueden predecir probabilidades).\nL8. Evaluar el modelo en los datos nuevos."
  },
  {
    "objectID": "tics411/lab-0.html#output-de-un-modelo",
    "href": "tics411/lab-0.html#output-de-un-modelo",
    "title": "TICS-411 Minería de Datos",
    "section": "Output de un Modelo",
    "text": "Output de un Modelo\n\nLos modelos no entregan directamente un output sino que los dejan almacenados en su interior como un estado.\nLos Estimators tienen dos estados:\n\nNot Fitted: Modelo antes de ser entrenado\nFitted: Una vez que el modelo ya está entrenado. (Después de aplicar .fit())\n\n\n\n\n\n\n\n\n\nMuchos modelos pueden entregar información sólo luego de ser entrenados (su atributo termina con un _).\nEj: model.coef_, model.intercept_.\n\n\n\n\n\n\n\n\n\n\n\nEl modelo es una herramienta a la cual le entregamos datos (Input), y nos devuelve datos (Predicciones)."
  },
  {
    "objectID": "tics411/lab-0.html#transformers",
    "href": "tics411/lab-0.html#transformers",
    "title": "TICS-411 Minería de Datos",
    "section": "Transformers",
    "text": "Transformers\n\n\n\n\n\n\n\n\nA diferencia de los Estimators, los Transformers no son modelos.\nSu input y su output son datos.\nAlgunos Transformers permiten escalar los datos, transformar categorías en números, rellenar valores faltantes. (Veremos más acerca de esto en los Preprocesamiento).\n\n\n\n\n\n\nfrom sklearn.preprocessing import Transformer \ntr = Transformer(hp1=v1, hp2=v2,...) \ntr.fit(X) \n\nX_new = tr.transform(X) \n\n## Opcionalmente\nX_new = tr.fit_transform(X) \n\nL1. Importar la clase a utilizar (en este caso del submodulo preprocessing, aunque pueden haber otros como impute).\nL2. Instanciar el Transformer y sus hiperparámetros.\nL3. Entrenar o ajustar el Transformer.\nL5. Transformar los datos.\nL7-8. Adicionalmente se puede entrenar y transformar los datos en un sólo paso."
  },
  {
    "objectID": "tics411/lab-0.html#pipelines",
    "href": "tics411/lab-0.html#pipelines",
    "title": "TICS-411 Minería de Datos",
    "section": "Pipelines",
    "text": "Pipelines\n\nEn ocasiones un Dataset requiere más de un preprocesamiento.\nEstas Transformaciones normalmente se hacen en serie de manera consecutiva.\n\n\n\n\n\n\n\n\n\n\n\n\n\nEl Estimator es opcional, es decir, el Pipeline puede ser para combinar sólo Transformers o Transformers + un Estimator.\n\n\n\n\n\n\n\n\n\n\nUn Pipeline puede tener sólo un Estimator."
  },
  {
    "objectID": "tics411/lab-0.html#pipelines-código",
    "href": "tics411/lab-0.html#pipelines-código",
    "title": "TICS-411 Minería de Datos",
    "section": "Pipelines: Código",
    "text": "Pipelines: Código\nfrom sklearn.tree import DecisionTreeClassifier \nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder \nfrom sklearn.pipeline import Pipeline \n\npipe = Pipeline(steps=[ \n    (\"ohe\", OneHotEncoder()),\n    (\"sc\", StandardScaler()),\n    (\"model\", DecisionTreeClassifier())\n])\n\npipe.fit(X_train, y_train) \ny_pred = pipe.predict(X_test) \n\npipe.score(X_test, y_test) \n\nL1-2. Importo mi modelo y mis preprocesamientos\nL3. Importo el Pipeline.\nL5-9. Instancio un Pipeline.\nL11. Entreno el Pipeline.\nL12. Predigo utilizando el Pipeline entrenado.\nL14. Evalúo el modelo en datos no vistos."
  },
  {
    "objectID": "tics411/lab-0.html#documentación",
    "href": "tics411/lab-0.html#documentación",
    "title": "TICS-411 Minería de Datos",
    "section": "Documentación",
    "text": "Documentación\n\nProbablemente Scikit-Learn tenga una de las mejores documentaciones existentes.\n\n\nVeamos el caso de la Documentación del One Hot Encoder"
  },
  {
    "objectID": "tics411/clase-10.html#árboles-de-decisión",
    "href": "tics411/clase-10.html#árboles-de-decisión",
    "title": "TICS-411 Minería de Datos",
    "section": "Árboles de Decisión",
    "text": "Árboles de Decisión\n\nTécnica de clasificación supervisada que genera una decisión basada en árboles de decisión para clasificar instancias no conocidas."
  },
  {
    "objectID": "tics411/clase-10.html#árboles-de-decisión-ejemplo",
    "href": "tics411/clase-10.html#árboles-de-decisión-ejemplo",
    "title": "TICS-411 Minería de Datos",
    "section": "Árboles de Decisión: Ejemplo",
    "text": "Árboles de Decisión: Ejemplo\n\nVisualmente, un árbol de decisión segmenta el espacio separando los datos en subgrupos.\n\n\n\n\n\n\n\nEsto permite la generacion de fronteras de decisión sumamente complejas.\n\n\n\nSupongamos el siguiente ejemplo:"
  },
  {
    "objectID": "tics411/clase-10.html#árboles-de-decisión-frontera-de-decisión",
    "href": "tics411/clase-10.html#árboles-de-decisión-frontera-de-decisión",
    "title": "TICS-411 Minería de Datos",
    "section": "Árboles de Decisión: Frontera de Decisión",
    "text": "Árboles de Decisión: Frontera de Decisión"
  },
  {
    "objectID": "tics411/clase-10.html#árboles-de-decisión-frontera-de-decisión-1",
    "href": "tics411/clase-10.html#árboles-de-decisión-frontera-de-decisión-1",
    "title": "TICS-411 Minería de Datos",
    "section": "Árboles de Decisión: Frontera de Decisión",
    "text": "Árboles de Decisión: Frontera de Decisión\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n¿Cuál sería el Nivel de Ajuste de un modelo de este tipo?"
  },
  {
    "objectID": "tics411/clase-10.html#árboles-de-decisión-inferencia",
    "href": "tics411/clase-10.html#árboles-de-decisión-inferencia",
    "title": "TICS-411 Minería de Datos",
    "section": "Árboles de Decisión: Inferencia",
    "text": "Árboles de Decisión: Inferencia\nUna vez construido el árbol de decisión basta con recorrerlo para poder generar la predicción para una instancia dada:"
  },
  {
    "objectID": "tics411/clase-10.html#características-de-árboles",
    "href": "tics411/clase-10.html#características-de-árboles",
    "title": "TICS-411 Minería de Datos",
    "section": "Características de Árboles",
    "text": "Características de Árboles\n\nPueden trabajar con valores discretos o continuos. Además pueden ser usados como modelos de Clasificación o Regresíon.\nUna vez seleccionado un atributo no es posible devolverse (backtracking).\nDebido al poder de un árbol de Decisión la mayoría de las veces tienden al Overfitting. Una forma de evitar esto es usar técnicas de Pruning.\nEs preferible usar árboles cortos (Principio de Parsimonia o Occam's Razor).\n\n\n\n\n\n\n\nEl principio de Parsimonia recomienda encontrar soluciones a problemas utilizando la menor cantidad de elementos/parámetros."
  },
  {
    "objectID": "tics411/clase-10.html#tipos-de-árboles-de-decisión",
    "href": "tics411/clase-10.html#tipos-de-árboles-de-decisión",
    "title": "TICS-411 Minería de Datos",
    "section": "Tipos de Árboles de Decisión",
    "text": "Tipos de Árboles de Decisión\n\n\n\n\n\n\n\n\n\nBinary Split\n\n\n\n\n\n\n\n\n\n\nMulti-way Split\n\n\n\n\n\n\n\nHunt’s Algorithm \\(\\implies\\) Primer Método.\nID3 \\(\\implies\\) Sólo utiliza variables categóricas.\nC4.5 \\(\\implies\\) incluye variables continuas.\nC5.0 \\(\\implies\\) Permite separación en Múltiples Splits (No ha sido implementado en Sklearn).\nCART (Classification and Regression Trees) \\(\\implies\\) Permite que el output sea continuo pero solo utilizando Splits binarios.\n\n\n\n\n\n\n\n\n\n\nLos CARTs son por lejos los árboles más utilizados en las librerías más famosas y potentes: Scikit-Learn, XGboost, LightGBM, Catboost."
  },
  {
    "objectID": "tics411/clase-10.html#creación-de-un-árbol-de-decisión",
    "href": "tics411/clase-10.html#creación-de-un-árbol-de-decisión",
    "title": "TICS-411 Minería de Datos",
    "section": "Creación de un Árbol de Decisión",
    "text": "Creación de un Árbol de Decisión\n\nPureza\n\nCorresponde a la probabilidad de no sacar dos registros de un Nodo que pertenezcan a la misma clase.\n\n\n\n\n\n\n\n\nEl árbol de Decisión busca crear Nodos lo más puro posible. Para ello puede utilizar las siguentes métricas:\n\n\n\n\n\nÍndice Gini\n\\[Gini(X) = 1 - \\sum_{x_i}p(x_i)^2\\]\n\nEntropía\n\\[H(X) = -\\sum_{x_i}p(x_i)log_2p(x_i)\\]\n\n\n\n\n\n\n\nA mayor valor, mayor nivel de impureza. 0 implica Nodo completamente puro."
  },
  {
    "objectID": "tics411/clase-10.html#árbol-de-decisión-ejemplo",
    "href": "tics411/clase-10.html#árbol-de-decisión-ejemplo",
    "title": "TICS-411 Minería de Datos",
    "section": "Árbol de Decisión: Ejemplo",
    "text": "Árbol de Decisión: Ejemplo\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCálculo de Impureza en Hoja\n\n\n\\[Gini_{(leaf)} = 1 - p(Yes)^2 - p(No)^2\\]\n\n\n\n\n\n\n\n\n\nCálculo de Impureza en Split\n\n\n\\[ Gini_{(split)} = \\frac{n_{(yes)}}{n} Gini_{(yes)} + \\frac{n_{(no)}}{n} Gini_{(no)}\\]"
  },
  {
    "objectID": "tics411/clase-10.html#árbol-de-decisión-raíz-popcorn",
    "href": "tics411/clase-10.html#árbol-de-decisión-raíz-popcorn",
    "title": "TICS-411 Minería de Datos",
    "section": "Árbol de Decisión: Raíz Popcorn",
    "text": "Árbol de Decisión: Raíz Popcorn\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\[Gini_{(yes)} = 1 - \\left(\\frac{1}{4}\\right)^2 - \\left(\\frac{3}{4}\\right)^2 = 0.375\\] \\[Gini_{(no)} = 1 - \\left(\\frac{2}{3}\\right)^2 - \\left(\\frac{1}{3}\\right)^2 = 0.444\\]\n\n\n\n\\[Gini_{(split)} = \\frac{4}{7}\\cdot 0.375 + \\frac{3}{7} \\cdot 0.444 = 0.405\\]"
  },
  {
    "objectID": "tics411/clase-10.html#árbol-de-decisión-raíz-soda",
    "href": "tics411/clase-10.html#árbol-de-decisión-raíz-soda",
    "title": "TICS-411 Minería de Datos",
    "section": "Árbol de Decisión: Raíz Soda",
    "text": "Árbol de Decisión: Raíz Soda\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\[Gini_{(yes)} = 1 - \\left(\\frac{3}{4}\\right)^2 - \\left(\\frac{1}{4}\\right)^2 = 0.375\\] \\[Gini_{(no)} = 1 - \\left(\\frac{0}{3}\\right)^2 - \\left(\\frac{3}{3}\\right)^2 = 0\\]\n\n\n\n\\[Gini_{(split)} = \\frac{4}{7}\\cdot 0.375 = 0.214\\]"
  },
  {
    "objectID": "tics411/clase-10.html#árbol-de-decisión-raíz-age",
    "href": "tics411/clase-10.html#árbol-de-decisión-raíz-age",
    "title": "TICS-411 Minería de Datos",
    "section": "Árbol de Decisión: Raíz Age",
    "text": "Árbol de Decisión: Raíz Age\n\n\n\n\n\n\n\n\n\n\n\n\n\nLos cortes de posibles Splits se calculan como el promedio de los valores adyacentes una vez que han sidos ordenados de mayor a menor.\n\n\n\n\n\n\n\n\n\n\\[Gini_{(yes)} = 1 - \\left(\\frac{0}{1}\\right)^2 - \\left(\\frac{1}{1}\\right)^2 = 0\\] \\[Gini_{(no)} = 1 - \\left(\\frac{3}{6}\\right)^2 - \\left(\\frac{3}{6}\\right)^2 = 0.5\\]\n\n\n\n\\[Gini_{(split)} = \\frac{6}{7}\\cdot 0.5 = 0.429\\]"
  },
  {
    "objectID": "tics411/clase-10.html#árbol-de-decisión-raíz-age-1",
    "href": "tics411/clase-10.html#árbol-de-decisión-raíz-age-1",
    "title": "TICS-411 Minería de Datos",
    "section": "Árbol de Decisión: Raíz Age",
    "text": "Árbol de Decisión: Raíz Age\n\n\n\n\n\n\n\n\n\n\n\n\n\nLos cortes de posibles Splits se calculan como el promedio de los valores adyacentes una vez que han sidos ordenados de mayor a menor.\n\n\n\n\n\n\n\n\n\n\\[Gini_{(yes)} = 1 - \\left(\\frac{0}{2}\\right)^2 - \\left(\\frac{2}{2}\\right)^2 = 0\\] \\[Gini_{(no)} = 1 - \\left(\\frac{3}{5}\\right)^2 - \\left(\\frac{2}{5}\\right)^2 = 0.48\\]\n\n\n\n\\[Gini_{(split)} = \\frac{5}{7}\\cdot 0.48 = 0.343\\]"
  },
  {
    "objectID": "tics411/clase-10.html#árbol-de-decisión-raíz-age-2",
    "href": "tics411/clase-10.html#árbol-de-decisión-raíz-age-2",
    "title": "TICS-411 Minería de Datos",
    "section": "Árbol de Decisión: Raíz Age",
    "text": "Árbol de Decisión: Raíz Age\n\n\n\n\n\n\n\n\n\n\n\n\n\nLos cortes de posibles Splits se calculan como el promedio de los valores adyacentes una vez que han sidos ordenados de mayor a menor.\n\n\n\n\n\n\n\n\n\n\\[Gini_{(yes)} = 1 - \\left(\\frac{1}{3}\\right)^2 - \\left(\\frac{2}{3}\\right)^2 = 0.444\\] \\[Gini_{(no)} = 1 - \\left(\\frac{2}{4}\\right)^2 - \\left(\\frac{2}{4}\\right)^2 = 0.5\\]\n\n\n\n\\[Gini_{(split)} = \\frac{3}{7}\\cdot 0.444 + \\frac{4}{7} \\cdot 0.5 = 0.476\\]"
  },
  {
    "objectID": "tics411/clase-10.html#árbol-de-decisión-raíz-age-3",
    "href": "tics411/clase-10.html#árbol-de-decisión-raíz-age-3",
    "title": "TICS-411 Minería de Datos",
    "section": "Árbol de Decisión: Raíz Age",
    "text": "Árbol de Decisión: Raíz Age\n\n\n\n\n\n\n\n\n\n\n\n\n\nLos cortes de posibles Splits se calculan como el promedio de los valores adyacentes una vez que han sidos ordenados de mayor a menor.\n\n\n\n\n\n\n\n\n\n\\[Gini_{(yes)} = 1 - \\left(\\frac{2}{4}\\right)^2 - \\left(\\frac{2}{4}\\right)^2 = 0.5\\] \\[Gini_{(no)} = 1 - \\left(\\frac{1}{3}\\right)^2 - \\left(\\frac{2}{3}\\right)^2 = 0.444\\]\n\n\n\n\\[Gini_{(split)} = \\frac{4}{7}\\cdot 0.5 + \\frac{3}{7} \\cdot 0.444 = 0.476\\]"
  },
  {
    "objectID": "tics411/clase-10.html#árbol-de-decisión-raíz-age-4",
    "href": "tics411/clase-10.html#árbol-de-decisión-raíz-age-4",
    "title": "TICS-411 Minería de Datos",
    "section": "Árbol de Decisión: Raíz Age",
    "text": "Árbol de Decisión: Raíz Age\n\n\n\n\n\n\n\n\n\n\n\n\n\nLos cortes de posibles Splits se calculan como el promedio de los valores adyacentes una vez que han sidos ordenados de mayor a menor.\n\n\n\n\n\n\n\n\n\n\\[Gini_{(yes)} = 1 - \\left(\\frac{3}{2}\\right)^2 - \\left(\\frac{2}{5}\\right)^2 = 0.48\\] \\[Gini_{(no)} = 1 - \\left(\\frac{0}{2}\\right)^2 - \\left(\\frac{2}{2}\\right)^2 = 0\\]\n\n\n\n\\[Gini_{(split)} = \\frac{5}{7}\\cdot 0.48 = 0.343\\]"
  },
  {
    "objectID": "tics411/clase-10.html#árbol-de-decisión-raíz-age-5",
    "href": "tics411/clase-10.html#árbol-de-decisión-raíz-age-5",
    "title": "TICS-411 Minería de Datos",
    "section": "Árbol de Decisión: Raíz Age",
    "text": "Árbol de Decisión: Raíz Age\n\n\n\n\n\n\n\n\n\n\n\n\n\nLos cortes de posibles Splits se calculan como el promedio de los valores adyacentes una vez que han sidos ordenados de mayor a menor.\n\n\n\n\n\n\n\n\n\n\\[Gini_{(yes)} = 1 - \\left(\\frac{3}{6}\\right)^2 - \\left(\\frac{3}{6}\\right)^2 = 0.5\\] \\[Gini_{(no)} = 1 - \\left(\\frac{0}{1}\\right)^2 - \\left(\\frac{1}{1}\\right)^2 = 0\\]\n\n\n\n\\[Gini_{(split)} = \\frac{6}{7}\\cdot 0.5 = 0.429\\]"
  },
  {
    "objectID": "tics411/clase-10.html#qué-split-elegiremos",
    "href": "tics411/clase-10.html#qué-split-elegiremos",
    "title": "TICS-411 Minería de Datos",
    "section": "¿Qué Split elegiremos?",
    "text": "¿Qué Split elegiremos?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEscogeremos el Split más pequeño que representa el que genera más pureza.\n\n\n\n\n\n\n\n\n\n\n\nEl nodo que no le gusta la Soda quedó completamente puro. Por lo tanto, no puede seguir dividiéndose. Seguiremos trabajando sólo con aquellos que sí les gusta la Soda."
  },
  {
    "objectID": "tics411/clase-10.html#árbol-de-decisión-2do-nivel",
    "href": "tics411/clase-10.html#árbol-de-decisión-2do-nivel",
    "title": "TICS-411 Minería de Datos",
    "section": "Árbol de Decisión: 2do Nivel",
    "text": "Árbol de Decisión: 2do Nivel\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\[Gini_{(yes)} = 1 - \\left(\\frac{1}{2}\\right)^2 - \\left(\\frac{1}{2}\\right)^2 = 0.5\\] \\[Gini_{(no)} = 1 - \\left(\\frac{2}{2}\\right)^2 - \\left(\\frac{0}{2}\\right)^2 = 0\\]\n\n\n\n\\[Gini_{(split)} = \\frac{2}{4}\\cdot 0.5 = 0.25\\]"
  },
  {
    "objectID": "tics411/clase-10.html#árbol-de-decisión-2do-nivel-1",
    "href": "tics411/clase-10.html#árbol-de-decisión-2do-nivel-1",
    "title": "TICS-411 Minería de Datos",
    "section": "Árbol de Decisión: 2do Nivel",
    "text": "Árbol de Decisión: 2do Nivel\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\[Gini_{(yes)} = 1 - \\left(\\frac{0}{1}\\right)^2 - \\left(\\frac{1}{1}\\right)^2 = 0\\] \\[Gini_{(no)} = 1 - \\left(\\frac{3}{3}\\right)^2 - \\left(\\frac{0}{3}\\right)^2 = 0\\]\n\n\n\n\\[Gini_{(split)} = 0\\]"
  },
  {
    "objectID": "tics411/clase-10.html#árbol-de-decisión-2do-nivel-2",
    "href": "tics411/clase-10.html#árbol-de-decisión-2do-nivel-2",
    "title": "TICS-411 Minería de Datos",
    "section": "Árbol de Decisión: 2do Nivel",
    "text": "Árbol de Decisión: 2do Nivel\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\[Gini_{(yes)} = 1 - \\left(\\frac{1}{2}\\right)^2 - \\left(\\frac{1}{2}\\right)^2 = 0.5\\] \\[Gini_{(no)} = 1 - \\left(\\frac{2}{2}\\right)^2 - \\left(\\frac{0}{2}\\right)^2 = 0\\]\n\n\n\n\\[Gini_{(split)} = \\frac{2}{4} \\cdot 0.5 = 0.25\\]"
  },
  {
    "objectID": "tics411/clase-10.html#árbol-de-decisión-2do-nivel-3",
    "href": "tics411/clase-10.html#árbol-de-decisión-2do-nivel-3",
    "title": "TICS-411 Minería de Datos",
    "section": "Árbol de Decisión: 2do Nivel",
    "text": "Árbol de Decisión: 2do Nivel\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\[Gini_{(yes)} = 1 - \\left(\\frac{2}{3}\\right)^2 - \\left(\\frac{1}{3}\\right)^2 = 0.444\\] \\[Gini_{(no)} = 1 - \\left(\\frac{1}{1}\\right)^2 - \\left(\\frac{0}{1}\\right)^2 = 0\\]\n\n\n\n\\[Gini_{(split)} = \\frac{3}{4} \\cdot 0.444 = 0.333\\]"
  },
  {
    "objectID": "tics411/clase-10.html#árbol-de-decisión",
    "href": "tics411/clase-10.html#árbol-de-decisión",
    "title": "TICS-411 Minería de Datos",
    "section": "Árbol de Decisión",
    "text": "Árbol de Decisión\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n¿Cuál sería la predicción?"
  },
  {
    "objectID": "tics411/clase-10.html#crecimiento-de-un-árbol",
    "href": "tics411/clase-10.html#crecimiento-de-un-árbol",
    "title": "TICS-411 Minería de Datos",
    "section": "Crecimiento de un Árbol",
    "text": "Crecimiento de un Árbol\n\nUn árbol sólo dejará de crecer si:\n\nNo hay más puntos a separar.\n\nTodas las muestras de un nodo pertenecen a la misma clase.\n\nNo hay más variables a separar.\n\n\n\n\n\n\n\n\n\nEsto normalmente termina en Overfitting.\n\n\n\n\n\n\n\n\n\n\nPara solucionar esto se aplica regularización. En el caso de Árboles esto se denomina prunning."
  },
  {
    "objectID": "tics411/clase-10.html#pruning",
    "href": "tics411/clase-10.html#pruning",
    "title": "TICS-411 Minería de Datos",
    "section": "Pruning",
    "text": "Pruning\nPrepruning: Define/Evita que el árbol crezca hasta:\n\nUn cierto nivel o número de hojas.\nAplicar un test estadístico (normalmente un proceso muy costoso).\nUsar medidas de complejidad para penalizar árboles de gran tamaño.\n\nPostpruning: Decide eliminar nodos, luego de que el árbol crezca.\n\nUsar un parámetro de Costo de Impureza."
  },
  {
    "objectID": "tics411/clase-10.html#hiperparámetros",
    "href": "tics411/clase-10.html#hiperparámetros",
    "title": "TICS-411 Minería de Datos",
    "section": "Hiperparámetros",
    "text": "Hiperparámetros\n\n\n\n\n\n\n\ncriterion: Elegir bajo qué criterio se mide la impureza.\nmax_depth: El nivel es la altura que tendrá el árbol. Niveles más bajos generan árboles más simples.\nmin_samples_split: Número de instancias necesarias para generar un split. Un mayor número o proporción generará árboles más simples.\nmin_samples_leaf: Número mínimo de instancias necesarias para que un nodo sea hoja. Un número o proporción más alta generará árboles más simples.\nccp_alpha: Está asociado a la pureza total del árbol. Para más información ver acá.\n\n\n\n\n\n\n\n\n\n\n¿Cómo se ve la complejidad/simplicidad en un árbol de Decisión?"
  },
  {
    "objectID": "tics411/clase-10.html#implementación-en-scikit-learn",
    "href": "tics411/clase-10.html#implementación-en-scikit-learn",
    "title": "TICS-411 Minería de Datos",
    "section": "Implementación en Scikit-Learn",
    "text": "Implementación en Scikit-Learn\nfrom sklearn.tree import DecisionTreeClassifier, plot_tree\n\ndt = DecisionTreeClassifier(criterion=\"gini\", max_depth=None, min_sample_split=2, \n                            min_samples_leaf=1,min_impurity_decrease=0, \n                            ccp_alpha=0, random_state=42)\ndt.fit(X_train, y_train)\n\ny_pred = dt.predict(X_test)\ny_proba = dt.predict_proba(X_test)\n\n## Permite Visualizar el Árbol de Decisión\nplt_tree(dt, filled = True, feature_names=None, class_names=None)\n\n\ncriterion: Puede ser gini o entropía. Por defecto \"gini\".\nmax_depth: Número de niveles que se permita que crezca el nivel, por defecto None, significa todos los que pueda.\nmin_samples_split: El número mínimo de elementos dentro de un nodo para permitir el split. Por defecto 2.\nmin_samples_leaf: El número mínimo de elementos para que un nodo pueda ser considerado hoja. Por defecto 1.\nmin_impurity_decreased: Decrecimiento mínimo de la impureza. Si no se cumple, no hay Split. Por defecto 0.\nccp_alpha: Parámetro de Post-Pruning. Valores más altos genera la poda de más nodos."
  },
  {
    "objectID": "tics411/clase-13.html#definición",
    "href": "tics411/clase-13.html#definición",
    "title": "TICS-411 Minería de Datos",
    "section": "Definición",
    "text": "Definición\n\nAnomalías\n\n\nConjunto de puntos que son considerablemente diferentes al resto.\n\n\n\n\n\n\n\n\n\nPor definición las Anomalías son relativamente raras. * Pueden ocurrir en proporciones extremadamente bajas en los datos. Ej: 1 entre mil. * El contexto es importante. Ej: Temperaturas bajo cero en Verano.\n\n\n\nEjemplos:\n\nTelecomunicaciones: Detección de Abusos de Roaming.\nBanca: Compras/Ventas inusualmente elevados.\nFinanzas y Seguros: Detectar y prevenir patrones de gastos fraudulentos.\nMantención: Predicción de comportamiento irregular/fallas.\nSmart Homes: Detecciones de fugas de Energía\netc."
  },
  {
    "objectID": "tics411/clase-13.html#más-ejemplos",
    "href": "tics411/clase-13.html#más-ejemplos",
    "title": "TICS-411 Minería de Datos",
    "section": "Más ejemplos",
    "text": "Más ejemplos\n\n\n\n\n\n\nLa definición de Anomalía es altamente subjetiva y depende mucho del Dominio en el cuál se está trabajando."
  },
  {
    "objectID": "tics411/clase-13.html#tipos-de-anomalías-series-de-tiempo",
    "href": "tics411/clase-13.html#tipos-de-anomalías-series-de-tiempo",
    "title": "TICS-411 Minería de Datos",
    "section": "Tipos de Anomalías (Series de Tiempo)",
    "text": "Tipos de Anomalías (Series de Tiempo)"
  },
  {
    "objectID": "tics411/clase-13.html#desafíos",
    "href": "tics411/clase-13.html#desafíos",
    "title": "TICS-411 Minería de Datos",
    "section": "Desafíos",
    "text": "Desafíos\n\n\n\n\n\n\nDesafíos\n\n\n\n¿Cuántos Atributos/Variables usamos para definir un Outlier?\n¿Cuántos Outliers existen?\nEste tipo de problema suele ser complicado de Etiquetar, por lo que es difícil resolverlo como un problema supervisado.\nPuede ser como “Encontrar una aguja en un pajar”."
  },
  {
    "objectID": "tics411/clase-13.html#enfoques",
    "href": "tics411/clase-13.html#enfoques",
    "title": "TICS-411 Minería de Datos",
    "section": "Enfoques",
    "text": "Enfoques"
  },
  {
    "objectID": "tics411/clase-13.html#técnicas-visuales",
    "href": "tics411/clase-13.html#técnicas-visuales",
    "title": "TICS-411 Minería de Datos",
    "section": "Técnicas Visuales",
    "text": "Técnicas Visuales\n\n\n\n\n\n\nEstas técnicas son muy subjetivas ya que dependen del criterio/apreciación del usuario.\n\n\n\n\n\nBox Plots\n\n\n\n\n\n\nScatter Plots"
  },
  {
    "objectID": "tics411/clase-13.html#técnicas-estadísticas-test-de-grubbs",
    "href": "tics411/clase-13.html#técnicas-estadísticas-test-de-grubbs",
    "title": "TICS-411 Minería de Datos",
    "section": "Técnicas Estadísticas: Test de Grubbs",
    "text": "Técnicas Estadísticas: Test de Grubbs\n\n\n\n\n\n\nEl test de Grubbs detecta si algún dato es un outlier sobre una variable asumiendo que se distribuyen de manera normal.\n\n\n\n\\[G = \\frac{\\underset{i = 1,2,...,n}{max}|x_i - \\bar{X}|}{S_x}\\]\ndonde \\(\\bar{X}\\) y \\(S_x\\) corresponden a la media y Desviación Estándar Muestral.\n\nEso implica que \\(G\\) se distribuye como una t-student de \\(n-2\\) grados de libertad, por lo tanto si:\n\n\\[ G_{critico} = \\frac{n-1}{\\sqrt{n}}\\sqrt{\\frac{t^2_{(\\alpha/n, n-2)}}{n-2+t_{(\\alpha/n, n-2)^2}}}\\]\n\n\n\n\n\n\nSi \\(G &gt; G_{critico}\\), \\(x_i\\) es considerado un outlier con una significancia \\(\\alpha/n\\) para una t-student con \\(n-2\\) grados de libertad."
  },
  {
    "objectID": "tics411/clase-13.html#test-de-grubs-en-python",
    "href": "tics411/clase-13.html#test-de-grubs-en-python",
    "title": "TICS-411 Minería de Datos",
    "section": "Test de Grubs en Python",
    "text": "Test de Grubs en Python\n\n\n\n\n\n\nEste código debiera entregar una lista de todos los puntos que son considerados outliers.\n\n\n\nfrom scipy import stats\nimport numpy as np\n\nn = 16 # Número de Datos\nalpha = 0.05 # nivel de confianza\n\nt_crit = stats.t.ppf(1-alpha/n, n-2)\nG_crit = (n-1)/np.sqrt(n)*np.sqrt(t_crit**2/(n-2 + t_crit**2))\n\ndata = np.array([5,14,15,15,19,17,16,20,22,8,21,28,11,9,29,40])\nG_test = np.abs(data-np.mean(data)/np.std(data))\n\ntest_grubbs = np.where(G_test&gt;G_crit)\nprint(f\"Outliers: {data[test_grubbs]}\")"
  },
  {
    "objectID": "tics411/clase-13.html#caso-multivariado",
    "href": "tics411/clase-13.html#caso-multivariado",
    "title": "TICS-411 Minería de Datos",
    "section": "Caso Multivariado",
    "text": "Caso Multivariado\n\n\n\n\n\n\n\n\n\n\n\nLa idea es calcular la distancia de cada punto al centro tomando en consideración la covarianza."
  },
  {
    "objectID": "tics411/clase-13.html#caso-multivariado-1",
    "href": "tics411/clase-13.html#caso-multivariado-1",
    "title": "TICS-411 Minería de Datos",
    "section": "Caso Multivariado",
    "text": "Caso Multivariado\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPaso 1\n\n\n\nCalcular el punto central de todos los puntos (Promedio) \\[\\mu = (3.16, 3.16)\\]\n\n\n\n\n\n\n\n\n\n\n\nPaso 2\n\n\n\nCalcular la Inversa de la Matriz de Covarianza:"
  },
  {
    "objectID": "tics411/clase-13.html#caso-multivariado-continuación",
    "href": "tics411/clase-13.html#caso-multivariado-continuación",
    "title": "TICS-411 Minería de Datos",
    "section": "Caso Multivariado: Continuación",
    "text": "Caso Multivariado: Continuación\n\n\n\n\n\n\nPaso 3\n\n\nCalcular la distancia de cada punto con respecto a la media y la inversa de la Covarianza.\n\n\n\n\\[d_i = (p_i - \\mu)^T \\Sigma^{-1}(p_i - \\mu)\\]\n\\[d_1 = (p_1 - \\mu)^T \\sigma^{-1}(p_1 - \\mu)\\]\n\\[d_1 = ([0,0] - [3.16, 3.16])^T \\begin{bmatrix}\n                            0.147 & -0.147  \\\\\n                            -0.147 & 1.911  \\\\\n                            \\end{bmatrix}\n                            ([0,0] - [3.16, 3.16])\\]\n\n\n\n\n\n\nSe debe repetir este procedimiento para cada punto."
  },
  {
    "objectID": "tics411/clase-13.html#caso-multivariado-continuación-1",
    "href": "tics411/clase-13.html#caso-multivariado-continuación-1",
    "title": "TICS-411 Minería de Datos",
    "section": "Caso Multivariado: Continuación",
    "text": "Caso Multivariado: Continuación\n\n\n\n\n\n\nPaso 4:\n\n\nSe debe calcular el punto crítico según t-student con 95% confianza, y orden de magnitud \\(m\\) dimensiones.\n\n\n\n\\[t_{(\\alpha = 0.95,2)} = 5.99\\]\n\n\n\n\n\n\nPaso 5\n\n\nComparar, Si \\(d_i&gt;t_{crit}\\) entonces \\(d_i\\) es Outlier.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEn este caso ningún valor de \\(d_i\\) es mayor al $t_{(crit)}, por lo tanto, no hay outliers."
  },
  {
    "objectID": "tics411/clase-13.html#distancia-de-mahalanobis",
    "href": "tics411/clase-13.html#distancia-de-mahalanobis",
    "title": "TICS-411 Minería de Datos",
    "section": "Distancia de Mahalanobis",
    "text": "Distancia de Mahalanobis\nLa distancia de Mahalanobis corresponde a:\n\\[d_i = \\sqrt{(p_i - \\mu)^T \\Sigma^{-1}(p_i - \\mu)}\\]\n\n\n\n\n\n\nSe puede repetir el mismo procedimiento anterior, sólo que se define una Distancia de Mahalonobis umbral. Las que superen dicho umbral son considerados como Outliers."
  },
  {
    "objectID": "tics411/clase-13.html#dbscan",
    "href": "tics411/clase-13.html#dbscan",
    "title": "TICS-411 Minería de Datos",
    "section": "DBSCAN",
    "text": "DBSCAN\nPodemos utilizar el procedimiento que aprendimos de DBSCAN. Todos los puntos Noise serán considerados como Anomalías.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEste punto corresponde a un Noise Point. Lo cuál en nuestro caso particular se considerará una Anomalía."
  },
  {
    "objectID": "tics411/clase-13.html#k-nearest-neighbor",
    "href": "tics411/clase-13.html#k-nearest-neighbor",
    "title": "TICS-411 Minería de Datos",
    "section": "K-Nearest Neighbor",
    "text": "K-Nearest Neighbor\n\n\n\n\n\n\nSe puede utilizar los modelos de vecinos más cercanos para determinar outliers siguiendo el siguiente procedimiento:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPaso 1: Definir el valor de \\(k\\) para encontrar los vecinos más cercanos.\nEj: Sea \\(k=3\\)\nPaso 2: Calcular la Matriz de Distancias y determinar los vecinos más cercanos."
  },
  {
    "objectID": "tics411/clase-13.html#k-nearest-neighbor-continuación",
    "href": "tics411/clase-13.html#k-nearest-neighbor-continuación",
    "title": "TICS-411 Minería de Datos",
    "section": "K-Nearest Neighbor: Continuación",
    "text": "K-Nearest Neighbor: Continuación\n\n\n\nPaso 3: Calcular la distancias Promedio.\n\n\n\n\n\n\nPaso 4: Escoger un Umbral. Si es que la distancia es mayor al Umbral entonces es un Outlier. Ej: \\(Dist_crit: 3\\)"
  },
  {
    "objectID": "tics411/clase-13.html#local-outlier-factor-lof",
    "href": "tics411/clase-13.html#local-outlier-factor-lof",
    "title": "TICS-411 Minería de Datos",
    "section": "Local Outlier Factor (LOF)",
    "text": "Local Outlier Factor (LOF)\n\nLocal Outlier Factor (LOF) detecta anomalías con sus vecindarios locales, en lugar de la distribución glocal de los datos.\n\n\n\n\n\n\n\nEn la Figura, \\(O1\\) y \\(O2\\) son anomalías locales en comparación con \\(C1\\), \\(O3\\) es una anomalía global, y \\(O4\\) no es una anomalía."
  },
  {
    "objectID": "tics411/clase-13.html#algoritmo",
    "href": "tics411/clase-13.html#algoritmo",
    "title": "TICS-411 Minería de Datos",
    "section": "Algoritmo",
    "text": "Algoritmo\n\nDeterminar \\(N(x,k)\\), los k-vecinos más cercanos de cada punto x.\nPara todo punto \\(y\\), calcular la distancia a su k-ésimo vecino más cercano.\nCalcular la reach-distance entre todos los puntos: \\[reach-distance_k(x,y) = max\\{k-distance(y), d(x,y)\\}\\]\nCalcule la densidad del vecindario local sobre sus \\(k\\) vecinos, donde \\(|N(x,k)| = k\\).\n\n\\[density(x,k) = lrd_k(x) = \\left(\\frac{\\sum_{y \\in N(x,k)} reach-distance_k(x,y)}{|N(x,k)|}\\right)^{-1}\\]\n\nCalcule el Local Outlier Factor para el punto x como la proporción de la densidad de sus \\(k\\) vecinos más cercanos, con respecto a la densidad del punto \\(x\\).\n\n\n\n\\[ LOF(x) = \\frac{\\sum_{y \\in N(x,k) density(y,k)}}{|N(x,k)|density(x,k)} \\]\n\n\n\n\n\n\n\nLOF(X) &gt;&gt; 1 implica anomalía."
  },
  {
    "objectID": "tics411/clase-13.html#ejemplo-local-outlier-factor",
    "href": "tics411/clase-13.html#ejemplo-local-outlier-factor",
    "title": "TICS-411 Minería de Datos",
    "section": "Ejemplo Local Outlier Factor",
    "text": "Ejemplo Local Outlier Factor\n\n\n\nConsideremos los siguientes 4 puntos de datos: a(0,0), b(0,1), c(1,1), d(3,0). Calcular el LOF para cada punto y mostrar la anomalía principal.\n\n\n\n\n\n\n\n\n\nUtilizar \\(K = 2\\) y Distancia Manhattan.\n\n\n\n\n\nPaso 1: Calcular Distancias\n\ndist(a,b) = 1\ndist(a,c) = 2\ndist(a,d) = 3\ndist(b,c) = 1\ndist(b,d) = 4\ndist(c,d) = 3"
  },
  {
    "objectID": "tics411/clase-13.html#ejemplo-local-outlier-factor-continuación",
    "href": "tics411/clase-13.html#ejemplo-local-outlier-factor-continuación",
    "title": "TICS-411 Minería de Datos",
    "section": "Ejemplo Local Outlier Factor: Continuación",
    "text": "Ejemplo Local Outlier Factor: Continuación\nPaso 2: Para todo punto \\(y\\), calcule la distancia a su k-ésimo vecino más cercano.\n\n\\(dist_2(a) = dist(a,c) = 2\\) (c es el 2do vecino más cercano)\n\\(dist_2(b) = dist(b,a) = 1\\) (a/c es el 2do vecino más cercano)\n\\(dist_2(c) = dist(c,a) = 2\\) (a es el 2do vecino más cercano)\n\\(dist_2(d) = dist(d,a) = 3\\) (a/c es el 2do vecino más cercano)"
  },
  {
    "objectID": "tics411/clase-13.html#ejemplo-local-outlier-factor-continuación-1",
    "href": "tics411/clase-13.html#ejemplo-local-outlier-factor-continuación-1",
    "title": "TICS-411 Minería de Datos",
    "section": "Ejemplo Local Outlier Factor: Continuación",
    "text": "Ejemplo Local Outlier Factor: Continuación\nPaso 3: Calcular la reach-distance entre todos los puntos, es decir, los puntos vecindarios a una distancia k.\n\n\n\n\\(N_k(o)\\): Vecindario de \\(k\\)-distancia de \\(o\\), \\(N_k(o)=\\{o'\\|o' \\in D, dist(o,o') \\le dist_k(o)\\}\\)\n\n\n\n\n\\(N_2(a) = \\{b,c\\}\\)\n\\(N_2(b) = \\{a,c\\}\\)\n\\(N_2(c) = \\{b,a\\}\\)\n\\(N_2(d) = \\{a,c\\}\\)"
  },
  {
    "objectID": "tics411/clase-13.html#ejemplo-local-outlier-factor-continuación-2",
    "href": "tics411/clase-13.html#ejemplo-local-outlier-factor-continuación-2",
    "title": "TICS-411 Minería de Datos",
    "section": "Ejemplo Local Outlier Factor: Continuación",
    "text": "Ejemplo Local Outlier Factor: Continuación\n\n\nPaso 4: Calcular la densidad del vecinadario local sobre sus \\(k\\) vecinos.\n\n\n\n\n\n\n\n\n\\(reach-dist_2(b \\leftarrow a) = max\\{dist_2(b), dist(b,a)\\} = max\\{1,1\\} = 1\\)\n\\(reach-dist_2(c \\leftarrow a) = max\\{dist_2(c), dist(c,a)\\} = max\\{2,2\\} = 2\\)\n\n\n\n\n\n\n\nCalcular el resto de manera análoga."
  },
  {
    "objectID": "tics411/clase-13.html#ejemplo-local-outlier-factor-continuación-3",
    "href": "tics411/clase-13.html#ejemplo-local-outlier-factor-continuación-3",
    "title": "TICS-411 Minería de Datos",
    "section": "Ejemplo Local Outlier Factor: Continuación",
    "text": "Ejemplo Local Outlier Factor: Continuación\nEntonces, \\(lrd_k(o)\\): Densidad de alcanzabilidad local de \\(o\\).\n\\[lrd_2(a) = \\frac{|\\mathcal{N}(a)|}{reach-dist_2(b\\leftarrow a) + reach-dist_2(c \\leftarrow a)} = \\frac{2}{1 + 2} = 0.667\\] \\[lrd_2(b) = \\frac{|\\mathcal{N}(b)|}{reach-dist_2(a\\leftarrow b) + reach-dist_2(b \\leftarrow b)} = \\frac{2}{2 + 2} = 0.5\\] \\[lrd_2(c) = \\frac{|\\mathcal{N}(c)|}{reach-dist_2(b\\leftarrow c) + reach-dist_2(a \\leftarrow c)} = \\frac{2}{1 + 2} = 0.667\\] \\[lrd_2(d) = \\frac{|\\mathcal{N}(d)|}{reach-dist_2(a\\leftarrow d) + reach-dist_2(c \\leftarrow d)} = \\frac{2}{1 + 2} = 0.33\\]"
  },
  {
    "objectID": "tics411/clase-13.html#ejemplo-local-outlier-factor-continuación-4",
    "href": "tics411/clase-13.html#ejemplo-local-outlier-factor-continuación-4",
    "title": "TICS-411 Minería de Datos",
    "section": "Ejemplo Local Outlier Factor: Continuación",
    "text": "Ejemplo Local Outlier Factor: Continuación\nPaso 5: Calcular el Local Outlier Factor para el punto \\(x\\) como la proporción de la densidad de sus \\(k\\) vecinos más cercanos, con respecto a la densidad del punto \\(x\\).\n\n\n\\[LOF(x) = \\frac{\\sum_{y \\in N(x,k)} density(y,k)}{|N(x,k)|density(x,k)}\\]\n\\[LOF_2(a) = \\frac{lrd_2(b) + lrd_2(c)}{N_2(a) \\cdot lrd_2(a)} = \\frac{0.5 + 0.667}{2 \\cdot 0.667} = 0.87\\] \\[LOF_2(b) = \\frac{lrd_2(a) + lrd_2(c)}{N_2(b) \\cdot lrd_2(b)} = \\frac{0.667 + 0.667}{2 \\cdot 0.5} = 1.334\\] \\[LOF_2(c) = \\frac{lrd_2(b) + lrd_2(a)}{N_2(c) \\cdot lrd_2(c)} = \\frac{0.5 + 0.667}{2 \\cdot 0.667} = 0.87\\] \\[LOF_2(d) = \\frac{lrd_2(a) + lrd_2(c)}{N_2(d) \\cdot lrd_2(d)} = \\frac{0.667 + 0.667}{2 \\cdot 0.33} = 2\\]"
  },
  {
    "objectID": "tics411/clase-13.html#ejemplo-local-outlier-factor-continuación-5",
    "href": "tics411/clase-13.html#ejemplo-local-outlier-factor-continuación-5",
    "title": "TICS-411 Minería de Datos",
    "section": "Ejemplo Local Outlier Factor: Continuación",
    "text": "Ejemplo Local Outlier Factor: Continuación\nPaso 6: Ordena todas las LOF_k(o)\n\nLOF_2(d) = 2 \\(\\implies\\) el punto paraecer una anomalía (LOF &gt;&gt; 1)\nLOF_2(b) = 1.334\nLOF_2(a) = 0.87\nLOF_2(c) = 0.87\n\n\n\n\n\n\n\nDetalles Técnicos\n\n\n\nDado que esto sigue un enfoque local, la resolución depende de la elección del usuario para \\(k\\).\nGenera una puntuación (Anomaly Score) para cada punto.\nComo \\(LOF\\) es una razón, es difícil de interpretar. No existe un valor umbral específico por encima del cual un punto se define como un valor atípico. La identificación de un valor atípico depende del problema y del usuario\nComo \\(LOF\\) es una razón, es difícil de interpretar. No existe un valor umbral específico por encima del cual un punto se define como un valor atípico. La identificación de un valor atípico depende del problema y del usuario."
  },
  {
    "objectID": "tics411/clase-9.html#intuición",
    "href": "tics411/clase-9.html#intuición",
    "title": "TICS-411 Minería de Datos",
    "section": "Intuición",
    "text": "Intuición\nSupongamos que tengo que estudiar para la prueba de Minería de Datos y tengo que aprender a calcular el Coeficiente de Silueta.\n\nQué pasa si sólo les entrego una pregunta para estudiar y no tiene respuesta.\n¿Qué pasa si ahora les doy la respuesta?\n¿Qué pasa si te doy más ejercicios?\n¿Qué pasa luego de que haces muchos ejercicios?\n\n\n\n\n\n\n\n\nVoy aprendiendo mejor la tarea de calcular el coeficiente de Silueta. Lo mismo pasa con los modelos.\n\n\n\n\n\n\n\n\n\n\n\nPero no puedo medir qué tan bien aprendiste en los ejercicios que yo ya entregué para practicar. Tengo que hacer una prueba que tú no hayas visto, para ver si realmente aprendiste."
  },
  {
    "objectID": "tics411/clase-9.html#uso-de-un-modelo",
    "href": "tics411/clase-9.html#uso-de-un-modelo",
    "title": "TICS-411 Minería de Datos",
    "section": "Uso de un Modelo",
    "text": "Uso de un Modelo\n\n\n\n\n\n\n\n\n\n\n\n\n¿Cómo saber que el modelo está funcionando como esperamos?"
  },
  {
    "objectID": "tics411/clase-9.html#métricas",
    "href": "tics411/clase-9.html#métricas",
    "title": "TICS-411 Minería de Datos",
    "section": "Métricas",
    "text": "Métricas\nEl Rendimieto de un Modelo de Clasificación permite evaluar el error asociado al proceso de predicción.\n\n\n\n\nClase Positiva\n\nCorresponde a la clase/evento de interés. Ej: Tiene cancer, va a pagar su deuda, es un gato. Normalmente se denota como la Clase 1.\n\nClase Negativa\n\nCorresponde a la clase/evento contrario al de interés. Ej: No tiene cancer, no va a pagar su deuda, no es un gato. Normalmente se denota como la Clase 0.\n\n\n\n\n\n\n\n\n\n\n\nScikit-Learn usa la siguiente convención:\n\nSi se llama *_score un mayor puntaje es mejor.\nSi se llama *_error o *_loss un mejor puntaje es mejor."
  },
  {
    "objectID": "tics411/clase-9.html#métricas-matriz-de-confusión",
    "href": "tics411/clase-9.html#métricas-matriz-de-confusión",
    "title": "TICS-411 Minería de Datos",
    "section": "Métricas: Matriz de Confusión",
    "text": "Métricas: Matriz de Confusión\n\nLa Matriz de Confusión ordena los valores correctamente predichos y también los distintos errores que el modelo puede cometer.\n\n\n\n\n\n\n\n\n\n\nTP (Verdaderos Positivos)\n\nCorresponde a valores reales de la clase 1 que fueron correctamente predichos como clase 1.\n\nTN (Verdaderos Negativos)\n\nCorresponde a valores reales de la clase 0 que fueron correctamente predichos como clase 0.\n\nFP (Falsos Positivos)\n\nCorresponde a valores reales de la clase 0 que fueron incorrectamente predichos como clase 1.\n\nFN (Falsos Negativos)\n\nCorresponde a valores reales de la clase 1 que fueron incorrectamente predichos como clase 0."
  },
  {
    "objectID": "tics411/clase-9.html#métricas-a-partir-de-la-matriz-de-confusión",
    "href": "tics411/clase-9.html#métricas-a-partir-de-la-matriz-de-confusión",
    "title": "TICS-411 Minería de Datos",
    "section": "Métricas: A partir de la Matriz de Confusión",
    "text": "Métricas: A partir de la Matriz de Confusión\n\n\n\n\n\nAccuracy\n\n\n\\[\\frac{TP + TN}{TP + TN + FP + FN}\\]\n\n\n\n\n\n\nPrecision\n\n\n\\[\\frac{TP}{TP + FP}\\]\n\n\n\n\n\n\n\nRecall\n\n\n\\[\\frac{TP}{TP + FN}\\]\n\n\n\n\n\n\nF1-Score\n\n\n\\[\\frac{2\\cdot Precision \\cdot Recall}{Precision + Recall} = \\frac{2 \\cdot TP}{2\\cdot TP + FP + FN}\\]\n\n\n\n\n\n\n\n\n\n\n\nAccuracy es probablemente la métrica más sencilla y más utilizada.\nPrecision y Recall ponderarán distintos errores (FP y FN respectivamente) con mayor severidad. Ambas métricas son Antagonistas.\nF1-Score corresponde a la media armónica del Precision y Recall, y tiende a ponderar los errores de manera más balanceada.\n\n\n\n\n¿Cuándo utilizar cada tipo de error?"
  },
  {
    "objectID": "tics411/clase-9.html#curva-roc",
    "href": "tics411/clase-9.html#curva-roc",
    "title": "TICS-411 Minería de Datos",
    "section": "Curva ROC",
    "text": "Curva ROC\nLa curva ROC fue desarrollada en 1950 para analizar señales ruidosas. La curva ROC permite al operador contrapesar la tasa de verdaderos positivos (Eje \\(y\\)) versus los falsos positivos (Eje x).\n\nEl área bajo la curva representa la calidad del modelo. Una manera de interpretarla es como la probabilidad de que una predicción de la clase positiva tenga mayor probabilidad que una de clase negativa. En otras palabras, mide que las probabilidades se encuentren correctamente ordenadas. Por lo tanto varía entre 0.5 y 1.\n\n\n\n\n\n\n\n\n\nROC \\(\\sim\\) 0.5\n\n\n\n\n\nROC \\(\\sim\\) 1"
  },
  {
    "objectID": "tics411/clase-9.html#implementación-en-python",
    "href": "tics411/clase-9.html#implementación-en-python",
    "title": "TICS-411 Minería de Datos",
    "section": "Implementación en Python",
    "text": "Implementación en Python\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n\naccuracy_score(y_true, y_pred)\nprecision_score(y_true, y_pred)\nrecall_score(y_true, y_pred)\nf1_score(y_true, y_pred)\nroc_auc_score(y_true, y_proba)\n\ny_true: Corresponde a las etiquetas reales del Dataset.\ny_pred: Corresponde a las predicciones realizadas por el modelo.\ny_proba: Corresponden a las probabilidades predichas por el modelo (si es que el modelo lo permite)."
  },
  {
    "objectID": "tics411/clase-9.html#implementación-en-python-matriz-de-confusión",
    "href": "tics411/clase-9.html#implementación-en-python-matriz-de-confusión",
    "title": "TICS-411 Minería de Datos",
    "section": "Implementación en Python: Matriz de Confusión",
    "text": "Implementación en Python: Matriz de Confusión\nfrom sklearn.metrics import ConfusionMatrixDisplay\n\nConfusionMatrixDisplay.from_predictions(y_true, y_pred)"
  },
  {
    "objectID": "tics411/clase-9.html#implementación-en-python-curva-roc",
    "href": "tics411/clase-9.html#implementación-en-python-curva-roc",
    "title": "TICS-411 Minería de Datos",
    "section": "Implementación en Python: Curva ROC",
    "text": "Implementación en Python: Curva ROC\nfrom sklearn.metrics import RocCurveDisplay\n\nRocCurveDisplay.from_predictions(y_true, y_proba)"
  },
  {
    "objectID": "tics411/clase-9.html#curva-de-aprendizaje-training",
    "href": "tics411/clase-9.html#curva-de-aprendizaje-training",
    "title": "TICS-411 Minería de Datos",
    "section": "Curva de Aprendizaje: Training",
    "text": "Curva de Aprendizaje: Training\n\n\n\n\n\n\n\n\n\n\n\n¿Qué sería la Complejidad del Modelo?"
  },
  {
    "objectID": "tics411/clase-9.html#curva-de-aprendizaje-validación",
    "href": "tics411/clase-9.html#curva-de-aprendizaje-validación",
    "title": "TICS-411 Minería de Datos",
    "section": "Curva de Aprendizaje: Validación",
    "text": "Curva de Aprendizaje: Validación\n\n\n\n\n\n\n\n\n\n\n\n¿Por qué el modelo pierde rendimiento cuando aumenta su Complejidad?"
  },
  {
    "objectID": "tics411/clase-9.html#curva-de-aprendizaje-mejor-ajuste",
    "href": "tics411/clase-9.html#curva-de-aprendizaje-mejor-ajuste",
    "title": "TICS-411 Minería de Datos",
    "section": "Curva de Aprendizaje: Mejor Ajuste",
    "text": "Curva de Aprendizaje: Mejor Ajuste\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverfitting:\n\n\nGran diferencia entre Training y Validation Score.\n\n\n\n\n\n\n\n\n\nUnderfitting:\n\n\nPoca diferencia entre Training y Validation Score, pero con ambos puntajes “relativamente bajos”.\n\n\n\n\n\n\n\n\n\nProper fitting o Sweet Spot:\n\n\nCorresponde al mejor puntaje en el set de Validación. Donde también la distancia entre Train y Test es poca."
  },
  {
    "objectID": "tics411/clase-9.html#complejidad-de-un-modelo",
    "href": "tics411/clase-9.html#complejidad-de-un-modelo",
    "title": "TICS-411 Minería de Datos",
    "section": "Complejidad de un Modelo",
    "text": "Complejidad de un Modelo\n¿Qué modelo es un mejor clasificador?"
  },
  {
    "objectID": "tics411/clase-9.html#bias-variance-tradeoff",
    "href": "tics411/clase-9.html#bias-variance-tradeoff",
    "title": "TICS-411 Minería de Datos",
    "section": "Bias Variance Tradeoff",
    "text": "Bias Variance Tradeoff\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLos puntos azules serán puntos que usaremos para entrenar.\nLos puntos verdes serán puntos que usaremos para validar."
  },
  {
    "objectID": "tics411/clase-9.html#bias-variance-tradeoff-bias",
    "href": "tics411/clase-9.html#bias-variance-tradeoff-bias",
    "title": "TICS-411 Minería de Datos",
    "section": "Bias Variance Tradeoff: Bias",
    "text": "Bias Variance Tradeoff: Bias\n\nBias\n\n\nSe refiere a la incapacidad de un modelo de capturar la verdadera relación entre los datos.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEl modelo está “sesgado” a tomar una cierta relación que no necesariamente existe."
  },
  {
    "objectID": "tics411/clase-9.html#bias-variance-tradeoff-variance",
    "href": "tics411/clase-9.html#bias-variance-tradeoff-variance",
    "title": "TICS-411 Minería de Datos",
    "section": "Bias Variance Tradeoff: Variance",
    "text": "Bias Variance Tradeoff: Variance\n\nVariance\n\n\nSe refiere a la diferencia de ajuste entre datasets (Train y Validación).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEl modelo varía demasiado su comportamiento entre Training y Testing Time."
  },
  {
    "objectID": "tics411/clase-9.html#complejidad-de-un-modelo-1",
    "href": "tics411/clase-9.html#complejidad-de-un-modelo-1",
    "title": "TICS-411 Minería de Datos",
    "section": "Complejidad de un Modelo",
    "text": "Complejidad de un Modelo\n\n\nOverfitting\n\n\n\n\n\n\n\n\n\n\n\n\nRegularización: Se refiere a una penalización para disminuir su complejidad.\n\nModelos más simples: Utilizar modelos con una Frontera de Decisión más simple.\nMás datos!!! Más datos más dificil aprender, por lo tanto, modelos complejos se ven más beneficiados de esto.\n\n\n\n\n\n\nUnderfitting\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuitar Regularización\nModelos más complejos\nMás variabilidad en los datos!!! Podría ser que los datos no permitan aprender patrones más complejos."
  },
  {
    "objectID": "tics411/clase-9.html#cómo-generamos-sets-de-validación",
    "href": "tics411/clase-9.html#cómo-generamos-sets-de-validación",
    "title": "TICS-411 Minería de Datos",
    "section": "¿Cómo generamos sets de Validación?",
    "text": "¿Cómo generamos sets de Validación?\n\nLa evaluación de modelos supervisados es fundamental. De no hacerlo de forma correcta podemos quedarnos con una idea muy equivocada del rendimiento del modelo.\n\n\nCross Validation (Validación Cruzada)\n\n\nSe debe evaluar el rendimiento de un modelo en un dataset diferente al que fue entrenado. Esta es la única manera en la que se puede medir el poder de generalización de un modelo.\n\n\nGeneralización\n\n\nCorresponde a la habilidad de un modelo de adaptarse apropiadamente a datos no vistos previamente.\n\n\n\n\n\n\n\n\n\nUtilizar una estrategia incorrecta de Validación puede llevar a problemas de generalización. La estrategia de Validación debe ser lo más parecida posible a cómo se utilizará el modelo en Producción.\n\n\n\n\n\n\n\n\n\nPara esto se asume que todos los datos son i.i.d (independent and identically distributed). De no lograr esto, lograr buenos rendimientos es más difícil."
  },
  {
    "objectID": "tics411/clase-9.html#validación-cruzada-holdout",
    "href": "tics411/clase-9.html#validación-cruzada-holdout",
    "title": "TICS-411 Minería de Datos",
    "section": "Validación Cruzada: Holdout",
    "text": "Validación Cruzada: Holdout\n\nTambién es conocido como Train Test Split o simplemente Split. Corresponde a la separacion de nuestra data cuando con el proposito de aislar observaciones que el modelo no vea para una correcta evaluación.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEl train set es la porción de los datos que se utilizará exclusivamente para entrenar los datos.\n\n\n\n\n\n\n\n\n\n\n\n\n\nEl test set es la porción de los datos que se utilizará exclusivamente para validar los datos.\nEl test set simula los datos que eventualmente entrarán el modelo para obtener una predicción.\n\n\n\n\n\n\n\n\n\n\n\n\n\nNormalmente se utilizan splits del tipo 70/30, 80/20 o 90/10.\n\n\n\n\n\n\n\n\n\n\n\n\n\n¿Cuál es el problema con este tipo de validación?"
  },
  {
    "objectID": "tics411/clase-9.html#variante-holdout",
    "href": "tics411/clase-9.html#variante-holdout",
    "title": "TICS-411 Minería de Datos",
    "section": "Variante Holdout",
    "text": "Variante Holdout\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSe agrega un validation set el cuál se utilizará para escoger los hiperparámetros que muestren un mejor poder de generalización.\n\n\n\n\n\n\n\n\n\n\n\n\n\nEl train set y el test set cumplen la misma función que tenían antes."
  },
  {
    "objectID": "tics411/clase-9.html#variante-holdout-procedimiento",
    "href": "tics411/clase-9.html#variante-holdout-procedimiento",
    "title": "TICS-411 Minería de Datos",
    "section": "Variante Holdout: Procedimiento",
    "text": "Variante Holdout: Procedimiento\n\n\n\n\n\n\n\n\nProcedimiento\n\nRepetir para cada Modelo a probar.\n\n\n\n\n\n\n\n\nVamos a entender un modelo como la combinación de un Algoritmo de Aprendizaje + Hiperparámetros + Preprocesamiento.\n\n\n\n\n\nSe entrena cada Modelo en el train set. Se mide una métrica de Evaluación apropiada utilizando el Validation Set. La llamaremos métrica de Validación.\nSe escoge el mejor Modelo como el que tenga la mejor métrica de Validación.\nSe reentrena el modelo escogido pero ahora en un “nuevo set” compuesto por el Train set + el Validation set.\nSe reporta el rendimiento final del mejor modelo (al momento del diseño) utilizando métricas medidas en el Test Set."
  },
  {
    "objectID": "tics411/clase-9.html#k-fold-cv",
    "href": "tics411/clase-9.html#k-fold-cv",
    "title": "TICS-411 Minería de Datos",
    "section": "K-Fold CV",
    "text": "K-Fold CV\n\n\n\n\n\n\n\nEl proceso de Holdout podría llevar a un proceso de overfitting del Test Set si el modelo no es lo suficientemente robusto.\n\n\n\n\n\n\n\n\n\n\n\n\nEl K-Fold CV se aplica sólo al Train Set y la métrica final que se reporta utilizando el Test Set.\n\n\n\n\n\n\n\n\n\n\nFold\n\nEntenderemos Folds como divisiones que haremos a nuestro dataset. (En el ejemplo se divide el dataset en 5 Folds).\n\nSplit\n\nEntenderemos Splits, como iteraciones. En cada iteración utilizaremos un Fold como Validation Set y todos los Folds restantes como Train Set.\n\n\n\n\n\n\n\n\n\nLa métrica final se calculará como el promedio de las Métricas de Validación para cada Split.\nA veces la variabilidad (medido a través de la Desviación Estándar) también es usado como criterio para elegir el mejor modelo.\n\n\n\n\n\n\n\n\n\n\n\nEn la práctica se le llama incorrectamente Cross Validation al K-Fold."
  },
  {
    "objectID": "tics411/clase-9.html#bootstrap",
    "href": "tics411/clase-9.html#bootstrap",
    "title": "TICS-411 Minería de Datos",
    "section": "Bootstrap",
    "text": "Bootstrap\nConsiste en generar subgrupos aleatorios con repetición. Normalmente requiere específicar el tamaño de la muestra de entrenamiento. Y la cantidad de repeticiones que del proceso. Los sets de validación (en morado) acá se denominan out-of-bag samples.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLa métrica final a reportar se mide como el promedio de los out-of-bag samples."
  },
  {
    "objectID": "tics411/clase-9.html#variantes-y-consejos",
    "href": "tics411/clase-9.html#variantes-y-consejos",
    "title": "TICS-411 Minería de Datos",
    "section": "Variantes y Consejos",
    "text": "Variantes y Consejos\n\nStratified K-Fold\n\nEs la variante más utilizada de K-Fold el cual genera los folds considerando que se mantenga la proporción de etiquetas en cada Fold.\n\nLeave One Out\n\nSería una variante con \\(K=n\\). Por lo tanto, el Validation Set tiene sólo una observación.\n\n\n\n\n\n\n\n\n\n¿Cuando usar cada uno?\n\n\n\nSi se tiene una cantidad de datos suficiente (normalmente tamaños muy grandes se prefiere) el Holdout.\n\nEntre más registros, menos % de Validation Set se deja.\n\nSi se requiere robustez, o hay Test sets que son muy variables se prefiere K-Fold.\n\nSi es que hay desbalance de clases, se prefiere la versión Stratified.\n\n\nSi se tienen muy pocos datos, entonces utilizar Leave-One-Out.\nBootstrap también es utilizado cuando se tengan pocos datos. Aunque suele ser un approach más estadístico."
  },
  {
    "objectID": "tics411/clase-9.html#baseline",
    "href": "tics411/clase-9.html#baseline",
    "title": "TICS-411 Minería de Datos",
    "section": "Baseline",
    "text": "Baseline\n\nUn modelo Baseline es un modelo simple, normalmente sin aprendizaje asociado o con poder de aprendizaje más limitado, el cuál será utilizado como medida de referencia para ver si algoritmos más complejos efectivamente están aprendiendo.\n\n\n\n\n\n\n\nSi estamos probando un nuevo modelo y éste es capaz de superar el rendimiento de un Baseline, se considera como que estamos aprendiendo algo nuevo.\n\n\n\n\n\n\n\n\n\nModelos que no superaron el puntaje de un modelo Baseline normalmente son deshechados."
  },
  {
    "objectID": "tics411/clase-9.html#implementación-en-python-baselines",
    "href": "tics411/clase-9.html#implementación-en-python-baselines",
    "title": "TICS-411 Minería de Datos",
    "section": "Implementación en Python: Baselines",
    "text": "Implementación en Python: Baselines\nfrom sklearn.dummy import DummyClassifier\n\ndc = DummyClassifier(strategy=\"prior\", random_state = 42, constant=None)\ndc.fit(X_train,y_train)\ny_pred = dc.predict(X_test)\n\n\n\nstrategy: Corresponde a estrategias “dummy” con las cuales generar predicciones.\n\n“prior”: predice siempre la clase más frecuente observada en el entrenamiento. Si se predice la probabilidad, se devuelve la probabilidad empírica.\n“constant”: Devuelve un valor constante provisto por el usuario.\n“uniform”: Predice probabilidades aleatorios obtenidas mediante una distribución uniforme."
  },
  {
    "objectID": "tics411/clase-9.html#data-leakage",
    "href": "tics411/clase-9.html#data-leakage",
    "title": "TICS-411 Minería de Datos",
    "section": "Data Leakage",
    "text": "Data Leakage\n\nFuga de Datos\n\n\nSe refiere al proceso donde el modelo por alguna razón conoce información que no debería conocer. Puede ser información del Test Set o variables que revelan información primordial sobre la etiqueta.\n\n\n\n\n\n\n\n\n\nCuando existe Data Leakage es posible que los resultados del modelo no reflejen correctamente su rendimiento dando una falsa sensación de optimismo.\n\n\n\nEjemplos\n\nEstandarizar o aplicar preprocesamientos antes del Split de la Data.\nUtilizar variables que tienen directa relación con el Target.\n\n\n\n\n\n\n\n\nSe recomienda siempre que sea posible utilizar Pipelines para poder evitar el Data Leakage."
  },
  {
    "objectID": "tics411/clase-6.html#evaluación",
    "href": "tics411/clase-6.html#evaluación",
    "title": "TICS-411 Minería de Datos",
    "section": "Evaluación",
    "text": "Evaluación\n\nPensemos en la Evaluación como una medida de desempeño el cuál “evalúa” qué tan bien realizado está el clustering. El objetivo principal del Clustering debe ser siempre la generación de clusters compactos que estén diferenciados los unos a los otros.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n¿Cuál es el Clustering que mejor describe el problema."
  },
  {
    "objectID": "tics411/clase-6.html#objetivos-de-la-evaluación",
    "href": "tics411/clase-6.html#objetivos-de-la-evaluación",
    "title": "TICS-411 Minería de Datos",
    "section": "Objetivos de la Evaluación",
    "text": "Objetivos de la Evaluación"
  },
  {
    "objectID": "tics411/clase-6.html#tendencia-hopkins",
    "href": "tics411/clase-6.html#tendencia-hopkins",
    "title": "TICS-411 Minería de Datos",
    "section": "Tendencia: Hopkins",
    "text": "Tendencia: Hopkins\n\nEstadístico Hopkins\n\n\nPermite evaluar a priori si es que efectivamente existen clusters antes de aplicar un algoritmo.\n\n\n\n\n\n\\[H = \\frac{\\sum_{i = 1}^p w_i}{\\sum_{i = 1}^p u_i + \\sum_{i = 1}^p w_i}\\]\n\n\\(w_i\\): corresponde a la distancia de un punto aleatorio al vecino más cercano en los datos originales.\n\\(u_i\\): corresponde a la distancia de un punto real del dataset al vecino más cercano.\n\\(p\\): Número de puntos generados en el espacio del Dataset.\n\n\nfrom pyclustertend import hopkins\n\n1-hopkins(X, p)\n\n\n\n\n\n\n\nX: Dataset al cuál se le aplica el Estadístico.\np: Número de Puntos para el cálculo.\n\n\n\n\n\n\n\n\n\n\npyclustertend entrega el valor 1-H."
  },
  {
    "objectID": "tics411/clase-6.html#tendencia-hopkins-1",
    "href": "tics411/clase-6.html#tendencia-hopkins-1",
    "title": "TICS-411 Minería de Datos",
    "section": "Tendencia: Hopkins",
    "text": "Tendencia: Hopkins"
  },
  {
    "objectID": "tics411/clase-6.html#cálculo-hopkins-ejemplo-p2",
    "href": "tics411/clase-6.html#cálculo-hopkins-ejemplo-p2",
    "title": "TICS-411 Minería de Datos",
    "section": "Cálculo Hopkins: Ejemplo p=2",
    "text": "Cálculo Hopkins: Ejemplo p=2\n\n\n\n\n\n\n\nPuntos obtenidos de los Datos\n\\[u_1\\approx 0\\]\n\\[u_2\\approx 0\\]\n\nPuntos Aleatorios en el Espacio de los Datos\n\\[w_1\\approx 1.8\\]\n\\[w_2\\approx 1.12\\]\n\nCálculo Hopkins\n\\[ H = \\frac{w_1 + w_2}{u_1 + u_2 + w_1 + w_2}\\] \\[ H = \\frac{1.8 + 1.12}{0 + 0 + 1.8 + 1.8} = 1\\]"
  },
  {
    "objectID": "tics411/clase-6.html#visual-assesment-of-tendency-vat",
    "href": "tics411/clase-6.html#visual-assesment-of-tendency-vat",
    "title": "TICS-411 Minería de Datos",
    "section": "Visual Assesment of Tendency (VAT)",
    "text": "Visual Assesment of Tendency (VAT)\n\nCorresponde a una inspección visual de la distancia entre los puntos (matriz de distancia). Colores más oscuros indican menor distancias entre dichos puntos lo que indica mayor cohesión.\n\n\n\n\n\n\n\n\n\nSe pueden ver claramente dos bloques.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo es posible ver bloques importantes.\n\n\n\n\n\n\n\n\n\nfrom pyclustertend import vat\n\nvat(X)"
  },
  {
    "objectID": "tics411/clase-6.html#correlación",
    "href": "tics411/clase-6.html#correlación",
    "title": "TICS-411 Minería de Datos",
    "section": "Correlación",
    "text": "Correlación\nProcedimiento:\n\nConstruir una matriz de similaridad entre todos los puntos de la siguiente manera:\n\n\\[s(i,j) = \\frac{1}{d(i,j) + 1}\\]\n\nConstruir una matriz de similaridad \"ideal\" basada en la pertenencia a un Cluster.\nSi \\(i\\) y \\(j\\) pertenecen al mismo cluster entonces \\(s(i,j)=1\\), en otro caso \\(s(i,j) = 0\\)\nCalcular la Correlación entre la matriz de similaridad y la matriz ideal (obtenidas en los pasos 1 y 2).\n\n\n\n\n\n\n\nUna correlación alta indica que los puntos que están en el mismo cluster son cercanos entre ellos."
  },
  {
    "objectID": "tics411/clase-6.html#cohesión",
    "href": "tics411/clase-6.html#cohesión",
    "title": "TICS-411 Minería de Datos",
    "section": "Cohesión",
    "text": "Cohesión\n\nCohesión\n\n\nMide cuán cercanos están los objetos dentro de un mismo cluster. Se utiliza la Suma de los Errores al Cuadrado, que es equivalente a la Inercia de K-Means (o Within Cluster).\n\n\n\n\\[ SSE_{total} = \\sum_{k = 1}^K\\sum_{x_i \\in C_k} (x_i - \\bar{C_k})^2\\]\n\n\\(C_k\\) corresponde al Centroide del Cluster \\(k\\). Dicho centroide puede ser calculado como la media/mediana de todos los puntos del Centroide.\n\\(K\\) corresponde al Número de Clusters.\n\n\n\n\n\n\n\n\nNo me gusta mucho este nombre, porque en realidad es como un inverso de la Cohesión."
  },
  {
    "objectID": "tics411/clase-6.html#separación",
    "href": "tics411/clase-6.html#separación",
    "title": "TICS-411 Minería de Datos",
    "section": "Separación",
    "text": "Separación\n\nSeparación\n\n\nMide cuán distinto es un cluster de otro. Se usa la suma de las distancias al cuadrado entre los centroides hacia el promedio de todos los puntos. (Between groups sum squares, SSB).\n\n\n\n\\[ SSB_{total} = \\sum_{k = 1}^K |C_k|(\\bar{X} - \\bar{C_k})^2\\]\n\n\\(|C_k|\\) corresponde al número de elementos (Cardinalidad) del Cluster \\(i\\).\n\\(\\bar{X}\\) corresponde al promedio de todos los puntos."
  },
  {
    "objectID": "tics411/clase-6.html#coeficiente-de-silhouette-coeficiente-de-silueta",
    "href": "tics411/clase-6.html#coeficiente-de-silhouette-coeficiente-de-silueta",
    "title": "TICS-411 Minería de Datos",
    "section": "Coeficiente de Silhouette (Coeficiente de Silueta)",
    "text": "Coeficiente de Silhouette (Coeficiente de Silueta)\n\nEl coeficiente de Silhouette es otra medida que combina la cohesión y la separación. Los valores varían entre -1 y 1, donde valores cercanos a 1 representan una mejor agrupación.\n\n\n\n\n\n\n\nValores cercanos a \\(-1\\) representan que el punto está incorrectamente asignado a un cluster.\n\n\n\n\\[S_i = \\frac{b_i - a_i}{max\\{a_i, b_i\\}}\\]\nfrom sklearn.metrics import silhouette_score\n\nsilhouette_score(X, labels, sample_size = None, metric=\"euclidean\")"
  },
  {
    "objectID": "tics411/clase-6.html#coeficiente-de-silhouette-ejemplo",
    "href": "tics411/clase-6.html#coeficiente-de-silhouette-ejemplo",
    "title": "TICS-411 Minería de Datos",
    "section": "Coeficiente de Silhouette: Ejemplo",
    "text": "Coeficiente de Silhouette: Ejemplo\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\[C_{silueta} = \\frac{1}{n}\\sum_{i} s_i\\]\n\n\\(a_i\\): Distancia promedio del punto \\(i\\) a todos los otros puntos del mismo cluster. (Cohesión)\n\\(b_{ij}\\): Distancia promedio del punto \\(i\\) a todos los puntos del cluster \\(j\\) donde no pertenezca \\(i\\). (Separación)\n\\(b_j\\): Mínimo de \\(b_{ij}\\) tal que el punto i no pertenezca al cluster \\(j\\). (Menor Separación)"
  },
  {
    "objectID": "tics411/clase-6.html#ejercicio-propuesto",
    "href": "tics411/clase-6.html#ejercicio-propuesto",
    "title": "TICS-411 Minería de Datos",
    "section": "Ejercicio Propuesto",
    "text": "Ejercicio Propuesto\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEjercicio Propuesto\n\n\nCalcule el coeficiente de Silueta. Tabla de resultado al final de las Slides."
  },
  {
    "objectID": "tics411/clase-6.html#curvas-de-silueta",
    "href": "tics411/clase-6.html#curvas-de-silueta",
    "title": "TICS-411 Minería de Datos",
    "section": "Curvas de Silueta",
    "text": "Curvas de Silueta\nEs común mostrar los resultados del coeficiente de silueta como gráficos de este estilo:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProblemas\n\n\n\nSiluetas negativas.\nClusters bajo el promedio.\nMucha variabilidad de Silueta en un sólo cluster."
  },
  {
    "objectID": "tics411/clase-6.html#curvas-de-silueta-implementación",
    "href": "tics411/clase-6.html#curvas-de-silueta-implementación",
    "title": "TICS-411 Minería de Datos",
    "section": "Curvas de Silueta: Implementación",
    "text": "Curvas de Silueta: Implementación\nimport scikitplot as skplt\nimport matplotlib.pyplot as plt\n\nskplt.metrics.plot_silhouette(X, labels, metric=\"euclidean\", title=\"Silhouette Analysis\")\nplt.show()\n\nL1-2: Importación de Librerías Necesarias. Esta implementación está en la librería Scikit-plot. (Para instalar pip install scikit-plot)\nX: Dataset usado para el clustering.\nlabels : etiquetas obtenidos de algún proceso de Clustering.\nmetric: Métrica a utilizar, por defecto usa “euclidean”.\ntitle: Se puede agregar un Título personalizado a la curva."
  },
  {
    "objectID": "tics411/clase-6.html#resultados-ejercicio-propuesto",
    "href": "tics411/clase-6.html#resultados-ejercicio-propuesto",
    "title": "TICS-411 Minería de Datos",
    "section": "Resultados Ejercicio Propuesto",
    "text": "Resultados Ejercicio Propuesto\n\n\n\n\n\nCoeficiente de Silhouette = 0.6148\n\n\n\n\n\n\nComprobar utilizando Scikit-Learn\n\n\n\n\n\nTics-411 Minería de Datos está licenciado bajo CC BY-NC-SA 4.0"
  },
  {
    "objectID": "tics411/clase-5.html#clustering-densidad",
    "href": "tics411/clase-5.html#clustering-densidad",
    "title": "TICS-411 Minería de Datos",
    "section": "Clustering: Densidad",
    "text": "Clustering: Densidad\n\nSe basan en la idea de continuar el crecimiento de un cluster a medida que la densidad (número de objetos o puntos) en el vecindario sobrepase algún umbral.\n\n\n\n\n\n\n\n\n\n\n\n\nEn nuestro caso utilizaremos DBSCAN (Density-Based Spatial Clustering Applications with Noise)."
  },
  {
    "objectID": "tics411/clase-5.html#dbscan-definiciones",
    "href": "tics411/clase-5.html#dbscan-definiciones",
    "title": "TICS-411 Minería de Datos",
    "section": "DBSCAN: Definiciones",
    "text": "DBSCAN: Definiciones\n\n\n\n\n\n\nHiperparámetros del Modelo\n\n\n\neps: Radio de análisis\nMinPts: Corresponde al mínimo de puntos necesarios en un Radio eps.\n\n\n\n\n\n\n\nDensidad\n\n\nDensidad es el número de puntos dentro del radio eps.\n\n\nCore Point/Punto Central\n\n\nUn punto central/core es aquel que tiene al menos MinPts puntos dentro de la esfera definida por eps (se incluye él mismo).\n\n\n\n\n\nBorder Point/Punto Borde\n\n\nUn punto de borde tiene menos puntos que MinPts del eps, pero está dentro de la esfera de un punto central.\n\n\nNoise Point/Punto Ruido\n\n\nUn punto de ruido es todo aquel que no es punto central ni de borde."
  },
  {
    "objectID": "tics411/clase-5.html#dbscan-algoritmo-categorización-de-puntos",
    "href": "tics411/clase-5.html#dbscan-algoritmo-categorización-de-puntos",
    "title": "TICS-411 Minería de Datos",
    "section": "DBSCAN: Algoritmo categorización de puntos",
    "text": "DBSCAN: Algoritmo categorización de puntos\n\nPrimeramente se aplica un algoritmo para categorizar cada punto de acuerdo a las definiciones anteriores.\n\n\nPara cada punto en el espacio:\n\nCalcular su densidad en EPS y aplicar el siguiente algoritmo:"
  },
  {
    "objectID": "tics411/clase-5.html#ejemplo-iteración-1",
    "href": "tics411/clase-5.html#ejemplo-iteración-1",
    "title": "TICS-411 Minería de Datos",
    "section": "Ejemplo: Iteración 1",
    "text": "Ejemplo: Iteración 1\n\nSupongamos un ejemplo con \\(MinPts=4\\).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEste punto corresponde a un Core Point."
  },
  {
    "objectID": "tics411/clase-5.html#ejemplo-iteración-2",
    "href": "tics411/clase-5.html#ejemplo-iteración-2",
    "title": "TICS-411 Minería de Datos",
    "section": "Ejemplo: Iteración 2",
    "text": "Ejemplo: Iteración 2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEste punto corresponde a un Border Point."
  },
  {
    "objectID": "tics411/clase-5.html#ejemplo-iteración-3",
    "href": "tics411/clase-5.html#ejemplo-iteración-3",
    "title": "TICS-411 Minería de Datos",
    "section": "Ejemplo: Iteración 3",
    "text": "Ejemplo: Iteración 3\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEste punto corresponde a un Noise Point."
  },
  {
    "objectID": "tics411/clase-5.html#ejemplo-iteración-final",
    "href": "tics411/clase-5.html#ejemplo-iteración-final",
    "title": "TICS-411 Minería de Datos",
    "section": "Ejemplo: Iteración Final",
    "text": "Ejemplo: Iteración Final\n\n\n\n\n\n\n\n\n\n\n\nAhora, ¿Cómo definimos que partes son clusters o no?"
  },
  {
    "objectID": "tics411/clase-5.html#algoritmo-de-clustering",
    "href": "tics411/clase-5.html#algoritmo-de-clustering",
    "title": "TICS-411 Minería de Datos",
    "section": "Algoritmo de Clustering",
    "text": "Algoritmo de Clustering\nSe aplica el siguiente algoritmo para calcular clusterings.\n\n\n\n\n\n\nAntes de aplicar se desechan los Noise Points ya que no serán considerados. (Veremos luego que ocurre con estos puntos).\n\n\n\nlabel=0\nfor punto_c in corePoints:\n    if punto_c no tiene etiqueta:\n        label += 1\n        punto_c = label\n    for point_eps dentro de eps:\n        if punto_eps no tiene etiqueta:\n            punto_eps = label"
  },
  {
    "objectID": "tics411/clase-5.html#iteración-1",
    "href": "tics411/clase-5.html#iteración-1",
    "title": "TICS-411 Minería de Datos",
    "section": "Iteración 1",
    "text": "Iteración 1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nlabel=0\nfor punto_c in corePoints:\n    if punto_c no tiene etiqueta:\n        label += 1\n        punto_c = label\n    for point_eps dentro de eps:\n        if punto_eps no tiene etiqueta:\n            punto_eps = label\n\n\nlabel=0\nfor punto_c in corePoints:\n    if punto_c no tiene etiqueta:\n        label += 1\n        punto_c = label\n    for point_eps dentro de eps:\n        if punto_eps no tiene etiqueta:\n            punto_eps = label\n\n\n\n\n\n\n\n\n\nTodos los puntos cercanos a un Core reciben la misma etiqueta."
  },
  {
    "objectID": "tics411/clase-5.html#iteración-2",
    "href": "tics411/clase-5.html#iteración-2",
    "title": "TICS-411 Minería de Datos",
    "section": "Iteración 2",
    "text": "Iteración 2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nlabel=0\nfor punto_c in corePoints:\n    if punto_c no tiene etiqueta:\n        label += 1\n        punto_c = label\n    for point_eps dentro de eps:\n        if punto_eps no tiene etiqueta:\n            punto_eps = label\n\n\n## label ya está en 1\nfor punto_c in corePoints:\n    if punto_c no tiene etiqueta:\n        label += 1\n        punto_c = label\n    for point_eps dentro de eps:\n        if punto_eps no tiene etiqueta:\n            punto_eps = label\n\n\n\n\n\n\n\n\n\nEn este caso obtuvimos 2 clusters, e indirectamente un 3er de puntos ruido."
  },
  {
    "objectID": "tics411/clase-5.html#dbscan",
    "href": "tics411/clase-5.html#dbscan",
    "title": "TICS-411 Minería de Datos",
    "section": "DBSCAN",
    "text": "DBSCAN\n\n\n\n\n\n\n\n\n\n\n\n\n¿Sería posible replicar un proceso de Clustering similar utilizando K-Means? ¿Por qué?"
  },
  {
    "objectID": "tics411/clase-5.html#dbscan-detalles-técnicos",
    "href": "tics411/clase-5.html#dbscan-detalles-técnicos",
    "title": "TICS-411 Minería de Datos",
    "section": "DBSCAN: Detalles Técnicos",
    "text": "DBSCAN: Detalles Técnicos\n\n\n\n\n\n\nFortalezas\n\n\n\nResistente al ruido.\nPuede lidiar con clusters de diferentes formas y tamaños.\nNo es necesario especificar cuántos clusters encontrar.\n\n\n\n\n\n\n\n\n\n\nDebilidades\n\n\n\nAlgoritmo de alta complejidad computacional que puede llegar \\(O(n^2)\\) en el peor caso.\nSe ve afectado por densidad de los datos y por datos con una alta dimensionalidad.\nSu óptimo resultado depende específicamente de sus Hiperparámetros.\nNo puede generalizar en datos no usados en entrenamiento."
  },
  {
    "objectID": "tics411/clase-5.html#cómo-encontrar-los-hiperparámetros",
    "href": "tics411/clase-5.html#cómo-encontrar-los-hiperparámetros",
    "title": "TICS-411 Minería de Datos",
    "section": "¿Cómo encontrar los Hiperparámetros?",
    "text": "¿Cómo encontrar los Hiperparámetros?\n\n\n\n\n\n\n\n\nminPts\n\n\nPara datasets multidimensionales grandes, la regla es:\n\\[minPts \\ge dim + 1\\]\n\n\n\n\n\n\n\n\n\nOtras recomendaciones:\n\n\n\nPara dos dimensiones: \\(minPts=4\\) (Ester et al., 1996)\nPara más de 2 dimensiones: \\(minPts = 2 \\cdot dim\\) (Sander et al., 1998)"
  },
  {
    "objectID": "tics411/clase-5.html#cómo-encontrar-los-hiperparámetros-1",
    "href": "tics411/clase-5.html#cómo-encontrar-los-hiperparámetros-1",
    "title": "TICS-411 Minería de Datos",
    "section": "¿Cómo encontrar los Hiperparámetros?",
    "text": "¿Cómo encontrar los Hiperparámetros?\n\nPara encontrar EPS se suele utilizar el método de Vecinos más cercanos.\n\n\n\nIdea\n\nLa distancia de los puntos dentro de un cluster a su k-ésimo vecino deberían ser similares.\nLuego, los puntos atípicos (o ruidosos) tienen el k-ésimo vecino a una mayor distancia.\n\n\n\n\n\n\n\n💡 Podemos plotear la distancia ordenada de cada punto a su k-ésimo vecino y seleccionar un eps cercano al crecimiento exponencial (codo)."
  },
  {
    "objectID": "tics411/clase-5.html#implementación-en-scikit-learn",
    "href": "tics411/clase-5.html#implementación-en-scikit-learn",
    "title": "TICS-411 Minería de Datos",
    "section": "Implementación en Scikit-Learn",
    "text": "Implementación en Scikit-Learn\nfrom sklearn.cluster import DBSCAN\n\ndbs = DBSCAN(min_samples = 5, eps = 0.5, metric = \"euclidean\")\n\n## Se entrena y se genera la predicción\ndbs.fit_predict(X)\n\n\nmin_samples: Corresponde a minPts. Por defecto 5.\neps: Corresponde al radio de la esfera en la que se buscan los puntos cercanos. Por defecto 0.5.\nmetric: Corresponde a la distancia utilizada para medir la distancia. Permite todas las distancias mencionadas acá.\n.fit_predict(): Entrenará el modelo en los datos suministrados e inmediatamente genera el cluster asociado a cada elemento. Adicionalmente los puntos ruidosos se etiquetarán como -1.\n\n\n👀 Veamos un ejemplo."
  },
  {
    "objectID": "tics411/clase-2.html#eda",
    "href": "tics411/clase-2.html#eda",
    "title": "TICS-411 Minería de Datos",
    "section": "EDA",
    "text": "EDA\n\nEl Analisis Exploratorio de Datos (EDA, por sus siglas en inglés) es procedimiento en el cual se analiza un dataset para explorar sus características principales.\n\n\nSu objetivo principal es poder familiarizarse con los datos además de encontrar potenciales problemas en su calidad.\nPrincipalmente hace uso de técnicas de manipulación de datos y visualizaciones.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLos hallazgos importantes dentro del proceso se les denomina insights.\n\n\n\n\n\n\n\n\n\nEl uso de visualizaciones inadecuadas podría llevar a conclusiones erróneas.\n\n\n\n\n\n\n\n\n\n\nSummary.\nVisualización."
  },
  {
    "objectID": "tics411/clase-2.html#medidas-de-tendencia-central",
    "href": "tics411/clase-2.html#medidas-de-tendencia-central",
    "title": "TICS-411 Minería de Datos",
    "section": "Medidas de Tendencia Central",
    "text": "Medidas de Tendencia Central"
  },
  {
    "objectID": "tics411/clase-2.html#medidas-de-dispersión-y-asimetría",
    "href": "tics411/clase-2.html#medidas-de-dispersión-y-asimetría",
    "title": "TICS-411 Minería de Datos",
    "section": "Medidas de Dispersión y Asimetría",
    "text": "Medidas de Dispersión y Asimetría"
  },
  {
    "objectID": "tics411/clase-2.html#eda-visualización",
    "href": "tics411/clase-2.html#eda-visualización",
    "title": "TICS-411 Minería de Datos",
    "section": "EDA: Visualización",
    "text": "EDA: Visualización\n\nLa visualización de datos es la presentación de datos en forma gráfica. Permite simplificar conceptos más complejos en especial a altos mandos.\n\n\nGracias a la evolución del cerebro humano somos capaces de detectar patrones complejos en la naturaleza a partir de la Visión.\n\n\n\n\n\n\n\n\nPuede ser difícil de aplicar si el tamaño de los datos es grande (sea en instancias o atributos). Por ejemplo, si los datos están en 4 dimensiones.\n\n\n\n\n\n\n\n\n\n\n\n\nSe suelen resumir los datos en estadísticas simples.\nGraficar datos en 1D, 2D y 3D (evitar dentro de lo posible).\nLa visualización debe ser comprensible ojalá sin ninguna explicación.\n\n\n\n\n\n\n\n\n\n\n\n\nEn caso de datos de alta dimensionalidad puede ser una buena idea reducir dimensiones mediante técnicas como:\n\nPCA\nUMAP\netc."
  },
  {
    "objectID": "tics411/clase-2.html#caso-de-visualización",
    "href": "tics411/clase-2.html#caso-de-visualización",
    "title": "TICS-411 Minería de Datos",
    "section": "Caso de Visualización",
    "text": "Caso de Visualización\n\n\n\n\n\n\n\nFiguras\nEscala de Colores.\nTamaño de los puntos.\nDemasiada información en un sólo gráfico.\nNo se entiende el mensaje."
  },
  {
    "objectID": "tics411/clase-2.html#canales-visuales",
    "href": "tics411/clase-2.html#canales-visuales",
    "title": "TICS-411 Minería de Datos",
    "section": "Canales Visuales",
    "text": "Canales Visuales\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSe les llama canales visuales a elementos visuales que pueden utilizarse para expresar información (Clase Visualizacion Andreas Mueller).\nLa idea es poder mapear cada uno de estos canales a valores que queremos visualizar.\n\n\n\n\n\n\n\n\n\n\n\nNo todos los canales son igual de útiles ni fáciles de entender."
  },
  {
    "objectID": "tics411/clase-2.html#visualizaciones-distribuciones",
    "href": "tics411/clase-2.html#visualizaciones-distribuciones",
    "title": "TICS-411 Minería de Datos",
    "section": "Visualizaciones: Distribuciones",
    "text": "Visualizaciones: Distribuciones\n\nHistograma\n\n\nEl histograma permite visualizar distribuciones univariadas acumulando los datos en rangos de igual tamaño (bins).\n\n\n\n\nPermite visualizar el centro, la extensión, la asimetría y outliers.\n\n\n\n\n\n\n\n\nEl histograma puede ser “engañoso” para conjuntos de datos pequeños.\nLa visualización puede resultar de manera muy distintas dependiendo del número de bins."
  },
  {
    "objectID": "tics411/clase-2.html#visualizaciones-distribuciones-1",
    "href": "tics411/clase-2.html#visualizaciones-distribuciones-1",
    "title": "TICS-411 Minería de Datos",
    "section": "Visualizaciones: Distribuciones",
    "text": "Visualizaciones: Distribuciones\n\nKernel Density\n\n\nCorresponde a un suavizamiento de un Histograma en el cuál se usa un Kernel (función no negativa que suma 1 y tiene media 0) para agrupar los puntos vecinos.\n\n\n\n\n\nLa función estimada es:\n\\[f(x) = \\frac{1}{n} = \\sum_{i=1}^n K \\left(\\frac{x - x(i)}{h}\\right)\\]\n\n\\(K(u)\\) es el Kernel.\n\\(h\\) es el ancho de banda."
  },
  {
    "objectID": "tics411/clase-2.html#visualizaciones-distribuciones-2",
    "href": "tics411/clase-2.html#visualizaciones-distribuciones-2",
    "title": "TICS-411 Minería de Datos",
    "section": "Visualizaciones: Distribuciones",
    "text": "Visualizaciones: Distribuciones\n\nBoxplot (Caja y Bigotes)\n\nEs un tipo de gráfico que muestra la distribución de manera univariada.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTiene la capacidad de mostrar varias distribuciones a la vez.\nAdemás presenta estadísticos de interés: Mediana, IQR y outliers.\nLos puntos fuera de los bigotes son considerados Outliers.\n\n\n\n\n\n\n\n\n\n\n\n\n\nLos bigotes pueden representar:\n\nMínimo y Máximo. (En este caso no hay outliers).\n\\(\\mu \\pm 3\\sigma\\)\nPercentiles 5 y 95.\nOtros valores."
  },
  {
    "objectID": "tics411/clase-2.html#visualizaciones-barras",
    "href": "tics411/clase-2.html#visualizaciones-barras",
    "title": "TICS-411 Minería de Datos",
    "section": "Visualizaciones: Barras",
    "text": "Visualizaciones: Barras\n\nBar Plot\n\n\nLa altura de la barra (normalmente Eje y) representa una agregación asociada a una categoría (normalmente Eje x).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOtras convenciones llaman a este gráfico Column Plot, mientras que el Bar Plot tiene las barras de manera horizontal."
  },
  {
    "objectID": "tics411/clase-2.html#visualizaciones-puntos",
    "href": "tics411/clase-2.html#visualizaciones-puntos",
    "title": "TICS-411 Minería de Datos",
    "section": "Visualizaciones: Puntos",
    "text": "Visualizaciones: Puntos\n\nScatter\n\n\nGráfico empleado para mostrar distribución de datos bivariados\n\n\n\n\nMuestra la relación entre una variable independiente (Eje X) y una variable dependiente (Eje Y).\nPermite mostrar relaciones lineales o no-lineales (Correlaciones).\nOutliers.\nSimplemente ubicación de Puntos en el Espacio."
  },
  {
    "objectID": "tics411/clase-2.html#visualizaciones-líneas",
    "href": "tics411/clase-2.html#visualizaciones-líneas",
    "title": "TICS-411 Minería de Datos",
    "section": "Visualizaciones: Líneas",
    "text": "Visualizaciones: Líneas\n\nLineplot\n\n\nGráfico empleado para visualizar tendencias y su evolución de una medida (Eje Y) en el tiempo (Eje X).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSi bien es posible utilizarlo para gráficar dos medidas continuas, las buenas prácticas indican que el eje X siempre debería contener una componente temporal."
  },
  {
    "objectID": "tics411/clase-2.html#estadísticos-vs-visualizaciones",
    "href": "tics411/clase-2.html#estadísticos-vs-visualizaciones",
    "title": "TICS-411 Minería de Datos",
    "section": "Estadísticos vs Visualizaciones",
    "text": "Estadísticos vs Visualizaciones"
  },
  {
    "objectID": "tics411/clase-2.html#otras-visualizaciones",
    "href": "tics411/clase-2.html#otras-visualizaciones",
    "title": "TICS-411 Minería de Datos",
    "section": "¿Otras Visualizaciones?",
    "text": "¿Otras Visualizaciones?"
  },
  {
    "objectID": "tics411/notebooks/04-analisis_centros.html",
    "href": "tics411/notebooks/04-analisis_centros.html",
    "title": "Análisis de Centros",
    "section": "",
    "text": "import seaborn as sns\nfrom sklearn.cluster import KMeans\nfrom sklearn.decomposition import PCA\n\ndf = sns.load_dataset(\"iris\")\npca = PCA(n_components=2)\npca_coords = pca.fit_transform(df.drop(columns=\"species\"))\nkm = KMeans(n_clusters=3, n_init=10, random_state=1)\nlabels = km.fit_predict(df.drop(columns=\"species\"))\n\n\ndef create_tables(df, labels, columns):\n    df[\"labels\"] = labels\n    std = df.groupby(\"labels\")[columns].std(numeric_only=True)\n    mean = df.groupby(\"labels\")[columns].mean(numeric_only=True)\n    return mean, std\n\n\nmean_table, std_table = create_tables(\n    df,\n    labels,\n    [\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\"],\n)\n## Corresponde a los valores promedios de cada variable por Cluster (los Centroides)\nmean_table\n\n\n\n\n\n\n\n\nsepal_length\nsepal_width\npetal_length\npetal_width\n\n\nlabels\n\n\n\n\n\n\n\n\n0\n5.901613\n2.748387\n4.393548\n1.433871\n\n\n1\n5.006000\n3.428000\n1.462000\n0.246000\n\n\n2\n6.850000\n3.073684\n5.742105\n2.071053\n## Corresponde a la Desviación Estándar de cada variable por Cluster\nstd_table\n\n\n\n\n\n\n\n\nsepal_length\nsepal_width\npetal_length\npetal_width\n\n\nlabels\n\n\n\n\n\n\n\n\n0\n0.466410\n0.296284\n0.508895\n0.297500\n\n\n1\n0.352490\n0.379064\n0.173664\n0.105386\n\n\n2\n0.494155\n0.290092\n0.488590\n0.279872"
  },
  {
    "objectID": "tics411/notebooks/04-analisis_centros.html#representación-gráfica",
    "href": "tics411/notebooks/04-analisis_centros.html#representación-gráfica",
    "title": "Análisis de Centros",
    "section": "Representación Gráfica",
    "text": "Representación Gráfica\nAcá les dejo una Función con la cual pueden realizar el Análisis de Centros. Para ello requieren un DataFrame que contenga las variables a analizar y su etiqueta.\nSe debe indicar, el df, el número de Clusters creados, la columna de la etiqueta, y las columnas a analizar. Adicionalmente se puede agregar un título y cambiar las dimensiones del gráfico.\n\nimport matplotlib.pyplot as plt\nimport matplotlib.colors as mcolors\n\n\ndef center_analysis_viz(\n    df, n_clusters, labels, columns, title=\"\", figsize=(20, 20)\n):\n    clusters_axis = [f\"Cluster {i}\" for i in range(1, n_clusters + 1)]\n\n    n_columns = len(columns)\n    colors = list(mcolors.TABLEAU_COLORS.values())[:n_columns]\n    fig, ax = plt.subplots(n_columns, figsize=figsize)\n\n    mean_table, std_table = create_tables(df, labels, columns)\n\n    for i in range(n_columns):\n        ax[i].errorbar(\n            clusters_axis,\n            mean_table[columns[i]],\n            yerr=std_table[columns[i]],\n            capsize=20,\n            linestyle=\"none\",\n            marker=\"o\",\n            lw=3,\n            capthick=3,\n            ms=10,\n            c=colors[i],\n        )\n        ax[i].set_title(columns[i].title())\n    plt.suptitle(title, fontsize=15)\n    plt.show()\n\n\ncolumns = df.drop(columns=[\"species\", \"labels\"]).columns.tolist()\ncenter_analysis_viz(\n    df,\n    n_clusters=3,\n    labels=labels,\n    columns=columns,\n    title=\"Análisis de Centros para Iris\",\n)"
  },
  {
    "objectID": "tics411/notebooks/legacy_code.html",
    "href": "tics411/notebooks/legacy_code.html",
    "title": "Clases UAI",
    "section": "",
    "text": "## Otra forma de calcular lo mismo pero mucho más ineficiente. No usar!!\n# def compute_ideal_sim(labels):\n#     labels = pd.Series(labels, name=\"labels\")\n#     labels_df = labels.to_frame().reset_index()\n#     return (\n#         labels_df.merge(labels_df, how=\"outer\", on=\"labels\")\n#         .add(1)\n#         .set_index([\"index_x\", \"index_y\"])\n#         .unstack(level=1)\n#         .fillna(0)\n#         .astype(bool)\n#         .astype(int)\n#     )\n\n\n# ideal_sim_pd = compute_ideal_sim(labels).to_numpy()\n\n\n## Es para demostrar que dan lo mismo.\n# np.array_equal(ideal_sim_np, ideal_sim_pd)\n\n\n\n\n Back to top"
  },
  {
    "objectID": "tics411/notebooks/14-ex-NB.html",
    "href": "tics411/notebooks/14-ex-NB.html",
    "title": "Clases UAI",
    "section": "",
    "text": "import pandas as pd\nimport seaborn as sns\n\ndf = sns.load_dataset(\"titanic\")\ndf\n\n\n\n\n\n\n\n\nsurvived\npclass\nsex\nage\nsibsp\nparch\nfare\nembarked\nclass\nwho\nadult_male\ndeck\nembark_town\nalive\nalone\n\n\n\n\n0\n0\n3\nmale\n22.0\n1\n0\n7.2500\nS\nThird\nman\nTrue\nNaN\nSouthampton\nno\nFalse\n\n\n1\n1\n1\nfemale\n38.0\n1\n0\n71.2833\nC\nFirst\nwoman\nFalse\nC\nCherbourg\nyes\nFalse\n\n\n2\n1\n3\nfemale\n26.0\n0\n0\n7.9250\nS\nThird\nwoman\nFalse\nNaN\nSouthampton\nyes\nTrue\n\n\n3\n1\n1\nfemale\n35.0\n1\n0\n53.1000\nS\nFirst\nwoman\nFalse\nC\nSouthampton\nyes\nFalse\n\n\n4\n0\n3\nmale\n35.0\n0\n0\n8.0500\nS\nThird\nman\nTrue\nNaN\nSouthampton\nno\nTrue\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n886\n0\n2\nmale\n27.0\n0\n0\n13.0000\nS\nSecond\nman\nTrue\nNaN\nSouthampton\nno\nTrue\n\n\n887\n1\n1\nfemale\n19.0\n0\n0\n30.0000\nS\nFirst\nwoman\nFalse\nB\nSouthampton\nyes\nTrue\n\n\n888\n0\n3\nfemale\nNaN\n1\n2\n23.4500\nS\nThird\nwoman\nFalse\nNaN\nSouthampton\nno\nFalse\n\n\n889\n1\n1\nmale\n26.0\n0\n0\n30.0000\nC\nFirst\nman\nTrue\nC\nCherbourg\nyes\nTrue\n\n\n890\n0\n3\nmale\n32.0\n0\n0\n7.7500\nQ\nThird\nman\nTrue\nNaN\nQueenstown\nno\nTrue\n\n\n\n\n891 rows × 15 columns\n\n\n\n\nX = df[[\"class\", \"sex\", \"embark_town\"]]\ny = df.survived\n\n\nimport numpy as np\nfrom sklearn.naive_bayes import MultinomialNB, GaussianNB\nfrom sklearn.pipeline import Pipeline\nfrom feature_engine.imputation import CategoricalImputer, MeanMedianImputer\nfrom feature_engine.encoding import OneHotEncoder\nfrom sklearn.preprocessing import StandardScaler\nfrom feature_engine.wrappers import SklearnTransformerWrapper\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score\nfrom sklearn.metrics import RocCurveDisplay, ConfusionMatrixDisplay\nfrom sklego.meta import Thresholder\n\n\ndef make_pipeline(parameters):\n    if parameters[\"sc_variables\"] == \"all\":\n        scaler = StandardScaler()\n    elif parameters[\"sc_variables\"] is not None:\n        scaler = SklearnTransformerWrapper(\n            StandardScaler(), variables=parameters[\"sc_variables\"]\n        )\n    else:\n        scaler = \"passthrough\"\n\n    if parameters[\"num_method\"] is None:\n        num_imp = \"passthrough\"\n    else:\n        num_imp = MeanMedianImputer(\n            imputation_method=parameters[\"num_method\"]\n        )\n\n    if parameters[\"cat_method\"] is None:\n        cat_imp = \"passthrough\"\n    else:\n        cat_imp = CategoricalImputer(\n            imputation_method=parameters[\"cat_method\"]\n        )\n\n    print(\n        f\"Entrenamiento para Naive Bayes y threshold = {parameters['threshold']}\"\n    )\n    print(\"===================================\")\n    pipe = Pipeline(\n        steps=[\n            (\"cat_imp\", cat_imp),\n            (\"num_imp\", num_imp),\n            (\"ohe\", parameters[\"encoder\"]),\n            (\"sc\", scaler),\n            (\n                \"model\",\n                Thresholder(\n                    parameters[\"model\"],\n                    threshold=parameters[\"threshold\"],\n                ),\n            ),\n        ]\n    )\n    return pipe\n\n\ndef make_evaluation(\n    model,\n    X_train,\n    X_test,\n    y_train,\n    y_test,\n):\n    model.fit(X_train, y_train)\n    y_pred_train = model.predict(X_train)\n    y_pred = model.predict(X_test)\n    y_pred_proba = model.predict_proba(X_test)\n\n    train_acc = accuracy_score(y_train, y_pred_train)\n    test_acc = accuracy_score(y_test, y_pred)\n    train_precision = precision_score(y_train, y_pred_train)\n    test_precision = precision_score(y_test, y_pred)\n    train_recall = recall_score(y_train, y_pred_train)\n    test_recall = recall_score(y_test, y_pred)\n\n    print(f\"Train Accuracy {train_acc}\")\n    print(f\"Test Accuracy {test_acc}\")\n    print(\"===================================\")\n    print(f\"Train Precision {train_precision}\")\n    print(f\"Test Precision {test_precision}\")\n    print(\"===================================\")\n    print(f\"Train Recall {train_recall}\")\n    print(f\"Test Recall {test_recall}\")\n\n    ConfusionMatrixDisplay.from_predictions(y_test, y_pred)\n    RocCurveDisplay.from_predictions(y_test, y_pred_proba[:, 1])\n\n\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.25, random_state=42\n)\n\n\nparameters = dict(\n    cat_method=\"frequent\",\n    num_method=None,\n    encoder=OneHotEncoder(),\n    threshold=0.5,\n    sc_variables=None,\n    model=MultinomialNB(),\n)\npipe = make_pipeline(parameters)\nmake_evaluation(pipe, X_train, X_test, y_train, y_test)\n\nEntrenamiento para Naive Bayes y threshold = 0.5\n===================================\nTrain Accuracy 0.7844311377245509\nTest Accuracy 0.757847533632287\n===================================\nTrain Precision 0.7137254901960784\nTest Precision 0.6732673267326733\n===================================\nTrain Recall 0.7193675889328063\nTest Recall 0.7640449438202247\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nparameters = dict(\n    cat_method=\"frequent\",\n    num_method=None,\n    encoder=OneHotEncoder(),\n    threshold=0.5,\n    sc_variables=None,\n    model=GaussianNB(),\n)\npipe = make_pipeline(parameters)\nmake_evaluation(pipe, X_train, X_test, y_train, y_test)\n\nEntrenamiento para Naive Bayes y threshold = 0.5\n===================================\nTrain Accuracy 0.7784431137724551\nTest Accuracy 0.7488789237668162\n===================================\nTrain Precision 0.6996197718631179\nTest Precision 0.6601941747572816\n===================================\nTrain Recall 0.7272727272727273\nTest Recall 0.7640449438202247\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nparameters = dict(\n    cat_method=\"frequent\",\n    num_method=None,\n    encoder=OneHotEncoder(),\n    threshold=0.5,\n    sc_variables=\"all\",\n    model=GaussianNB(),\n)\npipe = make_pipeline(parameters)\nmake_evaluation(pipe, X_train, X_test, y_train, y_test)\n\nEntrenamiento para Naive Bayes y threshold = 0.5\n===================================\nTrain Accuracy 0.7784431137724551\nTest Accuracy 0.7488789237668162\n===================================\nTrain Precision 0.6996197718631179\nTest Precision 0.6601941747572816\n===================================\nTrain Recall 0.7272727272727273\nTest Recall 0.7640449438202247\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nX = df[[\"class\", \"sex\", \"embark_town\", \"age\", \"fare\"]]\ny = df.survived\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.25, random_state=42\n)\n\n\nparameters = dict(\n    cat_method=\"frequent\",\n    num_method=\"mean\",\n    encoder=OneHotEncoder(),\n    threshold=0.5,\n    sc_variables=None,\n    model=MultinomialNB(),\n)\npipe = make_pipeline(parameters)\nmake_evaluation(pipe, X_train, X_test, y_train, y_test)\n\nEntrenamiento para Naive Bayes y threshold = 0.5\n===================================\nTrain Accuracy 0.6811377245508982\nTest Accuracy 0.7309417040358744\n===================================\nTrain Precision 0.6063829787234043\nTest Precision 0.7230769230769231\n===================================\nTrain Recall 0.4505928853754941\nTest Recall 0.5280898876404494\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nparameters = dict(\n    cat_method=\"frequent\",\n    num_method=\"mean\",\n    encoder=OneHotEncoder(),\n    threshold=0.5,\n    sc_variables=None,\n    model=GaussianNB(),\n)\npipe = make_pipeline(parameters)\nmake_evaluation(pipe, X_train, X_test, y_train, y_test)\n\nEntrenamiento para Naive Bayes y threshold = 0.5\n===================================\nTrain Accuracy 0.7844311377245509\nTest Accuracy 0.7623318385650224\n===================================\nTrain Precision 0.7056603773584905\nTest Precision 0.6730769230769231\n===================================\nTrain Recall 0.7391304347826086\nTest Recall 0.7865168539325843\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "tics411/notebooks/07-ex-evaluation.html",
    "href": "tics411/notebooks/07-ex-evaluation.html",
    "title": "Evaluación de Clusters",
    "section": "",
    "text": "import numpy as np\nimport pandas as pd\nfrom pyclustertend import vat, hopkins, ivat\nimport seaborn as sns\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn import set_config\n\nnp.random.seed(0)\n\nset_config(transform_output=\"pandas\")\n\nX = sns.load_dataset(\"iris\").drop(columns=\"species\")\nX_random = np.random.rand(150, 4)"
  },
  {
    "objectID": "tics411/notebooks/07-ex-evaluation.html#visualización-de-ambos-datasets",
    "href": "tics411/notebooks/07-ex-evaluation.html#visualización-de-ambos-datasets",
    "title": "Evaluación de Clusters",
    "section": "Visualización de ambos Datasets",
    "text": "Visualización de ambos Datasets\n\n!pip install pyclustertend\n\nRequirement already satisfied: pyclustertend in /home/datacuber/miniconda3/lib/python3.9/site-packages (1.8.2)\nRequirement already satisfied: scikit-learn&lt;2.0.0,&gt;=1.1.2 in /home/datacuber/miniconda3/lib/python3.9/site-packages (from pyclustertend) (1.4.1.post1)\nRequirement already satisfied: numba&lt;0.55.0,&gt;=0.54.1 in /home/datacuber/miniconda3/lib/python3.9/site-packages (from pyclustertend) (0.54.1)\nRequirement already satisfied: matplotlib&lt;4.0.0,&gt;=3.3.3 in /home/datacuber/miniconda3/lib/python3.9/site-packages (from pyclustertend) (3.7.5)\nRequirement already satisfied: numpy==1.20.3 in /home/datacuber/miniconda3/lib/python3.9/site-packages (from pyclustertend) (1.20.3)\nRequirement already satisfied: pandas&lt;2.0.0,&gt;=1.2.0 in /home/datacuber/miniconda3/lib/python3.9/site-packages (from pyclustertend) (1.5.3)\nRequirement already satisfied: pillow&gt;=6.2.0 in /home/datacuber/miniconda3/lib/python3.9/site-packages (from matplotlib&lt;4.0.0,&gt;=3.3.3-&gt;pyclustertend) (9.2.0)\nRequirement already satisfied: packaging&gt;=20.0 in /home/datacuber/miniconda3/lib/python3.9/site-packages (from matplotlib&lt;4.0.0,&gt;=3.3.3-&gt;pyclustertend) (23.0)\nRequirement already satisfied: pyparsing&gt;=2.3.1 in /home/datacuber/miniconda3/lib/python3.9/site-packages (from matplotlib&lt;4.0.0,&gt;=3.3.3-&gt;pyclustertend) (3.0.9)\nRequirement already satisfied: cycler&gt;=0.10 in /home/datacuber/miniconda3/lib/python3.9/site-packages (from matplotlib&lt;4.0.0,&gt;=3.3.3-&gt;pyclustertend) (0.11.0)\nRequirement already satisfied: contourpy&gt;=1.0.1 in /home/datacuber/miniconda3/lib/python3.9/site-packages (from matplotlib&lt;4.0.0,&gt;=3.3.3-&gt;pyclustertend) (1.2.0)\nRequirement already satisfied: importlib-resources&gt;=3.2.0 in /home/datacuber/miniconda3/lib/python3.9/site-packages (from matplotlib&lt;4.0.0,&gt;=3.3.3-&gt;pyclustertend) (6.4.0)\nRequirement already satisfied: python-dateutil&gt;=2.7 in /home/datacuber/miniconda3/lib/python3.9/site-packages (from matplotlib&lt;4.0.0,&gt;=3.3.3-&gt;pyclustertend) (2.8.2)\nRequirement already satisfied: fonttools&gt;=4.22.0 in /home/datacuber/miniconda3/lib/python3.9/site-packages (from matplotlib&lt;4.0.0,&gt;=3.3.3-&gt;pyclustertend) (4.37.0)\nRequirement already satisfied: kiwisolver&gt;=1.0.1 in /home/datacuber/miniconda3/lib/python3.9/site-packages (from matplotlib&lt;4.0.0,&gt;=3.3.3-&gt;pyclustertend) (1.4.4)\nRequirement already satisfied: setuptools in /home/datacuber/miniconda3/lib/python3.9/site-packages (from numba&lt;0.55.0,&gt;=0.54.1-&gt;pyclustertend) (67.5.1)\nRequirement already satisfied: llvmlite&lt;0.38,&gt;=0.37.0rc1 in /home/datacuber/miniconda3/lib/python3.9/site-packages (from numba&lt;0.55.0,&gt;=0.54.1-&gt;pyclustertend) (0.37.0)\nRequirement already satisfied: pytz&gt;=2020.1 in /home/datacuber/miniconda3/lib/python3.9/site-packages (from pandas&lt;2.0.0,&gt;=1.2.0-&gt;pyclustertend) (2022.2.1)\nRequirement already satisfied: threadpoolctl&gt;=2.0.0 in /home/datacuber/miniconda3/lib/python3.9/site-packages (from scikit-learn&lt;2.0.0,&gt;=1.1.2-&gt;pyclustertend) (3.1.0)\nRequirement already satisfied: scipy&gt;=1.6.0 in /home/datacuber/miniconda3/lib/python3.9/site-packages (from scikit-learn&lt;2.0.0,&gt;=1.1.2-&gt;pyclustertend) (1.10.1)\nRequirement already satisfied: joblib&gt;=1.2.0 in /home/datacuber/miniconda3/lib/python3.9/site-packages (from scikit-learn&lt;2.0.0,&gt;=1.1.2-&gt;pyclustertend) (1.3.2)\nRequirement already satisfied: zipp&gt;=3.1.0 in /home/datacuber/miniconda3/lib/python3.9/site-packages (from importlib-resources&gt;=3.2.0-&gt;matplotlib&lt;4.0.0,&gt;=3.3.3-&gt;pyclustertend) (3.11.0)\nRequirement already satisfied: six&gt;=1.5 in /home/datacuber/miniconda3/lib/python3.9/site-packages (from python-dateutil&gt;=2.7-&gt;matplotlib&lt;4.0.0,&gt;=3.3.3-&gt;pyclustertend) (1.16.0)\n\n\n\nfrom sklearn.decomposition import PCA\nimport matplotlib.pyplot as plt\n\npca = PCA(n_components=2)\npca_X = pca.fit_transform(X)\npca = PCA(n_components=2)\npca_random = pca.fit_transform(X_random)\n\n\ndef compute_hopkins(X, p):\n    h_s = 1 - hopkins(X, p)\n    print(f\"Hopskins para p={p} es: {h_s}\")\n    return h_s\n\n\nhs_X = compute_hopkins(X, p=50)\nhs_random = compute_hopkins(X_random, p=50)\n\nfig, ax = plt.subplot_mosaic([[\"iris\", \"random\"]], figsize=(15, 6))\n\nax[\"iris\"].scatter(pca_X[\"pca0\"], pca_X[\"pca1\"])\nax[\"random\"].scatter(pca_random[\"pca0\"], pca_random[\"pca1\"])\nax[\"random\"].set_title(\n    f\"Reducción a 2D de nuestros puntos aleatorios. H = {hs_random:.2f}\"\n)\nax[\"iris\"].set_title(f\"Reducción a 2D de Iris. H = {hs_X:.2f}\")\nplt.show()\n\nHopskins para p=50 es: 0.8241582644992403\nHopskins para p=50 es: 0.48048319214476964"
  },
  {
    "objectID": "tics411/notebooks/07-ex-evaluation.html#vat-iris",
    "href": "tics411/notebooks/07-ex-evaluation.html#vat-iris",
    "title": "Evaluación de Clusters",
    "section": "VAT: Iris",
    "text": "VAT: Iris\n\nimport matplotlib.pyplot as plt\n\nvat(X_sc)\nplt.title(\"VAT para Iris Escalado\")\nivat(X_sc)\nplt.title(\"iVAT para Iris Escalado\")\n\nText(0.5, 1.0, 'iVAT para Iris Escalado')"
  },
  {
    "objectID": "tics411/notebooks/07-ex-evaluation.html#vat-random",
    "href": "tics411/notebooks/07-ex-evaluation.html#vat-random",
    "title": "Evaluación de Clusters",
    "section": "VAT: Random",
    "text": "VAT: Random\n\nvat(X_random)\nplt.title(\"VAT para Dataset Random\")\nivat(X_random)\nplt.title(\"iVAT para Dataset Random\")\n\nText(0.5, 1.0, 'iVAT para Dataset Random')"
  },
  {
    "objectID": "tics411/notebooks/07-ex-evaluation.html#correlación",
    "href": "tics411/notebooks/07-ex-evaluation.html#correlación",
    "title": "Evaluación de Clusters",
    "section": "Correlación",
    "text": "Correlación\n\nfrom sklearn.cluster import KMeans\nfrom scipy.spatial import distance_matrix\n\nkm = KMeans(n_clusters=2, n_init=10, random_state=1)\nlabels = km.fit_predict(X_sc)\n\n\ndef cluster_correlation(X, labels, p=2):\n    \"\"\"p corresponde al nivel de la distancia de Minkowski\"\"\"\n    ideal_sim = (labels == labels.reshape(-1, 1)).astype(np.float32)\n\n    d_matrix = distance_matrix(X, X, p=p)\n    S = 1 / (d_matrix + 1)\n    return np.corrcoef(S.flatten(), ideal_sim.flatten()).min()\n\n\ncluster_correlation(X_sc, labels)\n\n0.6856891998862197"
  },
  {
    "objectID": "tics411/notebooks/07-ex-evaluation.html#cohesión-y-separación",
    "href": "tics411/notebooks/07-ex-evaluation.html#cohesión-y-separación",
    "title": "Evaluación de Clusters",
    "section": "Cohesión y Separación",
    "text": "Cohesión y Separación\n\ncenters = km.cluster_centers_\n\n\ndef compute_clustering_metrics(X, labels, centers, is_df=True):\n    if is_df:\n        X = X.to_numpy()\n    sse = np.square(X - centers[labels]).sum()\n    count = np.bincount(labels)\n    ssb = (\n        np.square(X.mean(axis=0) - centers) * count.reshape(-1, 1)\n    ).sum()\n    return sse, ssb\n\n\nsse, ssb = compute_clustering_metrics(X_sc, labels, centers, is_df=True)\nsse, ssb\n\n(222.36170496502297, 377.638295034977)"
  },
  {
    "objectID": "tics411/notebooks/07-ex-evaluation.html#ejemplo-de-clases",
    "href": "tics411/notebooks/07-ex-evaluation.html#ejemplo-de-clases",
    "title": "Evaluación de Clusters",
    "section": "Ejemplo de Clases",
    "text": "Ejemplo de Clases\n\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom scipy.spatial import distance_matrix\n\ndf = pd.DataFrame(\n    dict(\n        x=[2, 3, 4, 8, 9, 10, 6, 7, 8],\n        y=[5, 4, 6, 3, 2, 5, 10, 8, 9],\n        c=[0, 0, 0, 1, 1, 1, 2, 2, 2],\n    )\n)\n\nd_matrix = distance_matrix(df[[\"x\", \"y\"]], df[[\"x\", \"y\"]], p=2)\nplt.scatter(df.x, df.y, c=df.c, s=200, edgecolors=\"k\")\n\ndf\n\n\n\n\n\n\n\n\nx\ny\nc\n\n\n\n\n0\n2\n5\n0\n\n\n1\n3\n4\n0\n\n\n2\n4\n6\n0\n\n\n3\n8\n3\n1\n\n\n4\n9\n2\n1\n\n\n5\n10\n5\n1\n\n\n6\n6\n10\n2\n\n\n7\n7\n8\n2\n\n\n8\n8\n9\n2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfrom sklearn.metrics import silhouette_score\n\nsilhouette_score(df[[\"x\", \"y\"]], df.c)\n\n0.614855027897113\n\n\n\n## Esta función se hizo sólo para mostrar los pasos intermedios\n## Usen esta función para revisar sus resultados cuando estudien para la prueba.\n\n\ndef silhouette_score_m(d_matrix, clust_labels):\n    n_clusters = len(np.unique(clust_labels))\n    clusters = clust_labels\n    idx_cohesion = clusters == np.arange(n_clusters).reshape(-1, 1)\n    a = np.zeros_like(clusters, dtype=np.float32)\n    bj = np.zeros((len(clusters), n_clusters))\n    for i, (row, c) in enumerate(zip(d_matrix, clusters)):\n        val = row[idx_cohesion[c] & (row != 0)]\n        a[i] = val.mean() if len(val) else 0\n        for cl in range(n_clusters):\n            if cl != c:\n                val = row[idx_cohesion[cl]]\n                bj[i, cl] = val.mean() if len(val) else 0\n\n    b = np.sort(bj, axis=1)[:, -1]\n    return a, b, bj, n_clusters\n\n\na, b, bj, n_clusters = silhouette_score_m(d_matrix, df.c.values)\n\n\ndef create_table_for_silhouette(a, b, bj, n_clusters):\n    s_score = (b - a) / np.max((a, b), axis=0)\n    columns = (\n        [\"a\"] + [\"b\" + str(i) for i in range(n_clusters)] + [\"b\", \"s\"]\n    )\n\n    s_table = pd.DataFrame(\n        np.hstack(\n            [\n                a.reshape(-1, 1),\n                bj,\n                b.reshape(-1, 1),\n                s_score.reshape(-1, 1),\n            ]\n        ),\n        columns=columns,\n    )\n    return s_table\n\n\ns_score_table = create_table_for_silhouette(a, b, bj, n_clusters)\ns_score_table[\"s\"].mean()\n\n0.6395238095238095"
  },
  {
    "objectID": "tics411/notebooks/07-ex-evaluation.html#silhouette-curve",
    "href": "tics411/notebooks/07-ex-evaluation.html#silhouette-curve",
    "title": "Evaluación de Clusters",
    "section": "Silhouette Curve",
    "text": "Silhouette Curve\n\nimport scikitplot as skplt\n\nskplt.metrics.plot_silhouette(X_sc, labels)\nplt.show()"
  },
  {
    "objectID": "tics411/notebooks/15-ex-LR.html",
    "href": "tics411/notebooks/15-ex-LR.html",
    "title": "Clases UAI",
    "section": "",
    "text": "import pandas as pd\nimport seaborn as sns\n\ndf = sns.load_dataset(\"titanic\")\ndf\n\n\n\n\n\n\n\n\nsurvived\npclass\nsex\nage\nsibsp\nparch\nfare\nembarked\nclass\nwho\nadult_male\ndeck\nembark_town\nalive\nalone\n\n\n\n\n0\n0\n3\nmale\n22.0\n1\n0\n7.2500\nS\nThird\nman\nTrue\nNaN\nSouthampton\nno\nFalse\n\n\n1\n1\n1\nfemale\n38.0\n1\n0\n71.2833\nC\nFirst\nwoman\nFalse\nC\nCherbourg\nyes\nFalse\n\n\n2\n1\n3\nfemale\n26.0\n0\n0\n7.9250\nS\nThird\nwoman\nFalse\nNaN\nSouthampton\nyes\nTrue\n\n\n3\n1\n1\nfemale\n35.0\n1\n0\n53.1000\nS\nFirst\nwoman\nFalse\nC\nSouthampton\nyes\nFalse\n\n\n4\n0\n3\nmale\n35.0\n0\n0\n8.0500\nS\nThird\nman\nTrue\nNaN\nSouthampton\nno\nTrue\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n886\n0\n2\nmale\n27.0\n0\n0\n13.0000\nS\nSecond\nman\nTrue\nNaN\nSouthampton\nno\nTrue\n\n\n887\n1\n1\nfemale\n19.0\n0\n0\n30.0000\nS\nFirst\nwoman\nFalse\nB\nSouthampton\nyes\nTrue\n\n\n888\n0\n3\nfemale\nNaN\n1\n2\n23.4500\nS\nThird\nwoman\nFalse\nNaN\nSouthampton\nno\nFalse\n\n\n889\n1\n1\nmale\n26.0\n0\n0\n30.0000\nC\nFirst\nman\nTrue\nC\nCherbourg\nyes\nTrue\n\n\n890\n0\n3\nmale\n32.0\n0\n0\n7.7500\nQ\nThird\nman\nTrue\nNaN\nQueenstown\nno\nTrue\n\n\n\n\n891 rows × 15 columns\n\n\n\n\nX = df[[\"class\", \"sex\", \"embark_town\", \"fare\", \"age\"]]\ny = df.survived\n\n\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.25, random_state=42\n)\nX_train.shape, X_test.shape\n\n((668, 5), (223, 5))\n\n\n\nimport numpy as np\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.pipeline import Pipeline\nfrom feature_engine.imputation import MeanMedianImputer, CategoricalImputer\nfrom feature_engine.encoding import OneHotEncoder, OrdinalEncoder\nfrom sklearn.preprocessing import StandardScaler\nfrom feature_engine.wrappers import SklearnTransformerWrapper\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score\nfrom sklearn.metrics import RocCurveDisplay, ConfusionMatrixDisplay\nfrom sklego.meta import Thresholder\n\n\ndef make_pipeline(\n    num_method, cat_method, encoder, sc_variables, C, threshold=0.5\n):\n    scaler = SklearnTransformerWrapper(\n        StandardScaler(), variables=sc_variables\n    )\n\n    print(f\"Entrenamiento para C={C} y threshold = {threshold}\")\n    print(\"===================================\")\n    pipe = Pipeline(\n        steps=[\n            (\"num_imp\", MeanMedianImputer(imputation_method=num_method)),\n            (\"cat_imp\", CategoricalImputer(imputation_method=cat_method)),\n            (\"ohe\", encoder),\n            (\"sc\", scaler),\n            (\n                \"model\",\n                Thresholder(\n                    LogisticRegression(\n                        C=C, random_state=42, max_iter=10000\n                    ),\n                    threshold=threshold,\n                ),\n            ),\n        ]\n    )\n    return pipe\n\n\ndef make_evaluation(\n    model,\n    X_train,\n    X_test,\n    y_train,\n    y_test,\n):\n    model.fit(X_train, y_train)\n    y_pred_train = model.predict(X_train)\n    y_pred = model.predict(X_test)\n    y_pred_proba = model.predict_proba(X_test)\n\n    train_acc = accuracy_score(y_train, y_pred_train)\n    test_acc = accuracy_score(y_test, y_pred)\n    train_precision = precision_score(y_train, y_pred_train)\n    test_precision = precision_score(y_test, y_pred)\n    train_recall = recall_score(y_train, y_pred_train)\n    test_recall = recall_score(y_test, y_pred)\n\n    print(f\"Train Accuracy {train_acc}\")\n    print(f\"Test Accuracy {test_acc}\")\n    print(\"===================================\")\n    print(f\"Train Precision {train_precision}\")\n    print(f\"Test Precision {test_precision}\")\n    print(\"===================================\")\n    print(f\"Train Recall {train_recall}\")\n    print(f\"Test Recall {test_recall}\")\n\n    print(\"===================================\")\n    print(f\"Coeficientes: {model[-1].estimator_.coef_}\")\n    print(f\"Coeficientes: {model[-1].estimator_.intercept_}\")\n\n    ConfusionMatrixDisplay.from_predictions(y_test, y_pred)\n    RocCurveDisplay.from_predictions(y_test, y_pred_proba[:, 1])\n\n\npipe = make_pipeline(\n    num_method=\"mean\",\n    cat_method=\"missing\",\n    encoder=OneHotEncoder(),\n    sc_variables=[\"age\", \"fare\"],\n    C=10,\n    threshold=0.6,\n)\n\nmake_evaluation(pipe, X_train, X_test, y_train, y_test)\n\nEntrenamiento para C=10 y threshold = 0.6\n===================================\nTrain Accuracy 0.8068862275449101\nTest Accuracy 0.8026905829596412\n===================================\nTrain Precision 0.8444444444444444\nTest Precision 0.8082191780821918\n===================================\nTrain Recall 0.6007905138339921\nTest Recall 0.6629213483146067\n===================================\nCoeficientes: [[ 0.08468769 -0.35930833  0.91502373 -1.02074655  0.36843929 -1.13894327\n   1.40165975 -0.60754774  0.03083727 -0.10686131  0.94628825]]\nCoeficientes: [0.3325951]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImportante, normalemente es buena idea escoger sólo una métrica. O darle más preponderancia a una métrica, ya que el mejor modelo puede ser muy distinto dependiendo de la métrica a utilizar.\n\n\n\n\n Back to top"
  },
  {
    "objectID": "tics411/notebooks/hopkins.html",
    "href": "tics411/notebooks/hopkins.html",
    "title": "Ejemplos de Hopkins",
    "section": "",
    "text": "from pyclustertend import hopkins\nfrom sklearn.datasets import make_blobs\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n\ndef blobs_examples(\n    n_centers, cluster_std, n_samples=4000, p=100, center_box=(-10, 10)\n):\n    df_spread, labels = make_blobs(\n        n_samples=n_samples,\n        centers=n_centers,\n        n_features=2,\n        random_state=42,\n        center_box=center_box,\n        cluster_std=cluster_std,\n    )\n    df_spread = pd.DataFrame(df_spread, columns=[\"x\", \"y\"])\n    plt.scatter(df_spread.x, df_spread.y, c=labels)\n    plt.title(f\"H = {1-hopkins(df_spread, p)}\")\n    plt.tight_layout()\n\n\n## Una sola nube, muy compacta...\nblobs_examples(n_centers=1, cluster_std=0.5, n_samples=4000, p=100)\n\n\n\n\n\n\n\n\n\n## Muchos nubes muy compactos...\nblobs_examples(n_centers=5, cluster_std=0.5, n_samples=4000, p=100)\n\n\n\n\n\n\n\n\n\n## Muchas nubes extremadamente compactos\nblobs_examples(n_centers=5, cluster_std=0.001, n_samples=4000, p=100)\n\n\n\n\n\n\n\n\n\nEn este caso utilizamos la función make_blobs para simular clusters ficticios. Los clusters siempre son esféricos, es por eso que el Hopkins tiende a dar valores bastante buenos. Aunque, dependiendo de qué tan compacto sea la nube tiende a 1 de manera muy fuerte.\n\n\nimport numpy as np\n\nnp.random.seed(0)\n\n\ndef random_examples(n_samples=4000, p=100):\n    df_random = pd.DataFrame(\n        np.random.rand(n_samples, 2), columns=[\"x\", \"y\"]\n    )\n    plt.scatter(df_random.x, df_random.y)\n    plt.title(f\"H = {1-hopkins(df_random, p)}\")\n    plt.tight_layout()\n\n\n## Puntos más dispersos\nrandom_examples(n_samples=100, p=10)\n\n\n\n\n\n\n\n\n\n## Más denso, pero aún aleatorio...\nrandom_examples(n_samples=1000, p=100)\n\n\n\n\n\n\n\n\n\nEn este caso estamos usando np.random.rand para simular sólo valores aleatorios. Se puede ver que entre más lleno está el espacio, Hopkins tiende a 0.5.\n\n\n## valores uniformemente distribuidos y con poca tendencia a agruparse (normalmente pocos puntos)\n## tienen H más pequeños, pero es díficil obtenerlos...\nnp.random.seed(0)\n\n\ndef uniform_example(n_samples=10, max_val=10, p=10):\n    df_uniform = pd.DataFrame(\n        dict(\n            x=np.random.randint(0, max_val + 1, size=n_samples),\n            y=np.random.randint(0, max_val, size=n_samples),\n        )\n    )\n\n    plt.scatter(df_uniform.x, df_uniform.y)\n    plt.title(f\"H = {1-hopkins(df_uniform, p)}\")\n\n\nuniform_example(n_samples=11, max_val=10, p=10)\n\n\n\n\n\n\n\n\n\nuniform_example(n_samples=4000, max_val=1000, p=100)\n\n\n\n\n\n\n\n\n\nEn este caso también estamos forzando aleatoriedad pero con uniformidad de distancia. Para eso simulamos usando np.random.randint para generar valores aleatorios pero más o menos equiespaciados uniformemente. Es bien interesante este caso, porque si usamos muchos datos, se tiende a valores completamente aleatorios, es decir H \\(\\sim\\) 0.5.\n\n\n\n\n Back to top"
  },
  {
    "objectID": "tics411/notebooks/08-proyecto_clustering.html",
    "href": "tics411/notebooks/08-proyecto_clustering.html",
    "title": "Preparación de los Datos",
    "section": "",
    "text": "# En caso que de ejecutar esto en Colab, van a tener que instalar Scikit-Plot para poder ver la curva de Silhouette.\n#!pip install scikit-plot\nfrom sklearn.datasets import make_blobs\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.cluster import AgglomerativeClustering, KMeans, DBSCAN\nfrom sklearn.metrics import silhouette_score\nfrom sklearn import set_config\n\nset_config(transform_output=\"pandas\")\n\nRANDOM_STATE = 0\nnp.random.seed(RANDOM_STATE)\nN = np.random.randint(5, 15, size=1)[0]\nn_samples = np.random.randint(100, 1000, size=N)\nX, _ = make_blobs(\n    n_samples=n_samples,\n    n_features=9,\n    cluster_std=2.5,\n    random_state=RANDOM_STATE,\n)\ndf = pd.DataFrame(X)\ndict_cat = {\n    0: \"Cat 1\",\n    1: \"Cat 2\",\n    2: \"Cat 3\",\n}\nrng = np.random.default_rng()\ndf[\"cat_var\"] = rng.choice(a=[0, 1, 2], size=len(df), p=[0.2, 0.3, 0.5])\ndf[\"cat_var\"] = df[\"cat_var\"].map(dict_cat)\n\ndf.columns = [f\"x{i}\" for i, _ in enumerate(df.columns, start=1)]\ndf[\"x1\"] += 100\ndf[\"x5\"] *= 327\ndf[\"x9\"] /= 15\n\ndf.to_csv(\"proyecto_clustering.csv\", index=False)\n## Acá comienza oficialmente el código.\ndf = pd.read_csv(\"proyecto_clustering.csv\")\ndf.dtypes.value_counts().plot(\n    kind=\"bar\", title=\"Tipos de Datos en el Dataset\", edgecolor=\"k\"\n)\nplt.tight_layout()\ndf.hist(figsize=(20, 6), edgecolor=\"k\", grid=False)\nplt.tight_layout()\ndf[\"x10\"].value_counts().plot(\n    kind=\"bar\",\n    edgecolor=\"k\",\n    title=\"Distribución de las Variables Categóricas\",\n)\nplt.tight_layout()"
  },
  {
    "objectID": "tics411/notebooks/08-proyecto_clustering.html#variables-categóricas",
    "href": "tics411/notebooks/08-proyecto_clustering.html#variables-categóricas",
    "title": "Preparación de los Datos",
    "section": "Variables Categóricas",
    "text": "Variables Categóricas\n\nfrom sklearn.preprocessing import OneHotEncoder\n\nohe = OneHotEncoder(sparse_output=False)\ndummy_vars = ohe.fit_transform(df[[\"x10\"]])\n\nX = pd.concat([df.drop(columns=\"x10\"), dummy_vars], axis=1)\nX\n\n\n\n\n\n\n\n\nx1\nx2\nx3\nx4\nx5\nx6\nx7\nx8\nx9\nx10_Cat 1\nx10_Cat 2\nx10_Cat 3\n\n\n\n\n0\n105.576134\n4.823419\n3.409904\n-11.687494\n-1532.613468\n-4.589218\n-6.854641\n-8.877022\n-0.449964\n0.0\n0.0\n1.0\n\n\n1\n100.479786\n-4.876628\n-5.404970\n6.932649\n-4092.341900\n12.163845\n-6.502116\n10.874025\n0.348683\n0.0\n0.0\n1.0\n\n\n2\n97.357744\n8.467431\n-0.865210\n4.353712\n1444.577125\n-1.992772\n-12.223474\n-9.100414\n0.407230\n0.0\n0.0\n1.0\n\n\n3\n95.857842\n5.931475\n0.278352\n3.413013\n1959.773064\n-10.248761\n-8.136656\n-9.158037\n0.478212\n0.0\n0.0\n1.0\n\n\n4\n99.772427\n-2.876912\n4.499859\n1.308382\n-2318.502069\n2.062409\n-13.469304\n-0.236395\n0.478002\n0.0\n1.0\n0.0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n6418\n98.951606\n6.649525\n1.869195\n1.765821\n4348.322822\n-6.866256\n-1.578755\n-12.749590\n0.454056\n0.0\n0.0\n1.0\n\n\n6419\n94.996949\n-6.638457\n3.999433\n0.989885\n-1811.824888\n-0.859185\n-7.422772\n3.293839\n0.558469\n0.0\n0.0\n1.0\n\n\n6420\n95.495497\n6.664764\n0.019823\n1.825686\n2845.172238\n-7.376139\n-8.056029\n-10.066078\n0.224961\n0.0\n0.0\n1.0\n\n\n6421\n99.435967\n5.469512\n6.342347\n-1.182801\n-358.410366\n-1.205160\n2.248149\n6.840680\n0.748647\n0.0\n1.0\n0.0\n\n\n6422\n109.218858\n-6.367392\n-0.857113\n-6.749834\n1913.311965\n-4.103422\n0.343194\n-5.460592\n0.121518\n0.0\n0.0\n1.0\n\n\n\n\n6423 rows × 12 columns\n\n\n\n\npca = PCA(n_components=2, random_state=42)\npca_X = pca.fit_transform(X)\nplt.scatter(pca_X[\"pca0\"], pca_X[\"pca1\"])\nplt.title(\"Visualización PCA del Dataset\")\nplt.tight_layout()"
  },
  {
    "objectID": "tics411/notebooks/08-proyecto_clustering.html#k-means",
    "href": "tics411/notebooks/08-proyecto_clustering.html#k-means",
    "title": "Preparación de los Datos",
    "section": "K-Means",
    "text": "K-Means\n\ndef elbow_curve(X, k_max=10, color=\"blue\", title=None):\n    wc = []\n    for k in range(1, k_max + 1):\n        km = KMeans(n_clusters=k, random_state=1)\n        km.fit(X)\n        wc.append(km.inertia_)\n\n    k = [*range(1, k_max + 1)]\n    plt.plot(k, wc, c=color, marker=\"*\")\n    plt.title(title)\n    plt.xlabel(\"Número de Clústers\")\n    plt.ylabel(\"Within Distance\")\n    return wc\n\n\nwc = elbow_curve(\n    X, k_max=20, color=\"blue\", title=\"Curva del Codo para K-Means\"\n)\n\n\n\n\n\n\n\n\n\nmetricas = dict()\n\n\nK_KMEANS = 10\nkm = KMeans(n_clusters=K_KMEANS, n_init=10, random_state=RANDOM_STATE)\nlabels_km = km.fit_predict(X)\n\n\ns_km = silhouette_score(X, labels_km)\nmetricas[\"km_10\"] = s_km\nmetricas\n\n{'km_10': 0.39419687509752793}"
  },
  {
    "objectID": "tics411/notebooks/08-proyecto_clustering.html#jerárquico",
    "href": "tics411/notebooks/08-proyecto_clustering.html#jerárquico",
    "title": "Preparación de los Datos",
    "section": "Jerárquico",
    "text": "Jerárquico\n\nfrom scipy.cluster.hierarchy import dendrogram, linkage\n\n\ndef plot_dendogram(X, link=\"ward\"):\n    Z = linkage(X, method=link)\n\n    plt.figure(figsize=(10, 5))\n    plt.title(f\"Clustering Utilizando Iris, Método: {link}\")\n    plt.xlabel(\"Iris Samples\")\n    plt.ylabel(\"Distance\")\n    dendrogram(Z, leaf_rotation=90.0, leaf_font_size=8.0)\n    plt.show()\n\n\nlinkage_list = [\"single\", \"complete\", \"average\", \"ward\"]\nfor l in linkage_list:\n    plot_dendogram(X, link=l)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndef train_hierarchical(K_H, linkage):\n    hc = AgglomerativeClustering(n_clusters=K_H, linkage=linkage)\n    labels_h = hc.fit_predict(X)\n    s_h = silhouette_score(X, labels_h)\n    print(f\"El coeficiente de Silueta es {s_h}\")\n    return labels_h, s_h\n\n\nlabels_c9, s_c9 = train_hierarchical(K_H=9, linkage=\"complete\")\nlabels_a9, s_a9 = train_hierarchical(K_H=9, linkage=\"average\")\nlabels_w4, s_w4 = train_hierarchical(K_H=4, linkage=\"ward\")\n\nEl coeficiente de Silueta es 0.37657025597625804\nEl coeficiente de Silueta es 0.3812263959798965\nEl coeficiente de Silueta es 0.2852126845283154\n\n\n\nmetricas[\"s_c9\"] = s_c9\nmetricas[\"s_a9\"] = s_a9\nmetricas[\"s_w4\"] = s_w4\nmetricas\n\n{'km_10': 0.39419687509752793,\n 's_c9': 0.37657025597625804,\n 's_a9': 0.3812263959798965,\n 's_w4': 0.2852126845283154}"
  },
  {
    "objectID": "tics411/notebooks/08-proyecto_clustering.html#dbscan",
    "href": "tics411/notebooks/08-proyecto_clustering.html#dbscan",
    "title": "Preparación de los Datos",
    "section": "DBSCAN",
    "text": "DBSCAN\n\nfrom sklearn.neighbors import NearestNeighbors\n\nMIN_SAMPLES = X.shape[1] + 1\n\n\ndef dbscan_elbow_plot(X, k=5):\n    knn = NearestNeighbors(n_neighbors=k)\n    knn.fit(X)\n    distances, _ = knn.kneighbors(X)\n    distances = np.sort(distances[:, -1])\n    n_pts = distances.shape[0]\n\n    plt.plot(range(1, n_pts + 1), distances)\n    plt.xlabel(\n        f\"Puntos ordenados por Distancia al {k} vecino más cercano.\"\n    )\n    plt.ylabel(f\"Distancia al {k} vecino más cercano\")\n    plt.title(f\"Búsqueda de EPS para DBSCAN con k={k}\")\n\n\ndbscan_elbow_plot(X, k=MIN_SAMPLES)\n\nEPS = 1.6\n\n\n\n\n\n\n\n\n\ndbs = DBSCAN(eps=EPS, min_samples=MIN_SAMPLES)\nlabels_dbs = dbs.fit_predict(X)\ns_dbs = silhouette_score(X, labels_dbs)\nmetricas[\"s_dbs\"] = s_dbs\nmetricas\n\n{'km_10': 0.39419687509752793,\n 's_c9': 0.37657025597625804,\n 's_a9': 0.3812263959798965,\n 's_w4': 0.2852126845283154,\n 's_dbs': 0.1818560991479739}"
  },
  {
    "objectID": "tics411/notebooks/08-proyecto_clustering.html#evaluación",
    "href": "tics411/notebooks/08-proyecto_clustering.html#evaluación",
    "title": "Preparación de los Datos",
    "section": "Evaluación",
    "text": "Evaluación\n\npd.Series(metricas.values(), index=metricas.keys()).plot(\n    kind=\"bar\",\n    rot=0,\n    edgecolor=\"k\",\n    title=\"Silhouette Score para los modelos generados\",\n)\nplt.tight_layout()\n\n\n\n\n\n\n\n\n\nlabels_km\n\narray([5, 9, 2, ..., 2, 0, 1], dtype=int32)\n\n\n\nimport matplotlib.pyplot as plt\nimport matplotlib.colors as mcolors\n\n\ndef create_tables(df, labels, columns):\n    df[\"labels\"] = labels\n    std = df.groupby(\"labels\")[columns].std(numeric_only=True)\n    mean = df.groupby(\"labels\")[columns].mean(numeric_only=True)\n    return mean, std\n\n\ndef center_analysis_viz(\n    df, n_clusters, labels, columns, title=\"\", figsize=(20, 20)\n):\n    clusters_axis = [f\"Cluster {i}\" for i in range(1, n_clusters + 1)]\n\n    n_columns = len(columns)\n    colors = list(mcolors.TABLEAU_COLORS.values())[:n_columns]\n    fig, ax = plt.subplots(n_columns, figsize=figsize)\n\n    mean_table, std_table = create_tables(df, labels, columns)\n\n    for i in range(n_columns):\n        ax[i].errorbar(\n            clusters_axis,\n            mean_table[columns[i]],\n            yerr=std_table[columns[i]],\n            capsize=20,\n            linestyle=\"none\",\n            marker=\"o\",\n            lw=3,\n            capthick=3,\n            ms=10,\n            c=colors[i],\n        )\n        ax[i].set_title(columns[i])\n    plt.suptitle(title, fontsize=15)\n    plt.tight_layout()\n\n\ncenter_analysis_viz(\n    df,\n    n_clusters=10,\n    labels=labels_km,\n    columns=num_vars,\n    title=\"Análisis de Centro\",\n)\n\n\n\n\n\n\n\n\n\nplt.scatter(pca_X[\"pca0\"], pca_X[\"pca1\"], c=labels_km)\nplt.tight_layout()\n\n\n\n\n\n\n\n\n\nimport scikitplot as skplt\n\nskplt.metrics.plot_silhouette(X, labels_km)\nplt.show()"
  },
  {
    "objectID": "tics411/notebooks/pandas_basics.html",
    "href": "tics411/notebooks/pandas_basics.html",
    "title": "Seleccionar Filas, y columnas…",
    "section": "",
    "text": "import pandas as pd\nimport numpy as np\nimport seaborn as sns\n\ntitanic_df = sns.load_dataset(\"titanic\")\ntitanic_df.shape, titanic_df.columns\n\n((891, 15),\n Index(['survived', 'pclass', 'sex', 'age', 'sibsp', 'parch', 'fare',\n        'embarked', 'class', 'who', 'adult_male', 'deck', 'embark_town',\n        'alive', 'alone'],\n       dtype='object'))\ntitanic_df.dtypes\n\nsurvived          int64\npclass            int64\nsex              object\nage             float64\nsibsp             int64\nparch             int64\nfare            float64\nembarked         object\nclass          category\nwho              object\nadult_male         bool\ndeck           category\nembark_town      object\nalive            object\nalone              bool\ndtype: object\ntitanic_df[\"survived_new\"] = titanic_df[\"survived\"].astype(\"float64\")\ntitanic_df\n\n\n\n\n\n\n\n\nsurvived\npclass\nsex\nage\nsibsp\nparch\nfare\nembarked\nclass\nwho\nadult_male\ndeck\nembark_town\nalive\nalone\nsurvived_new\n\n\n\n\n0\n0\n3\nmale\n22.0\n1\n0\n7.2500\nS\nThird\nman\nTrue\nNaN\nSouthampton\nno\nFalse\n0.0\n\n\n1\n1\n1\nfemale\n38.0\n1\n0\n71.2833\nC\nFirst\nwoman\nFalse\nC\nCherbourg\nyes\nFalse\n1.0\n\n\n2\n1\n3\nfemale\n26.0\n0\n0\n7.9250\nS\nThird\nwoman\nFalse\nNaN\nSouthampton\nyes\nTrue\n1.0\n\n\n3\n1\n1\nfemale\n35.0\n1\n0\n53.1000\nS\nFirst\nwoman\nFalse\nC\nSouthampton\nyes\nFalse\n1.0\n\n\n4\n0\n3\nmale\n35.0\n0\n0\n8.0500\nS\nThird\nman\nTrue\nNaN\nSouthampton\nno\nTrue\n0.0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n886\n0\n2\nmale\n27.0\n0\n0\n13.0000\nS\nSecond\nman\nTrue\nNaN\nSouthampton\nno\nTrue\n0.0\n\n\n887\n1\n1\nfemale\n19.0\n0\n0\n30.0000\nS\nFirst\nwoman\nFalse\nB\nSouthampton\nyes\nTrue\n1.0\n\n\n888\n0\n3\nfemale\nNaN\n1\n2\n23.4500\nS\nThird\nwoman\nFalse\nNaN\nSouthampton\nno\nFalse\n0.0\n\n\n889\n1\n1\nmale\n26.0\n0\n0\n30.0000\nC\nFirst\nman\nTrue\nC\nCherbourg\nyes\nTrue\n1.0\n\n\n890\n0\n3\nmale\n32.0\n0\n0\n7.7500\nQ\nThird\nman\nTrue\nNaN\nQueenstown\nno\nTrue\n0.0\n\n\n\n\n891 rows × 16 columns\n## Mostrar la diferencia entre una Serie y un DataFrame.\ntitanic_df.loc[10]\n\nsurvived                 1\npclass                   3\nsex                 female\nage                    4.0\nsibsp                    1\nparch                    1\nfare                  16.7\nembarked                 S\nclass                Third\nwho                  child\nadult_male           False\ndeck                     G\nembark_town    Southampton\nalive                  yes\nalone                False\nName: 10, dtype: object\ntitanic_df[\"embark_town\"].to_frame()\n\n\n\n\n\n\n\n\nembark_town\n\n\n\n\n0\nSouthampton\n\n\n1\nCherbourg\n\n\n2\nSouthampton\n\n\n3\nSouthampton\n\n\n4\nSouthampton\n\n\n...\n...\n\n\n886\nSouthampton\n\n\n887\nSouthampton\n\n\n888\nSouthampton\n\n\n889\nCherbourg\n\n\n890\nQueenstown\n\n\n\n\n891 rows × 1 columns\n## Explicar que va una lista de elementos... no es un \"doble\" paréntesis.\ntitanic_df[[\"embark_town\", \"class\"]]\n\n\n\n\n\n\n\n\nembark_town\nclass\n\n\n\n\n0\nSouthampton\nThird\n\n\n1\nCherbourg\nFirst\n\n\n2\nSouthampton\nThird\n\n\n3\nSouthampton\nFirst\n\n\n4\nSouthampton\nThird\n\n\n...\n...\n...\n\n\n886\nSouthampton\nSecond\n\n\n887\nSouthampton\nFirst\n\n\n888\nSouthampton\nThird\n\n\n889\nCherbourg\nFirst\n\n\n890\nQueenstown\nThird\n\n\n\n\n891 rows × 2 columns\ntitanic_df.loc[[10, 15], [\"embark_town\", \"fare\", \"age\"]]\n\n\n\n\n\n\n\n\nembark_town\nfare\nage\n\n\n\n\n10\nSouthampton\n16.7\n4.0\n\n\n15\nSouthampton\n16.0\n55.0\ntitanic_df_shuffle = titanic_df.sample(frac=1)\ntitanic_df_shuffle\n\n\n\n\n\n\n\n\nsurvived\npclass\nsex\nage\nsibsp\nparch\nfare\nembarked\nclass\nwho\nadult_male\ndeck\nembark_town\nalive\nalone\n\n\n\n\n133\n1\n2\nfemale\n29.0\n1\n0\n26.0000\nS\nSecond\nwoman\nFalse\nNaN\nSouthampton\nyes\nFalse\n\n\n748\n0\n1\nmale\n19.0\n1\n0\n53.1000\nS\nFirst\nman\nTrue\nD\nSouthampton\nno\nFalse\n\n\n876\n0\n3\nmale\n20.0\n0\n0\n9.8458\nS\nThird\nman\nTrue\nNaN\nSouthampton\nno\nTrue\n\n\n226\n1\n2\nmale\n19.0\n0\n0\n10.5000\nS\nSecond\nman\nTrue\nNaN\nSouthampton\nyes\nTrue\n\n\n342\n0\n2\nmale\n28.0\n0\n0\n13.0000\nS\nSecond\nman\nTrue\nNaN\nSouthampton\nno\nTrue\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n283\n1\n3\nmale\n19.0\n0\n0\n8.0500\nS\nThird\nman\nTrue\nNaN\nSouthampton\nyes\nTrue\n\n\n863\n0\n3\nfemale\nNaN\n8\n2\n69.5500\nS\nThird\nwoman\nFalse\nNaN\nSouthampton\nno\nFalse\n\n\n124\n0\n1\nmale\n54.0\n0\n1\n77.2875\nS\nFirst\nman\nTrue\nD\nSouthampton\nno\nFalse\n\n\n583\n0\n1\nmale\n36.0\n0\n0\n40.1250\nC\nFirst\nman\nTrue\nA\nCherbourg\nno\nTrue\n\n\n85\n1\n3\nfemale\n33.0\n3\n0\n15.8500\nS\nThird\nwoman\nFalse\nNaN\nSouthampton\nyes\nFalse\n\n\n\n\n891 rows × 15 columns\n# Esto es un error... si es que no se separa...\ntitanic_df_shuffle.iloc[3][[\"who\", \"adult_male\"]]\n\nwho            man\nadult_male    True\nName: 226, dtype: object\n## Algunos métodos importante...\ntitanic_df.describe(percentiles=[0.05, 0.25, 0.75, 0.95])\n\n\n\n\n\n\n\n\nsurvived\npclass\nage\nsibsp\nparch\nfare\n\n\n\n\ncount\n891.000000\n891.000000\n714.000000\n891.000000\n891.000000\n891.000000\n\n\nmean\n0.383838\n2.308642\n29.699118\n0.523008\n0.381594\n32.204208\n\n\nstd\n0.486592\n0.836071\n14.526497\n1.102743\n0.806057\n49.693429\n\n\nmin\n0.000000\n1.000000\n0.420000\n0.000000\n0.000000\n0.000000\n\n\n5%\n0.000000\n1.000000\n4.000000\n0.000000\n0.000000\n7.225000\n\n\n25%\n0.000000\n2.000000\n20.125000\n0.000000\n0.000000\n7.910400\n\n\n50%\n0.000000\n3.000000\n28.000000\n0.000000\n0.000000\n14.454200\n\n\n75%\n1.000000\n3.000000\n38.000000\n1.000000\n0.000000\n31.000000\n\n\n95%\n1.000000\n3.000000\n56.000000\n3.000000\n2.000000\n112.079150\n\n\nmax\n1.000000\n3.000000\n80.000000\n8.000000\n6.000000\n512.329200\ntitanic_df.mean(numeric_only=True)\n\nsurvived       0.383838\npclass         2.308642\nage           29.699118\nsibsp          0.523008\nparch          0.381594\nfare          32.204208\nadult_male     0.602694\nalone          0.602694\ndtype: float64\ntitanic_df.median(numeric_only=True)\n\nsurvived       0.0000\npclass         3.0000\nage           28.0000\nsibsp          0.0000\nparch          0.0000\nfare          14.4542\nadult_male     1.0000\nalone          1.0000\ndtype: float64\ntitanic_df.mode()\n\n\n\n\n\n\n\n\nsurvived\npclass\nsex\nage\nsibsp\nparch\nfare\nembarked\nclass\nwho\nadult_male\ndeck\nembark_town\nalive\nalone\n\n\n\n\n0\n0\n3\nmale\n24.0\n0\n0\n8.05\nS\nThird\nman\nTrue\nC\nSouthampton\nno\nTrue"
  },
  {
    "objectID": "tics411/notebooks/pandas_basics.html#agrupar",
    "href": "tics411/notebooks/pandas_basics.html#agrupar",
    "title": "Seleccionar Filas, y columnas…",
    "section": "Agrupar",
    "text": "Agrupar\n\ndf = pd.DataFrame(\n    dict(a=[1, 1, 1, 1, 2, 2, 2, 2], b=[1, 2, 3, 4, 5, 6, 7, 8])\n)\n\ndf\n\n\n\n\n\n\n\n\na\nb\n\n\n\n\n0\n1\n1\n\n\n1\n1\n2\n\n\n2\n1\n3\n\n\n3\n1\n4\n\n\n4\n2\n5\n\n\n5\n2\n6\n\n\n6\n2\n7\n\n\n7\n2\n8\n\n\n\n\n\n\n\n\nfor i in [df.shape, df.columns, df.index, df.dtypes]:\n    print(i)\n\n(8, 2)\nIndex(['a', 'b'], dtype='object')\nRangeIndex(start=0, stop=8, step=1)\na    int64\nb    int64\ndtype: object\n\n\n\ngroups = df.groupby(\"a\")\nfor id, g in groups:\n    print(f\"Este es el grupo: {id}\")\n    display(g)\n\nEste es el grupo: 1\n\n\n\n\n\n\n\n\n\na\nb\n\n\n\n\n0\n1\n1.0\n\n\n1\n1\n2.0\n\n\n2\n1\n3.0\n\n\n3\n1\n4.0\n\n\n\n\n\n\n\nEste es el grupo: 2\n\n\n\n\n\n\n\n\n\na\nb\n\n\n\n\n4\n2\n5.0\n\n\n5\n2\n6.0\n\n\n6\n2\n7.0\n\n\n7\n2\n8.0\n\n\n\n\n\n\n\n\ndf.groupby(\"a\")[\"b\"].mean()\n\na\n1    2.5\n2    6.5\nName: b, dtype: float64\n\n\n\ntitanic_df.groupby(\"sex\")[\"fare\"].mean()\n\nsex\nfemale    44.479818\nmale      25.523893\nName: fare, dtype: float64\n\n\n\ntitanic_df.groupby([\"sex\", \"pclass\"])[[\"age\", \"fare\"]].median()\n\n\n\n\n\n\n\n\n\nage\nfare\n\n\nsex\npclass\n\n\n\n\n\n\nfemale\n1\n35.0\n82.66455\n\n\n2\n28.0\n22.00000\n\n\n3\n21.5\n12.47500\n\n\nmale\n1\n40.0\n41.26250\n\n\n2\n30.0\n13.00000\n\n\n3\n25.0\n7.92500"
  },
  {
    "objectID": "tics411/notebooks/06-ex-DBSCAN.html",
    "href": "tics411/notebooks/06-ex-DBSCAN.html",
    "title": "DBSCAN",
    "section": "",
    "text": "import numpy as np\nimport seaborn as sns\ndf = sns.load_dataset(\"iris\")\nX = df.drop(columns=\"species\")\nX\n\n\n\n\n\n\n\n\nsepal_length\nsepal_width\npetal_length\npetal_width\n\n\n\n\n0\n5.1\n3.5\n1.4\n0.2\n\n\n1\n4.9\n3.0\n1.4\n0.2\n\n\n2\n4.7\n3.2\n1.3\n0.2\n\n\n3\n4.6\n3.1\n1.5\n0.2\n\n\n4\n5.0\n3.6\n1.4\n0.2\n\n\n...\n...\n...\n...\n...\n\n\n145\n6.7\n3.0\n5.2\n2.3\n\n\n146\n6.3\n2.5\n5.0\n1.9\n\n\n147\n6.5\n3.0\n5.2\n2.0\n\n\n148\n6.2\n3.4\n5.4\n2.3\n\n\n149\n5.9\n3.0\n5.1\n1.8\n\n\n\n\n150 rows × 4 columns"
  },
  {
    "objectID": "tics411/notebooks/06-ex-DBSCAN.html#función-para-visualizar",
    "href": "tics411/notebooks/06-ex-DBSCAN.html#función-para-visualizar",
    "title": "DBSCAN",
    "section": "Función para Visualizar",
    "text": "Función para Visualizar\n\nimport matplotlib.pyplot as plt\n\n\n## Función ligeramente modificada para no requerir centroides en caso que no sea aplicable.\ndef pca_viz(pca_X, labels, pca_centroids=None, title=None, cmap=\"viridis\"):\n    plt.scatter(pca_X[:, 0], pca_X[:, 1], c=labels, cmap=cmap)\n    if pca_centroids is not None:\n        plt.scatter(\n            pca_centroids[:, 0],\n            pca_centroids[:, 1],\n            marker=\"*\",\n            c=\"red\",\n            s=150,\n        )\n    plt.title(title)\n\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.cluster import DBSCAN\n\nsc = StandardScaler()\ndbs = DBSCAN(min_samples=13, eps=0.6)\nX_sc = sc.fit_transform(X)\nlabels = dbs.fit_predict(X_sc)\n\n\nfrom sklearn.decomposition import PCA\n\n## Probar minPts = 4 y eps = 0.2\n## Probar minPts = 10 y eps = 0.5\n## Probar minPts = 13 y eps = 0.6\npca = PCA(n_components=2)\npca_X = pca.fit_transform(X_sc)\n\npca_viz(\n    pca_X,\n    labels=labels,\n    title=\"Visualización de DBSCAN para Iris en 2D\",\n)\n\n\n\n\n\n\n\n\n\nfrom sklearn.neighbors import NearestNeighbors\n\n\ndef dbscan_elbow_plot(X, k=5):\n    knn = NearestNeighbors(n_neighbors=k)\n    knn.fit(X)\n    distances, _ = knn.kneighbors(X)\n    distances = np.sort(distances[:, -1])\n    n_pts = distances.shape[0]\n\n    plt.plot(range(1, n_pts + 1), distances)\n    plt.xlabel(\n        f\"Puntos ordenados por Distancia al {k} vecino más cercano.\"\n    )\n    plt.ylabel(f\"Distancia al {k} vecino más cercano\")\n    plt.title(f\"Búsqueda de EPS para DBSCAN con k={k}\")\n\n\n# k = 5 escogido ya que tenemos 4 dimensiones.\ndbscan_elbow_plot(X_sc, k=5)"
  },
  {
    "objectID": "tics411/notebooks/06-ex-DBSCAN.html#modelo-entrenado-con-hiperparámetros-óptimos",
    "href": "tics411/notebooks/06-ex-DBSCAN.html#modelo-entrenado-con-hiperparámetros-óptimos",
    "title": "DBSCAN",
    "section": "Modelo entrenado con Hiperparámetros Óptimos",
    "text": "Modelo entrenado con Hiperparámetros Óptimos\n\nMIN_PTS = 20\nEPS = 0.75\nsc = StandardScaler()\ndbs = DBSCAN(min_samples=MIN_PTS, eps=EPS)\nX_sc = sc.fit_transform(X)\nlabels = dbs.fit_predict(X_sc)\npca_viz(\n    pca_X,\n    labels=labels,\n    title=f\"Visualización de DBSCAN para Iris en 2D con los mejores Hiperparámetros: MinPts: {MIN_PTS} y eps = {EPS}\",\n)"
  },
  {
    "objectID": "tics411/notebooks/11-ex-knn.html",
    "href": "tics411/notebooks/11-ex-knn.html",
    "title": "Clases UAI",
    "section": "",
    "text": "import numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn import set_config\n\nset_config(transform_output=\"pandas\")\n\ndf = sns.load_dataset(\"titanic\")\ndf\n\n\n\n\n\n\n\n\nsurvived\npclass\nsex\nage\nsibsp\nparch\nfare\nembarked\nclass\nwho\nadult_male\ndeck\nembark_town\nalive\nalone\n\n\n\n\n0\n0\n3\nmale\n22.0\n1\n0\n7.2500\nS\nThird\nman\nTrue\nNaN\nSouthampton\nno\nFalse\n\n\n1\n1\n1\nfemale\n38.0\n1\n0\n71.2833\nC\nFirst\nwoman\nFalse\nC\nCherbourg\nyes\nFalse\n\n\n2\n1\n3\nfemale\n26.0\n0\n0\n7.9250\nS\nThird\nwoman\nFalse\nNaN\nSouthampton\nyes\nTrue\n\n\n3\n1\n1\nfemale\n35.0\n1\n0\n53.1000\nS\nFirst\nwoman\nFalse\nC\nSouthampton\nyes\nFalse\n\n\n4\n0\n3\nmale\n35.0\n0\n0\n8.0500\nS\nThird\nman\nTrue\nNaN\nSouthampton\nno\nTrue\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n886\n0\n2\nmale\n27.0\n0\n0\n13.0000\nS\nSecond\nman\nTrue\nNaN\nSouthampton\nno\nTrue\n\n\n887\n1\n1\nfemale\n19.0\n0\n0\n30.0000\nS\nFirst\nwoman\nFalse\nB\nSouthampton\nyes\nTrue\n\n\n888\n0\n3\nfemale\nNaN\n1\n2\n23.4500\nS\nThird\nwoman\nFalse\nNaN\nSouthampton\nno\nFalse\n\n\n889\n1\n1\nmale\n26.0\n0\n0\n30.0000\nC\nFirst\nman\nTrue\nC\nCherbourg\nyes\nTrue\n\n\n890\n0\n3\nmale\n32.0\n0\n0\n7.7500\nQ\nThird\nman\nTrue\nNaN\nQueenstown\nno\nTrue\n\n\n\n\n891 rows × 15 columns\ndf.dtypes.value_counts().plot(\n    kind=\"bar\",\n    edgecolor=\"k\",\n    title=\"Tipos de Variable presente en Titanic\",\n)\nplt.tight_layout()"
  },
  {
    "objectID": "tics411/notebooks/11-ex-knn.html#supongamos-que-utilizaremos-las-siguientes-variables",
    "href": "tics411/notebooks/11-ex-knn.html#supongamos-que-utilizaremos-las-siguientes-variables",
    "title": "Clases UAI",
    "section": "Supongamos que utilizaremos las siguientes variables",
    "text": "Supongamos que utilizaremos las siguientes variables\n\nX = df[[\"class\", \"sex\", \"embark_town\", \"fare\", \"age\"]]\ny = df.alive\n\nX.shape, y.shape\n\n((891, 5), (891,))"
  },
  {
    "objectID": "tics411/notebooks/11-ex-knn.html#eda",
    "href": "tics411/notebooks/11-ex-knn.html#eda",
    "title": "Clases UAI",
    "section": "EDA",
    "text": "EDA\n\nnum_cols = X.select_dtypes(np.number).columns.tolist()\ncat_cols = [col for col in X.columns if col not in num_cols]\nprint(f\"Variables Numéricas: {num_cols}\")\nprint(f\"Variables Categóricas: {cat_cols}\")\n\nVariables Numéricas: ['fare', 'age']\nVariables Categóricas: ['class', 'sex', 'embark_town']\n\n\n\nValores Faltantes (Nulos)\n\nX.isnull().mean().plot(\n    kind=\"bar\",\n    edgecolor=\"k\",\n    title=\"Cantidad de Valores Nulos en el Titanic\",\n)\nplt.tight_layout()"
  },
  {
    "objectID": "tics411/notebooks/11-ex-knn.html#variables-numéricas",
    "href": "tics411/notebooks/11-ex-knn.html#variables-numéricas",
    "title": "Clases UAI",
    "section": "Variables Numéricas",
    "text": "Variables Numéricas\n\nX.hist(grid=False, edgecolor=\"k\")\nplt.suptitle(\"Distribución de Variables Numéricas\")\nplt.tight_layout()"
  },
  {
    "objectID": "tics411/notebooks/11-ex-knn.html#variables-categóricas",
    "href": "tics411/notebooks/11-ex-knn.html#variables-categóricas",
    "title": "Clases UAI",
    "section": "Variables Categóricas",
    "text": "Variables Categóricas\n\ncolor = [\"red\", \"blue\", \"green\"]\nfor cat, color in zip(cat_cols, color):\n    df[cat].value_counts().plot(\n        kind=\"bar\",\n        edgecolor=\"k\",\n        color=color,\n        title=f\"Categorías para '{cat}'\",\n    )\n    plt.show()"
  },
  {
    "objectID": "tics411/notebooks/11-ex-knn.html#preprocesamiento",
    "href": "tics411/notebooks/11-ex-knn.html#preprocesamiento",
    "title": "Clases UAI",
    "section": "Preprocesamiento",
    "text": "Preprocesamiento\n\nfrom feature_engine.imputation import CategoricalImputer\n\nci = CategoricalImputer(imputation_method=\"frequent\")\nX_imp = ci.fit_transform(X)\nX_imp\n\n\n\n\n\n\n\n\nclass\nsex\nembark_town\nfare\nage\n\n\n\n\n0\nThird\nmale\nSouthampton\n7.2500\n22.0\n\n\n1\nFirst\nfemale\nCherbourg\n71.2833\n38.0\n\n\n2\nThird\nfemale\nSouthampton\n7.9250\n26.0\n\n\n3\nFirst\nfemale\nSouthampton\n53.1000\n35.0\n\n\n4\nThird\nmale\nSouthampton\n8.0500\n35.0\n\n\n...\n...\n...\n...\n...\n...\n\n\n886\nSecond\nmale\nSouthampton\n13.0000\n27.0\n\n\n887\nFirst\nfemale\nSouthampton\n30.0000\n19.0\n\n\n888\nThird\nfemale\nSouthampton\n23.4500\nNaN\n\n\n889\nFirst\nmale\nCherbourg\n30.0000\n26.0\n\n\n890\nThird\nmale\nQueenstown\n7.7500\n32.0\n\n\n\n\n891 rows × 5 columns\n\n\n\n\nfrom feature_engine.imputation import MeanMedianImputer\n\nmmi = MeanMedianImputer(imputation_method=\"mean\")\nX_imp = mmi.fit_transform(X_imp)\nX_imp\n\n\n\n\n\n\n\n\nclass\nsex\nembark_town\nfare\nage\n\n\n\n\n0\nThird\nmale\nSouthampton\n7.2500\n22.000000\n\n\n1\nFirst\nfemale\nCherbourg\n71.2833\n38.000000\n\n\n2\nThird\nfemale\nSouthampton\n7.9250\n26.000000\n\n\n3\nFirst\nfemale\nSouthampton\n53.1000\n35.000000\n\n\n4\nThird\nmale\nSouthampton\n8.0500\n35.000000\n\n\n...\n...\n...\n...\n...\n...\n\n\n886\nSecond\nmale\nSouthampton\n13.0000\n27.000000\n\n\n887\nFirst\nfemale\nSouthampton\n30.0000\n19.000000\n\n\n888\nThird\nfemale\nSouthampton\n23.4500\n29.699118\n\n\n889\nFirst\nmale\nCherbourg\n30.0000\n26.000000\n\n\n890\nThird\nmale\nQueenstown\n7.7500\n32.000000\n\n\n\n\n891 rows × 5 columns\n\n\n\n\nfrom feature_engine.encoding import OneHotEncoder\n\nohe = OneHotEncoder()\nX_ohe = ohe.fit_transform(X_imp)\nX_ohe\n\n\n\n\n\n\n\n\nfare\nage\nclass_Third\nclass_First\nclass_Second\nsex_male\nsex_female\nembark_town_Southampton\nembark_town_Cherbourg\nembark_town_Queenstown\n\n\n\n\n0\n7.2500\n22.000000\n1\n0\n0\n1\n0\n1\n0\n0\n\n\n1\n71.2833\n38.000000\n0\n1\n0\n0\n1\n0\n1\n0\n\n\n2\n7.9250\n26.000000\n1\n0\n0\n0\n1\n1\n0\n0\n\n\n3\n53.1000\n35.000000\n0\n1\n0\n0\n1\n1\n0\n0\n\n\n4\n8.0500\n35.000000\n1\n0\n0\n1\n0\n1\n0\n0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n886\n13.0000\n27.000000\n0\n0\n1\n1\n0\n1\n0\n0\n\n\n887\n30.0000\n19.000000\n0\n1\n0\n0\n1\n1\n0\n0\n\n\n888\n23.4500\n29.699118\n1\n0\n0\n0\n1\n1\n0\n0\n\n\n889\n30.0000\n26.000000\n0\n1\n0\n1\n0\n0\n1\n0\n\n\n890\n7.7500\n32.000000\n1\n0\n0\n1\n0\n0\n0\n1\n\n\n\n\n891 rows × 10 columns\n\n\n\n\nfrom sklearn.preprocessing import StandardScaler\n\nsc_all = StandardScaler()\nX_sc_all = sc_all.fit_transform(X_ohe)\nX_sc_all\n\n\n\n\n\n\n\n\nfare\nage\nclass_Third\nclass_First\nclass_Second\nsex_male\nsex_female\nembark_town_Southampton\nembark_town_Cherbourg\nembark_town_Queenstown\n\n\n\n\n0\n-0.502445\n-0.592481\n0.902587\n-0.565685\n-0.510152\n0.737695\n-0.737695\n0.615838\n-0.482043\n-0.307562\n\n\n1\n0.786845\n0.638789\n-1.107926\n1.767767\n-0.510152\n-1.355574\n1.355574\n-1.623803\n2.074505\n-0.307562\n\n\n2\n-0.488854\n-0.284663\n0.902587\n-0.565685\n-0.510152\n-1.355574\n1.355574\n0.615838\n-0.482043\n-0.307562\n\n\n3\n0.420730\n0.407926\n-1.107926\n1.767767\n-0.510152\n-1.355574\n1.355574\n0.615838\n-0.482043\n-0.307562\n\n\n4\n-0.486337\n0.407926\n0.902587\n-0.565685\n-0.510152\n0.737695\n-0.737695\n0.615838\n-0.482043\n-0.307562\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n886\n-0.386671\n-0.207709\n-1.107926\n-0.565685\n1.960202\n0.737695\n-0.737695\n0.615838\n-0.482043\n-0.307562\n\n\n887\n-0.044381\n-0.823344\n-1.107926\n1.767767\n-0.510152\n-1.355574\n1.355574\n0.615838\n-0.482043\n-0.307562\n\n\n888\n-0.176263\n0.000000\n0.902587\n-0.565685\n-0.510152\n-1.355574\n1.355574\n0.615838\n-0.482043\n-0.307562\n\n\n889\n-0.044381\n-0.284663\n-1.107926\n1.767767\n-0.510152\n0.737695\n-0.737695\n-1.623803\n2.074505\n-0.307562\n\n\n890\n-0.492378\n0.177063\n0.902587\n-0.565685\n-0.510152\n0.737695\n-0.737695\n-1.623803\n-0.482043\n3.251373\n\n\n\n\n891 rows × 10 columns\n\n\n\n\nfrom feature_engine.wrappers import SklearnTransformerWrapper\n\nsc = SklearnTransformerWrapper(StandardScaler(), variables=[\"fare\", \"age\"])\nX_sc = sc.fit_transform(X_ohe)\nX_sc\n\n\n\n\n\n\n\n\nfare\nage\nclass_Third\nclass_First\nclass_Second\nsex_male\nsex_female\nembark_town_Southampton\nembark_town_Cherbourg\nembark_town_Queenstown\n\n\n\n\n0\n-0.502445\n-0.592481\n1\n0\n0\n1\n0\n1\n0\n0\n\n\n1\n0.786845\n0.638789\n0\n1\n0\n0\n1\n0\n1\n0\n\n\n2\n-0.488854\n-0.284663\n1\n0\n0\n0\n1\n1\n0\n0\n\n\n3\n0.420730\n0.407926\n0\n1\n0\n0\n1\n1\n0\n0\n\n\n4\n-0.486337\n0.407926\n1\n0\n0\n1\n0\n1\n0\n0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n886\n-0.386671\n-0.207709\n0\n0\n1\n1\n0\n1\n0\n0\n\n\n887\n-0.044381\n-0.823344\n0\n1\n0\n0\n1\n1\n0\n0\n\n\n888\n-0.176263\n0.000000\n1\n0\n0\n0\n1\n1\n0\n0\n\n\n889\n-0.044381\n-0.284663\n0\n1\n0\n1\n0\n0\n1\n0\n\n\n890\n-0.492378\n0.177063\n1\n0\n0\n1\n0\n0\n0\n1\n\n\n\n\n891 rows × 10 columns"
  },
  {
    "objectID": "tics411/notebooks/11-ex-knn.html#entrenamiento-del-modelo",
    "href": "tics411/notebooks/11-ex-knn.html#entrenamiento-del-modelo",
    "title": "Clases UAI",
    "section": "Entrenamiento del Modelo",
    "text": "Entrenamiento del Modelo\n\nfrom sklearn.neighbors import KNeighborsClassifier\n\n\ndef knn_clf(X, y, k=5, prep=\"\"):\n    knn = KNeighborsClassifier(\n        n_neighbors=k, metric=\"euclidean\", n_jobs=-1\n    )\n    ## Notar que es posible utilizar Variables categóricas como Etiquetas...\n    knn.fit(X, y)\n    y_pred = knn.predict(X)\n    print(\n        f\"Score k = {k}, y Preprocesamiento: {prep}: {knn.score(X,y):.4f}\"\n    )\n    return y_pred\n\n\nfor k in [3, 5, 7, 9, 11, 13, 15]:\n    print(\n        \"=================================================================\"\n    )\n    y_pred_sc = knn_clf(X_sc, y, k=k, prep=\"StandardScaler Numérico\")\n    y_pred_sc_all = knn_clf(X_sc_all, y, k=k, prep=\"StandardScaler a todo\")\n    y_pred_ohe = knn_clf(X_ohe, y, k=k, prep=\"Sin Escalar\")\n\n=================================================================\nScore k = 3, y Preprocesamiento: StandardScaler Numérico: 0.8844\nScore k = 3, y Preprocesamiento: StandardScaler a todo: 0.8855\nScore k = 3, y Preprocesamiento: Sin Escalar: 0.8384\n=================================================================\nScore k = 5, y Preprocesamiento: StandardScaler Numérico: 0.8698\nScore k = 5, y Preprocesamiento: StandardScaler a todo: 0.8698\nScore k = 5, y Preprocesamiento: Sin Escalar: 0.8204\n=================================================================\nScore k = 7, y Preprocesamiento: StandardScaler Numérico: 0.8608\nScore k = 7, y Preprocesamiento: StandardScaler a todo: 0.8575\nScore k = 7, y Preprocesamiento: Sin Escalar: 0.7834\n=================================================================\nScore k = 9, y Preprocesamiento: StandardScaler Numérico: 0.8418\nScore k = 9, y Preprocesamiento: StandardScaler a todo: 0.8406\nScore k = 9, y Preprocesamiento: Sin Escalar: 0.7733\n=================================================================\nScore k = 11, y Preprocesamiento: StandardScaler Numérico: 0.8373\nScore k = 11, y Preprocesamiento: StandardScaler a todo: 0.8361\nScore k = 11, y Preprocesamiento: Sin Escalar: 0.7643\n=================================================================\nScore k = 13, y Preprocesamiento: StandardScaler Numérico: 0.8272\nScore k = 13, y Preprocesamiento: StandardScaler a todo: 0.8283\nScore k = 13, y Preprocesamiento: Sin Escalar: 0.7587\n=================================================================\nScore k = 15, y Preprocesamiento: StandardScaler Numérico: 0.8215\nScore k = 15, y Preprocesamiento: StandardScaler a todo: 0.8249\nScore k = 15, y Preprocesamiento: Sin Escalar: 0.7486\n\n\n\nConclusión: Los Preprocesamientos afectan de manera importante el entrenamiento de un modelo."
  },
  {
    "objectID": "tics411/notebooks/11-ex-knn.html#uso-de-pipelines",
    "href": "tics411/notebooks/11-ex-knn.html#uso-de-pipelines",
    "title": "Clases UAI",
    "section": "Uso de Pipelines",
    "text": "Uso de Pipelines\n\nfrom sklearn.pipeline import Pipeline\n\n\ndef model_pipeline(num_method, cat_method, sc_variables, k=5):\n\n    sc = SklearnTransformerWrapper(\n        StandardScaler(), variables=sc_variables\n    )\n\n    pipe = Pipeline(\n        steps=[\n            (\"num_imp\", MeanMedianImputer(imputation_method=num_method)),\n            (\"cat_imp\", CategoricalImputer(imputation_method=cat_method)),\n            (\"ohe\", OneHotEncoder()),\n            # (\"sc\", StandardScaler()),\n            (\"sc\", sc),\n            (\"model\", KNeighborsClassifier(n_neighbors=k, n_jobs=-1)),\n        ]\n    )\n\n    return pipe\n\n\npipe = model_pipeline(\n    num_method=\"mean\", cat_method=\"frequent\", sc_variables=[\"age\", \"fare\"]\n)\npipe\n\nPipeline(steps=[('num_imp', MeanMedianImputer(imputation_method='mean')),\n                ('cat_imp', CategoricalImputer(imputation_method='frequent')),\n                ('ohe', OneHotEncoder()), ('sc', StandardScaler()),\n                ('model', KNeighborsClassifier(n_jobs=-1))])In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.  Pipeline?Documentation for PipelineiNot fittedPipeline(steps=[('num_imp', MeanMedianImputer(imputation_method='mean')),\n                ('cat_imp', CategoricalImputer(imputation_method='frequent')),\n                ('ohe', OneHotEncoder()), ('sc', StandardScaler()),\n                ('model', KNeighborsClassifier(n_jobs=-1))]) MeanMedianImputerMeanMedianImputer(imputation_method='mean') CategoricalImputerCategoricalImputer(imputation_method='frequent') OneHotEncoderOneHotEncoder()  StandardScaler?Documentation for StandardScalerStandardScaler()  KNeighborsClassifier?Documentation for KNeighborsClassifierKNeighborsClassifier(n_jobs=-1) \n\n\n\npipe.fit(X, y)\ny_pred = pipe.predict(X)\npipe.score(X, y)\n\n0.8698092031425365\n\n\n\ny_pred\n\narray(['no', 'yes', 'yes', 'yes', 'no', 'no', 'no', 'yes', 'yes', 'yes',\n       'yes', 'yes', 'no', 'no', 'yes', 'yes', 'no', 'no', 'yes', 'no',\n       'no', 'no', 'yes', 'yes', 'no', 'yes', 'no', 'no', 'yes', 'no',\n       'no', 'yes', 'yes', 'no', 'yes', 'no', 'no', 'no', 'no', 'yes',\n       'no', 'yes', 'no', 'yes', 'yes', 'no', 'no', 'yes', 'no', 'no',\n       'no', 'no', 'yes', 'yes', 'no', 'yes', 'yes', 'no', 'yes', 'no',\n       'no', 'yes', 'no', 'no', 'no', 'no', 'yes', 'no', 'yes', 'no',\n       'no', 'no', 'no', 'no', 'yes', 'no', 'no', 'no', 'yes', 'yes',\n       'no', 'no', 'yes', 'no', 'yes', 'yes', 'no', 'no', 'yes', 'no',\n       'no', 'no', 'no', 'no', 'no', 'no', 'no', 'yes', 'yes', 'no',\n       'yes', 'no', 'no', 'no', 'no', 'no', 'yes', 'no', 'no', 'yes',\n       'no', 'yes', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no',\n       'no', 'no', 'yes', 'no', 'no', 'no', 'no', 'yes', 'no', 'no', 'no',\n       'no', 'yes', 'no', 'no', 'yes', 'no', 'no', 'yes', 'no', 'yes',\n       'no', 'no', 'no', 'no', 'yes', 'no', 'no', 'no', 'no', 'yes', 'no',\n       'no', 'no', 'yes', 'yes', 'no', 'no', 'no', 'no', 'yes', 'no',\n       'no', 'no', 'yes', 'yes', 'no', 'no', 'yes', 'no', 'no', 'yes',\n       'no', 'no', 'no', 'no', 'yes', 'no', 'no', 'no', 'no', 'no', 'yes',\n       'yes', 'no', 'yes', 'no', 'no', 'no', 'yes', 'no', 'yes', 'yes',\n       'yes', 'yes', 'no', 'no', 'yes', 'yes', 'no', 'no', 'no', 'no',\n       'no', 'yes', 'no', 'no', 'yes', 'no', 'no', 'yes', 'no', 'no',\n       'no', 'yes', 'yes', 'no', 'yes', 'no', 'no', 'no', 'no', 'no',\n       'no', 'no', 'no', 'no', 'no', 'no', 'yes', 'no', 'no', 'no', 'no',\n       'no', 'no', 'yes', 'no', 'no', 'no', 'yes', 'no', 'no', 'no', 'no',\n       'no', 'yes', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'yes',\n       'yes', 'yes', 'yes', 'no', 'no', 'no', 'no', 'yes', 'no', 'no',\n       'no', 'yes', 'yes', 'no', 'no', 'yes', 'no', 'yes', 'yes', 'no',\n       'no', 'no', 'yes', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no',\n       'no', 'yes', 'yes', 'yes', 'no', 'no', 'no', 'no', 'no', 'yes',\n       'yes', 'yes', 'yes', 'no', 'no', 'yes', 'no', 'yes', 'yes', 'yes',\n       'no', 'yes', 'yes', 'yes', 'yes', 'no', 'no', 'yes', 'yes', 'no',\n       'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'no', 'yes',\n       'no', 'yes', 'yes', 'no', 'yes', 'no', 'yes', 'no', 'no', 'yes',\n       'no', 'no', 'yes', 'yes', 'no', 'no', 'no', 'yes', 'yes', 'yes',\n       'yes', 'no', 'no', 'yes', 'no', 'no', 'no', 'no', 'yes', 'yes',\n       'yes', 'yes', 'no', 'no', 'no', 'no', 'no', 'no', 'yes', 'no',\n       'yes', 'yes', 'yes', 'no', 'no', 'no', 'yes', 'yes', 'yes', 'no',\n       'yes', 'no', 'yes', 'yes', 'no', 'yes', 'no', 'no', 'no', 'yes',\n       'no', 'yes', 'no', 'no', 'no', 'yes', 'no', 'no', 'no', 'no', 'no',\n       'yes', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'yes', 'no', 'no',\n       'no', 'no', 'yes', 'no', 'no', 'no', 'yes', 'yes', 'no', 'no',\n       'no', 'no', 'no', 'no', 'no', 'no', 'yes', 'yes', 'no', 'no',\n       'yes', 'yes', 'yes', 'no', 'no', 'yes', 'no', 'yes', 'no', 'no',\n       'yes', 'no', 'no', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes',\n       'no', 'no', 'no', 'no', 'no', 'no', 'no', 'yes', 'yes', 'no', 'no',\n       'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'yes', 'no', 'no',\n       'yes', 'yes', 'yes', 'no', 'no', 'no', 'no', 'yes', 'no', 'no',\n       'no', 'no', 'yes', 'no', 'yes', 'no', 'no', 'yes', 'no', 'no',\n       'no', 'no', 'no', 'no', 'yes', 'no', 'yes', 'no', 'no', 'yes',\n       'yes', 'yes', 'yes', 'no', 'yes', 'no', 'no', 'yes', 'no', 'no',\n       'yes', 'yes', 'no', 'no', 'yes', 'no', 'yes', 'no', 'yes', 'no',\n       'no', 'yes', 'no', 'no', 'yes', 'no', 'no', 'no', 'yes', 'no',\n       'no', 'yes', 'no', 'yes', 'no', 'yes', 'no', 'yes', 'yes', 'no',\n       'no', 'no', 'no', 'no', 'yes', 'no', 'no', 'yes', 'no', 'no', 'no',\n       'no', 'yes', 'no', 'yes', 'no', 'yes', 'yes', 'no', 'no', 'no',\n       'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'yes', 'yes',\n       'yes', 'no', 'no', 'yes', 'yes', 'no', 'no', 'yes', 'yes', 'no',\n       'yes', 'no', 'yes', 'no', 'no', 'no', 'no', 'no', 'yes', 'no',\n       'yes', 'no', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'no', 'no',\n       'no', 'no', 'no', 'no', 'yes', 'yes', 'yes', 'no', 'no', 'yes',\n       'no', 'no', 'yes', 'no', 'yes', 'yes', 'no', 'no', 'no', 'yes',\n       'no', 'no', 'no', 'no', 'yes', 'no', 'no', 'no', 'no', 'no', 'no',\n       'no', 'yes', 'no', 'no', 'no', 'no', 'no', 'yes', 'no', 'yes',\n       'yes', 'yes', 'no', 'no', 'no', 'yes', 'no', 'yes', 'no', 'yes',\n       'yes', 'no', 'no', 'yes', 'no', 'no', 'no', 'no', 'no', 'no', 'no',\n       'no', 'no', 'no', 'no', 'yes', 'yes', 'no', 'no', 'no', 'no', 'no',\n       'no', 'yes', 'no', 'yes', 'yes', 'yes', 'no', 'no', 'no', 'no',\n       'no', 'no', 'no', 'yes', 'no', 'yes', 'yes', 'no', 'no', 'no',\n       'no', 'yes', 'no', 'no', 'yes', 'yes', 'no', 'no', 'no', 'no',\n       'yes', 'no', 'yes', 'no', 'yes', 'no', 'no', 'no', 'no', 'no',\n       'yes', 'yes', 'no', 'no', 'yes', 'no', 'no', 'no', 'no', 'no',\n       'yes', 'yes', 'no', 'no', 'yes', 'no', 'no', 'no', 'no', 'no',\n       'no', 'yes', 'no', 'no', 'yes', 'yes', 'yes', 'no', 'no', 'no',\n       'no', 'yes', 'no', 'no', 'yes', 'yes', 'no', 'no', 'yes', 'yes',\n       'no', 'no', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'no', 'yes',\n       'no', 'yes', 'no', 'no', 'no', 'no', 'yes', 'no', 'yes', 'no',\n       'no', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'no', 'no', 'no',\n       'yes', 'no', 'yes', 'yes', 'no', 'no', 'no', 'no', 'no', 'no',\n       'yes', 'no', 'no', 'no', 'no', 'yes', 'yes', 'no', 'yes', 'no',\n       'no', 'yes', 'no', 'yes', 'no', 'no', 'no', 'no', 'no', 'no',\n       'yes', 'no', 'no', 'no', 'yes', 'yes', 'no', 'yes', 'no', 'no',\n       'yes', 'no', 'no', 'yes', 'yes', 'yes', 'no', 'no', 'no', 'yes',\n       'no', 'no', 'yes', 'no', 'no', 'no', 'yes', 'no', 'no', 'no', 'no',\n       'no', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'yes', 'yes', 'yes',\n       'yes', 'yes', 'no', 'no', 'no', 'yes', 'no', 'no', 'yes', 'yes',\n       'no', 'no', 'yes', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'no',\n       'no', 'no', 'yes', 'yes', 'no', 'yes', 'no', 'no', 'yes', 'no',\n       'yes', 'no', 'no', 'no'], dtype=object)"
  },
  {
    "objectID": "tics411/notebooks/03-ex_kmeans.html",
    "href": "tics411/notebooks/03-ex_kmeans.html",
    "title": "Ejemplo K-Means",
    "section": "",
    "text": "import seaborn as sns\n\n# Importamos el Dataset Iris\ndf = sns.load_dataset(\"iris\")\ndf\ndf[\"species\"].value_counts()\n# Definimos X como una Matriz sin la variable Species.\nX = df.drop(columns=\"species\")\nX"
  },
  {
    "objectID": "tics411/notebooks/03-ex_kmeans.html#ayuda-visual",
    "href": "tics411/notebooks/03-ex_kmeans.html#ayuda-visual",
    "title": "Ejemplo K-Means",
    "section": "Ayuda Visual",
    "text": "Ayuda Visual\nVamos a utilizar PCA para poder reducir las dimensiones a un tamaño el cual podamos visualizar: 2D.\n\nfrom sklearn.decomposition import PCA\nimport pandas as pd\n\n## Esto es sólo una ayuda para poder visualizar datos\n# que están en más dimensiones de las que podemos ver.\npca = PCA(n_components=2, random_state=1)\npca_X = pca.fit_transform(X)\n\n\nimport matplotlib.pyplot as plt\n\nplt.scatter(pca_X[:, 0], pca_X[:, 1])\nplt.title(\"Visualización de Iris en 2D.\")\nplt.tight_layout()\n\n\n## Esta es una función que nos permitirá visualizar nuestras etiquetas en un espacio reducido por PCA.\n## Además permite la visualización de los centroides de nuestro proceso...\n\n\ndef pca_viz(pca_X, pca_centroids, labels, title=None, cmap=\"viridis\"):\n    plt.scatter(pca_X[:, 0], pca_X[:, 1], c=labels, cmap=cmap)\n    plt.scatter(\n        pca_centroids[:, 0],\n        pca_centroids[:, 1],\n        marker=\"*\",\n        c=\"red\",\n        s=150,\n    )\n    plt.title(title)\n\n\nImplementación de K-Means\n\nfrom sklearn.cluster import KMeans\n\nkm = KMeans(n_clusters=2, n_init=10, random_state=1)\nlabels = km.fit_predict(X)\ncentroids = km.cluster_centers_\npca_centroids = pca.transform(centroids)\n\n\npca_viz(\n    pca_X,\n    pca_centroids,\n    labels=labels,\n    title=\"Visualización de K-Means en Iris 2D\",\n)\n\n\n\nEfecto del Escalamiento en K-Means\n\nfrom sklearn.preprocessing import StandardScaler\n\nsc = StandardScaler()\nX_sc = sc.fit_transform(X)\npca = PCA(n_components=2, random_state=1)\npca_X_sc = pca.fit_transform(X_sc)\nkm = KMeans(n_clusters=2, n_init=10, random_state=1)\nsc_labels = km.fit_predict(X_sc)\ncentroids = km.cluster_centers_\npca_centroids = pca.transform(centroids)\npca_viz(\n    pca_X_sc,\n    pca_centroids,\n    sc_labels,\n    title=\"K-Means de Iris en 2D luego de Estandarizar los datos. \",\n)\n\n\nfrom sklearn.preprocessing import MinMaxScaler\n\nmm = MinMaxScaler()\nX_mm = mm.fit_transform(X)\npca = PCA(n_components=2, random_state=1)\npca_X_mm = pca.fit_transform(X_mm)\nkm = KMeans(n_clusters=3, n_init=10, random_state=1)\nmm_labels = km.fit_predict(X_mm)\ncentroids = km.cluster_centers_\npca_centroids = pca.transform(centroids)\n\npca_viz(\n    pca_X_mm,\n    pca_centroids,\n    mm_labels,\n    title=\"K-Means de Iris en 2D luego de Normalizar los datos.\",\n)"
  },
  {
    "objectID": "tics411/notebooks/03-ex_kmeans.html#ejemplo-más-avanzado-sin-entrenar-con-todos-los-datos",
    "href": "tics411/notebooks/03-ex_kmeans.html#ejemplo-más-avanzado-sin-entrenar-con-todos-los-datos",
    "title": "Ejemplo K-Means",
    "section": "Ejemplo más avanzado sin entrenar con todos los datos…",
    "text": "Ejemplo más avanzado sin entrenar con todos los datos…\n\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test = train_test_split(X, test_size=0.25, random_state=1)\n\n\nEstamos dejando un 25% de los datos fuera para poder chequear cuál sería la predicción que se le dan a dichos datos.\n\n\npca = PCA(n_components=2)\nkm = KMeans(n_clusters=2, n_init=10)\nsc = StandardScaler()\n## Fit siempre se hace con datos de `Entrenamiento`.\n\n## Escalamos los datos...\nsc.fit(X_train)\nX_train_sc = sc.transform(X_train)\nX_test_sc = sc.transform(X_test)\n\n# Generamos las coordenadas del PCA para visualizar\npca.fit(X_train_sc)\npca_train = pca.transform(X_train_sc)\npca_test = pca.transform(X_test_sc)\n\ntrain_labels = km.fit_predict(X_train_sc)\ntest_labels = km.predict(X_test_sc)\ncentroids = km.cluster_centers_\npca_centroids = pca.transform(centroids)\n\npca_viz(pca_train, pca_centroids, train_labels)\npca_viz(pca_test, pca_centroids, test_labels, cmap=\"tab20b\")"
  },
  {
    "objectID": "tics411/notebooks/03-ex_kmeans.html#cuál-es-el-k-óptimo",
    "href": "tics411/notebooks/03-ex_kmeans.html#cuál-es-el-k-óptimo",
    "title": "Ejemplo K-Means",
    "section": "Cuál es el K óptimo?",
    "text": "Cuál es el K óptimo?\n\ndef elbow_curve(X, k_max=10, color=\"blue\", title=None):\n    wc = []\n    for k in range(1, k_max + 1):\n        km = KMeans(n_clusters=k, random_state=1)\n        km.fit(X)\n        wc.append(km.inertia_)\n\n    k = [*range(1, k_max + 1)]\n    plt.plot(k, wc, c=color, marker=\"*\")\n    plt.title(title)\n    plt.xlabel(\"Número de Clústers\")\n    plt.ylabel(\"Within Distance\")\n    return wc\n\n\nwc = elbow_curve(\n    X_train,\n    k_max=15,\n    color=\"red\",\n    title=\"Curva del Codo para el Dataset Iris, sólo con Train Set.\",\n)\n\n\nwc"
  },
  {
    "objectID": "tics411/notebooks/preguntas-prueba-2.html",
    "href": "tics411/notebooks/preguntas-prueba-2.html",
    "title": "Clases UAI",
    "section": "",
    "text": "import pandas as pd\nfrom sklearn.metrics import classification_report, ConfusionMatrixDisplay\n\ndf = pd.DataFrame(\n    dict(\n        y=[0, 0, 1, 1, 1, 0, 1, 1, 0, 0],\n        y_pred=[1, 1, 0, 0, 0, 1, 1, 1, 0, 0],\n    )\n)\nprint(classification_report(df.y, df.y_pred, digits=2))\nConfusionMatrixDisplay.from_predictions(df.y, df.y_pred)\n\n              precision    recall  f1-score   support\n\n           0       0.40      0.40      0.40         5\n           1       0.40      0.40      0.40         5\n\n    accuracy                           0.40        10\n   macro avg       0.40      0.40      0.40        10\nweighted avg       0.40      0.40      0.40        10\n\n\n\n\n\n\n\n\n\n\n\ndf = pd.DataFrame(\n    dict(\n        X1=[\n            \"Mucho\",\n            \"Poco\",\n            \"Mucho\",\n            \"Mucho\",\n            \"Mucho\",\n            \"Mucho\",\n            \"Mucho\",\n            \"Poco\",\n            \"Mucho\",\n            \"Mucho\",\n        ],\n        X2=[\n            \"Alto\",\n            \"Bajo\",\n            \"Alto\",\n            \"Medio\",\n            \"Medio\",\n            \"Bajo\",\n            \"Bajo\",\n            \"Medio\",\n            \"Alto\",\n            \"Alto\",\n        ],\n        c=[1, 1, 0, 1, 1, 1, 1, 0, 0, 1],\n    )\n)\ndf\n\n\n\n\n\n\n\n\nX1\nX2\nc\n\n\n\n\n0\nMucho\nAlto\n1\n\n\n1\nPoco\nBajo\n1\n\n\n2\nMucho\nAlto\n0\n\n\n3\nMucho\nMedio\n1\n\n\n4\nMucho\nMedio\n1\n\n\n5\nMucho\nBajo\n1\n\n\n6\nMucho\nBajo\n1\n\n\n7\nPoco\nMedio\n0\n\n\n8\nMucho\nAlto\n0\n\n\n9\nMucho\nAlto\n1\n\n\n\n\n\n\n\n\nX_train = df.drop(index=[4, 5])\nX_test = df.loc[[4, 5]]\nX_train\n\n\n\n\n\n\n\n\nX1\nX2\nc\n\n\n\n\n0\nMucho\nAlto\n1\n\n\n1\nPoco\nBajo\n1\n\n\n2\nMucho\nAlto\n0\n\n\n3\nMucho\nMedio\n1\n\n\n6\nMucho\nBajo\n1\n\n\n7\nPoco\nMedio\n0\n\n\n8\nMucho\nAlto\n0\n\n\n9\nMucho\nAlto\n1\n\n\n\n\n\n\n\n\nX_test\n\n\n\n\n\n\n\n\nX1\nX2\nc\n\n\n\n\n4\nMucho\nMedio\n1\n\n\n5\nMucho\nBajo\n1\n\n\n\n\n\n\n\n\ndf = pd.DataFrame(\n    dict(X=[7, 5, 3, 5, 2], Y=[4, 7, 5, 7, 3], Clase=[1, 1, 1, -1, -1])\n)\nprint(df.to_latex())\n\n\\begin{tabular}{lrrr}\n\\toprule\n & X & Y & Clase \\\\\n\\midrule\n0 & 7 & 4 & 1 \\\\\n1 & 5 & 7 & 1 \\\\\n2 & 3 & 5 & 1 \\\\\n3 & 5 & 7 & -1 \\\\\n4 & 2 & 3 & -1 \\\\\n\\bottomrule\n\\end{tabular}\n\n\n\n\ndf = pd.DataFrame(\n    {\n        \"Humedad\": [\n            85,\n            90,\n            86,\n            96,\n            80,\n            65,\n            70,\n            70,\n            95,\n            80,\n            91,\n            70,\n            90,\n            75,\n        ],\n        \"Se juega?\": [\n            \"No\",\n            \"No\",\n            \"Sí\",\n            \"Sí\",\n            \"Sí\",\n            \"Sí\",\n            \"Sí\",\n            \"No\",\n            \"No\",\n            \"Sí\",\n            \"No\",\n            \"Sí\",\n            \"Sí\",\n            \"Sí\",\n        ],\n    }\n)\ndf.index = [*range(1, 15)]\nprint(df.to_latex())\n\n\\begin{tabular}{lrl}\n\\toprule\n & Humedad & Se juega? \\\\\n\\midrule\n1 & 85 & No \\\\\n2 & 90 & No \\\\\n3 & 86 & Sí \\\\\n4 & 96 & Sí \\\\\n5 & 80 & Sí \\\\\n6 & 65 & Sí \\\\\n7 & 70 & Sí \\\\\n8 & 70 & No \\\\\n9 & 95 & No \\\\\n10 & 80 & Sí \\\\\n11 & 91 & No \\\\\n12 & 70 & Sí \\\\\n13 & 90 & Sí \\\\\n14 & 75 & Sí \\\\\n\\bottomrule\n\\end{tabular}\n\n\n\n\nimport pandas as pd\nfrom sklearn.metrics import ConfusionMatrixDisplay, classification_report\n\ndf = pd.DataFrame(\n    dict(\n        y=[1, 1, 0, 2, 1, 0, 1, 2, 0, 1, 2],\n        y_pred=[1, 0, 2, 2, 1, 0, 1, 1, 2, 1, 2],\n    )\n)\n\nprint(classification_report(df.y, df.y_pred, digits=3))\nConfusionMatrixDisplay.from_predictions(df.y, df.y_pred)\n\n              precision    recall  f1-score   support\n\n           0      0.500     0.333     0.400         3\n           1      0.800     0.800     0.800         5\n           2      0.500     0.667     0.571         3\n\n    accuracy                          0.636        11\n   macro avg      0.600     0.600     0.590        11\nweighted avg      0.636     0.636     0.629        11\n\n\n\n\n\n\n\n\n\n\n\nConfusionMatrixDisplay.from_predictions(df.y, df.y_pred)\n\n\n\n\n\n\n\n\n\ndf = pd.DataFrame(\n    dict(\n        X1=[\n            \"Mucho\",\n            \"Poco\",\n            \"Mucho\",\n            \"Mucho\",\n            \"Mucho\",\n            \"Mucho\",\n            \"Mucho\",\n            \"Poco\",\n            \"Mucho\",\n            \"Mucho\",\n        ],\n        X2=[\n            \"Alto\",\n            \"Bajo\",\n            \"Alto\",\n            \"Medio\",\n            \"Medio\",\n            \"Bajo\",\n            \"Bajo\",\n            \"Medio\",\n            \"Alto\",\n            \"Alto\",\n        ],\n        c=[1, 1, 0, 1, 1, 1, 1, 0, 0, 1],\n    )\n)\nX_train = df.drop(index=[4, 5])\nX_test = df.loc[[4, 5]]\nX_train\n\n\n\n\n\n\n\n\nX1\nX2\nc\n\n\n\n\n0\nMucho\nAlto\n1\n\n\n1\nPoco\nBajo\n1\n\n\n2\nMucho\nAlto\n0\n\n\n3\nMucho\nMedio\n1\n\n\n6\nMucho\nBajo\n1\n\n\n7\nPoco\nMedio\n0\n\n\n8\nMucho\nAlto\n0\n\n\n9\nMucho\nAlto\n1\n\n\n\n\n\n\n\n\nimport matplotlib.pyplot as plt\nfrom sklearn.tree import DecisionTreeClassifier, plot_tree\nfrom sklearn.preprocessing import OrdinalEncoder\nfrom sklearn import set_config\n\nset_config(transform_output=\"pandas\")\n\ndf = pd.DataFrame(\n    dict(\n        X1=[\n            \"Mucho\",\n            \"Poco\",\n            \"Mucho\",\n            \"Mucho\",\n            \"Mucho\",\n            \"Mucho\",\n            \"Mucho\",\n            \"Poco\",\n            \"Mucho\",\n            \"Mucho\",\n        ],\n        X2=[\n            \"Alto\",\n            \"Bajo\",\n            \"Alto\",\n            \"Medio\",\n            \"Medio\",\n            \"Bajo\",\n            \"Bajo\",\n            \"Medio\",\n            \"Alto\",\n            \"Alto\",\n        ],\n        c=[1, 1, 0, 1, 1, 1, 1, 0, 0, 1],\n    )\n)\nX_train = df.drop(index=[4, 5])\nX_test = df.loc[[4, 5]]\n\ny_train = X_train.c\nX_train = X_train.drop(columns=\"c\")\n\noe = OrdinalEncoder()\nX_train_oe = oe.fit_transform(X_train)\nprint(oe.categories_)\ndt = DecisionTreeClassifier()\ndt.fit(X_train_oe, y_train)\n\nplt.figure(figsize=(20, 6))\nplot_tree(dt, filled=True, feature_names=X_train.columns)\nplt.tight_layout()\n\n[array(['Mucho', 'Poco'], dtype=object), array(['Alto', 'Bajo', 'Medio'], dtype=object)]\n\n\n\n\n\n\n\n\n\n\nfrom scipy.spatial import distance_matrix\n\ndf = pd.DataFrame(\n    dict(\n        Brillo=[40, 50, 60, 10, 70, 60, 25],\n        Saturacion=[20, 50, 90, 25, 70, 10, 80],\n    )\n)\n\ndisplay(df)\ndf = pd.DataFrame(distance_matrix(df, df, p=2))\ndf.index = [*range(1, 8)]\ndf.columns = [*range(1, 8)]\ndf\n\n\n\n\n\n\n\n\nBrillo\nSaturacion\n\n\n\n\n0\n40\n20\n\n\n1\n50\n50\n\n\n2\n60\n90\n\n\n3\n10\n25\n\n\n4\n70\n70\n\n\n5\n60\n10\n\n\n6\n25\n80\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n\n\n1\n0.000000\n31.622777\n72.801099\n30.413813\n58.309519\n22.360680\n61.846584\n\n\n2\n31.622777\n0.000000\n41.231056\n47.169906\n28.284271\n41.231056\n39.051248\n\n\n3\n72.801099\n41.231056\n0.000000\n82.006097\n22.360680\n80.000000\n36.400549\n\n\n4\n30.413813\n47.169906\n82.006097\n0.000000\n75.000000\n52.201533\n57.008771\n\n\n5\n58.309519\n28.284271\n22.360680\n75.000000\n0.000000\n60.827625\n46.097722\n\n\n6\n22.360680\n41.231056\n80.000000\n52.201533\n60.827625\n0.000000\n78.262379\n\n\n7\n61.846584\n39.051248\n36.400549\n57.008771\n46.097722\n78.262379\n0.000000\n\n\n\n\n\n\n\n\nimport numpy as np\n\nnp.sqrt((40 - 60) ** 2 + (20 - 10) ** 2)\n\n22.360679774997898\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "tics411/notebooks/distancia.html",
    "href": "tics411/notebooks/distancia.html",
    "title": "Clases UAI",
    "section": "",
    "text": "import pandas as pd\nimport numpy as np\n\ndf = pd.DataFrame(dict(x=[0, 2, 3, 5], y=[2, 0, 1, 1]))\ndf.index = [1, 2, 3, 4]\ndf\n\n\n\n\n\n\n\n\nx\ny\n\n\n\n\n1\n0\n2\n\n\n2\n2\n0\n\n\n3\n3\n1\n\n\n4\n5\n1\n\n\n\n\n\n\n\n\nnp.zeros((4, 4))\n\narray([[0., 0., 0., 0.],\n       [0., 0., 0., 0.],\n       [0., 0., 0., 0.],\n       [0., 0., 0., 0.]])\n\n\n\ndef distancia_l1(p, q):\n    x1 = p[\"x\"]\n    x2 = q[\"x\"]\n    y1 = p[\"y\"]\n    y2 = q[\"y\"]\n\n    return np.abs(x1 - x2) + np.abs(y1 - y2)\n\n\ndef distancia_l2(p, q):\n    x1 = p[\"x\"]\n    x2 = q[\"x\"]\n    y1 = p[\"y\"]\n    y2 = q[\"y\"]\n    return np.sqrt((x1 - x2) ** 2 + (y1 - y2) ** 2)\n\n\ndef distancia_linf(p, q):\n    x1 = p[\"x\"]\n    x2 = q[\"x\"]\n    y1 = p[\"y\"]\n    y2 = q[\"y\"]\n    d_x = np.abs(x1 - x2)\n    d_y = np.abs(y1 - y2)\n    return np.max([d_x, d_y])\n\n\ndef calculate_matrix(distance, n_puntos):\n    m = np.zeros((n_puntos, n_puntos))\n    for i in range(n_puntos):\n        for j in range(n_puntos):\n            p = df.iloc[i]\n            q = df.iloc[j]\n            m[i, j] = distance(p, q)\n\n    return m\n\n\nm_m = calculate_matrix(distancia_l1, 4)\nm_e = calculate_matrix(distancia_l2, 4)\nm_c = calculate_matrix(distancia_linf, 4)\n\n\nm_m\n\narray([[0., 4., 4., 6.],\n       [4., 0., 2., 4.],\n       [4., 2., 0., 2.],\n       [6., 4., 2., 0.]])\n\n\n\nm_e\n\narray([[0.        , 2.82842712, 3.16227766, 5.09901951],\n       [2.82842712, 0.        , 1.41421356, 3.16227766],\n       [3.16227766, 1.41421356, 0.        , 2.        ],\n       [5.09901951, 3.16227766, 2.        , 0.        ]])\n\n\n\nm_c\n\narray([[0., 2., 3., 5.],\n       [2., 0., 1., 3.],\n       [3., 1., 0., 2.],\n       [5., 3., 2., 0.]])\n\n\n\n\na = pd.Series(\n    [1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0, 5.5, 6.0, 6.5, 7.0]\n)\nb = pd.Series(\n    [1.0, 3.5, 3.6, 3.7, 3.8, 3.9, 4.0, 4.1, 4.2, 4.3, 4.4, 4.5, 7.0]\n)\n\na.var(ddof=0)  # Varianza Poblacional\n\n3.5\n\n\n\na.var(ddof=1)  # Varianza Muestral\n\n3.7916666666666665\n\n\n\nb.var(ddof=1)\n\n1.5916666666666668\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "tics579.html",
    "href": "tics579.html",
    "title": "Diapositivas",
    "section": "",
    "text": "Clase 0\n\n\nPresentación del Curso\n\n\n\n\n\n\n\n\n\n\n\n\nClase P1\n\n\nÁlgebra Tensorial\n\n\n\n\n\n\n\n\n\n\n\n\nClase P2\n\n\nCálculo Tensorial\n\n\n\n\n\n\n\n\n\n\n\n\nClase 1\n\n\nClase 1: Introducción a los Shallow Models\n\n\n\n\n\n\n\n\n\n\n\n\nClase 2\n\n\nClase 2: Introducción a las Redes Neuronales\n\n\n\n\n\n\n\n\n\n\n\n\nClase 3\n\n\nClase 3: Feed Forward Networks\n\n\n\n\n\n\n\n\n\n\n\n\nClase 4\n\n\nClase 4: Model Training\n\n\n\n\n\n\n\n\n\n\n\n\nClase 5\n\n\nClase 5: Training Tips & Tricks\n\n\n\n\n\n\n\n\n\n\n\n\nClase 6\n\n\nClase 6: Redes Convolucionales\n\n\n\n\n\n\n\n\n\n\n\n\nClase 7\n\n\nClase 7: Transfer Learning y Data Augmentation\n\n\n\n\n\nNo matching items\n Back to top",
    "crumbs": [
      "Diapositivas del Curso"
    ]
  },
  {
    "objectID": "tics411.html",
    "href": "tics411.html",
    "title": "Diapositivas",
    "section": "",
    "text": "Clase 0\n\n\nPresentación del Curso\n\n\n\nMar 7, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\nClase 1\n\n\nCalidad de los Datos y Feature Engineering\n\n\n\nMar 21, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\nClase 2\n\n\nExploratory Data Analysis (EDA)\n\n\n\nMar 28, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\nClase Bonus\n\n\nIntroducción a Scikit-Learn\n\n\n\nMar 28, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\nClase 3\n\n\nModelación Descriptiva y K-Means\n\n\n\nMar 28, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\nClase 4\n\n\nClustering Jerárquico\n\n\n\nApr 4, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\nClase 5\n\n\nDBSCAN\n\n\n\nApr 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\nClase 6\n\n\nEvaluación de Clusters\n\n\n\nApr 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\nClase 7\n\n\nAlgoritmo Apriori\n\n\n\nApr 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\nClase 8\n\n\nIntroducción al Aprendizaje Supervisado\n\n\n\nMay 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\nClase 9\n\n\nEvaluación de Modelos\n\n\n\nMay 16, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\nClase 10\n\n\nÁrboles de Decisión\n\n\n\nMay 30, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\nClase 11\n\n\nNaive Bayes\n\n\n\nMay 30, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\nClase 12\n\n\nRegresión Logística\n\n\n\nJun 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\nClase 13\n\n\nDetección de Anomalías\n\n\n\nJun 27, 2024\n\n\n\n\n\n\nNo matching items\n Back to top",
    "crumbs": [
      "Diapositivas del Curso"
    ]
  },
  {
    "objectID": "tics411-labs.html",
    "href": "tics411-labs.html",
    "title": "Prácticos",
    "section": "",
    "text": "Práctico\nColab\n\n\n\n\nPreprocesamiento\n\n\n\nEDA\n\n\n\nK-Means\n\n\n\nAnálisis de Centros\n\n\n\nAglomerativo\n\n\n\nDBSCAN\n\n\n\nEvaluación de Clusters\n\n\n\nEjemplos Hopkins\n\n\n\nProyecto Clustering\n\n\n\nApriori\n\n\n\nResolución Guía\n\n\n\nKNN\n\n\n\nCross Validation\n\n\n\nDecision Tree\n\n\n\nNaive Bayes\n\n\n\nLogistic Regression\n\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Notebooks"
    ]
  },
  {
    "objectID": "tics579/clase-0.html#quién-soy",
    "href": "tics579/clase-0.html#quién-soy",
    "title": "TICS-579-Deep Learning",
    "section": "¿Quién soy?",
    "text": "¿Quién soy?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAlfonso Tobar-Arancibia\nEstudié Ingeniería Civil pero llevo 10 años trabajando como:\n\nData Analyst.\nData Scientist.\nML Engineer.\nData Engineer.\n\nSoy Msc. en Data Science y estoy cursando el PhD. en la UAI especificamente en Deep Learning.\nMe gusta mucho programar (en vivo).\nContribuyo a HuggingFace y Feature Engine.\nHe ganado 2 competencias de Machine Learning.\nPubliqué mi primer paper el año pasado sobre Hate Speech en Español.\nJuego Tenis de Mesa, hacía Agility con mi perrita Kira y escribo en mi Blog (poco). Estoy volviendo a tocar batería."
  },
  {
    "objectID": "tics579/clase-0.html#disclaimer",
    "href": "tics579/clase-0.html#disclaimer",
    "title": "TICS-579-Deep Learning",
    "section": "Disclaimer",
    "text": "Disclaimer\n\n\n\n\n\n\n\nMucho del contenido de este curso será una mezcla entre inglés y español. Esto debido a que el contenido del curso está en constante desarrollo y casi no existen libros o artículos en español al respecto.\n\n\n\n\n\n\n\n\n\n\n\nEste curso se considera altamente teórico y con una fuerte componente en programación. ¡Están advertidos!\n\n\n\n\n\n\n\n\n\n\n\n\nEstá completamente prohibido copiar y pegar código de algún modelo de IA. Gente sorprendida se va directamente a Código de Honor. Y además… no se aprende.\nSe prohibe el uso de código de librerías no vistas en clases. Esto también se considerará copia.\n\n\n\n\n\n\n\n\n\n\n\n\nVamos a sufrir harto al menos las primeras semanas (yo al menos he sufrido harto preparando las clases), pero les aseguro que va a valer la pena.\nBare with me!!\n\n\n\n\n\n\n\n\n\n\n\nVamos a aprender conceptos muy avanzados que no muchos cursos consideran. Lo siento, pero van a ser mis conejillos de indias.\n\n\n\n\n\n\n\n\n\n\n\nVamos a pasarla bien mal, estudiando harto, demorándonos harto en las tareas, pero vamos a aprender harto."
  },
  {
    "objectID": "tics579/clase-0.html#objetivos-del-curso",
    "href": "tics579/clase-0.html#objetivos-del-curso",
    "title": "TICS-579-Deep Learning",
    "section": "Objetivos del Curso",
    "text": "Objetivos del Curso\n\n\n\n\n\n\n\n\nSer el curso más completo y exhaustivo de Deep Learning del país.\n\n\n\n\n\nIdentificar elementos claves de las Redes Neuronales.\n\nInputs, Capas, Outputs, Parámetros, Optimizadores, Funciones de Activación, Funciones de Pérdida, etc.\n\nEntender conceptos básicos como el Training Loop, Gradient Propagation, Optimización, etc.\nIdentificar los distintos tipos de Redes Neuronales:\n\nFeed Fordward Networks (MLP),\nConvolutional Neural Networks,\nRecurrent Neural Networks,\nTransformers.\n\nEntender las Arquitecturas Estado del Arte principalmente en Computer Vision y Natural Language Processing.\nImplementar, entrenar y evaluar Deep Neural Networks utilizando Pytorch."
  },
  {
    "objectID": "tics579/clase-0.html#cómo-aprovechar-las-diapositivas-al-máximo-véanlo-después",
    "href": "tics579/clase-0.html#cómo-aprovechar-las-diapositivas-al-máximo-véanlo-después",
    "title": "TICS-579-Deep Learning",
    "section": "¿Cómo aprovechar las diapositivas al máximo? (Véanlo después)",
    "text": "¿Cómo aprovechar las diapositivas al máximo? (Véanlo después)\n\n\nDiapositivas Interactivas creadas en Quarto (links van a estar disponibles en Webcursos)\n\nContiene un índice de todas las slides.\nPermite copiar y pegar código directamente.\nImágenes se pueden ver en tamaño completo al clickearlas.\nSe puede buscar contenido específico de cualquier Slide utilizando la Search Bar.\nSe puede obtener una copia en PDF presionando la tecla E para luego guardarlas para tomar notas."
  },
  {
    "objectID": "tics579/clase-0.html#cómo-apruebo",
    "href": "tics579/clase-0.html#cómo-apruebo",
    "title": "TICS-579-Deep Learning",
    "section": "¿Cómo apruebo?",
    "text": "¿Cómo apruebo?\n\n\n\n\n\n\n\nNota Final\n\n\n\\[NF = 0.7 \\cdot NP + 0.3\\cdot \\overline{NT}\\]\n\n\\(\\overline{NT}\\): Promedio de tareas. Será un 1.0 si es que NP es menor a 5.0.\n\n\n\n\n\n\n\n\n\n\nPruebas\n\n\nMidterm: Prueba a mitad del Curso el cuál vale un 30% de la Nota de Presentación.\nFinal Exam: 70% de la Nota Final, considera todo el contenido del curso.\n\n\n\n\n\n\n\n\n\nTareas\n\n\n\nSerán principalmente desafíos de programación y posibles problemas teóricos.\nSe prohibe la copia de código.\nHágalas a conciencia, ya que será material preguntado durante las pruebas.\nFechas de tarea serán anunciadas cuando corresponda."
  },
  {
    "objectID": "tics579/clase-4-legacy.html#pytorch",
    "href": "tics579/clase-4-legacy.html#pytorch",
    "title": "TICS-579-Deep Learning",
    "section": "Pytorch",
    "text": "Pytorch\n\nEs una librería de manipulación de Tensores especializada en Deep Learning. Provee principalmente, manipulación de tensores (igual que Numpy, pero en GPU), además de Autograd (calcula derivadas de manera automática).\n\nPara poder comenzar a utilizarlo se requieren normalmente 3 imports:\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\n\n\n\n\n\ntorch es donde se encuentran la mayoría de funciones básicas para manipular tensores.\ntorch.nn es donde se encuentran los módulos necesarios para poder crear redes neuronales (neural networks). Cada módulo es una clase en Python.\ntorch.nn.functional es donde se encontrarán las versiones funcionales de elementos de torch.nn."
  },
  {
    "objectID": "tics579/clase-4-legacy.html#gpu",
    "href": "tics579/clase-4-legacy.html#gpu",
    "title": "TICS-579-Deep Learning",
    "section": "GPU",
    "text": "GPU\n\n\n\n\n\n\n\nSu principal ventaja es que puede ejecutarse en GPU, lo cual entrega una ventaja comparativa enorme (Muchos más núcleos).\n\n\n\n\n\n\n\n\n\n\n\nLas GPUs están programadas en CUDA, una variante de C++ que es muy complicado de entender. Por lo que los mensajes de error son sumamente crípticos. Se recomienda desarrollar en CPU, y cambiar a GPU sólo cuando sea necesario ejecutar libre de errores.\n\n\n\n\n## Permite automáticamente reconocer si es que existe GPU en el sistema y de existir lo asigna.\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n\n\n\n\n\n\nEl código de arriba es particularmente útil para Google Colab o plataformas que permitan activar o desactivar GPUs.\nTambién es posible definirlo de manera manual en caso de querer debuggear algo en particular."
  },
  {
    "objectID": "tics579/clase-4-legacy.html#mapeando-lo-aprendido-con-pytorch",
    "href": "tics579/clase-4-legacy.html#mapeando-lo-aprendido-con-pytorch",
    "title": "TICS-579-Deep Learning",
    "section": "Mapeando lo aprendido con Pytorch",
    "text": "Mapeando lo aprendido con Pytorch\n\n\n\n\n\n\n\nSupongamos el caso particular en el cual queremos resolver un problema de clasificación binaria. ¿Cuánto valdría \\(k\\) y cuál sería la Loss Function a utilizar?\nSupongamos que queremos transformar una Matriz \\(X\\) de 1000 registros y 10 variables. Además tenemos un vector \\(y\\) el cuál queremos predecir.\nSupongamos que queremos llevar a 32 variables, luego a 64 para luego generar nuestra predicción.\nSupongamos además que queremos usar como función de activación la función ReLU en ambas capas de transformación.\n\n\n\n\n\n\n\n\n\n¿Cómo definimos los 3 elementos principales de una red?\n\n\n\n\n\n\n\n\n\n\n\n(Hipótesis, Loss Function y Optimizador)"
  },
  {
    "objectID": "tics579/clase-4-legacy.html#nn.module",
    "href": "tics579/clase-4-legacy.html#nn.module",
    "title": "TICS-579-Deep Learning",
    "section": "nn.Module",
    "text": "nn.Module\n\n\nEn Pytorch, cada parte de una red es una clase.\n\n\n\n\n\n\n\n\nUna clase tiene la ventaja de que es un objeto mutable que puede almacenar estados en su interior. En el caso particular de una red neuronal, ¿qué estado será importante que guarde?\n\n\n\n\n\n\n\n\n\n\nUna vez que un módulo es instanciado, acepta tensores de entrada y devuelve tensores de salida.\n\n\n\n\nnn.Linear()\n\nCorresponde a la Red más básica de Pytorch y permite realizar Transformaciones Affine.\n\n\n\nfc = nn.Linear(in_features, out_features, bias=True)\n\n\nin_features es la dimensión inicial (\\(n_i\\)).\nout_features la dimensión a la que se quiere llevar (\\(n_{i+1}\\)).\n\n\n\n\n\n\n\nDe manera análoga, nn.ReLU() será el módulo que representará una función de activación ReLU.\n\n\n\n\n\n\n\n\n\n\n\nPero, ¿Cómo combinamos distintos módulos para crear una sóla arquitectura que represente nuestra Hipótesis?"
  },
  {
    "objectID": "tics579/clase-4-legacy.html#hipótesis",
    "href": "tics579/clase-4-legacy.html#hipótesis",
    "title": "TICS-579-Deep Learning",
    "section": "Hipótesis",
    "text": "Hipótesis\n\nPara poder crear una Hipótesis en Pytorch podemos combinar cada Módulo entra clase que herede desde nn.Module.\n\nclass MyNeuralNetwork(nn.Module):\n    def __init__(self,):\n        pass\n    def forward(self,x):\n        pass\n\n\n\nLa red neuronal siempre debe heredar nn.Module. Esto permitirá que transformar la clase en Módulos que pueden combinarse para crear Arquitecturas cada vez más complejas.\n__init__() corresponde al constructor. Acá se deben definir todos los parámetros de entrada (similar a una función), con la que se instanciará la clase.\nforward() corresponde a la definición del *forward pass de la red en cuestión."
  },
  {
    "objectID": "tics579/clase-4-legacy.html#hipótesis-__init__",
    "href": "tics579/clase-4-legacy.html#hipótesis-__init__",
    "title": "TICS-579-Deep Learning",
    "section": "Hipótesis: __init__()",
    "text": "Hipótesis: __init__()\nclass MyNeuralNetwork(nn.Module):\n    def __init__(self,*):\n        super().__init__()\n        self.w1 = nn.Linear(10,32)\n        self.w2 = nn.Linear(32,64)\n        self.w3 = nn.Linear(64,1)\n        self.relu_1= nn.ReLU()\n        self.relu_2= nn.ReLU()\n\n\n\nSiempre el primer elemento de una red neuronal la inicialización del nn.Module mediante el super().__init__().\nEs importante notar que todos los elementos dentro de la clase deben tener el prefijo self. Esto permite que estos elementos puedan estar disponibles en cualquier método de la clase.\nEs posible inicializar elementos mediante parámetros (representado por *) para que la red sea flexible y reutilizable. La convención es que todos los métodos tienen que tener como primer parámetro la palabra self y luego pueden tener otros parámetros."
  },
  {
    "objectID": "tics579/clase-4-legacy.html#hipótesis-forward",
    "href": "tics579/clase-4-legacy.html#hipótesis-forward",
    "title": "TICS-579-Deep Learning",
    "section": "Hipótesis: forward()",
    "text": "Hipótesis: forward()\nclass MyNeuralNetwork(nn.Module):\n    def __init__(self,*):\n        super().__init__()\n        self.w1 = nn.Linear(10,32)\n        self.w2 = nn.Linear(32,64)\n        self.w3 = nn.Linear(64,1)\n        self.relu_1= nn.ReLU()\n        self.relu_2= nn.ReLU()\n    def forward(self,x):\n        x = self.w1(x)\n        x = self.relu_1(x)\n        x = self.w2(x)\n        x = self.relu_2(x)\n        x = self.w3(x)\n        return x\n\n\nLa método forward representa el *forward pass de la red e indica cómo están conectadas las distintas etapas de la red.\nEn este caso \\(x\\) representa una instancia/registro que va pasando por la red."
  },
  {
    "objectID": "tics579/clase-4-legacy.html#loss-function-y-optimizer",
    "href": "tics579/clase-4-legacy.html#loss-function-y-optimizer",
    "title": "TICS-579-Deep Learning",
    "section": "Loss Function y Optimizer",
    "text": "Loss Function y Optimizer\n\n\nLoss Function\n\n\nLa nomenclatura utilizada en Pytorch para referirse a la definición de la función de Pérdida es el criterion. Es decir, el criterio con el que se mide la pérdida. Más Loss Functions se pueden encontrar acá.\n\n\nOptimizador\n\n\nLa nomenclatura utilizada en Pytorch para referirse al optimizador a utilizar es optimizer. Éste se importa desde torch.optim y debe recibir como argumentos model.parameters() y al menos el learning_rate. Todos los optimizers pueden encontrarse acá.\n\n\n\n\nmodel = MyNeuralNetwork()\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr = 3e-4)"
  },
  {
    "objectID": "tics579/clase-4-legacy.html#training-loop",
    "href": "tics579/clase-4-legacy.html#training-loop",
    "title": "TICS-579-Deep Learning",
    "section": "Training Loop",
    "text": "Training Loop\n\nDefiniremos como Training Loop al proceso en el cual entrenaremos el modelo.\n\nfor e in range(EPOCHS):\n    ## Fijar el modelo en Modo Entrenamiento\n    model.train()\n\n    ## Fijar Gradientes en 0\n    optimizer.zero_grad()\n\n    ## Forward Pass\n    preds = model(X)\n\n    ## Cálculo del Loss (Ojo, primero va la predicción y luego el target). Ver Docs.\n    loss = criterion(preds, y)\n\n    ## Cálculo de Gradientes\n    loss.backward()\n\n    ## Update Rule\n    optimizer.step()\n\n\n\n\n\n\n\n\n.zero_grad() fijan los gradientes a cero, ya que Pytorch acumula gradientes siempre. Es importante que en cada epoch todos los gradientes acumulados vuelvan a cero para una siguiente optimización.\nEn el caso de querer dejar en zero los gradientes de un tensor, y no del optimizador, se puede usar .zero_()."
  },
  {
    "objectID": "tics579/clase-4-legacy.html#inferencia",
    "href": "tics579/clase-4-legacy.html#inferencia",
    "title": "TICS-579-Deep Learning",
    "section": "Inferencia",
    "text": "Inferencia\n\n\nPara generar predicciones basta con generar un Forward Pass con el modelo ya entrenado. Dependiendo del modelo, es posible que sea necesario aplicar un post-procesamiento.\n\n\n\n## Fijar el Modelo en Evaluación.\nmodel.eval()\n\n## Evita que Pytorch calcule Gradientes ya que no es necesario.\nwith torch.no_grad():\n    ## Cálculo de la salida del modelo (h)\n    h = model(X)\n\n## Cálculo de Probabilidades (si es que fuera necesario)\ny_proba = torch.sigmoid(h)\n\n## Clasificación propiamente tal\ny_preds = torch.where(y_proba&gt;=0.5, 1,0)"
  },
  {
    "objectID": "tics579/clase-4-legacy.html#mini-batching",
    "href": "tics579/clase-4-legacy.html#mini-batching",
    "title": "TICS-579-Deep Learning",
    "section": "Mini-Batching",
    "text": "Mini-Batching\n\n\n\n\n\n\n\n\nRara vez los datos vienen en formato de Tensor de Pytorch. Por lo tanto, el dataset (tablas, imágenes, videos, texto, audio, etc) debe ser llevado a formato Tensor, lo cual puede ser un proceso bastante costoso y que consume muchos recursos.\n\n\n\n\n\n\n\n\n\n\n\nAdemás, la cantidad de datos necesaria para poder entrenar un modelo de Deep Learning normalmente es alta. Lo cual limita el cierto Hardware al no contar con la capacidad necesaria.\n\n\n\n\n\nMini-Batching\n\nSe refiere a aplicar un proceso de Optimización Estocástica, con sólo una muestra de los datos. Se basa en que el gradiente de la suma de las muestras es equivalente al gradiente total.\n\n\nPara ello Pytorch introduce los conceptos de Dataset y DataLoader para implementar conversión y carga de datos on-the-fly.\n\n\nfrom torch.utils.data import Dataset, DataLoader"
  },
  {
    "objectID": "tics579/clase-4-legacy.html#mini-batching-dataset",
    "href": "tics579/clase-4-legacy.html#mini-batching-dataset",
    "title": "TICS-579-Deep Learning",
    "section": "Mini-Batching: Dataset",
    "text": "Mini-Batching: Dataset\n\nPytorch necesita crear una clase que herede de Dataset y que permita tomar elementos uno a uno y transformarlos en Tensores. Este clase debe tener al menos 3 métodos: __init__, __len__ y __getitem__.\n\n\n\n\n\n\n\nSupongamos que nuestros datos iniciales estaban en Numpy.\n\n\n\nclass MyDataSet(Dataset):\n    def __init__(self, X,y):\n        self.X = X\n        self.y = y\n    def __len__(self):\n        return len(self.X)\n    def __getitem__(self,idx):\n        features = torch.from_numpy(self.X[idx])\n        target = torch.from_numpy(self.y[idx])\n        return features, target"
  },
  {
    "objectID": "tics579/clase-4-legacy.html#model-registry",
    "href": "tics579/clase-4-legacy.html#model-registry",
    "title": "TICS-579-Deep Learning",
    "section": "Model Registry",
    "text": "Model Registry\n\nCada vez que nosotros llamamos un objeto modelo (que herede de nn.Module) este modelo mostrará el model registry. El registry permitirá ver todos los elementos que son parte del modelo. Para que un elemento sea parte del registro, debe haber sido definido como self.----.\n\n\n\n\n\n\n\n\n\n\n\n\n\nSi es que se define un elemento como self.--- debe definirse como un nn.Module y no como un F.---\nAdemás se puede acceder a cualquier elemento/atributo mediante el comando model.atributo."
  },
  {
    "objectID": "tics579/clase-4-legacy.html#model-registry-1",
    "href": "tics579/clase-4-legacy.html#model-registry-1",
    "title": "TICS-579-Deep Learning",
    "section": "Model Registry",
    "text": "Model Registry\n\n\n\n\n\n\n\n\n\n\n\n\n\nEs posible acceder a los datos de Parámetros y Bias de una capa linear utilizando:\n\n\n\n\nmodel.w1.weights.data\nmodel.w1.bias.data\n\n\n\n\n\n\nIdea:\n\n\n\nPodría utilizarse esto para poder definir valores iniciales de capas de parámetros y de bias.\n\n\n\n\n\nclass MyNeuralNetwork(nn.Module):\n    def __init__(self, *):\n        self.w1 = ...\n        self.relu = ...\n        self.model.w1.weights.data = tensor([...])\n        self.model.w1.bias.data = tensor([...])\n    \n    def forward(self,x):\n        ..."
  },
  {
    "objectID": "tics579/clase-4-legacy.html#mini-batching-dataloader",
    "href": "tics579/clase-4-legacy.html#mini-batching-dataloader",
    "title": "TICS-579-Deep Learning",
    "section": "Mini-Batching: Dataloader",
    "text": "Mini-Batching: Dataloader\n\n\nEl Dataloader permitirá ir cargando los datos en memoria en un cierto batch_size. La idea es no generar cuellos de botella por falta de memoria disponible.\n\n\ndata = MyDataset(X,y)\ntrain_loader = DataLoader(data, batch_size=32, pin_memory=True,num_workers=12, shuffle=True)\n\n\n\n\n\n\n\nEsto implica que nuestro Training Loop deberá sufrir ciertas modificaciones para ir actualizandose por Batch y no sólo por Epoch.\n\n\n\n\nfor e in range(EPOCHS):\n    train_loss = []\n\n    model.train()\n    for batch in train_loader:\n        X, y = batch\n        optimizer.zero_grad()\n        preds = model(X)\n        loss = criterion(preds, y)\n        loss.backward()\n        optimizer.step()\n        train_loss.append(loss.item())\n    print(f\"Loss para Epoch {e}: {np.mean(train_loss)}\")"
  },
  {
    "objectID": "tics579/clase-P1.html#historia",
    "href": "tics579/clase-P1.html#historia",
    "title": "TICS-579-Deep Learning",
    "section": "Historia",
    "text": "Historia\nLa verdad podríamos estudiar historia e importancia de porqué el Deep Learning es importante, pero la verdad…\n\n\n\n\n\n\nNO TENEMOS TIEMPO PARA ESO.\n\n\n\n\n\nAlexnet (2012)\n\n\nTransformers (2017)\n\n\nGPT (2019)\n\n\nLLMs (2023) (ChatGPT/Llama)"
  },
  {
    "objectID": "tics579/clase-P1.html#por-qué-estudiar-deep-learning",
    "href": "tics579/clase-P1.html#por-qué-estudiar-deep-learning",
    "title": "TICS-579-Deep Learning",
    "section": "¿Por qué estudiar Deep Learning?",
    "text": "¿Por qué estudiar Deep Learning?\n\n\n\n\n\n\n\nImágen tomada de la Clase de Zico Colter"
  },
  {
    "objectID": "tics579/clase-P1.html#por-qué-estudiar-deep-learning-1",
    "href": "tics579/clase-P1.html#por-qué-estudiar-deep-learning-1",
    "title": "TICS-579-Deep Learning",
    "section": "¿Por qué estudiar Deep Learning?",
    "text": "¿Por qué estudiar Deep Learning?\n\n\n\n\n\n\n\nFacilidad y Autograd\n\n\n\nFrameworks como Tensorflow, Pytorch o Jax permiten realizar esto de manera mucho más sencilla.\n\nFrameworks permiten calcular gradientes de manera automática.\nAntigua mente trabajar en Torch, Caffe o Theano podía tomar cerca de 50K líneas de código.\n\n\n\n\n\n\n\n\n\n\n\nCómputo\n\n\n\nProliferación de las GPUs, TPUs, HPUs, IPUs, como sistemas masivos de Cómputos.\n\nHow many computers to identify a cat? 16,000\n\n\n\n\n\n\n\n\n\n\n\nEstado del Arte\n\n\n\nModelos de Deep Learning pueden generar sistemas que entiendan imágenes, textos, audios, videos, grafos, etc."
  },
  {
    "objectID": "tics579/clase-P1.html#tensores",
    "href": "tics579/clase-P1.html#tensores",
    "title": "TICS-579-Deep Learning",
    "section": "Tensores",
    "text": "Tensores\n\nCorresponde a una generalización de los vectores y matrices que permite representar datos de múltiples dimensiones.\n\n\n\nEscalares (Orden 0)\n\\[-1, 11.27, \\pi\\]\n\nVectores Filas (Orden 1)\n\\[\\begin{bmatrix}1.0 & -0.27 & -1.22\\end{bmatrix}\\]\nVectores Columnas (Orden 1)\n\\[\\begin{bmatrix}\n1 \\\\\n-0.27\\\\\n-1.22\n\\end{bmatrix}\\]\n\nMatrices (Orden 2)\n\\[\\begin{bmatrix}\n1.0 & -0.27 & 3\\\\\n3.15 & 2.02 & 1.2\\\\\n-1.22& 0.55 & 3.97 \\\\\n\\end{bmatrix}\\]\n\n\n\n\n\n\n\n\nNormalmente los tensores utilizan un mismo tipo de dato: Integers o Float es lo más común."
  },
  {
    "objectID": "tics579/clase-P1.html#tensores-1",
    "href": "tics579/clase-P1.html#tensores-1",
    "title": "TICS-579-Deep Learning",
    "section": "Tensores",
    "text": "Tensores\n\n\nTensores (Orden 3+)\n\\[\\begin{bmatrix}\n    \\begin{bmatrix}\n        0.2 & 0.1 & -0.25 \\\\\n        0.1 & -1.0 & 0.22\\\\\n    \\end{bmatrix} \\\\\n    \\begin{bmatrix}\n        0.24 & 0.1 & -0.25 \\\\\n        0.05 & -0.69 & 0.98\n    \\end{bmatrix} \\\\\n    \\begin{bmatrix}\n        0.66& -1.0 & 0.22\\\\\n        -0.07 & -0.59 & 0.99\n    \\end{bmatrix} \\\\\n    \\begin{bmatrix}\n        0.16& 1.0 & 3.22\\\\\n        9.17 & 7.19 & 9.99\n    \\end{bmatrix}\n\\end{bmatrix}\n\\]\n\n\n\n\n\n\n\nNomenclatura\n\n\n\n\\(\\alpha\\), \\(\\beta\\), \\(\\gamma\\): Minúsculas griegas denotan a Escalares.\nx, y, z: Minúsculas latinas denotan a Vectores.\nX, Y, Z: Mayúsculas latinas denotan a Matrices o Tensores.\n\n\n\n\n\n\n\n\n\n\nShape/Tamaño: Tamaño del tensor, tiene tantas dimensiones como su orden.\n\n\n\nEscalar: No tiene dimensiones.\nVector: Tamaño es equivalente al número de elementos del vector. (3,)\n\nA veces se usa la versión (1,3) para vectores filas y (3,1) para vectores columnas.\n\nMatrices: Tamaño es equivalente al número de filas y columnas. Ejemplo: (3,3)\nTensores: Tamaño es equivalente al número de matrices que lo componen y el número de filas y columnas de cada una de ellas. Ejemplo: (4,2,3)\n\n\n\n\n\n\n\nImportante\n\n\n\nLa primera dimensión del shape se conoce como Batch Size el cual denota la cantidad de elementos de orden inferior.\n(3, ) tenemos 3 escalares.\n(3,2) tenemos 3 vectores filas de 2 elementos cada uno.\n(4,2,3) tenemos 4 matrices de (2,3) cada una."
  },
  {
    "objectID": "tics579/clase-P1.html#vectores-suma",
    "href": "tics579/clase-P1.html#vectores-suma",
    "title": "TICS-579-Deep Learning",
    "section": "Vectores: Suma",
    "text": "Vectores: Suma\n\nCorresponde a un arreglo unidimensional de números reales. Se puede representar como fila o columna. Por convención denotaremos \\(\\bar{x}\\) como vector columna y \\(\\bar{x}^T\\) como vector fila.\n\n\n\n\n\n\n\n\n\nOperación Suma\n\n\n\nPermite sumar dos vectores de igual tamaño dimensión por dimensión.\n\nEj: \\([7,2]^T + [2,3]^T = [9,5]^T\\)\n\n\n\n\n\n\n\n\n\n\nPropiedades\n\n\n\nConmutatividad: \\(\\bar{x}+\\bar{y} = \\bar{y}+\\bar{x}\\)\nAsociatividad: \\((\\bar{x}+\\bar{y})+\\bar{z} = \\bar{x}+(\\bar{y}+\\bar{z})\\)\nElemento Neutro: \\(\\bar{x} + \\bar{0} = \\bar{x}\\)"
  },
  {
    "objectID": "tics579/clase-P1.html#vectores-ponderación",
    "href": "tics579/clase-P1.html#vectores-ponderación",
    "title": "TICS-579-Deep Learning",
    "section": "Vectores: Ponderación",
    "text": "Vectores: Ponderación\n\nCorresponde a un arreglo unidimensional de números reales. Se puede representar como fila o columna. Por convención denotaremos \\(\\bar{x}\\) como vector columna y \\(\\bar{x}^T\\) como vector fila.\n\n\n\n\n\n\n\n\n\nOperación Ponderación\n\n\n\nPermite multiplicar/ponderar cada dimensión del vector por un escalar.\nEj: \\(2 \\cdot [3,2]^T = [6,4]^T\\)\n\n\n\n\n\n\n\n\n\n\n\nPropiedades\n\n\n\nDistributividad Escalar: \\(a(\\bar{x}+\\bar{y}) = a\\bar{x} + a\\bar{y}\\)\nDistributividad Vectorial: \\((a+b)\\bar{x} = a\\bar{x} + b\\bar{x}\\)\nElemento Neutro: \\(1\\cdot \\bar{x} = \\bar{x}\\)\nCompatibilidad: \\(a(b\\bar{x}) = (ab)\\bar{x}\\)"
  },
  {
    "objectID": "tics579/clase-P1.html#vectores-norma",
    "href": "tics579/clase-P1.html#vectores-norma",
    "title": "TICS-579-Deep Learning",
    "section": "Vectores: Norma",
    "text": "Vectores: Norma\n\n\n\n\n\n\n\n\nNorma (Euclideana)\n\n\nPara un vector \\(\\bar{x}=[x_1, ..., x_n] \\in \\mathbb{R}^n\\) se define la norma como:\n\\[||\\bar{x}|| = \\sqrt{\\sum_{i=1}^n x_i^2}\\]\n\n\n\n\n\n\n\n\n\n\nPropiedades\n\n\n\nDesigualdad Triangular: \\(||\\bar{x}+\\bar{y}|| \\leq ||\\bar{x}|| + ||\\bar{y}||\\)\n\\(||\\alpha \\bar{x}||= |\\alpha| \\cdot ||\\bar{x}||\\)\n\\(||\\bar{x}|| = 0 \\Longleftrightarrow \\bar{0}\\)\n\n\n\n\n\n\n\n\n\n\nAplicación\n\n\nLa norma permite calcular la distancia entre dos vectores.\n\\[d_{x,y} = ||\\bar{x} - \\bar{y}||\\]\nTambién serviría para puntos. ¿Por qué?"
  },
  {
    "objectID": "tics579/clase-P1.html#vectores-producto-interno-producto-punto",
    "href": "tics579/clase-P1.html#vectores-producto-interno-producto-punto",
    "title": "TICS-579-Deep Learning",
    "section": "Vectores: Producto Interno (Producto Punto)",
    "text": "Vectores: Producto Interno (Producto Punto)\n\n\n\n\n\n\n\n\nInner Product or Dot Product\n\n\nEl producto interno entre dos vectores en \\(\\mathbb{R}^n\\) se define como:\n\\(\\bar{x} = [x_1, ..., x_n]\\) e \\(\\bar{y} = [y_1, ..., y_n]\\)\n\\[ \\bar{x} \\cdot \\bar{y} = ||\\bar{x}|| ||\\bar{y}|| Cos\\theta =  \\sum_{i=1}^n x_i y_i = x_1 y_1 + ... + x_n y_n\\]\nA veces el producto interno se denota como \\(\\bar{x}^T \\bar{y}\\) o \\(\\langle \\bar{x}, \\bar{y} \\rangle\\).\n\n\n\n\n\n\n\n\n\n\nPropiedades\n\n\n\nConmutatividad: \\(\\bar{x} \\cdot \\bar{y} = \\bar{y} \\cdot \\bar{x}\\)\nLinealidad: \\((\\alpha \\bar{x})\\cdot \\bar{y} = \\alpha(\\bar{x}\\cdot \\bar{y})\\)\nDistributividad: \\(\\bar{x} \\cdot (\\bar{y} + \\bar{z}) = (\\bar{x} \\cdot \\bar{y}) + (\\bar{x} \\cdot \\bar{z})\\)\n\\(||\\bar{x}||^2 = \\bar{x} \\cdot \\bar{x}\\)\n\n\n\n\n\n\n\n\n\n\nAplicaciones\n\n\n\nOrtogonalidad: Dos vectores son ortogonales si su producto interno es cero.\nSimilaridad: Se puede usar el Cosine Similarity para calcular qué tan parecidos son dos vectores.\n\n\n\n\n\n\n\n\nCosine Similarity\n\n\n\\[sim(\\bar{a}, \\bar{b}) = \\frac{\\bar{a} \\cdot \\bar{b}}{||\\bar{a}|| \\cdot ||\\bar{b}||}\\]\n\n1 implica misma dirección (idénticos)\n-1 implica direcciones opuestas (opuestos).\n0 implica totalmente distintos (ortogonales)."
  },
  {
    "objectID": "tics579/clase-P1.html#vectores-otras-propiedades",
    "href": "tics579/clase-P1.html#vectores-otras-propiedades",
    "title": "TICS-579-Deep Learning",
    "section": "Vectores: Otras Propiedades",
    "text": "Vectores: Otras Propiedades\n\n\n\n\n\n\nCombinación Lineal\n\n\n\nSe denomina una combinación lineal de vectores a la suma ponderada de estos.\n\nEj: \\(\\bar{w} = \\alpha \\cdot \\bar{x} + \\beta \\cdot \\bar{y} + \\gamma \\cdot \\bar{z}\\)\n\\(\\bar{w}\\) es una combinación lineal de los vectores \\(\\bar{x}, \\bar{y}, \\bar{z}\\).\n\n\n\n\n\n\n\n\n\nIndependencia Lineal\n\n\n\nUn conjunto de vectores es linealmente independiente si:\n\n\\(\\alpha_1 \\cdot \\bar{x}_1 + \\alpha_2 \\cdot \\bar{x}_2 + ... + \\alpha_n \\cdot \\bar{x}_n = 0\\) implica que \\(\\alpha_i = 0\\) para todo \\(i\\).\n\n\n\n\n\n\n\n\n\n👀 Ojito\n\n\nHay otras propiedades sumamente importantes de vectores, por lo que coloquen atención al curso de Algebra Lineal."
  },
  {
    "objectID": "tics579/clase-P1.html#matrices-definición",
    "href": "tics579/clase-P1.html#matrices-definición",
    "title": "TICS-579-Deep Learning",
    "section": "Matrices: Definición",
    "text": "Matrices: Definición\n\n\nCorresponde a un arreglo bidimensional de números reales. Se dice que una matriz es de \\(m\\times n\\) o que es \\(\\mathbb{R}^{m \\times n}\\) cuando tiene \\(m\\) filas y \\(n\\) columnas.\n\\[A = \\begin{bmatrix}\nA_{1,1} & \\dots & A_{1,n} \\\\\nA_{2,1} & \\dots & A_{2,n} \\\\\n\\vdots & \\ddots & \\vdots \\\\\nA_{m, 1} & \\dots & A_{m,n} \\\\\n\\end{bmatrix} \\in \\mathbb{R}^{m \\times n}\\]\n\n\n\n\n\n👀\n\n\n\nNormalmente se utiliza \\(m\\) para denotar el número de registros y \\(n\\) como el número de features de un dataset tabular (o también conocido como Dataframe).\nSi \\(m=n\\) nos referimos a una matriz cuadrada."
  },
  {
    "objectID": "tics579/clase-P1.html#matrices-notación",
    "href": "tics579/clase-P1.html#matrices-notación",
    "title": "TICS-579-Deep Learning",
    "section": "Matrices: Notación",
    "text": "Matrices: Notación\n\nSi \\(A\\) es una matriz entonces:\n\n\\(A_{i,j}\\) corresponde al elemento en la fila \\(i\\) y columna \\(j\\). Es decir, un escalar.\n\\(A_{i,:}\\) corresponde a la fila \\(i\\) completa. Es decir, un vector fila.\n\\(A_{:,j}\\) corresponde a la columna \\(j\\) completa. Es decir un vector columna.\n\n\n\n\\[A = \\begin{bmatrix}\n0.2 & 1 & -5.2 & 3.1 & -1.3 \\\\\n-0.5 & 10 & 0 & 3.1 & 3 \\\\\n2 & 25 & -5.2 & 0 & 0 \\\\\n100 & 3.4 & 4.1 & 0 & 42\n\\end{bmatrix}\\]\n\n\n\n\n\n\n\nImportante: Recordar que los índices en Python son 0-based.\n\n\n\n\\(A_{2,4} = 3.1\\)\n\\(A_{:,3} = \\begin{bmatrix}-5.2 & 0 & -5.2 & 4.1\\end{bmatrix}^T\\)\n\\(A_{1,:} = \\begin{bmatrix} 0.2, 1, -5.2, 3.1, -1.3\\end{bmatrix}\\)"
  },
  {
    "objectID": "tics579/clase-P1.html#matrices-suma",
    "href": "tics579/clase-P1.html#matrices-suma",
    "title": "TICS-579-Deep Learning",
    "section": "Matrices: Suma",
    "text": "Matrices: Suma\n\n\n\n\n\n\n\n\nOperación Suma\n\n\n\nPermite sumar dos matrices elemento a elemento.\nEj: Sea \\(A\\) y \\(B\\) dos matrices:\n\n\\[A = \\begin{bmatrix}\nA_{1,1} & \\dots & A_{1,n} \\\\\nA_{2,1} & \\dots & A_{2,n} \\\\\n\\vdots & \\ddots & \\vdots \\\\\nA_{m, 1} & \\dots & A_{m,n} \\\\\n\\end{bmatrix} \\in \\mathbb{R}^{m \\times n}\\]\n\\[B = \\begin{bmatrix}\nB_{1,1} & \\dots & B_{1,n} \\\\\nB_{2,1} & \\dots & B_{2,n} \\\\\n\\vdots & \\ddots & \\vdots \\\\\nB_{m, 1} & \\dots & B_{m,n} \\\\\n\\end{bmatrix} \\in \\mathbb{R}^{m \\times n}\\]\n\n\n\n\n\n\n\n\nResultado\n\n\n\\[A + B = \\begin{bmatrix}\nA_{1,1} + B_{1,1} & \\dots & A_{1,n} + B_{1,n} \\\\\nA_{2,1} + A_{2,1} & \\dots & A_{2,n} + B_{2,n} \\\\\n\\vdots & \\ddots & \\vdots \\\\\nA_{m, 1} + B_{m,1} & \\dots & A_{m,n} + B_{m,n} \\\\\n\\end{bmatrix} \\in \\mathbb{R}^{m \\times n}\\]\n\n\n\n\n\n\n\n\n\n\n\nPropiedades\n\n\n\nAsociatividad: \\((A + B) + C = A + (B + C)\\)\nConmutatividad: \\(A + B = B + A\\)\nElemento Neutro: \\(A + 0 = A\\)\nElemento Inverso: \\(A + (-A) = 0\\)"
  },
  {
    "objectID": "tics579/clase-P1.html#matrices-ponderación",
    "href": "tics579/clase-P1.html#matrices-ponderación",
    "title": "TICS-579-Deep Learning",
    "section": "Matrices: Ponderación",
    "text": "Matrices: Ponderación\n\n\n\n\n\n\n\n\nOperación Ponderación\n\n\n\nPermite multiplicar/ponderar cada elemento de la matriz por un escalar.\nEj: Sea \\(A\\) una matriz:\n\n\\[A = \\begin{bmatrix}\nA_{1,1} & \\dots & A_{1,n} \\\\\nA_{2,1} & \\dots & A_{2,n} \\\\\n\\vdots & \\ddots & \\vdots \\\\\nA_{m, 1} & \\dots & A_{m,n} \\\\\n\\end{bmatrix} \\in \\mathbb{R}^{m \\times n}\\]\ny \\(\\gamma\\) un escalar.\n\n\n\n\n\n\n\n\nResultado\n\n\n\\[\\gamma \\cdot A = \\begin{bmatrix}\n\\gamma \\cdot A_{1,1} & \\dots & \\gamma \\cdot A_{1,n} \\\\\n\\gamma \\cdot A_{2,1} & \\dots & \\gamma \\cdot A_{2,n} \\\\\n\\vdots & \\ddots & \\vdots \\\\\n\\gamma \\cdot A_{m, 1} & \\dots & \\gamma \\cdot A_{m,n} \\\\\n\\end{bmatrix} \\in \\mathbb{R}^{m \\times n}\\]\n\n\n\n\n\n\n\n\n\n\n\nPropiedades\n\n\n\nDistibutividad Escalar: \\(\\gamma(A + B) = \\gamma A + \\gamma B\\)\nDistibutividad Matricial: \\((\\gamma + \\delta) A = \\gamma A + \\delta A\\)\nCompatibilidad: \\((\\gamma \\delta) A = \\gamma (\\delta A) = \\delta (\\gamma A)\\)"
  },
  {
    "objectID": "tics579/clase-P1.html#transpuesta-y-reshape",
    "href": "tics579/clase-P1.html#transpuesta-y-reshape",
    "title": "TICS-579-Deep Learning",
    "section": "Transpuesta y Reshape",
    "text": "Transpuesta y Reshape\n\n\n\n\n\n\n\n\n\nTranspuesta\n\n\nSea:\n\\[A = \\begin{bmatrix}\nA_{1,1} & \\dots & A_{1,n} \\\\\nA_{2,1} & \\dots & A_{2,n} \\\\\n\\vdots & \\ddots & \\vdots \\\\\nA_{m, 1} & \\dots & A_{m,n} \\\\\n\\end{bmatrix} \\in \\mathbb{R}^{m \\times n}\\]\nEntonces, \\(A^T\\) se define como:\n\\[A^T = \\begin{bmatrix}\nA_{1,1} & \\dots & A_{1,m} \\\\\n\\vdots & \\ddots & \\vdots \\\\\nA_{n,1} & \\dots & A_{n,m} \\\\\n\\end{bmatrix} \\in \\mathbb{R}^{n \\times m}\\]\nEs decir, intercambiamos filas por las columnas y viceversa.\n\n\n\n\n\n\n\n\n\n\n\nPropiedades\n\n\n\n\\((A^T)^T = A\\)\n\\((A + B)^T = A^T + B^T\\)\n\\((A \\cdot B)^T = B^T \\cdot A^T\\)\n\n\n\n\n\n\n\n\n\n\n\n\nReshape\n\n\n\\[B = \\begin{bmatrix}\n1 & 3 & 5 \\\\\n1 & 7 & 9 \\\\\n4 & 6 & 7 \\\\\n3 & 3 & 5 \\\\\n\\end{bmatrix} \\in \\mathbb{R}^{4 \\times 3}\\]\nPodemos hacer un reshape a (6,2)\n\\[B_{reshaped} = \\begin{bmatrix}\n1 & 3 \\\\\n5 & 1 \\\\\n7 & 9 \\\\\n4 & 6 \\\\\n7 & 3 \\\\\n3 & 5\n\\end{bmatrix} \\in \\mathbb{R}^{6 \\times 2}\\]"
  },
  {
    "objectID": "tics579/clase-P1.html#producto-matriz-vector-por-la-derecha",
    "href": "tics579/clase-P1.html#producto-matriz-vector-por-la-derecha",
    "title": "TICS-579-Deep Learning",
    "section": "Producto Matriz-Vector (Por la derecha)",
    "text": "Producto Matriz-Vector (Por la derecha)\nA diferencia de todas las otras operaciones, el producto entre una matriz y un vector no es conmutativo.\nPost-multiplicación (Multiplicación por la derecha)\n\n\n\n\n\n\n\n\nSea\n\n\n\\[\\bar{y} = A \\cdot \\bar{x}\\]\n\\[A = \\begin{bmatrix}\n2 & 3 & 0 \\\\\n1 & 0 & 7\n\\end{bmatrix}\\]\n\\[\\bar{x} = \\begin{bmatrix}\n4 \\\\\n2 \\\\\n1\n\\end{bmatrix}\\]\n\n\n\n\n\n\n\n\n\n\nAtención\n\n\nLa post-multiplicación se puede ver como la combinación lineal de las columnas de una matriz por cada elemento del vector. \\[\n\\begin{align}\n\\bar{y} = A \\cdot \\bar{x} &= \\begin{bmatrix}\n2 \\cdot 4 + 3 \\cdot 2 + 0 \\cdot 1 \\\\\n1 \\cdot 4 + 0 \\cdot 2 + 7 \\cdot 1\n\\end{bmatrix} \\\\\n&= 4 \\cdot \\begin{bmatrix}2 \\\\ 1\\end{bmatrix} + 2 \\cdot \\begin{bmatrix}3 \\\\ 0\\end{bmatrix} + 1 \\cdot \\begin{bmatrix}0 \\\\ 7\\end{bmatrix} \\\\\n&= \\begin{bmatrix}14 \\\\ 11\\end{bmatrix}\n\\end{align}\\]\n\n\n\n\n\n\n\n\n👀\n\n\n\nLa multiplicación sólo es válida si la dimensión de las columnas de la matriz es igual a la dimensión del vector. El resultado siempre es un vector columna.\nLa multiplicación de una fila por una columna es equivalente al Producto Interno. Es decir, \\(\\bar{y}_{i,:} = A_{i,:} \\cdot \\bar{x}\\)"
  },
  {
    "objectID": "tics579/clase-P1.html#producto-matriz-vector-por-la-izquierda",
    "href": "tics579/clase-P1.html#producto-matriz-vector-por-la-izquierda",
    "title": "TICS-579-Deep Learning",
    "section": "Producto Matriz-Vector (Por la izquierda)",
    "text": "Producto Matriz-Vector (Por la izquierda)\nA diferencia de todas las otras operaciones, el producto entre una matriz y un vector no es conmutativo.\nPre-multiplicación (Multiplicación por la izquierda)\n\n\n\n\n\n\n\n\nSea\n\n\n\\[\\bar{y}^T = \\bar{x}^T \\cdot A\\]\n\\[A = \\begin{bmatrix}\n2 & 3 & 0 \\\\\n1 & 0 & 7\n\\end{bmatrix}\\]\n\\[\\bar{x}^T = \\begin{bmatrix}\n2 & 1\n\\end{bmatrix}\\]\n\n\n\n\n\n\n\n\n\n\nAtención\n\n\nLa pre-multiplicación se puede ver como la combinación lineal de las filas de una matriz por cada elemento del vector. \\[\n\\begin{align}\n\\bar{y}^T = \\bar{x}^T \\cdot A &=\n\\begin{bmatrix}\n(2 \\cdot 2 + 1 \\cdot 1)  & (2 \\cdot 3 + 1 \\cdot 0) & (2 \\cdot 0 + 1 \\cdot 7) \\\\\n\\end{bmatrix} \\\\\n&= 2 \\cdot \\begin{bmatrix} 2 & 3 & 0\\end{bmatrix} + 1 \\cdot \\begin{bmatrix} 1 & 0 & 7\\end{bmatrix} \\\\\n&= \\begin{bmatrix}5 & 6 & 7\\end{bmatrix}\n\\end{align}\n\\]\n\n\n\n\n\n\n\n\n👀\n\n\n\nLa multiplicación sólo es válida si la dimensión de las filas de la matriz es igual a la dimensión del vector. El resultado siempre es un vector fila"
  },
  {
    "objectID": "tics579/clase-P1.html#producto-matriz-matriz",
    "href": "tics579/clase-P1.html#producto-matriz-matriz",
    "title": "TICS-579-Deep Learning",
    "section": "Producto Matriz-Matriz",
    "text": "Producto Matriz-Matriz\nCorresponde a una operación que permite multiplicar 2 matrices si las columnas de la primera son iguales a las filas de la segunda. Una matriz de \\(n \\times p\\) multiplicada con una de \\(p \\times m\\) nos dará una matriz de \\(n \\times m\\). La manera de multiplicar es tomar cada fila de la primera y multiplicarla por cada columna de la segunda.\n\n\n\n\nOjito!!\n\n\n\nLa multiplicación matricial es equivalente a \\(m\\) post-multiplicaciones Matriz-Vector, stackeadas hacia el lado.\nTambién se puede ver como \\(n\\) pre-multiplicaciones Matriz-Vector, stackeadas hacia abajo.\n\n\\[\n\\begin{align}\nAB &= \\begin{bmatrix}\nA_{1,1} & \\dots & A_{1,p} \\\\\n\\vdots & \\ddots & \\vdots \\\\\nA_{n, 1} & \\dots & A_{n,p} \\\\\n\\end{bmatrix}\n\\begin{bmatrix}\nB_{1,1} & \\dots & B_{1,m} \\\\\n\\vdots & \\ddots & \\vdots \\\\\nB_{p, 1} & \\dots & B_{p,m} \\\\\n\\end{bmatrix} \\\\\n&= \\begin{bmatrix}\n| & &  | \\\\\nA \\cdot B_{:,1}& \\dots &  A \\cdot B_{:,m} \\\\\n| & &  | \\\\\n\\end{bmatrix}\\\\\n&= \\begin{bmatrix}\n- & A_{1,:} \\cdot B & - \\\\\n& \\vdots &  \\\\\n- & A_{n,:} \\cdot B & - \\\\\n\\end{bmatrix}\\\\\n\\end{align}\\]"
  },
  {
    "objectID": "tics579/clase-P1.html#producto-matriz-matriz-propiedades-útiles",
    "href": "tics579/clase-P1.html#producto-matriz-matriz-propiedades-útiles",
    "title": "TICS-579-Deep Learning",
    "section": "Producto Matriz-Matriz: Propiedades Útiles",
    "text": "Producto Matriz-Matriz: Propiedades Útiles\n\n\n\n\n\n\n\n\nSupongamos el siguiente caso:\n\n\n\\[A = \\begin{bmatrix}\n4 & 3 & 2 \\\\\n2 & 2 & 4 \\\\\n4 & 4 & 4\n\\end{bmatrix}\nB = \\begin{bmatrix}\n1 & 2 & 1 \\\\\n2 & 3 & 4 \\\\\n4 & 3 & 1 \\\\\n\\end{bmatrix}\n\\]\n\\[\nAB = \\begin{bmatrix}\n18 & 23  & 18\\\\\n22 & 14  & 22\\\\\n28 & 32  & 24\\\\\n\\end{bmatrix}\n\\]\n\n\n\n\n\n\n\n\n\n\nPermutación de Columnas en Post-multiplicación\n\n\nSi permuto columnas de \\[B^* = \\begin{bmatrix}\n1 & 1 & 2 \\\\\n2 & 4 & 3 \\\\\n4 & 1 & 3 \\\\\n\\end{bmatrix}\nAB^*= \\begin{bmatrix}\n18 & 18 & 23\\\\\n22 & 22 & 14\\\\\n28 & 24 & 32\\\\\n\\end{bmatrix}\n\\]\n\n\n\n\n\n\n\n\n\n\n\nRecordar que la multiplicación no es conmutativa. \\(AB \\neq BA\\)."
  },
  {
    "objectID": "tics579/clase-P1.html#otros-productos",
    "href": "tics579/clase-P1.html#otros-productos",
    "title": "TICS-579-Deep Learning",
    "section": "Otros Productos",
    "text": "Otros Productos\n\n\n\n\n\n\n\n\nHadamard Product\n\n\nCorresponde a otra operación que permite multiplicar 2 matrices si y sólo si tienen el mismo tamaño. La multiplicación se realiza elemento a elemento.\n\\[A = \\begin{bmatrix}\n2 & 3 & 0 \\\\\n1 & 0 & 7\n\\end{bmatrix}\\]\n\\[B = \\begin{bmatrix}\n2 & 5 & 1 \\\\\n2& 3 & 7\n\\end{bmatrix}\\]\n\\[A \\odot B = \\begin{bmatrix} 4 & 15 & 0 \\\\ 2 & 0 & 49\\end{bmatrix}\\]\n\n\n\n\n\n\n\n\n\n\nOuter Product (Producto Externo)\n\n\nCorresponde a otra operación que permite multiplicar 2 vectores. El resultado es una matriz de tamaño \\(d1 \\times d2\\) donde \\(d1\\) es la dimensión del primer vector y \\(d2\\) es la dimensión del segundo vector.\n\\[\\bar{x} = \\begin{bmatrix}\n2 \\\\\n-1 \\\\\n3\n\\end{bmatrix} \\, \\bar{y} = \\begin{bmatrix}\n4 \\\\\n1 \\\\\n5 \\\\\n-2\n\\end{bmatrix}\\]\n\\[\n\\begin{align}\n\\bar{x} \\otimes \\bar{y} = \\bar{x} \\cdot \\bar{y}^T &= \\begin{bmatrix}\n2 \\cdot 4 & 2 \\cdot 1 & 2 \\cdot 5 & 2 \\cdot -2 \\\\\n-1 \\cdot 4 & -1 \\cdot 1 & -1 \\cdot 5 & -1 \\cdot -2 \\\\\n3 \\cdot 4 & 3 \\cdot 1 & 3 \\cdot 5 & 3 \\cdot -2\n\\end{bmatrix} \\\\\n&= \\begin{bmatrix}\n8 & 2 & 10 & -4 \\\\\n-4 & -1 & -5 & 2 \\\\\n12 & 3 & 15 & -6\n\\end{bmatrix}\n\\end{align}\n\\]"
  },
  {
    "objectID": "tics579/clase-P1.html#batch-product",
    "href": "tics579/clase-P1.html#batch-product",
    "title": "TICS-579-Deep Learning",
    "section": "Batch Product",
    "text": "Batch Product\nEste tipo de operación es bastante poco común en otras áreas, pero extremadamente común en Deep Learning.\n\n\n\n\n\n\nEjemplo\n\n\n¿Qué pasa si queremos calcular la multiplicación de un tensor de dimensiones (2, 3, 2) y otra de (2, 2, 4)?\n\nEl resultado es un tensor de dimensiones (2, 3, 4). Podemos interpretarlo como que se harán 2 multiplicaciones a matrices de (3,2) y (2,4) respectivamente (las cuales son compatibles).\n\n\n\n\n\n\n\n\\[A = \\begin{bmatrix}\n\\begin{bmatrix}\n2 & 2 \\\\\n2 & 3 \\\\\n1 & 2 \\\\\n\\end{bmatrix} \\\\\n\\begin{bmatrix}\n1 & 2 \\\\\n4 & 1 \\\\\n1 & 4 \\\\\n\\end{bmatrix} \\\\\n\\end{bmatrix}\nB = \\begin{bmatrix}\n\\begin{bmatrix}\n4 & 3 & 4 & 4 \\\\\n3 & 3 & 3 & 2 \\\\\n\\end{bmatrix} \\\\\n\\begin{bmatrix}\n4 & 2 & 4 & 4 \\\\\n4 & 1 & 1 & 4 \\\\\n\\end{bmatrix}\n\\end{bmatrix}\n\\]\n\\[\nAB = \\begin{bmatrix}\n\\begin{bmatrix}\n14 & 12 & 14 & 12 \\\\\n17 & 15 & 17 & 14 \\\\\n10 & 9 & 10 & 8 \\\\\n\\end{bmatrix} \\\\\n\\begin{bmatrix}\n12 & 4 & 6 & 12 \\\\\n20 & 9 & 17 & 20 \\\\\n20 & 6 & 8 & 20 \\\\\n\\end{bmatrix} \\\\\n\\end{bmatrix}\n\\]\n\n\n\n\n\n\n\n\nImportante\n\n\n\nEs importante notar que para que esta multiplicación sea válida. Las dimensiones de las matrices internas deben ser compatibles.\nEl Batch Size tiene que ser idéntico."
  },
  {
    "objectID": "tics579/clase-9.html#datos-secuenciales",
    "href": "tics579/clase-9.html#datos-secuenciales",
    "title": "TICS-579-Deep Learning",
    "section": "Datos Secuenciales",
    "text": "Datos Secuenciales\n\n\n\n\n\n\nHasta ahora, asumimos que todos nuestros datos son i.i.d. Pero en la realidad existen datos que contienen una secuencia temporal y que debe ser considerada al momento de modelarlos.\n\n\n\n\n\nTime Series\n\n\n\n\n\nAudio\n\n\n\n\n\n\nText\n\n\n\n\n\nGenoma"
  },
  {
    "objectID": "tics579/clase-9.html#datos-secuenciales-1",
    "href": "tics579/clase-9.html#datos-secuenciales-1",
    "title": "TICS-579-Deep Learning",
    "section": "Datos Secuenciales",
    "text": "Datos Secuenciales\n\nTambién pudiesen existir datos “multimodales”, donde por ejemplo, se combinan secuencias con imágenes.\n\n\n\nImage Time Series\n\n\n\n\n\n\nVideo"
  },
  {
    "objectID": "tics579/clase-9.html#modelamiento-de-una-secuencia",
    "href": "tics579/clase-9.html#modelamiento-de-una-secuencia",
    "title": "TICS-579-Deep Learning",
    "section": "Modelamiento de una secuencia",
    "text": "Modelamiento de una secuencia\n\n\n\n\n\n\n\n\n\n\n\nEn este caso consideramos que \\(x_t\\) corresponde a la instancia de un dato en el tiempo \\(t\\) asociado a un target \\(y_t\\). Además tenemos cierta dependencia entre los elementos en \\(t\\) y \\(t+1\\).\n\n\n\n\n\n\n\n\n\nEs importante notar que \\(x_t\\) no tiene por qué ser un escalar, sino que puede ser un vector de constituidos por varios features.\n\n\n\n\n\n\n\n\n\nOjo\n\n\nUn dato corresponde una secuencia de elementos, por lo tanto \\(x = [x_1,x_2,...x_L]\\), donde \\(L\\) es el largo de la secuencia."
  },
  {
    "objectID": "tics579/clase-9.html#modelamiento-de-una-secuencia-ejemplo",
    "href": "tics579/clase-9.html#modelamiento-de-una-secuencia-ejemplo",
    "title": "TICS-579-Deep Learning",
    "section": "Modelamiento de una secuencia: Ejemplo",
    "text": "Modelamiento de una secuencia: Ejemplo\nPart of Speech Tagging\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEs importante recalcar que la correcta descripción de cada palabra depende del contexto en el que se está usando y no sólo la palabra en sí misma."
  },
  {
    "objectID": "tics579/clase-9.html#speech-recognition",
    "href": "tics579/clase-9.html#speech-recognition",
    "title": "TICS-579-Deep Learning",
    "section": "Speech Recognition",
    "text": "Speech Recognition\n\nEl contexto ayuda a interpretar cuál es la manera correcta de interpretar el sonido emitido."
  },
  {
    "objectID": "tics579/clase-9.html#recurrent-neural-networks",
    "href": "tics579/clase-9.html#recurrent-neural-networks",
    "title": "TICS-579-Deep Learning",
    "section": "Recurrent Neural Networks",
    "text": "Recurrent Neural Networks\n\nRNN\n\nCorresponden a un tipo de red neuronal diseñada para procesar secuencias de datos manteniendo en memoria los inputs previos. A diferencia de los otros tipos de redes que procesan datos de manera independiente, acá existen conexiones cíclicas que permiten retener información en el tiempo.\n\n\nEjemplo\n\n\n\n\n\n\n\n\n\n\n\nPros\n\n\n\nPueden tomar secuencias de distinto tamaño (Largo) como predictores de un problema.\nToman como antecedentes los puntos pasados como referencia para las predicciones futuras.\n\n\n\n\n\n\n\nCons\n\n\n\nSe van complicando a medida que las secuencias son cada vez más largas.\nVanishing/Exploding Gradients Problem."
  },
  {
    "objectID": "tics579/clase-9.html#rnns",
    "href": "tics579/clase-9.html#rnns",
    "title": "TICS-579-Deep Learning",
    "section": "RNNs",
    "text": "RNNs\n\n\n\n\n\n\n\n\n\n\n\n\n\nSupongamos los siguientes parámetros para nuestro modelo:\n\n\\(W_1\\) = 1.8\n\\(W_2\\) = -0.5\n\\(W_3\\) = 1.1\n\\(sigma(\\cdot) = ReLU(\\cdot)\\)\nConsideraremos los bias como 0.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOjo\n\n\nEsta es solamente una secuencia de largo 9."
  },
  {
    "objectID": "tics579/clase-9.html#unrolled-rnn",
    "href": "tics579/clase-9.html#unrolled-rnn",
    "title": "TICS-579-Deep Learning",
    "section": "Unrolled RNN",
    "text": "Unrolled RNN\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEl “Unrollment” o el desenrollar la Red, se refiere a generar copias de las redes que irán recibiendo las salidas de las capas en un \\(t\\) anterior. Estos valores, conocidos como “hidden state”, irán alimentando las siguientes copias considerando los casos anteriores. Sólo el último output es el que nos interesa para la predicción.\n\n\n\n\n\n\n\n\n\n\n\nTodos los parámetros de la red (Weights and Biases), son compartidos por cada una de las copias realizadas.\nSe realizarán tantas copias como el largo de la secuencia. Esto permite que pase toda la secuencia “de una sola vez”.\nSin importar cuantas copias se realicen, el número de parámetros NO aumenta."
  },
  {
    "objectID": "tics579/clase-9.html#rnn-formalmente",
    "href": "tics579/clase-9.html#rnn-formalmente",
    "title": "TICS-579-Deep Learning",
    "section": "RNN formalmente",
    "text": "RNN formalmente\n\n\n\n\n\n\n\ndonde:\n\\[h_t = f(W_{hh} \\cdot h_{t-1} + W_{hx} \\cdot x_t + b_h)\\] \\[y_t = g(W_{yh}\\cdot h_{t} + b_y)\\]\n\n\n\\(h_t \\in \\mathbb{R}^d\\)\n\\(x_t \\in \\mathbb{R}^n\\)\n\\(y_t \\in \\mathbb{R}^k\\)\n\n\n\n\\(W_{hh} \\in \\mathbb{R}^{d \\times d}\\)\n\\(W_{hx} \\in \\mathbb{R}^{d \\times n}\\)\n\\(W_{yh} \\in \\mathbb{R}^{k \\times d}\\)\n\\(b_h \\in \\mathbb{R}^d\\)\n\\(b_y \\in \\mathbb{R}^k\\)"
  },
  {
    "objectID": "tics579/clase-9.html#stacking-rnns",
    "href": "tics579/clase-9.html#stacking-rnns",
    "title": "TICS-579-Deep Learning",
    "section": "Stacking RNNs",
    "text": "Stacking RNNs\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEs posible juntar varias capas recurrentes, para que las salidas de una alimenten un siguiente Hidden State, y que luego de algunas capas efectivamente se llegue a las salidas de interés.\n\n\n\n\n\n\n\n\n\nA diferencia de otro tipos de Redes como las Convolucionales o FFN, la profundidad en este tipo de redes es de bastante menos impacto.\n\n\n\n\n\n\n\n\n\nOJO\n\n\nNo existen salidas intermedias, sino que los Hidden States de capas anteriores son utilizados directamente como inputs de los hidden states posteriores."
  },
  {
    "objectID": "tics579/clase-9.html#vanishingexploding-gradients",
    "href": "tics579/clase-9.html#vanishingexploding-gradients",
    "title": "TICS-579-Deep Learning",
    "section": "Vanishing/Exploding Gradients",
    "text": "Vanishing/Exploding Gradients\n\n\n\n\n\n\n\nEntre más larga se la secuencia (más unrolls se realicen), más difícil es entrenar la red.\n\n\n\n\n\n\n\n\n\n\n\n\n\\[Output = Input \\times W_2^{N_{Unroll}}\\]\n\nSi \\(W_2\\) corresponde a parámetros muy pequeños (menores a 1), entonces, el gradiente se desvanecerá (vanishing gradient).\nSi \\(W_2\\) corresponde a parámetros muy grandes (mayores a 1), entonces, el gradiente explotará (exploding gradient).\n\n\n\n\n\n\n\nEsto ocurre ya que si intentamos derivar la función de pérdida con respecto a alguno de los parámetros, eventualmente \\(W_2^{N_unroll}\\) aparecerá en la ecuación, provocando dicho efecto en el gradiente.\n\n\n\n\n\n\n\n\n\nEsta es quizás la razón más importante del por qué Vanilla RNNs son usadas rara vez en la práctica. Lo importante histórica de este tipo de redes es que abrieron las puertas a sistemas más modernos que hoy en día sí son usados (LSTMs, y Transformers)."
  },
  {
    "objectID": "tics579/clase-9.html#lstm-formalmente",
    "href": "tics579/clase-9.html#lstm-formalmente",
    "title": "TICS-579-Deep Learning",
    "section": "LSTM: Formalmente",
    "text": "LSTM: Formalmente\n\nLSTMs\n\nEs un tipo de Red Neuronal Recurrente que está diseñada para capturar dependencias de largo rango en datos secuenciales abordando algunas de las limitaciones de las RNNs tradicionales, tales como el vanishing gradient problem.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCorresponde a la misma forma de una RNN, sólo que el “hidden state” se divide en dos partes: \\(h_t\\) y \\(C_t\\), llamados “hidden state” y “cell state” respectivamente.\n\n\n\n\n\n\n\n\n\nLa manera de calcular el “Hidden State” y el “Cell State” es muchísimo más engorrosa.\n\n\n\n\n\n\n\n\n\n\nSpoiler: El Hidden y Cell State está compuesto por multiples set de parámetros a los cuales se les dan los nombres de forget gate, input gate, cell gate y output gate. Su interpretabilidad nunca ha logrado ser completamente explicada."
  },
  {
    "objectID": "tics579/clase-9.html#long-short-term-memory-rnns-1997",
    "href": "tics579/clase-9.html#long-short-term-memory-rnns-1997",
    "title": "TICS-579-Deep Learning",
    "section": "Long Short-Term Memory RNNs (1997)",
    "text": "Long Short-Term Memory RNNs (1997)\n\n\n\n\n\n\n\n\nLa LSTM está regida por las siguientes ecuaciones:\n\\[i_t = \\sigma(W_{ii}x_t) + b_{ii} + W_{hi}h_{t-1} + b_{hi}\\]\n\\[f_t = \\sigma(W_{if}x_t + b_{if} + W_{hf}h_{t-1} + b_{hf})\\]\n\\[g_t = tanh(W_{ig}x_t + b_{ig} + W_{hg}h_{t-1} + b_{hg})\\]\n\\[o_t = \\sigma(W_{io}x_t + b_{io} + W_{ho}h_{t-1} + b_{ho})\\]\n\\[c_t = f_t \\odot c_{t-1} + i_t \\odot g_t\\]\n\\[h_t = o_t \\odot tanh(c_t)\\]\n\n\n\n\n\n\n\n\nTodas estos elementos \\(i_t,f_t, g_t,o_t, c_t,h_t \\in \\mathbb{R}^d\\), donde \\(d\\) corresponde a la “hidden dimension”."
  },
  {
    "objectID": "tics579/clase-9.html#lstm-forget-gate",
    "href": "tics579/clase-9.html#lstm-forget-gate",
    "title": "TICS-579-Deep Learning",
    "section": "LSTM: Forget Gate",
    "text": "LSTM: Forget Gate\n\n\n\n\n\n\n\n\n\nForget Gate\n\n\n\nCorresponde a una red neuronal que indica qué informacion debe ser descartada del Cell State.\nBásicamente combina la secuencia en el tiempo t y el hidden state anterior.\nLuego se le aplica una Sigmoide que indicará el porcentaje a olvidar.\n\n\\[f_t = \\sigma(W_{if}x_t + b_{if} + W_{hf}h_{t-1} + b_{hf})\\]"
  },
  {
    "objectID": "tics579/clase-9.html#lstm-input-y-cell-gate",
    "href": "tics579/clase-9.html#lstm-input-y-cell-gate",
    "title": "TICS-579-Deep Learning",
    "section": "LSTM: Input y Cell Gate",
    "text": "LSTM: Input y Cell Gate\n\n\n\n\n\n\n\n\n\nInput Gate\n\n\n\nControla Cuánta información debe ingresar al Cell State.\n\n\\[i_t = \\sigma(W_{ii}x_t) + b_{ii} + W_{hi}h_{t-1} + b_{hi}\\]\n\n\n\n\n\n\n\n\nCell Gate\n\n\n\nRepresenta los potenciales nuevos candidatos a entrar al Cell State.\n\n\\[g_t = tanh(W_{ig}x_t + b_{ig} + W_{hg}h_{t-1} + b_{hg})\\]"
  },
  {
    "objectID": "tics579/clase-9.html#output-gate-y-hidden-state",
    "href": "tics579/clase-9.html#output-gate-y-hidden-state",
    "title": "TICS-579-Deep Learning",
    "section": "Output Gate y Hidden State",
    "text": "Output Gate y Hidden State\n\n\n\n\n\n\n\n\n\nOutput Gate\n\n\n\nDetermina qué “porcentaje” de información del “Cell State” debe salir como “Hidden State” para el tiempo \\(t\\) actual.\n\\[o_t = \\sigma(W_{io}x_t + b_{io} + W_{ho}h_{t-1} + b_{ho})\\]\n\n\n\n\n\n\n\n\n\nHidden State\n\n\n\nCorresponde a las dependencias del tiempo anterior que se van traspasando en cada time step.\nAdicionalmente el Hidden State corresponde a la salida de la red para el tiempo \\(t\\).\n\n\\[h_t = o_t \\odot tanh(c_t)\\]"
  },
  {
    "objectID": "tics579/clase-9.html#cell-state",
    "href": "tics579/clase-9.html#cell-state",
    "title": "TICS-579-Deep Learning",
    "section": "Cell State",
    "text": "Cell State\n\n\n\n\n\n\n\n\n\nCell State\n\n\nRepresenta la principal innovación de este tipo de redes ya que permite recordar dependencias de largo plazo (es decir time steps anteriores en secuencias largas). Esto ya que el Cell State puede avanzar casi sin interacciones lineales (no hay parámetros que influyen en ella, por lo que no es afectada por problemas de gradientes).\n\\[c_t = f_t \\odot c_{t-1} + i_t \\odot g_t\\]"
  },
  {
    "objectID": "tics579/clase-9.html#gated-recurrent-unit-2014",
    "href": "tics579/clase-9.html#gated-recurrent-unit-2014",
    "title": "TICS-579-Deep Learning",
    "section": "Gated Recurrent Unit (2014)",
    "text": "Gated Recurrent Unit (2014)\n\nGRU\n\nCorresponde a otro tipo de Arquitectura Recurrente, similar a la LSTM, pero con una estructura más simplificada en la cuál se mantiene sólo un “Hidden State” y se tienen menos gates.\n\n\n\n\n\n\n\n\n\n\n\n\nHidden State\n\n\nRepresenta la potencial actualización del “Hidden State”.\n\\[h_t = (1-z_t) \\odot n_t + z_t \\odot h_{t-1}\\]\n\n\n\n\n\n\n\nUpdate Gate\n\n\nControla qué porcentaje del “hidden state” previo se lleva al siguiente paso.\n\\[z_t = \\sigma(W_{iz} x_t + b_{iz} + W_{hz}h_{t-1} + b_{hz})\\]\n\n\n\n\n\n\nReset Gate\n\n\nControla cuánta información del pasado se debe olvidar.\n\\[r_t = \\sigma(W_{ir} x_t + b_{ir} + W_{hr}h_{t-1} + b_{hr})\\]\n\n\n\n\n\n\nCandidate Hidden State\n\n\nRepresenta la potencial actualización del “Hidden State”.\n\\[n_t = tanh(W_{in} x_t + b_{in} + r_t \\odot (W_{hn} h_{t-1} + b_{hn}))\\]"
  },
  {
    "objectID": "tics579/clase-9.html#bidirectional-rnns",
    "href": "tics579/clase-9.html#bidirectional-rnns",
    "title": "TICS-579-Deep Learning",
    "section": "Bidirectional RNNs",
    "text": "Bidirectional RNNs\nExisten ocasiones en las que se requiere no sólo el contexto de los tiempos anteriores, sino también de los posteriores. Por ejemplo, problemas de traducción.\n\nPara ello existen las redes bidireccionales, en la cual se agrega una segunda capa pero que mueve los hidden state en el otro sentido.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEn este caso la capa amarilla será la encargada de detectar dependencias del pasado.\nMientras que la capa verde será la encargada de traer dependencias desde el futuro.\n\n\n\n\n\n\n\n\n\n\nLos hidden states pueden ser capas Vanilla RNN, LSTM o GRUs."
  },
  {
    "objectID": "tics579/clase-9.html#pytorch-layers",
    "href": "tics579/clase-9.html#pytorch-layers",
    "title": "TICS-579-Deep Learning",
    "section": "Pytorch Layers",
    "text": "Pytorch Layers\nnn.RNN(input_size, hidden_size, num_layers=1, batch_first=False, \n        dropout=0, bidirectional=False, nonlinearity=\"tanh\")\nnn.LSTM(input_size, hidden_size, num_layers=1, batch_first=False, \n        dropout=0, bidirectional=False) \nnn.GRU(input_size, hidden_size, num_layers=1, batch_first=False, \n        dropout=0, bidirectional=False) \n\n\ninput_size: Corresponde al número de features de la secuencia.\nhidden_size: Corresponde al número de dimensiones del hidden state.\nnum_layers: Corresponderá al número de capas recurrentes a apilar, por defecto 1.\nbatch_first: Este siempre deben fijarlo como True, de esa manera se espera que los tensores a recibir siempre tengan el batch como primera dimensión. Por defecto False.\n\nLuego RNNs esperan tensores de tamaño \\((N,L,H_{in})\\). Donde \\(N\\) es el batch_size, \\(L\\) es el largo de secuencia y \\(H_in\\) es el input_size.\n\ndropout: Cantidad de dropout a aplicar a la salida de cada capa, excepto la última. Por defecto 0.\nbidirectional: Indica si se hace la red Bidireccional o no. Por defecto False.\nnonlinearity: Función de activación a utilizar para activar cada matriz de peso. Puede ser “tanh” o “relu”. Sólo para Vanilla RNN."
  },
  {
    "objectID": "tics579/clase-6.html#limitaciones-de-las-ffn",
    "href": "tics579/clase-6.html#limitaciones-de-las-ffn",
    "title": "TICS-579-Deep Learning",
    "section": "Limitaciones de las FFN",
    "text": "Limitaciones de las FFN\nSin duda las Redes Feed Forward son una herramienta poderosa para resolver problemas de clasificación y regresión. Sin embargo, presentan ciertas limitaciones cuando se aplican a datos con estructuras espaciales o temporales, como imágenes o secuencias de texto.\n\n\n\n⚠️ Pérdida de estructura espacial o secuencial\n\n\nCada registro es considerado de manera independiente, sin tener en cuenta la relación espacial o secuencial entre los datos.\n\n\n\n\n\n\n☢️ Gran cantidad de parámetros\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNúmero de Parametros\n(Imagen: 28x28=784 píxeles):\n\n\\(W_1 = 784 \\cdot 256 + 256 = 200960\\)\n\\(W_2 = 256 \\cdot 128 + 128 = 32896\\)\n\\(W_3 = 128 \\cdot 10 + 10 = 1290\\)\nTotal = 235,146.\n\n\n\n\n\n\n\n\n¿Y si tengo una imágen de \\(512 \\times 512\\)? 67,143,306 de parámetros."
  },
  {
    "objectID": "tics579/clase-6.html#limitaciones-de-las-ffn-1",
    "href": "tics579/clase-6.html#limitaciones-de-las-ffn-1",
    "title": "TICS-579-Deep Learning",
    "section": "Limitaciones de las FFN",
    "text": "Limitaciones de las FFN\n\n\n\n🚧 Ineficiencia en el aprendizaje de patrones locales\n\n\n\nTranslation Invariance\n\nSe refiere a la capacidad de poder detectar un patrón/objeto en diferentes posiciones de la imágen.\n\n\nProblema: Un perrito centrado, desplazado a la izquierda o a la derecha debería seguir siendo reconocido como un perrito. Para una FFN, las features que describen los perritos desplazados son completamente distintos."
  },
  {
    "objectID": "tics579/clase-6.html#limitaciones-de-las-ffn-2",
    "href": "tics579/clase-6.html#limitaciones-de-las-ffn-2",
    "title": "TICS-579-Deep Learning",
    "section": "Limitaciones de las FFN",
    "text": "Limitaciones de las FFN\n\n\n\n⛔ Escalabilidad Limitada\n\n\nSu alto número de parámetros sumado a la incapacidad de capturar patrones espaciales o temporales hace que las FFN no escalen bien a datos complejos como imágenes de alta resolución o secuencias largas haciendo que su rendimiento disminuya considerablemente y no sean aplicables por sí solas a casos reales.\n\n\n\n\n\nImagenes actuales cada vez más grandes\n\n\n\n\n\n\nTextos actuales cada vez más largos"
  },
  {
    "objectID": "tics579/clase-6.html#imágenes",
    "href": "tics579/clase-6.html#imágenes",
    "title": "TICS-579-Deep Learning",
    "section": "Imágenes",
    "text": "Imágenes\n\n\n\nImagen\n\nDefiniremos una imágen como un Tensor de Orden 3. Normalmente cada dimensión representa H, W y C (Altura, Ancho y Canales).\n\n\n\n\n\nConvención en Pytorch\n\n\nPytorch utiliza la convención (C, H, W) para representar imágenes, donde C es el número de canales, H es la altura y W es el ancho de la imagen. Es decir, un Tensor de Dimensiones (3, 512, 512)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLa convención más común es utilizar imágenes de 24-bits, es decir 3 canales de \\(2^8\\) valores (8-bits por canal). Es por eso que el valor de los píxeles va de 0 a 255 y representan la intensidad del color del canal que representan."
  },
  {
    "objectID": "tics579/clase-6.html#imágenes-1",
    "href": "tics579/clase-6.html#imágenes-1",
    "title": "TICS-579-Deep Learning",
    "section": "Imágenes",
    "text": "Imágenes\n\n\nLibrerías como PIL u OpenCV permiten importar imágenes en Python. Ambas usan la convención de \\((H,W,C)\\), la diferencia está en el orden de los canales. PIL utiliza la convención RGB, mientras que OpenCV utiliza BGR por lo que se necesitan algunas transformaciones adicionales.\n\n\n\n\n\n\n\n\n\n\nEjemplo para importar imágenes con PIL y Pytorch\nfrom PIL import Image\nimport numpy as np\nimport torch\npath = \"path/to/imagen.png\"\nimg = Image.open(path)\n\n# Convierte a Tensor y cambia a (C,H,W)\ntorch_image= torch.from_numpy(np.array(img)).permute(2,0,1)  \ntorch_image.shape\n(3,1200,1200)\nimport matplotlib.pyplot as plt\n\n## Imágen en canal Rojo\nplt.imshow(torch_image[0].numpy(), cmap=\"Reds\")\nplt.axis(\"off\")\nplt.show()\n## Imágen en canal Verde\nplt.imshow(torch_image[1].numpy(),cmap=\"Greens\")\nplt.axis(\"off\")\nplt.show()\n## Imágen en canal Azul\nplt.imshow(torch_image[2].numpy(), cmap=\"Blues\")\nplt.axis(\"off\")\nplt.show()"
  },
  {
    "objectID": "tics579/clase-6.html#batch-de-imágenes",
    "href": "tics579/clase-6.html#batch-de-imágenes",
    "title": "TICS-579-Deep Learning",
    "section": "Batch de Imágenes",
    "text": "Batch de Imágenes\n\n\n\n\n\nConjunto/Set/Batch de Imágenes\n\n\nSe define como un Tensor de Orden 4. En Pytorch esto se representa como N, C, H, W (Número de Imágenes, Canales, Altura y Ancho).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLuego un Tensor de Dimensiones (32,3,224,512) implica que tenemos 32 imágenes RGB de dimensiones \\(224\\times512\\).\n\n\n\n\n## Simulación de 2 imágenes RGB de 5x5 píxeles\ntorch.randint(0,256, (2,3,5,5))\n\ntensor([[[[248, 240, 146,  73, 228],\n          [ 79, 125, 191, 203, 133],\n          [202,  12, 237, 109,  62],\n          [133, 227, 148,  78, 229],\n          [121, 247, 202,  51,   3]],\n\n         [[253,  28,  20, 144, 255],\n          [115, 132, 114,  45, 164],\n          [ 57, 238, 117, 250,  41],\n          [ 58,  73,  29, 253, 240],\n          [246,  84,  93,   2, 145]],\n\n         [[ 83,   4, 144, 126, 202],\n          [ 98, 235,  55,  83, 104],\n          [ 21, 185,  27, 102, 117],\n          [255, 133,  23,  83, 150],\n          [ 49, 152,  81, 233,  98]]],\n-----------------------------------------------\n        [[[216,  92, 251, 214, 178],\n          [252,  48,  88,  82,  79],\n          [168, 208, 223,   9, 169],\n          [145, 148, 254, 128, 156],\n          [238, 175, 233, 136, 118]],\n\n         [[112,  68, 143,  93, 150],\n          [ 32, 103,  97,  93, 223],\n          [205,  56,  90,  24, 108],\n          [ 13, 135,  98,  20,  93],\n          [ 20,  91,  37,  81,  10]],\n\n         [[109, 145,  90, 243,  63],\n          [103, 134, 130,  11,  72],\n          [132, 163, 153,  26, 255],\n          [ 45, 228,  26, 169, 212],\n          [ 34, 211, 229,  82, 201]]]])"
  },
  {
    "objectID": "tics579/clase-6.html#redes-convolucionales-definición-e-inspiración",
    "href": "tics579/clase-6.html#redes-convolucionales-definición-e-inspiración",
    "title": "TICS-579-Deep Learning",
    "section": "Redes Convolucionales: Definición e Inspiración",
    "text": "Redes Convolucionales: Definición e Inspiración\n\nRedes Convolucionales (CNN)\n\nSon un tipo de red neuronal cuyos parámetros entrenables son filtros (también llamados Kernels) que aprenden a detectar patrones en los datos de entrada.\n\n\nEl resultado de una Convolucional es un feature map, el cual representa la presencia y localización de ciertos patrones visuales.\n\n\n\n\n\n\n\n\nExiste el mito de que las Redes Convolucionales se inspiraron en el funcionamiento del Cortex Visual humano. No sé si es tan así.\nEl mito dice que las CNNs fueron diseñadas para imitar el cortex visual humano. Esto viene de los trabajos de Hubel y Wiesel (década de 1960), que estudiaron cómo las neuronas en la corteza visual de gatos respondían a estímulos:\n\nDescubrieron neuronas simples que respondían a líneas en cierta orientación y posición.\nDescubrieron neuronas complejas que respondían a patrones similares, pero en distintas posiciones (invarianza local)."
  },
  {
    "objectID": "tics579/clase-6.html#redes-convolucionales-definición-e-inspiración-1",
    "href": "tics579/clase-6.html#redes-convolucionales-definición-e-inspiración-1",
    "title": "TICS-579-Deep Learning",
    "section": "Redes Convolucionales: Definición e Inspiración",
    "text": "Redes Convolucionales: Definición e Inspiración\n\n\n\n\n\n\n¿Por qué necesitamos las Redes Convolucionales? Evitar la sobreparametrización. ¿Por qué esto es un problema?\n\n\n\n\n\n\n🔔 Importancia\n\n\nNo es exagerado afirmar que las CNNs han sido la arquitectura más influyente en Deep Learning, ya que han impulsado avances importantes en tareas de visión por computador, como clasificación de imágenes, detección de objetos y segmentación semántica. Además, contribuyeron a que el Deep Learning ganara popularidad en la industria tecnológica y superara la época conocida como el AI Winter.\n\n\n\n\n\n🗓️ Algunos hitos importantes:\n\n1990: Yann LeCun et al. propone uno de los primeros intentos de CNN, el cual va agregando features más simples en features más complejas progresivamente.\n1998: Yann LeCun, propone LeNet-5 con 2 redes convolucionales y 3 FFN.\n2012: Krizhevsky, Sutskever y Hinton proponen AlexNet (5 capas convolucionales y 3 FFN), el cual obtiene SOTA performance en ImageNet."
  },
  {
    "objectID": "tics579/clase-6.html#convolutional-neural-network-cnns",
    "href": "tics579/clase-6.html#convolutional-neural-network-cnns",
    "title": "TICS-579-Deep Learning",
    "section": "Convolutional Neural Network (CNNs)",
    "text": "Convolutional Neural Network (CNNs)\n\n\n\nArchitectura General\n\n\nUna Convolutional Neural Network (CNN) está formada por múltiples capas que colaboran para identificar y extraer características significativas de las imágenes, con el fin de clasificarlas o detectar objetos dentro de ellas.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFeature Extractor - Encoder - Backbone\n\n\nCorresponde al bloque en el que se detectan características o patrones relevantes de la imagen. En este bloque es donde se aplican normalmente las operaciones de Convolución y Pooling.\n\n\n\n\n\n\nFlatten\n\n\nCorresponde a una operación intermedia que aplana los feature maps generadas para ser utilizados como features de entrada para ser utilizados por la parte final de la red.\n\n\n\n\n\n\nPrediction Head - Head - MLP\n\n\nCorresponde a una FFN que tomará las features aprendidas por la CNN y generará una predicción."
  },
  {
    "objectID": "tics579/clase-6.html#la-convolución",
    "href": "tics579/clase-6.html#la-convolución",
    "title": "TICS-579-Deep Learning",
    "section": "La Convolución",
    "text": "La Convolución\n\n\nConvolución\n\nCorresponde a una operación que permite extraer feature maps, donde un filtro o kernel se desplaza sobre distintas secciones de los datos, ya sea una secuencia, una imagen o un video, para capturar sus patrones más relevantes.\n\n\n\n\n\n\n☝️Atención\n\n\nEsto es nuevamente un término marketero, porque no es una Convolucional real, sino una operación llamada Cross Correlation.\n\n\n\n\n\n\n\n\n\n\nFeature Map\n\nCorresponde a la salida de una convolución (equivalente a la Activación) y es un nuevo tensor que captura ciertas características del dato (secuencia, imagen o video). Cuando se trata de imágenes, captura features como bordes, cambios de textura, color, formas, o elementos más pequeños.\n\n\n\n\n\n\n\n\n\nEs importante notar que los features maps son de una tamaño menor a la entrada debido a la operación de Convolución.\n\n\n\n\n\n\n\n\n\nSe obtendrán tantos feature maps como filtros se apliquen. Esto es otro hiperparámetro de la Red Convolucional que se conoce como los canales de salida o out_channels."
  },
  {
    "objectID": "tics579/clase-6.html#el-filtro-o-kernel",
    "href": "tics579/clase-6.html#el-filtro-o-kernel",
    "title": "TICS-579-Deep Learning",
    "section": "El filtro o Kernel",
    "text": "El filtro o Kernel\n\n\nGaussian Blur\n\n\n\n\n\nLíneas Horizontales\n\n\n\n\n\nBordes\n\n\n\n\n\n\n\n\n\n\n\n\nKernel\n\n\nCorresponde a una matriz pequeña que permite detectar patrones específicos en la imagen al aplicarse de manera móvil sobre ella. Estos Kernel solías estudiarse y diseñarse manualmente para tareas específicas como detección de bordes, desenfoque, realce de contraste, entre otros.\nEn una red convolucional, el kernel es un conjunto de pesos que se ajustan durante el proceso de entrenamiento para identificar características relevantes en las imágenes. Es decir, la CNN aprende qué Kernels son más importantes para la tarea que se está resolviendo.\n\n\n\n\n\n\n\n\n\nEl Kernel se aplica a todos los canales a la vez, lo cuál inicialmente lo hace ver como una operación bastante costosa computacionalmente.\n\n\n\n\n\n\n\n\n\nEl Kernel introduce el primer hiperparámetro de las CNN que es el Kernel Size. En general son cuadrados, y de dimensión impar."
  },
  {
    "objectID": "tics579/clase-6.html#feature-maps",
    "href": "tics579/clase-6.html#feature-maps",
    "title": "TICS-579-Deep Learning",
    "section": "Feature Maps",
    "text": "Feature Maps\n\n\nFeature Map\n\nCorresponde a la salida de una convolución (equivalente a la Activación) y es un nuevo tensor que captura ciertas características del dato (secuencia, imagen o video). Cuando se trata de imágenes, captura features como bordes, cambios de textura, color, formas, o elementos más pequeños.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBásicamente los feature maps son imágenes que resaltan ciertos patrones aprendidos por los kernels.\n\n\n\n\n\n\n\n\n\nA medida que avanzamos en las capas convolucionales, los feature maps tienden a capturar patrones más complejos y abstractos.\n\n\n\n\n\n\n\n\n\nCada feature map es de tamaño más pequeño que la imagen original, pero contiene información más relevante para la tarea de clasificación o detección.\n\n\n\n\n\n\n\n\n\nSe obtendrán tantos feature maps como filtros se apliquen. Esto es otro hiperparámetro de la Red Convolucional que se conoce como los canales de salida o out_channels."
  },
  {
    "objectID": "tics579/clase-6.html#hiperparámetros-de-la-convolución",
    "href": "tics579/clase-6.html#hiperparámetros-de-la-convolución",
    "title": "TICS-579-Deep Learning",
    "section": "Hiperparámetros de la Convolución",
    "text": "Hiperparámetros de la Convolución\n\n\n\n\n\n\n\n\n\n\nStride\n\n\nHace referencia al número de posiciones que el kernel se desplaza sobre la imagen de entrada en cada paso. Un stride más grande produce feature maps más pequeños y con menos detalle, mientras que un stride más pequeño preserva mayor información, aunque incrementa la cantidad de operaciones necesarias.\n\n\n\n\n\n\n\n\n\n\n\n\nPadding\n\n\nConsiste en añadir un relleno alrededor de la imagen de entrada para facilitar el desplazamiento del kernel y evitar que la convolución reduzca en exceso sus dimensiones. Este relleno también permite conservar la información presente en los bordes de la imagen. Cuando no se aplica padding, la operación se denomina “valid”, mientras que si se agregan los píxeles necesarios para mantener el tamaño original, se conoce como “same”.\n\n\n\n\n\n\n\n\n\n\n\n\nDilation\n\n\nHace referencia a los espacios o intervalos que se insertan entre los elementos del kernel durante la convolución. El uso de dilation permite ampliar el campo receptivo de la red, capturando un mayor contexto sin aumentar el tamaño del kernel. Un valor de 1 indica que no se aplica dilation."
  },
  {
    "objectID": "tics579/clase-6.html#convolución-en-pytorch",
    "href": "tics579/clase-6.html#convolución-en-pytorch",
    "title": "TICS-579-Deep Learning",
    "section": "Convolución en Pytorch",
    "text": "Convolución en Pytorch\n\nnn.Conv2d(in_channels, out_channels, kernel_size, stride=1,padding=0,dilation=1)\n\n\n\n\nInput\n\n\nEste tipo de redes no requiere que se le den las dimensiones de las entradas, pero sí espera recibir tensores de dimensión \\((N,C_{in}, H_{in},W_{in})\\).\n\n\n\n\n\n\nOutput\n\n\nLa Red convolucional devuelve un Tensor de Dimensiones \\((N,C_{out}, H_{out}, W_{out})\\). Donde:\n\\[H_{out} = \\left\\lfloor \\frac{H_{in} + 2 \\cdot padding[0] - dilation[0]\\cdot (kernel\\_size[0] - 1) - 1}{stride[0]} + 1 \\right\\rfloor\\] \\[W_{out} = \\left\\lfloor \\frac{W_{in} + 2 \\cdot padding[1] - dilation[1]\\cdot (kernel\\_size[1] - 1) - 1}{stride[1]} + 1 \\right\\rfloor\\]\n\n\n\n\n\n\n\n\n\n\nEs importante tener noción del tamaño de la imagen para poder escoger un kernel_size que recorra la imagen completa y que no deje partes sin convolucionar."
  },
  {
    "objectID": "tics579/clase-6.html#partes-de-una-cnn-pooling",
    "href": "tics579/clase-6.html#partes-de-una-cnn-pooling",
    "title": "TICS-579-Deep Learning",
    "section": "Partes de una CNN: Pooling",
    "text": "Partes de una CNN: Pooling\n\nPooling\n\nEl Pooling es una operación de agregación que permite ir disminuyendo el tamaño de las entradas. De esta manera la red puede comenzar a especializarse en aspectos cada vez más finos.\n\n\n\n\n\n\n\n\n\n\nEl Pooling también se aplica de manera móvil como una convolución. Pero a diferencia de esta normalmente no genera traslape.\n\n\n\n\n\n\n\n\n\nAcá se introduce otro hiperparámetro que es el Pooling Size. En general es cuadrado y de dimensión par, y utiliza un stride del mismo tamaño que el Pooling Size para evitar traslapes."
  },
  {
    "objectID": "tics579/clase-6.html#pooling-in-pytorch",
    "href": "tics579/clase-6.html#pooling-in-pytorch",
    "title": "TICS-579-Deep Learning",
    "section": "Pooling in Pytorch",
    "text": "Pooling in Pytorch\n\nnn.AvgPool2d(kernel_size, stride=None,padding=0)\nnn.MaxPool2d(kernel_size, stride=None,padding=0, dilation=1)\n\n\n\n\n\n\nOjo\n\n\n\nPytorch llama también kernel_size al tamaño del Pooling.\nstride=None implica stride = kernel_size.\n\n\n\n\n\n\n\nMaxPool\n\n\n\\[H_{out} = \\left\\lfloor \\frac{H_{in} + 2 \\cdot padding[0] - dilation[0]\\cdot (kernel\\_size[0] - 1) - 1}{stride[0]} + 1 \\right\\rfloor\\] \\[W_{out} = \\left\\lfloor \\frac{W_{in} + 2 \\cdot padding[1] - dilation[1]\\cdot (kernel\\_size[1] - 1) - 1}{stride[1]} + 1 \\right\\rfloor\\]\n\n\n\n\n\n\nAvgPool\n\n\n\\[H_{out} = \\left\\lfloor \\frac{H_{in} + 2 \\cdot padding[0] - kernel\\_size[0]}{stride[0]} + 1 \\right\\rfloor\\] \\[W_{out} = \\left\\lfloor \\frac{W_{in} + 2 \\cdot padding[1] - kernel\\_size[1]}{stride[1]} + 1 \\right\\rfloor\\]\n\n\n\n\n\n\n\n\n\nEl Average Pool no permite Dilation."
  },
  {
    "objectID": "tics579/clase-6.html#adaptivepooling",
    "href": "tics579/clase-6.html#adaptivepooling",
    "title": "TICS-579-Deep Learning",
    "section": "AdaptivePooling",
    "text": "AdaptivePooling\n\nLa mayoría de las arquitecturas CNN modernas aplican un procedimiento llamado Adaptive Pooling antes de la etapa de predicción (FFN). Independientemente del tamaño de la imagen de entrada, el Adaptive Pooling siempre genera una salida de tamaño fijo, ya que ajusta sus parámetros para asegurar que la dimensión de salida sea la deseada.\n\n\n\nnn.AdaptiveAvgPool2d(output_size)\nnn.AdaptiveMaxPool2d(output_size, return_indices=False)\n\n\n\nreturn_indices=True permite devolver en qué posiciones se encontraron los valores máximos, lo cual es útil para operaciones de unpooling para revertir el proceso de pooling."
  },
  {
    "objectID": "tics579/clase-6.html#mnist-con-cnn",
    "href": "tics579/clase-6.html#mnist-con-cnn",
    "title": "TICS-579-Deep Learning",
    "section": "MNIST con CNN",
    "text": "MNIST con CNN\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEl número de Parámetros para una Red Convolucional con muchas más capas bajó considerablemente, de 67M a 373K de Parámetros para una imagen de \\(512 \\times 512\\)."
  },
  {
    "objectID": "tics579/clase-6.html#grafo-cnn-sencilla",
    "href": "tics579/clase-6.html#grafo-cnn-sencilla",
    "title": "TICS-579-Deep Learning",
    "section": "Grafo CNN sencilla",
    "text": "Grafo CNN sencilla\n\n\n\n\n\n\n\n\n## Una Imagen de 1 Canal de Tamaño 6x6\nX = torch.tensor([\n        [[[7., 6., 8., 5., 1., 3.],\n          [8., 6., 5., 3., 5., 5.],\n          [9., 1., 1., 5., 3., 5.],\n          [4., 5., 5., 9., 2., 6.],\n          [9., 5., 3., 1., 2., 2.],\n          [4., 4., 8., 8., 9., 8.]]]\n])\nX.shape\n(1,1,6,6)\nC_out = 2\nN, C_in, H, W = X.shape\nkH, kW = (3,3)\n## 2 filtros de un Canal de tamaño 3x3\ngiven_w = torch.tensor([\n        [[[-1.,  0.,  1.],\n          [ 0., -1.,  1.],\n          [ 0.,  0.,  1.]]],\n\n        [[[-1., -1.,  0.],\n          [ 1.,  0.,  0.],\n          [ 1.,  1.,  0.]]]])\ngiven_w.shape\n(2,1,3,3)\ngiven_bias = torch.tensor([1., 1.])"
  },
  {
    "objectID": "tics579/clase-6.html#grafo-cnn-sencilla-convolución",
    "href": "tics579/clase-6.html#grafo-cnn-sencilla-convolución",
    "title": "TICS-579-Deep Learning",
    "section": "Grafo CNN sencilla: Convolución",
    "text": "Grafo CNN sencilla: Convolución\n\n\n\n\n\n\n\n\ndef calculate_out(X, k_size=(3,3), stride=1, dilation=1, padding=0):\n  kH, kW = k_size\n  N, in_channels, H_in, W_in = X.shape\n  out_H = np.floor((H_in +2*padding-dilation*(kH-1)-1)/stride + 1)\n  out_W = np.floor((W_in +2*padding-dilation*(kW-1)-1)/stride + 1)\n  return int(out_H), int(out_W)\n\nH_out, W_out = calculate_out(X, k_size = (kH,kW))\nH_out, W_out\n(4,4)\nO = torch.zeros((N, C_out, H_out, W_out))\nfor n in range(N):\n    for co in range(C_out):\n        for i in range(H_out):\n            for j in range(W_out):\n                # submatriz de tamaño kH x kW\n                patch = X[n, :, i:i+kH, j:j+kW]\n                O[n, co, i, j] = (patch * given_w[co]).sum() + given_bias[co]\nO\ntensor([[[[  5.,   5.,  -1.,  -4.],\n          [ -4.,  -7.,  -1.,  -6.],\n          [ -1., -10.,   6.,  -8.],\n          [ -9.,  -8.,  -6.,  -6.]],\n\n         [[ -3.,   5.,   3.,  -6.],\n          [ -3.,  -7.,   3., -13.],\n          [ -5., -12.,   4.,  -7.],\n          [ -9.,  -4.,  -6.,  -5.]]]])\n\n\n\n\n\n\n\nEste proceso es extremadamente ineficiente computacionalmente hablando. Por lo que se utiliza un proceso equivalente llamado im2col."
  },
  {
    "objectID": "tics579/clase-6.html#im2col",
    "href": "tics579/clase-6.html#im2col",
    "title": "TICS-579-Deep Learning",
    "section": "im2col",
    "text": "im2col\n\nim2col es un algoritmo que permite transformar la operación de convolución en una operación de multiplicación de matrices, lo cual es computacionalmente más eficiente. En este caso los parches que requieren la convolución se aplanan y se organizan en columnas de una nueva matriz.\n\n\n\n\n\n\n\n\n\nEl procedimiento en Pytorch se realiza de la siguiente manera:\n## Cada columna es un patche aplanado de 3x3. 16 patches en total.\nX_col = F.unfold(X, kernel_size=(kH, kW))  # (1, 9, 16) (N,kH*kW,n_patches)\nprint(f\"X_col shape: {X_col.shape}\")\nX_col\nX_col shape: torch.Size([1, 9, 16])\ntensor([[[7., 6., 8., 5., 8., 6., 5., 3., 9., 1., 1., 5., 4., 5., 5., 9.],\n         [6., 8., 5., 1., 6., 5., 3., 5., 1., 1., 5., 3., 5., 5., 9., 2.],\n         [8., 5., 1., 3., 5., 3., 5., 5., 1., 5., 3., 5., 5., 9., 2., 6.],\n         [8., 6., 5., 3., 9., 1., 1., 5., 4., 5., 5., 9., 9., 5., 3., 1.],\n         [6., 5., 3., 5., 1., 1., 5., 3., 5., 5., 9., 2., 5., 3., 1., 2.],\n         [5., 3., 5., 5., 1., 5., 3., 5., 5., 9., 2., 6., 3., 1., 2., 2.],\n         [9., 1., 1., 5., 4., 5., 5., 9., 9., 5., 3., 1., 4., 4., 8., 8.],\n         [1., 1., 5., 3., 5., 5., 9., 2., 5., 3., 1., 2., 4., 8., 8., 9.],\n         [1., 5., 3., 5., 5., 9., 2., 6., 3., 1., 2., 2., 8., 8., 9., 8.]]])"
  },
  {
    "objectID": "tics579/clase-6.html#im2col-1",
    "href": "tics579/clase-6.html#im2col-1",
    "title": "TICS-579-Deep Learning",
    "section": "im2col",
    "text": "im2col\n¿Qué pasa si ahora aplanamos los filtros también?\n\n\n## Dejamos cada filtro como una fila\nW_row = given_w.reshape(C_out, -1)\nprint(W_row.shape)\nW_row\n(2,9)\ntensor([[ 1.,  1.,  0., -1.,  1., -1.,  0., -1., -1.],\n        [ 1.,  1.,  0., -1.,  1., -1., -1.,  0., -1.]])\n\n\n\n\n💭 Luego La convolución se puede pensar como una transformación lineal aplicada a parches aplanados de la imagen de entrada. Es decir cada parches es transformado linealmente por los filtros aplanados, generando una nueva representación de la imagen (un feature map).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEntonces podemos expresar la convolución como una multiplicación de matrices muy similar a una FFN:\n\\[H_{col} = W_{row} \\cdot X_{col} + b \\cdot 1_{C_{in}*kH*KW}^T \\]\nDonde \\(b\\) tiene dimensiones \\(C_{out} \\times 1\\) y \\(1^T_{C_{in}*kH*kW}\\) tiene dimensiones \\(1 \\times C_{in}*kH*kW\\). Aunque es más sencillo pensar el \\(b\\) como un vector que se le aplica Broadcasting.\n\n\n\n\n\n\nLuego para volver a la forma de la imagen basta con hacer un reshape:\nH = H_col.reshape(N, C_out, H_out, W_out)\nprint(H.shape)\nH\n(1, 2, 4, 4)\n\ntensor([[[[  5.,   5.,  -1.,  -4.],\n          [ -4.,  -7.,  -1.,  -6.],\n          [ -1., -10.,   6.,  -8.],\n          [ -9.,  -8.,  -6.,  -6.]],\n\n         [[ -3.,   5.,   3.,  -6.],\n          [ -3.,  -7.,   3., -13.],\n          [ -5., -12.,   4.,  -7.],\n          [ -9.,  -4.,  -6.,  -5.]]]])"
  },
  {
    "objectID": "tics579/clase-6.html#pooling",
    "href": "tics579/clase-6.html#pooling",
    "title": "TICS-579-Deep Learning",
    "section": "Pooling",
    "text": "Pooling\n\n\nNuevamente necesitamos hacer un im2col para poder hacer el pooling como una multiplicación de matrices.\nEso implica que H quedará como:\npool_size = 2\nH_pool, W_pool = calculate_out(H, k_size=(2,2),stride=2) \n## (2,2)\nh_col = F.unfold(H, kernel_size=pool_size, stride=pool_size)\nprint(h_col.shape)\nh_col\n(1,8,4)\ntensor([[[  5.,  -1.,  -1.,   6.],\n         [  5.,  -4., -10.,  -8.],\n         [ -4.,  -1.,  -9.,  -6.],\n         [ -7.,  -6.,  -8.,  -6.],\n         [ -3.,   3.,  -5.,   4.],\n         [  5.,  -6., -12.,  -7.],\n         [ -3.,   3.,  -9.,  -6.],\n         [ -7., -13.,  -4.,  -5.]]])\n\n\n\n😱Notar como la operación de im2col genera parches para todos los canales a la vez. Por lo tanto es necesario separar por canales para aplicar el pooling.\n\n\n\n\n\n\n\n## Tenemos 2 canales de 4 por cada uno\n## al cuál debemos aplicar el máximo.\nh_col_reshaped = h_col.reshape(N, C_out, pool_size*pool_size, -1)\nh_col_reshaped\n(1,2,4,4)\ntensor([[[[  5.,  -1.,  -1.,   6.],\n          [  5.,  -4., -10.,  -8.],\n          [ -4.,  -1.,  -9.,  -6.],\n          [ -7.,  -6.,  -8.,  -6.]],\n\n         [[ -3.,   3.,  -5.,   4.],\n          [  5.,  -6., -12.,  -7.],\n          [ -3.,   3.,  -9.,  -6.],\n          [ -7., -13.,  -4.,  -5.]]]])\n\n## Calculamos el máximo de cada columna (que es un parche de 2x2)\n## Además guardamos la posición del máximo\nM_flat, pool_indices = h_col_reshaped.max(dim=2)\nM_flat\ntensor([[[ 5., -1., -1.,  6.],\n         [ 5.,  3., -4.,  4.]]])\n## Recuperamos la forma del feature map luego del pooling\nM = M_flat.reshape(N, C_out, H_pool, W_pool)\nprint(M.shape)\nM\n(1,2,2,2)\ntensor([[[[ 5., -1.],\n          [-1.,  6.]],\n\n         [[ 5.,  3.],\n          [-4.,  4.]]]])"
  },
  {
    "objectID": "tics579/clase-6.html#flatten-y-ffn",
    "href": "tics579/clase-6.html#flatten-y-ffn",
    "title": "TICS-579-Deep Learning",
    "section": "Flatten y FFN",
    "text": "Flatten y FFN\n\n\nf = M.reshape(N, -1)\nprint(f.shape)\ntensor([[ 5., -1., -1.,  6.,  5.,  3., -4.,  4.]])\nZ = f @ W_fc + b_fc\nZ\ntensor([[18.]])\nUtilizando nn.Module\nclass Conv(nn.Module):\n  def __init__(self):\n      super().__init__()\n      self.conv = nn.Conv2d(in_channels=1, out_channels=2, kernel_size=3, bias=True)\n      self.conv.weight.data = given_w\n      self.conv.bias.data = given_bias\n      self.max_pool = nn.MaxPool2d(kernel_size=2, return_indices=True)\n      self.fc = nn.Linear(8, 1)\n      nn.init.ones_(self.fc.weight)\n      nn.init.ones_(self.fc.bias)\n      self.flatten = nn.Flatten()\n\n  def forward(self, x):\n      x = self.conv(x)\n      x, self.indices = self.max_pool(x)\n      x = self.flatten(x)\n      x = self.fc(x)\n      return x\n\nmodel = Conv()\n# Forward con PyTorch\nlogits = model(X)\ntensor([[18.]])\n\n# Linear\nW_fc = torch.ones(8, 1)\ntensor([[1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.]])\n\nb_fc = torch.ones(1)\ntensor([1.])"
  },
  {
    "objectID": "tics579/clase-6.html#le-interesa-calcular-los-gradientes",
    "href": "tics579/clase-6.html#le-interesa-calcular-los-gradientes",
    "title": "TICS-579-Deep Learning",
    "section": "¿Le interesa calcular los gradientes?",
    "text": "¿Le interesa calcular los gradientes?\n\n\n\nCalcular los gradientes de una CNN se simplifica bastante utilizando el enfoque de im2col, ya que la convolución se ha transformado en una multiplicación de matrices. Esto permite aplicar los conceptos que aprendimos en la primera parte del curso.\n\n\n\n\n\n\n\n\n\nAún así aparecen conceptos que escapan del conocimiento del Cálculo que conocemos, como por ejemplo el Gradiente del im2col (que Spoiler, es el algoritmo col2im).\n\n\n\n\n\n\n\n\n\nÉchele una miradita al notebook de la clase, hay muchas horas de esfuerzo invertidas ahí."
  },
  {
    "objectID": "tics579/clase-6.html#variante-en-1d",
    "href": "tics579/clase-6.html#variante-en-1d",
    "title": "TICS-579-Deep Learning",
    "section": "Variante en 1d",
    "text": "Variante en 1d\n\n\n\nConv1d\n\nCorresponde a la variante de una dimensión, en la cual la entrada corresponden a secuencias de elementos como podrían ser series de tiempo, audio o hasta cadenas de texto.\n\n\n\n\n\nEn este caso la implementación en Pytorch es similar a la 2D sólo que esperando tensores de dimensiones \\((N,C_{in}, L_{in})\\), donde \\(C_{in}\\) corresponde al número de canales, que en el caso de series de tiempo equivale a features, y \\(L_{in}\\) corresponde al largo de la secuencia.\n\n\n\n\n\n\nLa salida de la Conv1d tendrá dimensiones \\((N,C_{out},L_{out})\\) con:\n\\[L_{out} = \\left\\lfloor \\frac{L_{in} + 2 \\cdot padding - dilation \\cdot (kernel\\_size - 1) - 1}{stride} + 1 \\right\\rfloor\\]"
  },
  {
    "objectID": "tics579/clase-6.html#variante-en-3d",
    "href": "tics579/clase-6.html#variante-en-3d",
    "title": "TICS-579-Deep Learning",
    "section": "Variante en 3d",
    "text": "Variante en 3d\n\n\n\nConv3d\n\nCorresponde a la variante de tres dimensiones, en la cual la entrada corresponde a secuencias de imágenes, es decir, videos.\n\n\n\n\n\nEste caso también es similar sólo que se esperan tensores de dimensiones \\((N, C_{in}, D_{in}, H_{in}, W_{in})\\) donde \\(C_in\\) corresponde al número de canales, \\(D\\) en el caso de un video corresponde al número de frames de tamaño \\(H_{in} \\times W_{in}\\).\n\n\n\n\n\n\nLa salida de la Conv1d tendrá dimensiones \\((N,C_{out},D_{out},H_{out},W_{out})\\) con:\n\\[D_{out} = \\left\\lfloor \\frac{D_{in} + 2 \\cdot padding[0] - dilation[0] \\cdot (kernel\\_size[0] - 1) - 1}{stride[0]} + 1 \\right\\rfloor\\] \\[H_{out} = \\left\\lfloor \\frac{H_{in} + 2 \\cdot padding[1] - dilation[1]\\cdot (kernel\\_size[1] - 1) - 1}{stride[1]} + 1 \\right\\rfloor\\] \\[W_{out} = \\left\\lfloor \\frac{W_{in} + 2 \\cdot padding[2] - dilation[2]\\cdot (kernel\\_size[2] - 1) - 1}{stride[2]} + 1 \\right\\rfloor\\]"
  },
  {
    "objectID": "tics579/clase-5.html#machine-learning-vs-deep-learning-workflow",
    "href": "tics579/clase-5.html#machine-learning-vs-deep-learning-workflow",
    "title": "TICS-579-Deep Learning",
    "section": "Machine Learning vs Deep Learning Workflow",
    "text": "Machine Learning vs Deep Learning Workflow\n\n\n\n\n\n\n\n\n\n\n\n\n\nMachine Learning\n\n\nEl proceso completo de entrenamiento del modelo se divide en dos etapas: preprocesamiento de datos y entrenamiento del modelo.\n\n\n\n\n\n\n\n\n\n\nDeep Learning\n\n\nEl entrenamiento del modelo abarca tres etapas: preprocesamiento de datos, diseño de la arquitectura y entrenamiento propiamente tal como uno solo."
  },
  {
    "objectID": "tics579/clase-5.html#preprocesamiento",
    "href": "tics579/clase-5.html#preprocesamiento",
    "title": "TICS-579-Deep Learning",
    "section": "Preprocesamiento",
    "text": "Preprocesamiento\nAlgunos de los problemas más comunes para los que se requieren preprocesamientos en Deep Learning son:\n\n\n\n\n\n\n\n\nEncoding de Variables Categóricas\n\n\n\nOne Hot Encoding\nEmbeddings\n\n\n\n\n\n\n\n\n\n\nProblemas de Escala:\n\n\n\nEstandarización\nNormalización\nNormalization Layers\n\n\n\n\n\n\n\n\n\n\n\nProblemas de Convergencia y combate contra el Overfitting:\n\n\n\nRegularización L2 (Weight Decay)\nDropout\nWeights Initialization\n\n\n\n\n\n\n\n\n\n\nProblemas de Recursos Computacionales:\n\n\n\nCheckpointing\nEarly Stopping\nGradient Accumulation"
  },
  {
    "objectID": "tics579/clase-5.html#problemas-de-escala-1",
    "href": "tics579/clase-5.html#problemas-de-escala-1",
    "title": "TICS-579-Deep Learning",
    "section": "Problemas de Escala",
    "text": "Problemas de Escala\n\nEn general el término Normalización está muy trillado y en la práctica se utiliza para referirse a muchos temas distintos. Algunas definiciones conocidas:\n\n\n\nNormalización\n\\[x_{i\\_norm} = \\frac{x_i-x_{min}}{x_{max} - x_{min}}\\] Esta operación se puede hacer mediante MinMaxScaler de Scikit-Learn.\n\nEstandarización\n\\[ x_{i\\_est} = \\frac{x_i - E[x]}{\\sqrt(Var[x])}\\]\nEsta operación se puede hacer mediante StandardScaler de Scikit-Learn.\n\n\n\n\n👀 Ojo\n\n\nLa implementación de este tipo de técnicas normalmente requiere librerías externas a Pytorch (como Scikit-Learn o Feature Engine). Por lo que no es tan común en prácticas más avanzadas del área.\n\n\n\n\n\n\n\n\n\nAlerta de Data Leakage\n\n\nUtilizar estas estrategias externas pueden producir problemas de Data Leakage cuando se hace entrenamiento por Mini-Batches que es lo más común. Para evitar esto, lo más común es utilizar Normalization Layers dentro de la misma Arquitectura de la Red Neuronal."
  },
  {
    "objectID": "tics579/clase-5.html#normalization-layers-batch-normalization",
    "href": "tics579/clase-5.html#normalization-layers-batch-normalization",
    "title": "TICS-579-Deep Learning",
    "section": "Normalization Layers: Batch Normalization",
    "text": "Normalization Layers: Batch Normalization\nIoffe & Szegedy, 2015: Batch Normalization\n\nConsiste en la primera implementación de una Normalización para cada Batch.\n\n\n\n\n\n\n\n\n\nPros\n\n\n\nResuelve el problema de Internal Covariate Shift.\nDisminuye la importancia de los Parámetros iniciales e inicio del aprendizaje.\nGenera un modelo más estable debido a que las activaciones están normalizadas.\n\n\n\n\n\n\n\n\n\n\n\nCons\n\n\n\nGenera más parámetros entrenables y, por ende, más cálculos en la red.\nSe complica el proceso de inferencia (test time).\n\n\n\n\n\n\nInternal Covariate Shift\n\nAl entrenar una red neuronal, cada capa depende de las salidas (activaciones) de la capa anterior.\nDurante el entrenamiento, esas salidas cambian porque sus pesos se están actualizando, lo que implica que la distribución de entrada que ve cada capa está cambiando constantemente. Esto es lo que se conoce como internal covariate shift.\n\n\nEsto significa que cada capa debe adaptarse continuamente a nuevas distribuciones de entrada, lo que ralentiza el entrenamiento y dificulta la convergencia."
  },
  {
    "objectID": "tics579/clase-5.html#normalization-layers-batch-norm-punto-de-partida",
    "href": "tics579/clase-5.html#normalization-layers-batch-norm-punto-de-partida",
    "title": "TICS-579-Deep Learning",
    "section": "Normalization Layers: Batch Norm, Punto de Partida",
    "text": "Normalization Layers: Batch Norm, Punto de Partida\nEjemplo: Supongamos que dado la altura y la edad queremos predecir si será deportista de alto rendimiento.\n\n\n\n\n\n\n\n\n\n\n\n\n\nObservaciones\n\n\n\nRango de Edad es mucho mayor que el de Altura.\nCambios en Altura deben ser mucho más pequeños que en Edad debido al rango.\nSi el learning rate es alto puede diverger si nos movemos en la dirección de altura.\nSi el learning rate es bajo, podría demorar mucho más en converger si nos movemos en la dirección de edad.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nObservaciones\n\n\n\nSin importar el punto inicial, el mínimo se encuentra casi a la misma distancia.\n\nEs posible utilizar un learning rate más grande sin miedo a diverger."
  },
  {
    "objectID": "tics579/clase-5.html#batch-norm-implementación-forward-pass",
    "href": "tics579/clase-5.html#batch-norm-implementación-forward-pass",
    "title": "TICS-579-Deep Learning",
    "section": "Batch Norm: Implementación (Forward Pass)",
    "text": "Batch Norm: Implementación (Forward Pass)\n\n\nSupongamos el siguiente Batch de tamaño \\(B=15\\) con 3 features:\n\\[\nX = \\begin{bmatrix}\n16 & 14 & 12 \\\\\n15 & 3  & 15 \\\\\n16 & 7  & 6  \\\\\n14 & 3  & 16 \\\\\n4  & 4  & 18 \\\\\n8  & 11 & 9  \\\\\n18 & 18 & 14 \\\\\n5  & 17 & 11 \\\\\n15 & 9  & 11 \\\\\n10 & 7  & 7\n\\end{bmatrix}\n\\]\n\n\n\n\n1. Calcular estadísticos de cada Batch: Promedio y Varianza.\n\n\n\\[\\mu_B = \\begin{bmatrix}\n12.1 & 9.3 & 11.9\n\\end{bmatrix}\n\\] \\[\n\\sigma^2_B=\\begin{bmatrix}\n22.29 & 27.81 & 13.69\n\\end{bmatrix}\n\\]\n\n\\(\\sigma^2_B\\) corresponde a la varianza sesgada (dividida por N).\n\n\n\n\n\n\n\n2. Calcular normalización de cada Batch.\n\n\n\\[x_{norm} = \\frac{X - \\mu_B}{\\sqrt{\\sigma_B^2 + \\epsilon}}\\]\n\n\n\n\n\n\n3. Calcular Activación\n\n\n\\[h = \\gamma \\odot x_{norm} + \\beta\\]\nPor defecto, Pytorch considera que \\(\\gamma = \\begin{bmatrix}\n1 & ... & 1\n\\end{bmatrix}\\) y \\(\\beta = \\begin{bmatrix}\n0 & ... & 0\n\\end{bmatrix}\\).\nLuego \\(\\gamma\\) y \\(\\beta\\) son parámetros entrenables por el modelo. Tanto \\(\\gamma\\) como \\(\\beta\\) tienen la misma dimensión que el número de features (en este caso 3)."
  },
  {
    "objectID": "tics579/clase-5.html#batch-norm-implementación-forward-pass-1",
    "href": "tics579/clase-5.html#batch-norm-implementación-forward-pass-1",
    "title": "TICS-579-Deep Learning",
    "section": "Batch Norm: Implementación (Forward Pass)",
    "text": "Batch Norm: Implementación (Forward Pass)\n\n\nCálculo Manual\neps = 1e-5\nbatch_mean = X.mean(dim=0, keepdim=True)\nbatch_var_train = X.var(dim=0, unbiased=False, keepdim=True)\nx_norm = (X-batch_mean)/torch.sqrt(batch_var_train + eps)\nw = torch.tensor([1,1,1])\nb = torch.tensor([0,0,0])\nw*x_norm + b\n============================================================\nForward Pass Train obtenido Manualmente\n============================================================\ntensor([[ 0.8261,  0.8912,  0.0270],\n        [ 0.6142, -1.1946,  0.8378],\n        [ 0.8261, -0.4361, -1.5946],\n        [ 0.4024, -1.1946,  1.1081],\n        [-1.7157, -1.0050,  1.6486],\n        [-0.8684,  0.3224, -0.7838],\n        [ 1.2497,  1.6498,  0.5676],\n        [-1.5038,  1.4601, -0.2432],\n        [ 0.6142, -0.0569, -0.2432],\n        [-0.4448, -0.4361, -1.3243]])\n\n\nCálculo en Pytorch\nbn = nn.BatchNorm1d(3)\n## Importantísimo ya que BatchNorm tiene distinto \n## funcionamiento en Modo Train y Eval\nbn.train()\noutput_pytorch= bn(X)\noutput_pytorch\n============================================================\nForward Pass en Modo Train utilizando Pytorch\n============================================================\ntensor([[ 0.8261,  0.8912,  0.0270],\n        [ 0.6142, -1.1946,  0.8378],\n        [ 0.8261, -0.4361, -1.5946],\n        [ 0.4024, -1.1946,  1.1081],\n        [-1.7157, -1.0050,  1.6486],\n        [-0.8684,  0.3224, -0.7838],\n        [ 1.2497,  1.6498,  0.5676],\n        [-1.5038,  1.4601, -0.2432],\n        [ 0.6142, -0.0569, -0.2432],\n        [-0.4448, -0.4361, -1.3243]], grad_fn=&lt;NativeBatchNormBackward0&gt;)"
  },
  {
    "objectID": "tics579/clase-5.html#batch-norm-implementación-test-time",
    "href": "tics579/clase-5.html#batch-norm-implementación-test-time",
    "title": "TICS-579-Deep Learning",
    "section": "Batch Norm: Implementación (Test Time)",
    "text": "Batch Norm: Implementación (Test Time)\nProblema\nLa predicción de una instancia \\(i\\) específica, ahora depende de otros elementos dentro del Batch.\n¿Cómo funciona entonces el modelo en Test Time?\n\n\n\n1. Calcular running mean y running var.\n\n\n\\[\n\\begin{aligned}\n\\mu_{running} &= (1 - \\alpha) \\mu_{running} + \\alpha \\cdot \\mu_B \\\\\ns^2_{running} &= (1 - \\alpha) \\cdot s^2_{running} + \\alpha \\cdot s^2_B\n\\end{aligned}\n\\]\nOjo: En este caso se usa la Varianza insesgada (dividida por N-1). \\(\\alpha\\) es un hiperparámetro que mide la contribución del Batch actual a los estadísticos globales. Por defecto en Pytorch \\(\\alpha = 0.1\\).\n\n\n\n\n\n\n2. Calcular normalización de cada Batch.\n\n\n\\[x_{norm}^{test} = \\frac{X - \\mu_{running}}{\\sqrt{s_{running}^2 + \\epsilon}}\\]\n\n\n\n\n\n\n3. Calcular Activación\n\n\n\\[h = \\gamma \\cdot x_{norm}^{test} + \\beta\\]\nEn este caso, \\(\\gamma\\) y \\(\\beta\\) son parámetros aprendidos durante el entrenamiento."
  },
  {
    "objectID": "tics579/clase-5.html#batch-norm-implementación-test-time-1",
    "href": "tics579/clase-5.html#batch-norm-implementación-test-time-1",
    "title": "TICS-579-Deep Learning",
    "section": "Batch Norm: Implementación (Test Time)",
    "text": "Batch Norm: Implementación (Test Time)\n\n\nCálculo Manual\nbatch_var_eval = X.var(dim=0, unbiased=True, keepdim=True)\n\nalpha = 0.1\nrm = (1-alpha)*torch.tensor([0,0,0]) + alpha*batch_mean\nrv = (1-alpha)*torch.tensor([1,1,1]) + alpha*batch_var_eval\n\nx_normalized_eval = (X - rm)/torch.sqrt(rv + eps)\nbn.weight.data*x_normalized_eval+bn.bias.data\n============================================================\nTest Time: \n============================================================\nMedia: \ntensor([[1.2100, 0.9300, 1.1900]])\nVarianza: \ntensor([[3.3767, 3.9900, 2.4211]])\nForward Pass en Modo Evaluación obtenido de manera manual...\n============================================================\ntensor([[ 8.0487,  6.5432,  6.9473],\n        [ 7.5045,  1.0363,  8.8753],\n        [ 8.0487,  3.0388,  3.0913],\n        [ 6.9603,  1.0363,  9.5180],\n        [ 1.5183,  1.5369, 10.8034],\n        [ 3.6951,  5.0413,  5.0193],\n        [ 9.1370,  8.5457,  8.2327],\n        [ 2.0625,  8.0451,  6.3046],\n        [ 7.5045,  4.0400,  6.3046],\n        [ 4.7835,  3.0388,  3.7339]])\n\nCálculo en Pytorch\nbn.eval()\nbn(X)\n============================================================\nForward Pass en Modo Evaluación usando Pytorch...\n============================================================\ntensor([[ 8.0487,  6.5432,  6.9473],\n        [ 7.5045,  1.0363,  8.8753],\n        [ 8.0487,  3.0388,  3.0913],\n        [ 6.9603,  1.0363,  9.5180],\n        [ 1.5183,  1.5369, 10.8034],\n        [ 3.6951,  5.0413,  5.0193],\n        [ 9.1370,  8.5457,  8.2327],\n        [ 2.0625,  8.0451,  6.3046],\n        [ 7.5045,  4.0400,  6.3046],\n        [ 4.7835,  3.0388,  3.7339]], grad_fn=&lt;NativeBatchNormBackward0&gt;)"
  },
  {
    "objectID": "tics579/clase-5.html#batch-norm-consejos",
    "href": "tics579/clase-5.html#batch-norm-consejos",
    "title": "TICS-579-Deep Learning",
    "section": "Batch Norm: Consejos",
    "text": "Batch Norm: Consejos\n\nAndrew Ng propone utilizar BatchNorm justo antes de la función de Activacion.\nEl paper original también propone su uso justo antes de la activación.\nFrancoise Chollet, creador de Keras dice que los autores del paper en realidad lo utilizaron después de la función de activación.\nAdicionalmente existen benchmarks que muestran mejoras usando BatchNorm después de las funciones de activación.\n\n\n\n\n\n\n\nEntonces, la posición del BatchNorm termina siendo parte de la Arquitectura, y se debe comprobar donde tiene un mejor efecto.\n\n\n\n\n\n\n\n\n\nBatchnorm tiene efectos distintos al momento de entrenar o de evaluar/predecir en un modelo. Por lo tanto, de usar Batchnorm es imperativo utilizar los modos model.train() y model.eval()."
  },
  {
    "objectID": "tics579/clase-5.html#normalización-layer-norm",
    "href": "tics579/clase-5.html#normalización-layer-norm",
    "title": "TICS-579-Deep Learning",
    "section": "Normalización: Layer Norm",
    "text": "Normalización: Layer Norm\nLey, Ryan, Hinton, 2016: Layer Normalization\n\n\n\n\n\n\nBatch Norm tiene algunos problemas:\n\n\n\nMuy difícil de calcular en datos secuenciales (lo veremos más adelante).\nInestable cuando el Batch Size es muy pequeño.\nDifícil de Paralelizar.\n\n\n\n\n\n\n\n\n\n\nBeneficios de Layer Norm\n\n\n\nPuede trabajar con secuencias (Esencial para Transformers).\nNo tiene problemas para trabajar con cualquier tipo de Batch Size.\nSe puede paralelizar, lo cuál es útil en redes como las RNN.\n\n\n\n\n\n\n\n\n\n\n\nEn este caso se realiza la normalización por instancia y no por Batch."
  },
  {
    "objectID": "tics579/clase-5.html#normalización-layer-norm-1",
    "href": "tics579/clase-5.html#normalización-layer-norm-1",
    "title": "TICS-579-Deep Learning",
    "section": "Normalización: Layer Norm",
    "text": "Normalización: Layer Norm\n\n\n\n1. Calcular estadísticos de cada Instancia: Promedio y Varianza.\n\n\n\\[\\mu = \\begin{bmatrix}\n14.0000 & 11.0000 & 9.6667 & 11.0000 & 8.6667 & 9.3333 & 16.6667 & 11.0000 & 11.6667 & 8.0000\n\\end{bmatrix}^T\n\\]\n\\[\n\\sigma^2 = \\begin{bmatrix}\n2.6667 & 32.0000 & 20.2222 & 32.6667 & 43.5556 & 1.5556 & 3.5556 & 24.0000 & 6.2222 & 2.0000\n\\end{bmatrix}^T\n\\]\n\n\\(\\sigma^2_B\\) corresponde a la varianza sesgada (dividida por N).\n\n\n\n\n\n\n\n2. Calcular normalización de cada Instancia.\n\n\n\\[x_{norm} = \\frac{X - \\mu}{\\sqrt{\\sigma^2 + \\epsilon}}\\]\n\n\n\n\n\n\n3. Calcular Activación\n\n\n\\[h = \\gamma \\odot x_{norm} + \\beta\\]\nPor defecto, Pytorch considera que \\(\\gamma = \\begin{bmatrix}\n1 & ... & 1\n\\end{bmatrix}\\) y \\(\\beta = \\begin{bmatrix}\n0 & ... & 0\n\\end{bmatrix}\\).\nLuego \\(\\gamma\\) y \\(\\beta\\) son parámetros entrenables por el modelo. Tanto \\(\\gamma\\) como \\(\\beta\\) tienen la misma dimensión que el número de features (en este caso 3)."
  },
  {
    "objectID": "tics579/clase-5.html#layer-norm-implementación-forward-pass",
    "href": "tics579/clase-5.html#layer-norm-implementación-forward-pass",
    "title": "TICS-579-Deep Learning",
    "section": "Layer Norm: Implementación (Forward Pass)",
    "text": "Layer Norm: Implementación (Forward Pass)\n\n\nCálculo Manual\neps = 1e-5\nsample_mean = X.mean(dim=1, keepdim=True)\nsample_var = X.var(dim=1, unbiased=False, keepdim=True)\nx_normalized = (X - sample_mean) / torch.sqrt(sample_var + eps)\nprint(\"=\"*60)\nprint(\"=\"*60)\nln.weight.data*x_normalized + ln.bias.data\n============================================================\nForward Pass Obtenido de manera Manual\n============================================================\ntensor([[ 1.2247,  0.0000, -1.2247],\n        [ 0.7071, -1.4142,  0.7071],\n        [ 1.4084, -0.5930, -0.8154],\n        [ 0.5249, -1.3997,  0.8748],\n        [-0.7071, -0.7071,  1.4142],\n        [-1.0690,  1.3363, -0.2673],\n        [ 0.7071,  0.7071, -1.4142],\n        [-1.2247,  1.2247,  0.0000],\n        [ 1.3363, -1.0690, -0.2673],\n        [ 1.4142, -0.7071, -0.7071]])\n\nCálculo en Pytorch\nln = nn.LayerNorm(3)\noutput_pytorch = ln(X)\noutput_pytorch\n============================================================\nForward Pass obtenido utilizando Pytorch\n============================================================\ntensor([[ 1.2247,  0.0000, -1.2247],\n        [ 0.7071, -1.4142,  0.7071],\n        [ 1.4084, -0.5930, -0.8154],\n        [ 0.5249, -1.3997,  0.8748],\n        [-0.7071, -0.7071,  1.4142],\n        [-1.0690,  1.3363, -0.2673],\n        [ 0.7071,  0.7071, -1.4142],\n        [-1.2247,  1.2247,  0.0000],\n        [ 1.3363, -1.0690, -0.2673],\n        [ 1.4142, -0.7071, -0.7071]], grad_fn=&lt;NativeLayerNormBackward0&gt;)"
  },
  {
    "objectID": "tics579/clase-5.html#normalization-rmsnorm",
    "href": "tics579/clase-5.html#normalization-rmsnorm",
    "title": "TICS-579-Deep Learning",
    "section": "Normalization: RMSNorm",
    "text": "Normalization: RMSNorm\n\n\n\n1. Calcular Root Mean Square de cada Instancia.\n\n\n\\[RMS(X)= \\sqrt{\\frac{1}{d} \\sum_{i=1}^{d} X^2 + \\epsilon}\\]\n\n\n\n\n\n\n2. Calcular normalización de cada Instancia.\n\n\n\\[x_{norm} = \\frac{X}{RMS(X)}\\]\n\n\n\n\n\n\n3. Calcular Activación\n\n\n\\[h = \\gamma \\odot x_{norm}\\]\nPor defecto, Pytorch considera que \\(\\gamma = \\begin{bmatrix}\n1 & ... & 1\n\\end{bmatrix}\\).\nLuego \\(\\gamma\\) son parámetros entrenables por el modelo. \\(\\gamma\\) tienen la misma dimensión que el número de features (en este caso 3)."
  },
  {
    "objectID": "tics579/clase-5.html#rmsnorm-implementación",
    "href": "tics579/clase-5.html#rmsnorm-implementación",
    "title": "TICS-579-Deep Learning",
    "section": "RMSNorm: Implementación",
    "text": "RMSNorm: Implementación\n\n\nCálculo Manual\nrms = torch.sqrt((X**2).mean(dim=1, keepdims = True))\nrms_layer.weight.data*X/rms\n============================================================\nForward Pass Obtenido de manera Manual\n============================================================\ntensor([[1.1352, 0.9933, 0.8514],\n        [1.2127, 0.2425, 1.2127],\n        [1.5007, 0.6566, 0.5628],\n        [1.1294, 0.2420, 1.2907],\n        [0.3672, 0.3672, 1.6524],\n        [0.8496, 1.1682, 0.9558],\n        [1.0732, 1.0732, 0.8347],\n        [0.4152, 1.4118, 0.9135],\n        [1.2573, 0.7544, 0.9220],\n        [1.2309, 0.8616, 0.8616]])\n\nCálculo en Pytorch\nrms_layer = nn.RMSNorm(3)\nrms_layer(X)\n============================================================\nForward Pass Obtenido utilizando Pytorch\n============================================================\ntensor([[1.1352, 0.9933, 0.8514],\n        [1.2127, 0.2425, 1.2127],\n        [1.5007, 0.6566, 0.5628],\n        [1.1294, 0.2420, 1.2907],\n        [0.3672, 0.3672, 1.6524],\n        [0.8496, 1.1682, 0.9558],\n        [1.0732, 1.0732, 0.8347],\n        [0.4152, 1.4118, 0.9135],\n        [1.2573, 0.7544, 0.9220],\n        [1.2309, 0.8616, 0.8616]], grad_fn=&lt;MulBackward0&gt;)"
  },
  {
    "objectID": "tics579/clase-5.html#regularización-l2-aka-weight-decay",
    "href": "tics579/clase-5.html#regularización-l2-aka-weight-decay",
    "title": "TICS-579-Deep Learning",
    "section": "Regularización L2 aka Weight Decay",
    "text": "Regularización L2 aka Weight Decay\nPaper 1991: Weight Decay\n\nEn general, el principal problema de las redes neuronales es el overfitting, ya que estas redes suelen ser consideradas modelos sobredimensionados (overparameterized models). ¿Qué implica esto exactamente?\n\n\nWeight Decay\n\n\nCorresponde a una penalización que se da a los modelos para limitar su complejidad y asegurar que pueda generalizar correctamente en datos no vistos.\n\n\n\n\\[ \\underset{W_{i:L}}{minimize} \\frac{1}{m} L + \\frac{\\lambda}{2} \\sum_{i=1}^L ||W_i||_f^2\\]"
  },
  {
    "objectID": "tics579/clase-5.html#regularización-l2-aka-weight-decay-1",
    "href": "tics579/clase-5.html#regularización-l2-aka-weight-decay-1",
    "title": "TICS-579-Deep Learning",
    "section": "Regularización L2 aka Weight Decay",
    "text": "Regularización L2 aka Weight Decay\nEso implica una transformación a nuestro Update Rule:\n\\[W_i := W_i - \\alpha \\frac{1}{m} \\nabla L - \\alpha \\lambda W_i = (1-\\alpha\\lambda)W_i - \\alpha \\nabla L\\]\n\n\n\n\n\n\nSe puede ver que los pesos (weights) se contraen (decaen) antes de actualizarse en la dirección del gradiente. Lo que genera parámetros más pequeños y, por ende, un modelo más simple.\n\n\n\n\n\n\n\n\n\nPor alguna razón Pytorch decidió implementarlo como una propiedad de los Optimizers cuando en realidad debió ser de la Loss Function.\n\n\n\ntorch.optim.Adam(model.parameters(), lr=3e-4, weight_decay=0.3)\n\n\n\n\n\n\nEn este caso 0.3 corresponde al valor de \\(\\lambda\\)."
  },
  {
    "objectID": "tics579/clase-5.html#dropout",
    "href": "tics579/clase-5.html#dropout",
    "title": "TICS-579-Deep Learning",
    "section": "Dropout",
    "text": "Dropout\nPaper 2014: Dropout\nDefiniremos el Dropout como:\n\\[D(h)= \\begin{cases}\n\\frac{h}{1-p}  & \\text{con prob 1-p} \\\\\n0, & \\text{con prob p}\n\\end{cases}\\]\ndonde \\(D\\) implica la aplicación de Dropout a la activación \\(h\\). \\(p\\) se conoce como el Dropout Rate.\n\n\n\n\n\n\nEl factor \\(\\frac{1}{1-p}\\) se aplica para mantener la varianza estable luego de haber eliminado activaciones con probabilidad \\(p\\).\n\n\n\n\n\n\n\n\n\nDropout se aplica normalmente al momento de entrenar el modelo. Por lo tanto, de usar Dropout es imperativo cambiar al modo model.eval() al momento de predecir."
  },
  {
    "objectID": "tics579/clase-5.html#weights-initialization",
    "href": "tics579/clase-5.html#weights-initialization",
    "title": "TICS-579-Deep Learning",
    "section": "Weights Initialization",
    "text": "Weights Initialization\nPaper 2010: Xavier Initialization\nPaper 2015: Kaiming Initialization\nHasta ahora, hemos inicializado los pesos de las redes neuronales de forma aleatoria. Sin embargo, diversos estudios han explorado estrategias de inicialización de los parámetros para lograr una convergencia más eficiente. Entre las técnicas más comunes se encuentran:\n\n\n\n\n\n\nActivaciones Triviales\n\n\n\nConstante\nSólo unos\nSólo Zeros\nCon Distribución Uniforme\nCon Distribución Normal"
  },
  {
    "objectID": "tics579/clase-5.html#weights-initialization-1",
    "href": "tics579/clase-5.html#weights-initialization-1",
    "title": "TICS-579-Deep Learning",
    "section": "Weights Initialization",
    "text": "Weights Initialization\n\n\nXavier o Glorot Uniforme\nSe inicia con valores provenientes de una distribución uniforme: \\(\\mathcal{U}(-a,a)\\)\n\\[ a = gain \\cdot \\sqrt{\\frac{6}{fan_{in} + fan_{out}}}\\]\n\nXavier o Glorot Normal\nSe inicia con valores provenientes de una distribución Normal: \\(\\mathcal{N}(0,std^2)\\)\n\\[ std = gain \\cdot \\sqrt{\\frac{2}{fan_{in} + fan_{out}}}\\]\n\n\n\n\n\n\n\n\n\\(fan_{in}\\) corresponde al número de conexiones que entran a una neurona. Mientras que \\(fan_{out}\\) corresponde al número de neuronas que salen de dicha neurona.\n\\(fan\\_mode\\) corresponde a la elección de \\(fan_{in}\\) o \\(fan_{out}\\).\n\n\n\n\n\n\nKaiming (aka He) Uniforme\nSe inicia con valores provenientes de una distribución Uniforme: \\(\\mathcal{U}(-bound,bound)\\)\n\\[ bound = gain \\cdot \\sqrt{\\frac{3}{fan\\_mode}}\\]\n\nKaiming (aka He) Normal\nSe inicia con valores provenientes de una distribución Normal: \\(\\mathcal{N}(0,std^2)\\)\n\\[std =\\sqrt{\\frac{gain}{fan\\_mode}}\\]"
  },
  {
    "objectID": "tics579/clase-5.html#checkpointing",
    "href": "tics579/clase-5.html#checkpointing",
    "title": "TICS-579-Deep Learning",
    "section": "Checkpointing",
    "text": "Checkpointing\nEntrenar una red neuronal puede requerir una gran cantidad de tiempo y recursos computacionales. Por ello, es una buena práctica guardar los pesos del modelo en distintos momentos del entrenamiento, con el fin de no perder el progreso alcanzado ante posibles imprevistos (como un corte de energía o un fallo del sistema).\nEsto ofrece varias ventajas, entre ellas:\n\nPoder disponer de resultados intermedios incluso si el entrenamiento aún no finaliza.\nAlmacenar los pesos correspondientes al mejor modelo obtenido durante el proceso de entrenamiento.\n\n\n\n\n\n\n\nCheckpoints\n\n\nPytorch permite el uso de Checkpointing de manera sencilla mediante la función torch.save() y torch.load().\nAlgunas estrategias comunes de Checkpointing son:\n\nGuardar el modelo cada cierto número de epochs.\nGuardar el modelo cuando se alcanza un nuevo mejor desempeño en el conjunto de validación.\nGuardar tanto el modelo como el optimizador para poder reanudar el entrenamiento desde el último checkpoint. En especial cuando existen restricciones de tiempo en el uso de recursos computacionales.\nGuardar el modelo antes de alcanzar el Overfitting.\nGuardar el modelo final al concluir el entrenamiento.\nGuardar modelos intermedios para analizar si se va por buen camino."
  },
  {
    "objectID": "tics579/clase-5.html#early-stopping",
    "href": "tics579/clase-5.html#early-stopping",
    "title": "TICS-579-Deep Learning",
    "section": "Early Stopping",
    "text": "Early Stopping\n\nEl Early Stopping consiste en monitorear el rendimiento sobre un conjunto de validación durante el entrenamiento y detener el proceso cuando el rendimiento comienza a empeorar. De esta manera, se evita invertir tiempo y recursos computacionales en seguir entrenando un modelo que ya no mejora su capacidad de generalización.\n\n\n\n\n\n\n\nGrokking\n\n\nUn nuevo concepto que anda dando vuelta en el último tiempo es el grokking. El cuál es una mejora del performance del modelo pasado el punto de overfitting. Por lo que el Early Stopping podría impedir que se alcance este punto.\n\n\n\nEn general este proceso detiene el entrenamiento luego de patience epochs sin mejorar el validation loss u otro criterio. Una lógica simple para implementarlo es agregar lo siguiente al training loop:\n# ---- Early Stopping ----\n    if val_loss &gt; best_val_loss:\n        best_val_loss = val_loss\n        best_model_state = model.state_dict()\n        counter = 0  # resetea paciencia\n    else:\n        counter += 1\n        if counter &gt;= patience:\n            print(f\"Early stopping en epoch {epoch+1}\")\n            break"
  },
  {
    "objectID": "tics579/clase-5.html#gradient-accumulation",
    "href": "tics579/clase-5.html#gradient-accumulation",
    "title": "TICS-579-Deep Learning",
    "section": "Gradient Accumulation",
    "text": "Gradient Accumulation\n\nOtra estrategia para enfrentar limitaciones de memoria es el Gradient Accumulation. Esta técnica permite simular batch sizes más grandes al acumular los gradientes durante varios pasos. De esta forma, se obtienen resultados equivalentes a los de un entrenamiento con batches grandes, pero utilizando menos recursos computacionales (a costa de requerir más iteraciones o epochs).\n\n## Training with Accumulation\naccumulation_steps=4\nmodel.zero_grad()                                   # Resetea Gradientes Iniciales\nfor e in range(epochs):\n  logits = model(X)                     \n  loss = criterion(logits, y.unsqueeze(-1))\n  print(f\"Epoch: {e+1}. Loss: {loss.item()}\")\n  loss = loss / accumulation_steps                # Normaliza Loss\n  loss.backward()                                 # Backward pass \n  # (Recordar que Pytorch Acumula Gradientes hasta que se use .zero_grad())\n  if (e+1) % accumulation_steps == 0:             \n      optimizer.step()                            # Se actualizan pesos sólo cada ciertos steps\n      model.zero_grad()                           # Y ahora se resetea"
  },
  {
    "objectID": "tics579/legacy.html",
    "href": "tics579/legacy.html",
    "title": "Intuición y conceptos iniciales",
    "section": "",
    "text": "Las redes neuronales artificiales (ANN), son modelos inspirados en el mecanismo cerebral de sinapsis. Su unidad más básica es una Neurona.\n\n\n\n\n\n\n\n\n\n\n\n\nImportante\n\n\n\nSi bien los modelos están inspirados en el función neuronal, existe muy poca evidencia de que las neuronas de verdad efectivamente funcionen similar a una red Neuronal."
  },
  {
    "objectID": "tics579/legacy.html#el-nacimiento-de-las-redes-neuronales",
    "href": "tics579/legacy.html#el-nacimiento-de-las-redes-neuronales",
    "title": "Intuición y conceptos iniciales",
    "section": "",
    "text": "Las redes neuronales artificiales (ANN), son modelos inspirados en el mecanismo cerebral de sinapsis. Su unidad más básica es una Neurona.\n\n\n\n\n\n\n\n\n\n\n\n\nImportante\n\n\n\nSi bien los modelos están inspirados en el función neuronal, existe muy poca evidencia de que las neuronas de verdad efectivamente funcionen similar a una red Neuronal."
  },
  {
    "objectID": "tics579/legacy.html#el-nacimiento-de-las-redes-neuronales-1",
    "href": "tics579/legacy.html#el-nacimiento-de-las-redes-neuronales-1",
    "title": "Intuición y conceptos iniciales",
    "section": "El nacimiento de las Redes Neuronales",
    "text": "El nacimiento de las Redes Neuronales\n\nLas redes neuronales artificiales (ANN), son modelos inspirados en el mecanismo cerebral de sinapsis. Su unidad más básica es una Neurona.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\n\n\n\n\nEste cálculo se puede representar como:\n\n\\[ y = \\phi(w_1 \\cdot x_1 + w_2 \\cdot x_2 + ... + w_5 \\cdot x_5)\\] \\[ y = \\phi(w^T \\cdot x)\\]\ndonde \\(w = [w_1, w_2, w_3, w_4, w_5]\\) y \\(x = [x_1, x_2, x_3, x_4, x_5]\\).\n\n\n\n\n\n\nWarning\n\n\n\n\n¿Qué pasa si \\(\\phi(.)\\) vale la función identidad?\nTenemos una Regresión Lineal.\n\n\n\n\n\n\n\n\n\nWarning\n\n\n\n\n¿Qué pasa si \\(\\phi(.)\\) vale la función sigmoide?\nTenemos una Regresión Logística."
  },
  {
    "objectID": "tics579/legacy.html#arquitectura-de-una-red",
    "href": "tics579/legacy.html#arquitectura-de-una-red",
    "title": "Intuición y conceptos iniciales",
    "section": "Arquitectura de una Red",
    "text": "Arquitectura de una Red\n\n\n\n\n\n\n\n\n\nEstructura más común\n\n(Probablemente tampoco seguiremos esta nomenclatura)\n\nNodos o Neuronas\nEdges o Conexiones\nCapas\n\n\n\n\n\n\n\nCaution\n\n\n\n¿Cuántas capas tiene esta red?\n\n\n\n\n\n\n\n\nTip\n\n\n\nDepende\n\n\n\n\n\n\n\nNormalmente todas las neuronas de una capa anterior se conectan con las de una capa posterior (Hay excepciones).\nDependiendo de la forma en la que se conecten, cada Arquitectura recibe un nombre."
  },
  {
    "objectID": "tics579/legacy.html#los-ingredientes-de-un-algoritmo-de-aprendizaje",
    "href": "tics579/legacy.html#los-ingredientes-de-un-algoritmo-de-aprendizaje",
    "title": "Intuición y conceptos iniciales",
    "section": "Los Ingredientes de un Algoritmo de Aprendizaje",
    "text": "Los Ingredientes de un Algoritmo de Aprendizaje\n\nHipótesis\n\n\nUna función que describe como mapear inputs (features) con outputs (labels) por medio de parámetros.\n\n\nLoss Function\n\n\nUna función que especifica cuanta información se pierde. Mayor pérdida implica más error de estimación.\n\n\nMétodo de Optimización\n\n\nEs el responsable de combinar la hipótesis y la loss function. Corresponde a un procedimiento para determinar los parámetros de la hipótesis, minimizando la suma de las pérdidas en un set de entrenamiento."
  },
  {
    "objectID": "tics579/legacy.html#ejemplo-softmax-regression",
    "href": "tics579/legacy.html#ejemplo-softmax-regression",
    "title": "Intuición y conceptos iniciales",
    "section": "Ejemplo: Softmax Regression",
    "text": "Ejemplo: Softmax Regression\n\nSoftmax Regression\n\n\nCorresponde la versión multiclase de una Regresión Logística. También se le llama una Shallow Network.\n\n\n\n\n\n\n\n\n\n\n\nConsideremos un problema de clasificación multiclase de \\(k\\) clases tal que:\n\n\n\n\nDatos de Entrenamiento: \\(x^{(i)}, y^{(i)} \\in {1,...,k}\\) para \\(i=1,...,m\\).\n\n\\(n\\): Es el número de Features.\n\\(m\\): Es el número de puntos en el training set.\n\\(k\\): Es el número de clases del problema.\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nVamos a tener en total \\(n \\times k\\) parámetros o pesos que actualizar."
  },
  {
    "objectID": "tics579/legacy.html#softmax-regression-hipótesis",
    "href": "tics579/legacy.html#softmax-regression-hipótesis",
    "title": "Intuición y conceptos iniciales",
    "section": "Softmax Regression: Hipótesis",
    "text": "Softmax Regression: Hipótesis\n\nVamos a definir una función que mapea valores de \\(x \\in \\mathbb{R}\\) a vectores de \\(k\\) dimensiones.\n\n\\[ h: \\mathbb{R}^n \\rightarrow \\mathbb{R}^k\\] \\[ x \\rightarrow h_\\theta(x) = \\theta^T x\\]\n\ndonde \\(\\theta \\in \\mathbb{R}^{n \\times k}\\) y \\(x \\in \\mathbb{R}^{n\\times 1}\\)\n\n\n\n\n\n\n\nWarning\n\n\n\nEn este caso usamos una hipótesis lineal, ya que se usa una multiplicación matricial (o producto punto) para relacionar \\(\\theta\\) y \\(x\\).\n\n\n\n\n\n\n\n\nNote\n\n\n\nEn este caso el output de \\(h_i(x)\\) devolverá la probabilidad de pertenecer a una cierta clase \\(i\\).\n\n\n\n\n\n\n\n\nImportant\n\n\n\n¿Cuál es el tamaño/dimensión de \\(h_\\theta(x)\\)?"
  },
  {
    "objectID": "tics579/legacy.html#notación-matricial",
    "href": "tics579/legacy.html#notación-matricial",
    "title": "Intuición y conceptos iniciales",
    "section": "Notación Matricial",
    "text": "Notación Matricial\n\nUna manera más conveniente de escribir estas operaciones es utilizar (Matrix Batch Form).\n\n\n\n\nDesign Matrix\n\\[X \\in \\mathbb{R}^{m \\times n} = \\begin{bmatrix}\n&-x^{(1)T}-\\\\\n& \\vdots & \\\\\n&-x^{(m)T}- &\\\\\n\\end{bmatrix}\\]\n\n\n\nLabels Vector\n\\[y \\in {1,...,k} = \\begin{bmatrix}\n&-y^{(1)}-\\\\\n& \\vdots & \\\\\n&-y^{(m)}- &\\\\\n\\end{bmatrix}\\]\n\n\n\nLa hipótesis también se puede reescribir de manera matricial como:\n\n\n\\[h_\\theta(X) = \\begin{bmatrix}\n&-h_\\theta(x^{(1)})^T-\\\\\n& \\vdots & \\\\\n&-h_\\theta(x^{(m)})^T-\\\\\n\\end{bmatrix}\\]\n\n\\[h_\\theta(X)= \\begin{bmatrix}\n&-x^{(1)T} \\theta-\\\\\n& \\vdots & \\\\\n&-x^{(m)T} \\theta-\\\\\n\\end{bmatrix} = X  \\theta\\]\n\n\n\n\n\n\n\n\nImportant\n\n\n\nNormalmente este tipo de operaciones son las que utilizaremos para hacer nuestro código."
  },
  {
    "objectID": "tics579/legacy.html#loss-function-softmaxcross-entropy-loss",
    "href": "tics579/legacy.html#loss-function-softmaxcross-entropy-loss",
    "title": "Intuición y conceptos iniciales",
    "section": "Loss Function: Softmax/Cross-Entropy Loss",
    "text": "Loss Function: Softmax/Cross-Entropy Loss\n\n\n\n\n\n\nWarning\n\n\n\nLa salida de nuestra Shallow Network retornará valores reales.\n\n\n\n\n\n\n\n\nTip\n\n\n\nPara poder tener una mejor interpretación del significado de cada una aplicaremos la función Softmax lo cual permitirá normalizar los resultados y llevará los resultados a una “distribución de probabilidad” (valores positivos que sumen 1).\n\n\n\n\n\n\n\n\n\n\nFormalmente definiremos la función Softmax como:\n\\[s_i = p(label = i) = \\frac{exp(h_i(x))}{\\sum_{j=1}^k exp(h_j(x))}\\]\n\\[s = \\begin{bmatrix}\n&s_1&\\\\\n& \\vdots & \\\\\n&s_k&\\\\\n\\end{bmatrix}\\]"
  },
  {
    "objectID": "tics579/legacy.html#loss-function-softmaxcross-entropy-loss-1",
    "href": "tics579/legacy.html#loss-function-softmaxcross-entropy-loss-1",
    "title": "Intuición y conceptos iniciales",
    "section": "Loss Function: Softmax/Cross-Entropy Loss",
    "text": "Loss Function: Softmax/Cross-Entropy Loss\nPara medir el error/pérdida de información utilizaremos el Negative Log Loss o Cross Entropy Loss.\n\\[l_{ce}(h(x), y) = -log\\left(p(label = y)\\right)\\]\n\n\n\n\n\n\nTip\n\n\n\nPara garantizar el éxito de nuestro modelo, básicamente queremos maximizar la probabilidad de encontrar la etiqueta correcta, es decir, que \\(p(label = y)\\) sea lo más alto posible.\n\n\n\n\n\n\n\n\nCaution\n\n\n\nNormalmente en los problemas de optimización no se suele maximizar sino minimizar. Minimizar el valor negativo es equivalente a maximizar. Esto sería equivalente a minimizar el error del modelo.\n\n\n\n\n\n\n\n\nWarning\n\n\n\nFinalmente por razones de estabilidad numérica, minimizamos el logaritmo de la probabilidad que es una técnica bien conocida en Estadística.\n\n\n\n\\[\\begin{align}\nl_{ce}(h(x), y) = -log\\left(p(label = y)\\right) &= -log \\left(\\frac{exp(h_{(i = y)}(x))}{\\sum_{j=1}^k exp(h_j(x))}\\right) \\\\\n&= - h_{(i=y)}(x) + log\\left(\\sum_{j = 1}^k exp(h_j(x))\\right)\\end{align}\\]"
  },
  {
    "objectID": "tics579/legacy.html#método-de-optimización",
    "href": "tics579/legacy.html#método-de-optimización",
    "title": "Intuición y conceptos iniciales",
    "section": "Método de Optimización",
    "text": "Método de Optimización\n\nEl último ingrediente de un algoritmo de aprendizaje es el método de optimización. Es necesario minimizar la pérdida promedio asociada a todos los puntos de un cierto set de entrenamiento. Para ello definimos esto formalmente como:\n\n\\[\\underset{\\theta}{minimize} = \\frac{1}{m} \\sum_{i=1}^m l_{ce}(h_\\theta(x^{(i)}), y^{(i)})\\]\n\n\n\n\n\n\nNote\n\n\n\n¿Cómo encontramos los parámetros \\(\\theta\\) que minimizan la pérdida de información/error de estimación?\n\n\n\nGradient Descent\n\n\nEs un método numérico que permite minimizar funciones moviéndose en dirección contraria al Gradiente. Es computacionalmente muy eficiente y fácil de implementar en código."
  },
  {
    "objectID": "tics579/legacy.html#gradient-descent",
    "href": "tics579/legacy.html#gradient-descent",
    "title": "Intuición y conceptos iniciales",
    "section": "Gradient Descent",
    "text": "Gradient Descent\n\n\nSe define el gradiente como la matriz que contiene las derivadas parciales de una función \\(f\\). Se denota como:\n\\[\\nabla_\\theta f(\\theta) \\in \\mathbb{R}^{n \\times k} =  \\begin{bmatrix}\n\\frac{\\partial f(\\theta)}{\\partial \\theta_{11}} & \\cdots & \\frac{\\partial f(\\theta)}{\\partial \\theta_{1k}} \\\\\n\\cdots & \\ddots & \\cdots \\\\\n\\frac{\\partial f(\\theta)}{\\partial \\theta_{n1}} & \\cdots & \\frac{\\partial f(\\theta)}{\\partial \\theta_{nk}}\n\\end{bmatrix}\\]\n\n\n\n\n\n\nTip\n\n\n\n\\(\\theta_{ij}\\) corresponde al parámetro que une el nodo/feature \\(i\\) con el nodo/predicción \\(j\\).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nEl gradiente apunta a la dirección de máximo crecimiento de la función \\(f\\)."
  },
  {
    "objectID": "tics579/legacy.html#gradient-descent-regla-de-actualización",
    "href": "tics579/legacy.html#gradient-descent-regla-de-actualización",
    "title": "Intuición y conceptos iniciales",
    "section": "Gradient Descent: Regla de Actualización",
    "text": "Gradient Descent: Regla de Actualización\nPara minimizar la función, la idea es descender iterativamente por el trayecto en contra del gradiente. La regla de actualización se define como:\n\\[\\theta := \\theta - \\alpha \\nabla_\\theta f(\\theta) = \\theta - \\frac{\\alpha}{m}\\nabla_\\theta l_{ce}(X\\theta,y)\\]\ncon \\(\\theta \\in \\mathbb{R}^{n \\times k}\\) y \\(\\alpha &gt; 0\\) corresponde al step size o learning rate.\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nEn nuestro caso \\(f\\) corresponderá a nuestro \\(l_{ce}\\) calculado anteriormente. El problema es, ¿cuánto vale el gradiente del Cross Entropy Loss?"
  },
  {
    "objectID": "tics579/legacy.html#calculando-el-gradiente-a-mano",
    "href": "tics579/legacy.html#calculando-el-gradiente-a-mano",
    "title": "Intuición y conceptos iniciales",
    "section": "Calculando el Gradiente a mano",
    "text": "Calculando el Gradiente a mano\n\nSimplifiquemos el problema a calcular para un sólo vector \\(x\\).\n\\[\\theta := \\theta - \\alpha \\nabla_\\theta l_{ce}(\\theta^Tx,y) \\]\n\n\n\n\n\n\n\nWarning\n\n\n\n¿Cuánto vale el Gradiente?\n\nNo es tan sencillo, ya que derivamos respecto a \\(\\theta\\) que es una matriz.\nPero derivamos a \\(\\theta^T x\\) que es un vector.\nPara ello, lo correcto es utilizar Calculo Diferencial Matricial, Jacobianos y Productos de Kroenecker (que probablemente no han visto en ningún curso).\n\nSPOILER: Yo tampoco lo he visto en ningún curso.\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\n\nUsaremos un truco (sumamente hacky 😱) que jamás deben revelar y que avergonzaría a cualquier profesor de Cálculo.\n\nPretenderemos que todos los valores son escalares y corregiremos las dimensiones al final."
  },
  {
    "objectID": "tics579/legacy.html#calculando-el-gradiente-a-mano-1",
    "href": "tics579/legacy.html#calculando-el-gradiente-a-mano-1",
    "title": "Intuición y conceptos iniciales",
    "section": "Calculando el Gradiente a mano",
    "text": "Calculando el Gradiente a mano\n\nSimplifiquemos el problema pensando que calcularemos el Gradiente para un sólo vector \\(x\\).\n\n\nEs decir, \\(x \\in \\mathbb{R}^{n\\times1}\\).\n\nAdemás sabemos que \\(\\nabla_\\theta l_{ce}(\\theta^Tx, y)\\) debe tener dimensiones \\(n \\times k\\).\n\n\n\n\n\n\nImportant\n\n\n\n¿Por qué?\n\n\n\n\n\\[\\nabla_\\theta l_{ce}(\\theta^T x,y) = \\frac{\\partial l_{ce}(\\theta^T x,y)}{\\partial \\theta^T x} \\cdot \\frac{\\partial \\theta^Tx}{\\partial \\theta}\\]\n\n\\[\\frac{\\partial l_{ce}(\\theta^T x,y)}{\\partial \\theta^T x} = \\frac{\\partial l_{ce}(h_\\theta(x), y)}{\\partial h_\\theta(x)} = \\begin{bmatrix}\n\\frac{\\partial l_{ce}(h,y)}{\\partial h_1} \\\\\n\\vdots\\\\\n\\frac{\\partial l_{ce}(h,y)}{\\partial h_k} \\\\\n\\end{bmatrix}\\]\n\n\n\n\n\n\n\n\nTip\n\n\n\nLuego el gradiente de \\(l_{ce}\\) respecto a \\(h\\) tiene dimensiones \\(k \\times 1\\)."
  },
  {
    "objectID": "tics579/legacy.html#calculando-el-gradiente-a-mano-2",
    "href": "tics579/legacy.html#calculando-el-gradiente-a-mano-2",
    "title": "Intuición y conceptos iniciales",
    "section": "Calculando el Gradiente a mano",
    "text": "Calculando el Gradiente a mano\n\\[\\begin{align}\n\\frac{\\partial l_{ce}(h,y)}{\\partial h_i} &= \\frac{\\partial }{\\partial h_i}\\left(-h_{(i = y)} + log \\sum_{j = 1}^k exp(h_j)\\right) \\\\\n&= -\\frac{\\partial h_{(i = y)}}{\\partial h_i}+ \\frac{1}{\\sum_{j = 1}^k exp(h_j)} \\cdot \\frac{\\partial}{\\partial h_i}\\left(\\sum_{j=1}^k exp(h_j)\\right) \\\\\n&= -\\frac{\\partial h_{(i = y)}}{\\partial h_i}+ \\frac{exp(h_i)}{\\sum_{j = 1}^k exp(h_j)} \\\\\n&= - 1\\{i=y\\} + s_i = s_i - 1\\{i=y\\}\n\\end{align}\n\\]\n\n\n\n\n\n\nTip\n\n\n\n\\[1\\{i = y\\} = \\begin{cases}\n1,  & \\text{i = y} \\\\\n0, & \\text{otherwise}\n\\end{cases}\n\\]\n\n\n\nFinalmente en forma vectorial quedaría como:\n\n\n\\[\\frac{\\partial l_{ce}(\\theta^T x,y)}{\\partial \\theta^T x} = s - e_y\\]\n\n\n\n\n\n\n\nTip\n\n\n\nDonde \\(z\\), es el vector de Softmax y \\(e_y\\) es un vector con un 1 en la posición \\(y\\) y 0 en el resto."
  },
  {
    "objectID": "tics579/legacy.html#calculando-el-gradiente-a-mano-3",
    "href": "tics579/legacy.html#calculando-el-gradiente-a-mano-3",
    "title": "Intuición y conceptos iniciales",
    "section": "Calculando el Gradiente a mano",
    "text": "Calculando el Gradiente a mano\n\n\n\\[\\nabla_\\theta l_{ce}(\\theta^T x,y) = \\frac{\\partial l_{ce}(\\theta^T x,y)}{\\partial \\theta^T x} \\cdot \\frac{\\partial \\theta^Tx}{\\partial \\theta}\\] \\[\\nabla_\\theta l_{ce}(\\theta^T x,y) = (s-e_y)\\cdot x \\]\n\n\n\n\n\n\n\nOjo con las dimensiones\n\n\n\n\n\\(s-e_y \\in \\mathbb{R}^{k \\times 1}\\)\n\\(x \\in \\mathbb{R}^{n \\times 1}\\)\n\n\n\n\n\n\nLuego:\n\\[\\nabla_\\theta l_{ce}(\\theta^T x,y) = x (s-e_y)^T\\]\n\n\n\n\n\n\n\nCaution\n\n\n\n¿Cuál es el tamaño de \\(\\nabla_\\theta l_{ce}(\\theta^T x,y)\\)?\n\n\n\n\n\n\n\n\nNote\n\n\n\n\\(n \\times k\\)\n\n\n\n\n\n\n\n\nWarning\n\n\n\n¿Por qué?"
  },
  {
    "objectID": "tics579/legacy.html#calculando-el-gradiente-matrix-batch-form",
    "href": "tics579/legacy.html#calculando-el-gradiente-matrix-batch-form",
    "title": "Intuición y conceptos iniciales",
    "section": "Calculando el Gradiente Matrix Batch Form",
    "text": "Calculando el Gradiente Matrix Batch Form\n\nEsto sería equivalente a tomar en consideración todos los puntos del Training Set\n\n\n\\[\\begin{align}\\nabla_\\theta l_{ce}(X\\theta,y) &= \\frac{\\partial l_{ce}(X\\theta,y)}{\\partial X\\theta} \\cdot \\frac{\\partial X\\theta}{\\partial \\theta}\\\\\n&= (S - I_y) \\cdot X \\\\\n&= X^T \\cdot (S - I_y)\n\\end{align}\\]\n\n\n\n\n\n\nTip\n\n\n\n\n\\(S\\) corresponde al Softmax de \\(X\\theta\\) aplicado por filas.\n\\(I_y\\) corresponde al One Hot Encoder de las etiquetas. Filas con 1 en la etiqueta correcta y 0 en el resto.\n\n\n\n\n\n\n\n\n\n\nOjo con las dimensiones\n\n\n\n\n\\(S - I_y \\in \\mathbb{R}^{m \\times k}\\)\n\\(X \\in \\mathbb{R}^{m \\times n}\\)\n\n\n\n\n\n\n\n\n\nWarning\n\n\n\n¿Cuál es el tamaño de \\(\\nabla_\\theta l_{ce}(X\\theta,y)\\)?\n\n\n\n\n\nFinalmente la Regla de Actualización de parámetros usando Gradient Descent queda como:\n\\[\\theta := \\theta - \\frac{\\alpha}{m} X^T (S - I_y)\\]"
  },
  {
    "objectID": "tics579/legacy.html#conclusiones",
    "href": "tics579/legacy.html#conclusiones",
    "title": "Intuición y conceptos iniciales",
    "section": "Conclusiones",
    "text": "Conclusiones\n\n\n\n\n\n\n\n\nTip\n\n\n\n\nAcabamos de entrenar una Shallow Network, sin definir ningún concepto Fancy que es propio del área.\nNo hemos hablado ni de:\n\nForward Pass\nEpochs\nBackpropagation\nAdam\nActivation Functions\netc.\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nAplicando esta simple regla se puede obtener cerca de un 8% de error clasificando dígitos en MNIST.\nSe puede programar en pocas líneas en Python.\n\n\n\n\n\n\n\n\n\n\nPero, ¿qué pasa con arquitecturas más complejas?\n\n\n\n\n\n\n\n\nMás info legacy que tiene que ir entrando en próximas clases."
  },
  {
    "objectID": "tics579/legacy.html#clase-anterior",
    "href": "tics579/legacy.html#clase-anterior",
    "title": "Intuición y conceptos iniciales",
    "section": "Clase anterior",
    "text": "Clase anterior\n\nLa Regresión Softmax es capaz de generar separaciones lineales para más de dos clases para cualquier punto \\(x \\in \\mathbb{R}^{1 \\times n}\\):\n\n\n\n\n\n\\(h_\\theta(x) = \\theta^T x\\), tal que \\(\\theta \\in \\mathbb{R}^{n \\times k}\\).\n\n\n\n\n\n\n\n\nCaution\n\n\n\nEsta hipótesis es bastante limitada, y existen muchos problemas que no podrán solucionarse con este tipo de solución."
  },
  {
    "objectID": "tics579/legacy.html#limitaciones-de-una-hipótesis-lineal",
    "href": "tics579/legacy.html#limitaciones-de-una-hipótesis-lineal",
    "title": "Intuición y conceptos iniciales",
    "section": "Limitaciones de una Hipótesis Lineal",
    "text": "Limitaciones de una Hipótesis Lineal\n\nEs claro que un problema como el que se muestra acá no podrá ser resuelto mediante un clasificador lineal (hipótesis lineal).\n\n\n\n\n\n\n\n\n\n¿Cómo se resuelve este tipo de problemas?\n\n\n\n\nCreando nuevas features que permitan predecir problemas no-lineales.\n\n\n\n\n\\[h_\\theta(x) = \\theta^T \\phi(x)\\]\n\ntal que \\(\\theta \\in \\mathbb{R}^{n \\times k}\\) y \\(\\phi(x): \\mathbb{R}^n \\rightarrow \\mathbb{R}^d\\) con \\(d &gt; n\\).\n\n\n\n\n\n\nTip\n\n\n\n\nBásicamente \\(\\phi(.)\\) es la manera matemática de denotar la creación de más features que permiten resolver el problema.\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nSVM es un algoritmo que hace esto de manera automática utilizando el famoso Kernel Trick, donde \\(\\phi(.)\\) es conocido como el Kernel."
  },
  {
    "objectID": "tics579/legacy.html#diferencias-entre-ml-y-dl",
    "href": "tics579/legacy.html#diferencias-entre-ml-y-dl",
    "title": "Intuición y conceptos iniciales",
    "section": "Diferencias entre ML y DL",
    "text": "Diferencias entre ML y DL\n\n\n\n\n\n\nLa diferencia principal entre el Machine Learning y el Deep Learning es la manera en la que se crean las features.\n\n\n\n\n\n\n\nImportant\n\n\n\n\nNormalmente el Machine Learning está enfocado en que manualmente se generen features.\nDeep Learning busca que el Algoritmo busque esas features. El énfasis está en buscar la Arquitectura adecuada."
  },
  {
    "objectID": "tics579/legacy.html#cómo-creamos-features-de-manera-automática",
    "href": "tics579/legacy.html#cómo-creamos-features-de-manera-automática",
    "title": "Intuición y conceptos iniciales",
    "section": "¿Cómo creamos features de manera automática?",
    "text": "¿Cómo creamos features de manera automática?\n\n\nUna primera idea sería crearlas de manera lineal:\n\\[\\phi(x) = W^T x\\]\ndonde \\(W \\in \\mathbb{R}^{n \\times d}\\).\n\n\n\n\n\n\n\n\n\n\nEn este caso nuestra hipótesis queda como: \\[ h_\\theta(x) = \\theta^T \\phi(x) = \\theta^T W^T x = \\tilde{\\theta}^T x\\]\n\n\n\n\n\n\nCaution\n\n\n\nLamentablemente este approach no funciona, ya que \\(\\tilde{\\theta}^T\\) es sólo otra matriz que genera dos transformaciones simultáneas, pero que en este caso llevará de \\(n\\) a \\(k\\) de manera directa.\n\n\n\n\n\n\n\n\n\nOjo con las dimensiones.\n\n\n\n\n\\(W^t\\) tiene dimensión \\(d \\times n\\).\nSabemos que \\(h_\\theta(x)\\) tiene que devolver \\(k\\) outputs. Por lo tanto, \\(\\theta^T\\) tiene que tener dimensiones \\(k \\times d\\).\n\\(x\\) es un vector con \\(n\\) features por lo tanto es de dimensión \\(n \\times 1\\).\nEso hará que \\(h_\\theta(x)\\) sea de tamaño \\(k \\times 1\\)."
  },
  {
    "objectID": "tics579/legacy.html#entonces-cómo",
    "href": "tics579/legacy.html#entonces-cómo",
    "title": "Intuición y conceptos iniciales",
    "section": "¿Entonces cómo?",
    "text": "¿Entonces cómo?\n\n\nVamos a utilizar funciones no lineales. Cualquiera sirve tal que:\n\\[\\phi(x) = \\sigma(W^Tx)\\]\ndonde \\(W \\in \\mathbb{R}^{n \\times d}\\) y \\(\\sigma: \\mathbb{R}^d \\rightarrow \\mathbb{R}^d\\), es decir, \\(\\sigma\\) es una función escalar.\n\n\n\n\n\n\n\n\n\nDe este modo nuestra hipótesis quedaría como:\n\\[h_\\theta(x) = \\theta^T \\sigma(W^T x) \\neq \\tilde{\\theta}^T x\\]\n\n\n\n\n\n\n\nImportant\n\n\n\nEstamos aplicando una transformación no-lineal a la transformación lineal de \\(x\\) con \\(W\\).\n\n\n\n\n\n\n\n\nTip\n\n\n\nNormalmente escogeremos funciones no-lineales que sean diferenciables para poder actualizar \\(\\theta\\) y \\(W\\).\nEsto es lo que llamaremos el entrenamiento de una red neuronal."
  },
  {
    "objectID": "tics579/legacy.html#activation-functions",
    "href": "tics579/legacy.html#activation-functions",
    "title": "Intuición y conceptos iniciales",
    "section": "Activation Functions",
    "text": "Activation Functions\n\n\n\nDefiniremos las funciones de activación como funciones no-lineales que se aplican a la salida de cada capa para evitar la composición de dos trasnformaciones lineales consecutivas.\n\n\n\n\n\n\n\nImportant\n\n\n\nEsta es la única manera de transformar hipótesis lineales en hipótesis no lineales.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFunciones Clásicas\n\n\n\n\nSigmoide\nReLU\nTanh\nSoftmax\n\n\n\n\n\n\n\n\n\n\nFunciones más modernas\n\n\n\n\nSwish\nGELU\nELU"
  },
  {
    "objectID": "tics579/legacy.html#layer-non-linear-softmax-regression",
    "href": "tics579/legacy.html#layer-non-linear-softmax-regression",
    "title": "Intuición y conceptos iniciales",
    "section": "2-Layer non-linear Softmax Regression",
    "text": "2-Layer non-linear Softmax Regression\n\n\n\\[h_\\theta(x) = W_2^T \\phi(x) = W_2^T \\sigma(W_1^T x)\\]\ndonde \\(\\theta=\\{W_1 \\in \\mathbb{R}^{n \\times d}, W_2 \\in \\mathbb{R}^{d \\times k}\\}\\)\n\n\n\n\n\n\nCaution\n\n\n\n\nPodemos pensar que \\(W_1 \\in \\mathbb{R}^{n \\times d}\\) es aquella matriz que lleva a un vector \\(x\\) de \\(n\\) a \\(d\\) dimensiones.\nDe la misma forma, \\(W_2 \\in \\mathbb{R}^{d \\times k}\\) es aquella matriz que lleva a un vector \\(x\\) de \\(d\\) a \\(k\\) dimensiones/salidas.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMatrix Batch Form\n\\[h_\\theta(X) = \\sigma(XW_1)W_2\\]\n\n\n\nUpdate Rule\n\\[W_1 := W_1 - \\frac{\\alpha}{m} \\nabla_{W_1} l_{ce}(h_\\theta(X),y)\\] \\[W_2 := W_2 - \\frac{\\alpha}{m} \\nabla_{W_2} l_{ce}(h_\\theta(X),y)\\]"
  },
  {
    "objectID": "tics579/legacy.html#cálculo-de-gradientes",
    "href": "tics579/legacy.html#cálculo-de-gradientes",
    "title": "Intuición y conceptos iniciales",
    "section": "Cálculo de Gradientes",
    "text": "Cálculo de Gradientes\n\n\n\n\n\n\n\n\nGradiente de \\(W_1\\)\n\n\n\n\\[\\begin{align} \\nabla_{W_1} &= \\frac{\\partial l_{ce}(h_\\theta(X),y)}{\\partial \\sigma(XW_1)} \\cdot \\frac{\\partial h_\\theta(X)}{\\partial \\sigma(XW_1)} \\cdot \\frac{\\partial \\sigma(XW_1)}{\\partial XW_1} \\cdot \\frac{\\partial XW_1}{\\partial W_1} \\\\\n&= (Z-I_y)_{m \\times k} \\cdot (W_{2})_{d \\times k}  \\cdot \\sigma'(XW_1)_{m \\times d} \\cdot X_{m \\times n}\n\\end{align}\\]\nLuego, corrigiendo por dimensiones obtenemos que \\[\\nabla_{W_1} \\in \\mathbb{R}^{n \\times d} = X^T_{n \\times m} \\left[\\sigma'(XW_1) \\odot (Z-I_y)W_2^T \\right]_{m \\times d}\\]\n\n\n\n\n\n\n\n\n\nGradiente de \\(W_2\\)\n\n\n\n\\[\\begin{align} \\nabla_{W_2} &= \\frac{\\partial l_{ce}(h_\\theta(X),y)}{\\partial h_\\theta(X)} \\cdot \\frac{\\partial h_\\theta(X)}{\\partial W_2}\\\\\n&= (Z-I_y)_{m\\times k} \\cdot \\sigma(XW_1)_{m \\times d}\n\\end{align}\\]\nLuego, corrigiendo por dimensiones obtenemos que \\[\\nabla_{W_2} \\in \\mathbb{R}^{d \\times k} = \\sigma(XW_1)^T_{d \\times m}(Z - I_y)_{m \\times k}\\]\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\n\n\\(\\odot\\) representa el producto Hadamard entre dos matrices. Esto es, multiplicación elemento a elemento.\n\\(\\sigma'(.)\\) representa la derivada de la función de activación \\(\\sigma(.)\\)"
  },
  {
    "objectID": "tics579/legacy.html#definiciones",
    "href": "tics579/legacy.html#definiciones",
    "title": "Intuición y conceptos iniciales",
    "section": "Definiciones",
    "text": "Definiciones\n\n\n\n\n\n\n\n\n\n\n\n\n\nInputs\n\n\n\n\\[Z_1 = X\\]\n\n\n\n\n\n\n\n\n\nIntermediate Outputs\n\n\n\n\\[Z_{i+1} = \\sigma_i(Z_iW_i), i=1,...,L\\] \\[Z_i \\in \\mathbb{R}^{m \\times n_i}\\]\n\n\n\n\n\n\n\n\n\nOutput (Head)\n\n\n\n\\[h_\\theta(X) = Z_{L+1}\\]\n\n\n\n\n\n\n\n\n\nParámetros\n\n\n\n\\[\\theta = \\left[W_1,..., W_L\\right]\\] \\[ W_i \\in \\mathbb{R}^{n_i \\times n_{i+1}}\\]\n\n\n\n\n\n\n\n\n\n\nCaution\n\n\n\n\nLas salidas intermedias (intermediate outputs) son las mal llamadas hidden layers. Esta red cuenta con \\(L\\) hidden layers \\(W\\)."
  },
  {
    "objectID": "tics579/legacy.html#definiciones-1",
    "href": "tics579/legacy.html#definiciones-1",
    "title": "Intuición y conceptos iniciales",
    "section": "Definiciones",
    "text": "Definiciones\n\n\n\n\n\n\nRed Neuronal\n\n\n\nVamos a definir como Red Neuronal un tipo particular de hipótesis que consiste en:\n\nMultiples capas que permiten cambiar de dimensión.\nFunciones de activación no-lineales y diferenciables que permiten desacoplar transformaciones lineales.\nUn set de parámetros optimizables, que permiten reducir una Loss Function.\n\n\n\n\n\n\n\n\n\nCaution\n\n\n\nSi bien estas redes toman inspiración de la biólogía, poco o nada tienen que ver con neuronas reales.\n\n\n\n\n\n\n\n\nWarning\n\n\n\nTérminos como Neural Network, Deep Networks, Deep Learning, son ampliamente usados y algunas veces usados para diferenciar el tamaño de distintas arquitecturas.\nNosotros los vamos a usar prácticamente como sinónimos.\n\n\n\nUpdate Rule\n\\[W_i := W_i - \\frac{\\alpha}{m} \\nabla_{W_i} l(h_\\theta(X),y)\\]"
  },
  {
    "objectID": "tics579/legacy.html#cálculo-de-gradientes-de-una-red-neuronal",
    "href": "tics579/legacy.html#cálculo-de-gradientes-de-una-red-neuronal",
    "title": "Intuición y conceptos iniciales",
    "section": "Cálculo de Gradientes de una Red Neuronal",
    "text": "Cálculo de Gradientes de una Red Neuronal\n\\[\\nabla_{W_i} l(Z_{L+1},y) = \\underbrace{\\frac{\\partial l(Z_{L+1},i)}{\\partial Z_{L+1}} \\cdot \\frac{\\partial Z_{{L+1}}}{\\partial Z_L} \\cdot \\frac{\\partial Z_L}{\\partial Z_{L-1}}...\\cdot \\frac{\\partial Z_{i+2}}{\\partial Z_{i+1}}}_{G_{i+1} = \\frac{\\partial l(Z_{L+1},y)}{\\partial Z_{i+1}}}\\cdot \\frac{\\partial Z_{i+1}}{\\partial W_i}\\]\n\n\n\n\n\n\nGradiente Entrante (Incoming Backward Gradient)\n\n\n\n\nVamos a definir el Gradiente Entrante hasta antes de la capa \\(i\\) (desde la salida en dirección a la entrada) como: \\[\\begin{align}G_i &= G_{i+1} \\cdot \\frac{\\partial Z_{i + 1}}{\\partial Z_i} \\\\\n&= G_{i+1} \\cdot \\frac{\\partial \\sigma_i(Z_i W_i)}{\\partial Z_i W_i} \\cdot \\frac{\\partial Z_i W_i}{\\partial Z_i}_{} \\\\\n&= (G_{i+1})_{m \\times n_{i+1}} \\cdot \\sigma'(Z_i W_i)_{m \\times n_{i + 1}} \\cdot (W_i)_{n_i \\times n_{i+1}}\n\\end{align}\\]\n\n\n\nLuego, \\[ G_i \\in \\mathbb{R}^{m \\times n_i} = \\left[ G_{i+1} \\odot \\sigma_i'(Z_i W_i)\\right] W_i^T\\]"
  },
  {
    "objectID": "tics579/legacy.html#cálculo-de-gradientes-de-una-red-neuronal-1",
    "href": "tics579/legacy.html#cálculo-de-gradientes-de-una-red-neuronal-1",
    "title": "Intuición y conceptos iniciales",
    "section": "Cálculo de Gradientes de una Red Neuronal",
    "text": "Cálculo de Gradientes de una Red Neuronal\n\\[\\begin{align}\\nabla_{W_i} l(Z_{L+1},y) &= G_{i+1} \\cdot \\frac{\\partial Z_{i+1}}{\\partial W_i} \\\\\n&= G_{i+1} \\cdot \\frac{\\partial \\sigma_i'(Z_i W_i)}{\\partial Z_i W_i} \\cdot \\frac{\\partial Z_i W_i}{\\partial W_i} \\\\\n&= (G_{i+1})_{m \\times n_{i+1}} \\cdot \\sigma'(Z_i W_i)_{m \\times n_{i+1}} \\cdot (Z_i)_{m \\times n_i}\n\\end{align}\\]\n\n\n\n\n\n\n\nImportant\n\n\n\nLuego el Gradiente de cualquier Loss Function con respecto a un set de parámetros \\(W_i\\) se escribe como:\n\\[\\nabla_{W_i}l(Z_{L+1}, y) = Z_i^T \\left[G_{i+1} \\odot \\sigma'(Z_i W_i)\\right]\\]"
  },
  {
    "objectID": "tics579/legacy.html#forward-y-backward-passes",
    "href": "tics579/legacy.html#forward-y-backward-passes",
    "title": "Intuición y conceptos iniciales",
    "section": "Forward y Backward Passes",
    "text": "Forward y Backward Passes\n\nBackpropagation\n\nCorresponde al Algoritmo con el cuál calcularemos los Gradientes de una Red Neuronal. Es un nombre muy fancy para calcular la Regla de la Cadena de manera eficiente aplicando caching de los resultados intermedios.\n\n\n\n\nForward Pass\n\nInicializar \\(Z_1 = X\\).\nIterar calculando: \\(Z_i = \\sigma_i(Z_i W_i), i=1,...,L\\).\n\n\n\nBackward Pass\n\nInicializar \\(G_{L+1} = \\nabla_{Z_{L+1}}l(Z_{L+1},y) = S-I_y\\) (Este ejemplo es sólo el caso de Cross Entropy como Loss Function).\nIterar calculando: \\(G_i = \\left[G_{i+1} \\odot \\sigma_i'(Z_i W_i)\\right]W_i^T, i=L,...,1\\)\n\n\n\nUpdate Rule\n\nCalcular Gradientes para poder aplicar el Update Rule.\n\n\\[W_i := W_i - \\frac{\\alpha}{m}\\nabla_{W_i}l(Z_{L+1},y) = W_i - \\frac{\\alpha}{m} Z_i^T\\left[G_{i+1} \\odot \\sigma'(Z_i W_i)\\right]\\]"
  },
  {
    "objectID": "tics579/legacy.html#conceptos-clásicos-del-entrenamiento-de-una-nn",
    "href": "tics579/legacy.html#conceptos-clásicos-del-entrenamiento-de-una-nn",
    "title": "Intuición y conceptos iniciales",
    "section": "Conceptos Clásicos del Entrenamiento de una NN",
    "text": "Conceptos Clásicos del Entrenamiento de una NN\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nDefiniremos una Epoch como el número de veces que repetiremos el Algoritmo de Backpropagation con todos los datos de Entrenamiento. El número de epochs de entrenamiento será un hiperparámetro de un modelo.\nDefiniremos el learning rate como un hiperparámetro que controlará el aprendizaje del modelo.\nDefiniremos este tipo de redes neuronales como Feed Forward Networks o FFN aunque en la práctica tienen una pequeña modificación que veremos en la siguiente clase.\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nEste tipo de redes es muy utilizada y recibe diversos nombres:\n\nFully Connected Layers\nDense Layers: Proviene de la nomenclatura utilizada por Tensorflow.\nLinear Layers: Proviene de la nomenclatura utilizada por Pytorch, pero no es del todo correcto.\nMLP o Multilayer Perceptron."
  },
  {
    "objectID": "tics579/notebooks/Training_Tricks.html",
    "href": "tics579/notebooks/Training_Tricks.html",
    "title": "1. BatchNorm",
    "section": "",
    "text": "import torch\nimport torch.nn as nn\ntorch.manual_seed(42)\n\nX = torch.randint(1,20, (10, 3)).float()\nprint(\"=\"*60)\nprint(\"Data antes de ser Normalizada: \")\nprint(\"=\"*60)\nX\n\n============================================================\nData antes de ser Normalizada: \n============================================================\n\n\ntensor([[16., 14., 12.],\n        [15.,  3., 15.],\n        [16.,  7.,  6.],\n        [14.,  3., 16.],\n        [ 4.,  4., 18.],\n        [ 8., 11.,  9.],\n        [18., 18., 14.],\n        [ 5., 17., 11.],\n        [15.,  9., 11.],\n        [10.,  7.,  7.]])\nbn = nn.BatchNorm1d(3)\nbn.train()\noutput_pytorch= bn(X)\nprint(\"=\"*60)\nprint(\"Forward Pass Train utilizando Pytorch\")\nprint(\"=\"*60)\noutput_pytorch\n\n============================================================\nForward Pass Train utilizando Pytorch\n============================================================\n\n\ntensor([[ 0.8261,  0.8912,  0.0270],\n        [ 0.6142, -1.1946,  0.8378],\n        [ 0.8261, -0.4361, -1.5946],\n        [ 0.4024, -1.1946,  1.1081],\n        [-1.7157, -1.0050,  1.6486],\n        [-0.8684,  0.3224, -0.7838],\n        [ 1.2497,  1.6498,  0.5676],\n        [-1.5038,  1.4601, -0.2432],\n        [ 0.6142, -0.0569, -0.2432],\n        [-0.4448, -0.4361, -1.3243]], grad_fn=&lt;NativeBatchNormBackward0&gt;)\nprint(\"=\"*60)\nprint(\"Parámetros Utilizados: \")\nprint(\"=\"*60)\nbn.weight.data, bn.bias.data\n\n============================================================\nParámetros Utilizados: \n============================================================\n\n\n(tensor([1., 1., 1.]), tensor([0., 0., 0.]))\nprint(\"=\"*60)\nprint(\"Promedio y Varianza Acumuladas\")\nprint(\"=\"*60)\nbn.running_mean, bn.running_var\n\n============================================================\nPromedio y Varianza Acumuladas\n============================================================\n\n\n(tensor([1.2100, 0.9300, 1.1900]), tensor([3.3767, 3.9900, 2.4211]))"
  },
  {
    "objectID": "tics579/notebooks/Training_Tricks.html#cálculo-manual",
    "href": "tics579/notebooks/Training_Tricks.html#cálculo-manual",
    "title": "1. BatchNorm",
    "section": "Cálculo Manual",
    "text": "Cálculo Manual\n\neps = 1e-5\nbatch_mean = X.mean(dim=0, keepdim=True)\nbatch_var_train = X.var(dim=0, unbiased=False, keepdim=True)\nx_norm = (X-batch_mean)/torch.sqrt(batch_var_train + eps)\nw = torch.tensor([1,1,1])\nb = torch.tensor([0,0,0])\n\n\nprint(\"=\"*60)\nprint(\"Forward Pass Train obtenido Manualmente\")\nprint(\"=\"*60)\nw*x_norm + b\n\n============================================================\nForward Pass Train obtenido Manualmente\n============================================================\n\n\ntensor([[ 0.8261,  0.8912,  0.0270],\n        [ 0.6142, -1.1946,  0.8378],\n        [ 0.8261, -0.4361, -1.5946],\n        [ 0.4024, -1.1946,  1.1081],\n        [-1.7157, -1.0050,  1.6486],\n        [-0.8684,  0.3224, -0.7838],\n        [ 1.2497,  1.6498,  0.5676],\n        [-1.5038,  1.4601, -0.2432],\n        [ 0.6142, -0.0569, -0.2432],\n        [-0.4448, -0.4361, -1.3243]])\n\n\n\nbatch_var_train\n\ntensor([[22.2900, 27.8100, 13.6900]])\n\n\n\nprint(\"=\"*60)\nprint(\"Test Time: \")\nprint(\"=\"*60)\n\nbatch_var_eval = X.var(dim=0, unbiased=True, keepdim=True)\n\nalpha = 0.1\nrm = (1-alpha)*torch.tensor([0,0,0]) + alpha*batch_mean\nrv = (1-alpha)*torch.tensor([1,1,1]) + alpha*batch_var_eval\nprint(\"Media: \")\nprint(rm)\nprint(\"Varianza: \")\nprint(rv)\n\nprint(\"Normalización en Modo Evaluación obtenido de manera manual...\")\nprint(\"=\"*60)\nx_normalized_eval = (X - rm)/torch.sqrt(rv + eps)\nbn.weight.data*x_normalized_eval+bn.bias.data\n\n============================================================\nTest Time: \n============================================================\nMedia: \ntensor([[1.2100, 0.9300, 1.1900]])\nVarianza: \ntensor([[3.3767, 3.9900, 2.4211]])\nNormalización en Modo Evaluación obtenido de manera manual...\n============================================================\n\n\ntensor([[ 8.0487,  6.5432,  6.9473],\n        [ 7.5045,  1.0363,  8.8753],\n        [ 8.0487,  3.0388,  3.0913],\n        [ 6.9603,  1.0363,  9.5180],\n        [ 1.5183,  1.5369, 10.8034],\n        [ 3.6951,  5.0413,  5.0193],\n        [ 9.1370,  8.5457,  8.2327],\n        [ 2.0625,  8.0451,  6.3046],\n        [ 7.5045,  4.0400,  6.3046],\n        [ 4.7835,  3.0388,  3.7339]])\n\n\n\nbn.eval()\nprint(\"=\"*60)\nprint(\"Forward Pass en Modo Evaluación usando Pytorch...\")\nprint(\"=\"*60)\nbn(X)\n\n============================================================\nForward Pass en Modo Evaluación usando Pytorch...\n============================================================\n\n\ntensor([[ 8.0487,  6.5432,  6.9473],\n        [ 7.5045,  1.0363,  8.8753],\n        [ 8.0487,  3.0388,  3.0913],\n        [ 6.9603,  1.0363,  9.5180],\n        [ 1.5183,  1.5369, 10.8034],\n        [ 3.6951,  5.0413,  5.0193],\n        [ 9.1370,  8.5457,  8.2327],\n        [ 2.0625,  8.0451,  6.3046],\n        [ 7.5045,  4.0400,  6.3046],\n        [ 4.7835,  3.0388,  3.7339]], grad_fn=&lt;NativeBatchNormBackward0&gt;)"
  },
  {
    "objectID": "tics579/notebooks/Training_Tricks.html#layer-norm",
    "href": "tics579/notebooks/Training_Tricks.html#layer-norm",
    "title": "1. BatchNorm",
    "section": "2. Layer Norm",
    "text": "2. Layer Norm\n\nln = nn.LayerNorm(3)\noutput_pytorch = ln(X)\nprint(\"=\"*60)\nprint(\"Forward Pass obtenido utilizando Pytorch\")\nprint(\"=\"*60)\noutput_pytorch\n\n============================================================\nForward Pass obtenido utilizando Pytorch\n============================================================\n\n\ntensor([[ 1.2247,  0.0000, -1.2247],\n        [ 0.7071, -1.4142,  0.7071],\n        [ 1.4084, -0.5930, -0.8154],\n        [ 0.5249, -1.3997,  0.8748],\n        [-0.7071, -0.7071,  1.4142],\n        [-1.0690,  1.3363, -0.2673],\n        [ 0.7071,  0.7071, -1.4142],\n        [-1.2247,  1.2247,  0.0000],\n        [ 1.3363, -1.0690, -0.2673],\n        [ 1.4142, -0.7071, -0.7071]], grad_fn=&lt;NativeLayerNormBackward0&gt;)\n\n\n\nprint(\"=\"*60)\nprint(\"Parámetros Iniciales: \")\nprint(\"=\"*60)\nln.weight.data, ln.bias.data\n\n============================================================\nParámetros Iniciales: \n============================================================\n\n\n(tensor([1., 1., 1.]), tensor([0., 0., 0.]))\n\n\n\neps = 1e-5\nsample_mean = X.mean(dim=1, keepdim=True)\nsample_var = X.var(dim=1, unbiased=False, keepdim=True)\nx_normalized = (X - sample_mean) / torch.sqrt(sample_var + eps)\nprint(\"=\"*60)\nprint(\"Forward Pass Obtenido de manera Manual\")\nprint(\"=\"*60)\nln.weight.data*x_normalized + ln.bias.data\n\n============================================================\nForward Pass Obtenido de manera Manual\n============================================================\n\n\ntensor([[ 1.2247,  0.0000, -1.2247],\n        [ 0.7071, -1.4142,  0.7071],\n        [ 1.4084, -0.5930, -0.8154],\n        [ 0.5249, -1.3997,  0.8748],\n        [-0.7071, -0.7071,  1.4142],\n        [-1.0690,  1.3363, -0.2673],\n        [ 0.7071,  0.7071, -1.4142],\n        [-1.2247,  1.2247,  0.0000],\n        [ 1.3363, -1.0690, -0.2673],\n        [ 1.4142, -0.7071, -0.7071]])"
  },
  {
    "objectID": "tics579/notebooks/Training_Tricks.html#rmsnorm",
    "href": "tics579/notebooks/Training_Tricks.html#rmsnorm",
    "title": "1. BatchNorm",
    "section": "3. RMSNorm",
    "text": "3. RMSNorm\n\nprint(\"=\"*60)\nprint(\"Forward Pass Obtenido utilizando Pytorch\")\nprint(\"=\"*60)\nrms_layer = nn.RMSNorm(3)\nrms_layer(X)\n\n============================================================\nForward Pass Obtenido utilizando Pytorch\n============================================================\n\n\ntensor([[1.1352, 0.9933, 0.8514],\n        [1.2127, 0.2425, 1.2127],\n        [1.5007, 0.6566, 0.5628],\n        [1.1294, 0.2420, 1.2907],\n        [0.3672, 0.3672, 1.6524],\n        [0.8496, 1.1682, 0.9558],\n        [1.0732, 1.0732, 0.8347],\n        [0.4152, 1.4118, 0.9135],\n        [1.2573, 0.7544, 0.9220],\n        [1.2309, 0.8616, 0.8616]], grad_fn=&lt;MulBackward0&gt;)\n\n\n\nprint(\"=\"*60)\nprint(\"Forward Pass Obtenido de manera Manual\")\nprint(\"=\"*60)\nrms = torch.sqrt((X**2).mean(dim=1, keepdims = True))\nrms_layer.weight.data*X/rms\n\n============================================================\nForward Pass Obtenido de manera Manual\n============================================================\n\n\ntensor([[1.1352, 0.9933, 0.8514],\n        [1.2127, 0.2425, 1.2127],\n        [1.5007, 0.6566, 0.5628],\n        [1.1294, 0.2420, 1.2907],\n        [0.3672, 0.3672, 1.6524],\n        [0.8496, 1.1682, 0.9558],\n        [1.0732, 1.0732, 0.8347],\n        [0.4152, 1.4118, 0.9135],\n        [1.2573, 0.7544, 0.9220],\n        [1.2309, 0.8616, 0.8616]])"
  },
  {
    "objectID": "tics579/notebooks/Training_Tricks.html#dropout",
    "href": "tics579/notebooks/Training_Tricks.html#dropout",
    "title": "1. BatchNorm",
    "section": "Dropout",
    "text": "Dropout\n\ntorch.manual_seed(42)\np = 0.5\ndo = nn.Dropout(p = p)\ndo.train()\noutput_pytorch = do(X)\nprint(\"=\"*60)\nprint(\"Output obtenido utilizando Pytorch\")\nprint(\"=\"*60)\noutput_pytorch\n\n============================================================\nOutput obtenido utilizando Pytorch\n============================================================\n\n\ntensor([[32., 28., 24.],\n        [30.,  0., 30.],\n        [ 0.,  0., 12.],\n        [28.,  6., 32.],\n        [ 0.,  0., 36.],\n        [ 0., 22.,  0.],\n        [ 0., 36., 28.],\n        [ 0., 34., 22.],\n        [30., 18.,  0.],\n        [20., 14., 14.]])\n\n\n\nprint(\"=\"*60)\nprint(\"Se genera una máscara aleatoria de los Elementos a mantenerse...\")\nprint(\"=\"*60)\nmask = torch.where(output_pytorch!=0, 1, 0)\nmask\n\n============================================================\nSe genera una máscara aleatoria de los Elementos a mantenerse...\n============================================================\n\n\ntensor([[1, 1, 1],\n        [1, 0, 1],\n        [0, 0, 1],\n        [1, 1, 1],\n        [0, 0, 1],\n        [0, 1, 0],\n        [0, 1, 1],\n        [0, 1, 1],\n        [1, 1, 0],\n        [1, 1, 1]])\n\n\n\nprint(\"=\"*60)\nprint(\"A todos los elementos escogidos para mantenerse son escalados...\")\nprint(\"=\"*60)\nscale = 1/(1-p)\nprint(\"\")\nprint(\"=\"*60)\nprint(\"Output Obtenido Manualmente\")\nprint(\"=\"*60)\nx_do = X*mask*scale\nx_do\n\n============================================================\nA todos los elementos escogidos para mantenerse son escalados...\n============================================================\n\n============================================================\nOutput Obtenido Manualmente\n============================================================\n\n\ntensor([[32., 28., 24.],\n        [30.,  0., 30.],\n        [ 0.,  0., 12.],\n        [28.,  6., 32.],\n        [ 0.,  0., 36.],\n        [ 0., 22.,  0.],\n        [ 0., 36., 28.],\n        [ 0., 34., 22.],\n        [30., 18.,  0.],\n        [20., 14., 14.]])\n\n\n\ndo = nn.Dropout(p = p)\ndo.eval()\noutput_pytorch = do(X)\noutput_pytorch\n\ntensor([[16., 14., 12.],\n        [15.,  3., 15.],\n        [16.,  7.,  6.],\n        [14.,  3., 16.],\n        [ 4.,  4., 18.],\n        [ 8., 11.,  9.],\n        [18., 18., 14.],\n        [ 5., 17., 11.],\n        [15.,  9., 11.],\n        [10.,  7.,  7.]])"
  },
  {
    "objectID": "tics579/notebooks/Training_Tricks.html#inicialización-de-parámetros",
    "href": "tics579/notebooks/Training_Tricks.html#inicialización-de-parámetros",
    "title": "1. BatchNorm",
    "section": "Inicialización de Parámetros",
    "text": "Inicialización de Parámetros\n\nfc = nn.Linear(5,3)\nfc.weight.data, fc.bias.data\n\n(tensor([[ 0.0282, -0.3052,  0.1379, -0.1540,  0.1370],\n         [-0.0932,  0.3709, -0.2651, -0.2667, -0.2667],\n         [ 0.4022,  0.1490,  0.4303, -0.3691, -0.4436]]),\n tensor([-0.3499, -0.3008,  0.1811]))\n\n\n\nnn.init.ones_(fc.weight)\nfc.weight.data, fc.bias.data\n\n(tensor([[1., 1., 1., 1., 1.],\n         [1., 1., 1., 1., 1.],\n         [1., 1., 1., 1., 1.]]),\n tensor([-0.3499, -0.3008,  0.1811]))\n\n\n\nnn.init.ones_(fc.weight)\nnn.init.zeros_(fc.bias)\nfc.weight.data, fc.bias.data\n\n(tensor([[1., 1., 1., 1., 1.],\n         [1., 1., 1., 1., 1.],\n         [1., 1., 1., 1., 1.]]),\n tensor([0., 0., 0.]))\n\n\n\nnn.init.ones_(fc.weight)\nnn.init.zeros_(fc.bias)\nfc.weight.data, fc.bias.data\n\n(tensor([[1., 1., 1., 1., 1.],\n         [1., 1., 1., 1., 1.],\n         [1., 1., 1., 1., 1.]]),\n tensor([0., 0., 0.]))\n\n\n\nnn.init.constant_(fc.weight, 0.3)\nnn.init.constant_(fc.bias, 0.5)\nfc.weight.data, fc.bias.data\n\n(tensor([[0.3000, 0.3000, 0.3000, 0.3000, 0.3000],\n         [0.3000, 0.3000, 0.3000, 0.3000, 0.3000],\n         [0.3000, 0.3000, 0.3000, 0.3000, 0.3000]]),\n tensor([0.5000, 0.5000, 0.5000]))\n\n\n\nnn.init.uniform_(fc.weight, 1,100)\nfc.weight.data\n\ntensor([[68.2248, 91.6308, 24.9369, 16.7553, 76.7636],\n        [30.4919, 80.5427, 38.7536, 78.8163, 12.0401],\n        [25.5198, 65.5914, 60.9647, 37.8795, 80.0054]])\n\n\n\ntorch.nn.init.calculate_gain(\"relu\", param=None)\nnn.init.xavier_uniform_(fc.weight.data, gain=nn.init.calculate_gain(\"relu\"))\n\ntensor([[ 0.8326, -0.8882, -0.6539,  1.1215, -0.4133],\n        [-0.4342, -1.1851, -0.7014,  0.3059, -0.1617],\n        [-0.8890,  0.0287, -0.8366, -1.0391, -0.6744]])\n\n\n\nnn.init.kaiming_uniform_(fc.weight.data, mode=\"fan_in\", nonlinearity=\"relu\")\n\ntensor([[-0.9587, -0.6975,  1.0950,  0.2069,  0.3376],\n        [-1.0217, -0.7195, -0.3646,  0.1713, -0.9639],\n        [-0.4720, -0.6558,  0.0030, -0.4076, -0.0759]])"
  },
  {
    "objectID": "tics579/notebooks/Training_Tricks.html#checkpoint",
    "href": "tics579/notebooks/Training_Tricks.html#checkpoint",
    "title": "1. BatchNorm",
    "section": "Checkpoint",
    "text": "Checkpoint\n\n## Checkpoint\n\nX = torch.randint(1,20, (10, 3)).float()\ny = torch.randint(0,2, (10,)).float()\n\nclass Net(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.fc = nn.Linear(3, 1)\n\n    def forward(self, x):\n        return self.fc(x)\n\n\n\ntorch.manual_seed(42)\nepochs=20\nepoch_loss = []\nmodel = Net()\noptimizer = torch.optim.SGD(model.parameters(), lr=0.01)\ncriterion = nn.BCEWithLogitsLoss()\nfor e in range(epochs):\n  model.train()\n  optimizer.zero_grad()\n  logits = model(X)\n  loss = criterion(logits, y.unsqueeze(-1))\n  loss.backward()\n  optimizer.step()\n  epoch_loss.append(loss.item())\n  print(f\"Epoch: {e+1}. Loss: {loss.item()}\")\n\nmodel.fc.weight.data\n\nEpoch: 1. Loss: 5.684591770172119\nEpoch: 2. Loss: 4.632599830627441\nEpoch: 3. Loss: 3.6506359577178955\nEpoch: 4. Loss: 2.812757968902588\nEpoch: 5. Loss: 2.171171188354492\nEpoch: 6. Loss: 1.7123682498931885\nEpoch: 7. Loss: 1.4345756769180298\nEpoch: 8. Loss: 1.284837007522583\nEpoch: 9. Loss: 1.182861089706421\nEpoch: 10. Loss: 1.0974228382110596\nEpoch: 11. Loss: 1.0225789546966553\nEpoch: 12. Loss: 0.9574964642524719\nEpoch: 13. Loss: 0.9016749262809753\nEpoch: 14. Loss: 0.8543142080307007\nEpoch: 15. Loss: 0.8144165277481079\nEpoch: 16. Loss: 0.7809440493583679\nEpoch: 17. Loss: 0.7529222965240479\nEpoch: 18. Loss: 0.7294866442680359\nEpoch: 19. Loss: 0.7098948359489441\nEpoch: 20. Loss: 0.6935199499130249\n\n\ntensor([[ 0.1235, -0.1139, -0.0554]])\n\n\n\ncheckpoint = {\n    'epoch': epochs,\n    'model_state_dict': model.state_dict(),\n    'optimizer_state_dict': optimizer.state_dict(),\n    'loss': loss\n}\n\ntorch.save(checkpoint, 'checkpoint.pth')\n\n\ncheckpoint = torch.load('checkpoint.pth')\n\nmodel.load_state_dict(checkpoint['model_state_dict'])\noptimizer.load_state_dict(checkpoint['optimizer_state_dict'])\nepoch = checkpoint['epoch']\nloss = checkpoint['loss']\n\nprint(f\"✅ Loaded checkpoint from epoch {epoch}, loss={loss}\")\n\n✅ Loaded checkpoint from epoch 20, loss=0.6935199499130249\n\n\n\nmodel.fc.weight.data\n\ntensor([[ 0.1235, -0.1139, -0.0554]])"
  },
  {
    "objectID": "tics579/notebooks/Training_Tricks.html#gradient-accumulation",
    "href": "tics579/notebooks/Training_Tricks.html#gradient-accumulation",
    "title": "1. BatchNorm",
    "section": "Gradient Accumulation",
    "text": "Gradient Accumulation\n\n## Training with Accumulation\ntorch.manual_seed(42)\nepochs=20\naccumulation_steps=4\nmodel = Net()\noptimizer = torch.optim.SGD(model.parameters(), lr=0.01)\ncriterion = nn.BCEWithLogitsLoss()\nmodel.zero_grad()                                   # Resetea Gradientes Iniciales\nfor e in range(epochs):\n  logits = model(X)\n  loss = criterion(logits, y.unsqueeze(-1))\n  print(f\"Epoch: {e+1}. Loss: {loss.item()}\")\n  loss = loss / accumulation_steps                # Normaliza Loss\n  loss.backward()                                 # Backward pass (Recordar que Pytorch Acumula Gradientes hasta que se use .zero_grad())\n  if (e+1) % accumulation_steps == 0:\n      optimizer.step()                            # Se actualizan pesos sólo cada ciertos steps\n      model.zero_grad()                           # Y ahora se resetea\n\nEpoch: 1. Loss: 5.684591770172119\nEpoch: 2. Loss: 5.684591770172119\nEpoch: 3. Loss: 5.684591770172119\nEpoch: 4. Loss: 5.684591770172119\nEpoch: 5. Loss: 4.632599830627441\nEpoch: 6. Loss: 4.632599830627441\nEpoch: 7. Loss: 4.632599830627441\nEpoch: 8. Loss: 4.632599830627441\nEpoch: 9. Loss: 3.6506359577178955\nEpoch: 10. Loss: 3.6506359577178955\nEpoch: 11. Loss: 3.6506359577178955\nEpoch: 12. Loss: 3.6506359577178955\nEpoch: 13. Loss: 2.812757968902588\nEpoch: 14. Loss: 2.812757968902588\nEpoch: 15. Loss: 2.812757968902588\nEpoch: 16. Loss: 2.812757968902588\nEpoch: 17. Loss: 2.171171188354492\nEpoch: 18. Loss: 2.171171188354492\nEpoch: 19. Loss: 2.171171188354492\nEpoch: 20. Loss: 2.171171188354492\n\n\n\nmodel.fc.weight.data\n\ntensor([[ 0.2156,  0.1241, -0.2904]])\n\n\n\n## Training with Accumulation\ntorch.manual_seed(42)\nepochs=80\naccumulation_steps=4\nmodel = Net()\noptimizer = torch.optim.SGD(model.parameters(), lr=0.01)\ncriterion = nn.BCEWithLogitsLoss()\nmodel.zero_grad()                                   # Resetea Gradientes Iniciales\nfor e in range(epochs):\n  logits = model(X)\n  loss = criterion(logits, y.unsqueeze(-1))\n  print(f\"Epoch: {e+1}. Loss: {loss.item()}\")\n  loss = loss / accumulation_steps                # Normaliza Loss\n  loss.backward()                                 # Backward pass (Recordar que Pytorch Acumula Gradientes hasta que se use .zero_grad())\n  if (e+1) % accumulation_steps == 0:\n      optimizer.step()                            # Se actualizan pesos sólo cada ciertos steps\n      model.zero_grad()                           # Y ahora se resetea\n\nmodel.fc.weight.data\n\nEpoch: 1. Loss: 5.684591770172119\nEpoch: 2. Loss: 5.684591770172119\nEpoch: 3. Loss: 5.684591770172119\nEpoch: 4. Loss: 5.684591770172119\nEpoch: 5. Loss: 4.632599830627441\nEpoch: 6. Loss: 4.632599830627441\nEpoch: 7. Loss: 4.632599830627441\nEpoch: 8. Loss: 4.632599830627441\nEpoch: 9. Loss: 3.6506359577178955\nEpoch: 10. Loss: 3.6506359577178955\nEpoch: 11. Loss: 3.6506359577178955\nEpoch: 12. Loss: 3.6506359577178955\nEpoch: 13. Loss: 2.812757968902588\nEpoch: 14. Loss: 2.812757968902588\nEpoch: 15. Loss: 2.812757968902588\nEpoch: 16. Loss: 2.812757968902588\nEpoch: 17. Loss: 2.171171188354492\nEpoch: 18. Loss: 2.171171188354492\nEpoch: 19. Loss: 2.171171188354492\nEpoch: 20. Loss: 2.171171188354492\nEpoch: 21. Loss: 1.7123682498931885\nEpoch: 22. Loss: 1.7123682498931885\nEpoch: 23. Loss: 1.7123682498931885\nEpoch: 24. Loss: 1.7123682498931885\nEpoch: 25. Loss: 1.4345756769180298\nEpoch: 26. Loss: 1.4345756769180298\nEpoch: 27. Loss: 1.4345756769180298\nEpoch: 28. Loss: 1.4345756769180298\nEpoch: 29. Loss: 1.284837007522583\nEpoch: 30. Loss: 1.284837007522583\nEpoch: 31. Loss: 1.284837007522583\nEpoch: 32. Loss: 1.284837007522583\nEpoch: 33. Loss: 1.182861089706421\nEpoch: 34. Loss: 1.182861089706421\nEpoch: 35. Loss: 1.182861089706421\nEpoch: 36. Loss: 1.182861089706421\nEpoch: 37. Loss: 1.0974228382110596\nEpoch: 38. Loss: 1.0974228382110596\nEpoch: 39. Loss: 1.0974228382110596\nEpoch: 40. Loss: 1.0974228382110596\nEpoch: 41. Loss: 1.0225789546966553\nEpoch: 42. Loss: 1.0225789546966553\nEpoch: 43. Loss: 1.0225789546966553\nEpoch: 44. Loss: 1.0225789546966553\nEpoch: 45. Loss: 0.9574964642524719\nEpoch: 46. Loss: 0.9574964642524719\nEpoch: 47. Loss: 0.9574964642524719\nEpoch: 48. Loss: 0.9574964642524719\nEpoch: 49. Loss: 0.9016749262809753\nEpoch: 50. Loss: 0.9016749262809753\nEpoch: 51. Loss: 0.9016749262809753\nEpoch: 52. Loss: 0.9016749262809753\nEpoch: 53. Loss: 0.8543142080307007\nEpoch: 54. Loss: 0.8543142080307007\nEpoch: 55. Loss: 0.8543142080307007\nEpoch: 56. Loss: 0.8543142080307007\nEpoch: 57. Loss: 0.8144165277481079\nEpoch: 58. Loss: 0.8144165277481079\nEpoch: 59. Loss: 0.8144165277481079\nEpoch: 60. Loss: 0.8144165277481079\nEpoch: 61. Loss: 0.7809440493583679\nEpoch: 62. Loss: 0.7809440493583679\nEpoch: 63. Loss: 0.7809440493583679\nEpoch: 64. Loss: 0.7809440493583679\nEpoch: 65. Loss: 0.7529222965240479\nEpoch: 66. Loss: 0.7529222965240479\nEpoch: 67. Loss: 0.7529222965240479\nEpoch: 68. Loss: 0.7529222965240479\nEpoch: 69. Loss: 0.7294866442680359\nEpoch: 70. Loss: 0.7294866442680359\nEpoch: 71. Loss: 0.7294866442680359\nEpoch: 72. Loss: 0.7294866442680359\nEpoch: 73. Loss: 0.7098948359489441\nEpoch: 74. Loss: 0.7098948359489441\nEpoch: 75. Loss: 0.7098948359489441\nEpoch: 76. Loss: 0.7098948359489441\nEpoch: 77. Loss: 0.6935199499130249\nEpoch: 78. Loss: 0.6935199499130249\nEpoch: 79. Loss: 0.6935199499130249\nEpoch: 80. Loss: 0.6935199499130249\n\n\ntensor([[ 0.1235, -0.1139, -0.0554]])"
  },
  {
    "objectID": "tics579/notebooks/legacy/Intro_pytorch.html",
    "href": "tics579/notebooks/legacy/Intro_pytorch.html",
    "title": "Clases UAI",
    "section": "",
    "text": "import torch\nimport torch.nn as nn\nimport numpy as np\nfrom sklearn.datasets import fe\n\nnp.random.seed(1)\n\n\nX_numpy = np.random.randn(1000, 10)\ny_numpy = np.random.randint(0, 2, 1000)\n\nX = torch.from_numpy(X_numpy).float()\ny = torch.from_numpy(y_numpy).float()\ny.shape\n\n((750, 10), (250, 10), (750,), (250,))\n\n\n\ntorch.__version__\n\n'2.4.0'\n\n\n\nw1 = nn.Linear(in_features=10, out_features=32)\nrelu_1 = nn.ReLU()\nw2 = nn.Linear(in_features=32, out_features=64)\nrelu_2 = nn.ReLU()\nw3 = nn.Linear(64, 1)\n\n\nout_w1 = w1(X)\nout_relu_1 = relu_1(out_w1)\nout_w2 = w2(out_relu_1)\nout_relu_2 = relu_2(out_w2)\nout_w3 = w3(out_relu_2)\nout_w3.shape\n\ntorch.Size([1000, 1])\n\n\n\nclass MyFFN(nn.Module):\n    def __init__(self, n_features, hidden_dim_1, hidden_dim_2, out_dim):\n        super().__init__()\n        self.w1 = nn.Linear(\n            in_features=n_features, out_features=hidden_dim_1\n        )\n        self.relu_1 = nn.ReLU()\n        self.w2 = nn.Linear(\n            in_features=hidden_dim_1, out_features=hidden_dim_2\n        )\n        self.relu_2 = nn.ReLU()\n        self.w3 = nn.Linear(hidden_dim_2, out_dim)\n\n    def forward(self, x):\n        x = self.w1(x)\n        x = self.relu_1(x)\n        x = self.w2(x)\n        x = self.relu_2(x)\n        x = self.w3(x)\n        return x\n\n\nmodel = MyFFN(n_features=10, hidden_dim_1=32, hidden_dim_2=64, out_dim=1)\nmodel\n\nMyFFN(\n  (w1): Linear(in_features=10, out_features=32, bias=True)\n  (relu_1): ReLU()\n  (w2): Linear(in_features=32, out_features=64, bias=True)\n  (relu_2): ReLU()\n  (w3): Linear(in_features=64, out_features=1, bias=True)\n)\n\n\n\ncriterion = nn.BCEWithLogitsLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n\n\nimport matplotlib.pyplot as plt\n\n## Entrenamiento... (Training Loop)\nEPOCHS = 2000\n\nloss_list = []\nfor e in range(EPOCHS):\n    model.train()\n    optimizer.zero_grad()\n    preds = model(X)\n    ## predicciones primero, y luego el target\n    loss = criterion(preds, y.unsqueeze(1))\n    loss.backward()\n    optimizer.step()\n    loss_list.append(loss.item())\n\nplt.plot(range(EPOCHS), loss_list)\n\n\n\n\n\n\n\n\n\nmodel.w1\n\nLinear(in_features=10, out_features=32, bias=True)\n\n\n\nmodel\n\n\n\n\n Back to top"
  },
  {
    "objectID": "tics579/notebooks/legacy/pretrained-models.html",
    "href": "tics579/notebooks/legacy/pretrained-models.html",
    "title": "Torchvision",
    "section": "",
    "text": "import torchvision\nfrom torchvision.models import list_models\n\nlist_models(module=torchvision.models)\n\n['alexnet',\n 'convnext_base',\n 'convnext_large',\n 'convnext_small',\n 'convnext_tiny',\n 'densenet121',\n 'densenet161',\n 'densenet169',\n 'densenet201',\n 'efficientnet_b0',\n 'efficientnet_b1',\n 'efficientnet_b2',\n 'efficientnet_b3',\n 'efficientnet_b4',\n 'efficientnet_b5',\n 'efficientnet_b6',\n 'efficientnet_b7',\n 'efficientnet_v2_l',\n 'efficientnet_v2_m',\n 'efficientnet_v2_s',\n 'googlenet',\n 'inception_v3',\n 'maxvit_t',\n 'mnasnet0_5',\n 'mnasnet0_75',\n 'mnasnet1_0',\n 'mnasnet1_3',\n 'mobilenet_v2',\n 'mobilenet_v3_large',\n 'mobilenet_v3_small',\n 'regnet_x_16gf',\n 'regnet_x_1_6gf',\n 'regnet_x_32gf',\n 'regnet_x_3_2gf',\n 'regnet_x_400mf',\n 'regnet_x_800mf',\n 'regnet_x_8gf',\n 'regnet_y_128gf',\n 'regnet_y_16gf',\n 'regnet_y_1_6gf',\n 'regnet_y_32gf',\n 'regnet_y_3_2gf',\n 'regnet_y_400mf',\n 'regnet_y_800mf',\n 'regnet_y_8gf',\n 'resnet101',\n 'resnet152',\n 'resnet18',\n 'resnet34',\n 'resnet50',\n 'resnext101_32x8d',\n 'resnext101_64x4d',\n 'resnext50_32x4d',\n 'shufflenet_v2_x0_5',\n 'shufflenet_v2_x1_0',\n 'shufflenet_v2_x1_5',\n 'shufflenet_v2_x2_0',\n 'squeezenet1_0',\n 'squeezenet1_1',\n 'swin_b',\n 'swin_s',\n 'swin_t',\n 'swin_v2_b',\n 'swin_v2_s',\n 'swin_v2_t',\n 'vgg11',\n 'vgg11_bn',\n 'vgg13',\n 'vgg13_bn',\n 'vgg16',\n 'vgg16_bn',\n 'vgg19',\n 'vgg19_bn',\n 'vit_b_16',\n 'vit_b_32',\n 'vit_h_14',\n 'vit_l_16',\n 'vit_l_32',\n 'wide_resnet101_2',\n 'wide_resnet50_2']\nmodel = torchvision.models.alexnet(weights=\"IMAGENET1K_V1\")\nmodel\n\nAlexNet(\n  (features): Sequential(\n    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n    (1): ReLU(inplace=True)\n    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n    (4): ReLU(inplace=True)\n    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (7): ReLU(inplace=True)\n    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (9): ReLU(inplace=True)\n    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (11): ReLU(inplace=True)\n    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n  (classifier): Sequential(\n    (0): Dropout(p=0.5, inplace=False)\n    (1): Linear(in_features=9216, out_features=4096, bias=True)\n    (2): ReLU(inplace=True)\n    (3): Dropout(p=0.5, inplace=False)\n    (4): Linear(in_features=4096, out_features=4096, bias=True)\n    (5): ReLU(inplace=True)\n    (6): Linear(in_features=4096, out_features=1000, bias=True)\n  )\n)\nfrom torchinfo import summary\n\nsummary(model, input_size=(1, 3, 224, 224))\n\n==========================================================================================\nLayer (type:depth-idx)                   Output Shape              Param #\n==========================================================================================\nAlexNet                                  [1, 1000]                 --\n├─Sequential: 1-1                        [1, 256, 6, 6]            --\n│    └─Conv2d: 2-1                       [1, 64, 55, 55]           23,296\n│    └─ReLU: 2-2                         [1, 64, 55, 55]           --\n│    └─MaxPool2d: 2-3                    [1, 64, 27, 27]           --\n│    └─Conv2d: 2-4                       [1, 192, 27, 27]          307,392\n│    └─ReLU: 2-5                         [1, 192, 27, 27]          --\n│    └─MaxPool2d: 2-6                    [1, 192, 13, 13]          --\n│    └─Conv2d: 2-7                       [1, 384, 13, 13]          663,936\n│    └─ReLU: 2-8                         [1, 384, 13, 13]          --\n│    └─Conv2d: 2-9                       [1, 256, 13, 13]          884,992\n│    └─ReLU: 2-10                        [1, 256, 13, 13]          --\n│    └─Conv2d: 2-11                      [1, 256, 13, 13]          590,080\n│    └─ReLU: 2-12                        [1, 256, 13, 13]          --\n│    └─MaxPool2d: 2-13                   [1, 256, 6, 6]            --\n├─AdaptiveAvgPool2d: 1-2                 [1, 256, 6, 6]            --\n├─Sequential: 1-3                        [1, 1000]                 --\n│    └─Dropout: 2-14                     [1, 9216]                 --\n│    └─Linear: 2-15                      [1, 4096]                 37,752,832\n│    └─ReLU: 2-16                        [1, 4096]                 --\n│    └─Dropout: 2-17                     [1, 4096]                 --\n│    └─Linear: 2-18                      [1, 4096]                 16,781,312\n│    └─ReLU: 2-19                        [1, 4096]                 --\n│    └─Linear: 2-20                      [1, 1000]                 4,097,000\n==========================================================================================\nTotal params: 61,100,840\nTrainable params: 61,100,840\nNon-trainable params: 0\nTotal mult-adds (Units.MEGABYTES): 714.68\n==========================================================================================\nInput size (MB): 0.60\nForward/backward pass size (MB): 3.95\nParams size (MB): 244.40\nEstimated Total Size (MB): 248.96\n=========================================================================================="
  },
  {
    "objectID": "tics579/notebooks/legacy/pretrained-models.html#uso-de-timm",
    "href": "tics579/notebooks/legacy/pretrained-models.html#uso-de-timm",
    "title": "Torchvision",
    "section": "Uso de Timm",
    "text": "Uso de Timm\n\nimport timm\n\nlen(timm.list_models())\n\ntimm.list_models(\"efficientnet*\")\n\n['efficientnet_b0',\n 'efficientnet_b0_g8_gn',\n 'efficientnet_b0_g16_evos',\n 'efficientnet_b0_gn',\n 'efficientnet_b1',\n 'efficientnet_b1_pruned',\n 'efficientnet_b2',\n 'efficientnet_b2_pruned',\n 'efficientnet_b3',\n 'efficientnet_b3_g8_gn',\n 'efficientnet_b3_gn',\n 'efficientnet_b3_pruned',\n 'efficientnet_b4',\n 'efficientnet_b5',\n 'efficientnet_b6',\n 'efficientnet_b7',\n 'efficientnet_b8',\n 'efficientnet_blur_b0',\n 'efficientnet_cc_b0_4e',\n 'efficientnet_cc_b0_8e',\n 'efficientnet_cc_b1_8e',\n 'efficientnet_el',\n 'efficientnet_el_pruned',\n 'efficientnet_em',\n 'efficientnet_es',\n 'efficientnet_es_pruned',\n 'efficientnet_h_b5',\n 'efficientnet_l2',\n 'efficientnet_lite0',\n 'efficientnet_lite1',\n 'efficientnet_lite2',\n 'efficientnet_lite3',\n 'efficientnet_lite4',\n 'efficientnet_x_b3',\n 'efficientnet_x_b5',\n 'efficientnetv2_l',\n 'efficientnetv2_m',\n 'efficientnetv2_rw_m',\n 'efficientnetv2_rw_s',\n 'efficientnetv2_rw_t',\n 'efficientnetv2_s',\n 'efficientnetv2_xl']\n\n\n\nresnet = timm.create_model(\"resnet18\", pretrained=True, num_classes=0)\nresnet\n\nResNet(\n  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (act1): ReLU(inplace=True)\n  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act1): ReLU(inplace=True)\n      (aa): Identity()\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act2): ReLU(inplace=True)\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act1): ReLU(inplace=True)\n      (aa): Identity()\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act2): ReLU(inplace=True)\n    )\n  )\n  (layer2): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act1): ReLU(inplace=True)\n      (aa): Identity()\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act2): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act1): ReLU(inplace=True)\n      (aa): Identity()\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act2): ReLU(inplace=True)\n    )\n  )\n  (layer3): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act1): ReLU(inplace=True)\n      (aa): Identity()\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act2): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act1): ReLU(inplace=True)\n      (aa): Identity()\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act2): ReLU(inplace=True)\n    )\n  )\n  (layer4): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act1): ReLU(inplace=True)\n      (aa): Identity()\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act2): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act1): ReLU(inplace=True)\n      (aa): Identity()\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act2): ReLU(inplace=True)\n    )\n  )\n  (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n  (fc): Identity()\n)"
  },
  {
    "objectID": "tics579/notebooks/legacy/pretrained-models.html#get-activations-from-a-specific-layer",
    "href": "tics579/notebooks/legacy/pretrained-models.html#get-activations-from-a-specific-layer",
    "title": "Torchvision",
    "section": "Get Activations from a specific Layer",
    "text": "Get Activations from a specific Layer\n\nmodel = torchvision.models.alexnet(weights=\"IMAGENET1K_V1\")\nmodel\n\nAlexNet(\n  (features): Sequential(\n    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n    (1): ReLU(inplace=True)\n    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n    (4): ReLU(inplace=True)\n    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (7): ReLU(inplace=True)\n    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (9): ReLU(inplace=True)\n    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (11): ReLU(inplace=True)\n    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n  (classifier): Sequential(\n    (0): Dropout(p=0.5, inplace=False)\n    (1): Linear(in_features=9216, out_features=4096, bias=True)\n    (2): ReLU(inplace=True)\n    (3): Dropout(p=0.5, inplace=False)\n    (4): Linear(in_features=4096, out_features=4096, bias=True)\n    (5): ReLU(inplace=True)\n    (6): Linear(in_features=4096, out_features=1000, bias=True)\n  )\n)\n\n\n\nimport torch\nimport torch.nn as nn\n\ntorch.manual_seed(0)\ntorch.cuda.manual_seed(0)\n\n\ndef hook_fn(model, input, output):\n    print(output.shape)\n\n\nmodel = torchvision.models.alexnet(weights=\"IMAGENET1K_V1\")\nmodel.classifier[4].register_forward_hook(hook_fn)\n\na = torch.zeros(1, 3, 224, 256)\nmodel.eval()\nwith torch.no_grad():\n    model(a)\n\ntorch.Size([1, 4096])\n\n\n\nresnet.layer1[0].conv1.register_forward_hook(hook_fn)\na = torch.zeros(1, 3, 224, 256)\nresnet.eval()\nwith torch.no_grad():\n    resnet(a)\n\ntorch.Size([1, 64, 56, 64])"
  },
  {
    "objectID": "tics579/notebooks/legacy/pretrained-models.html#transfer-learning",
    "href": "tics579/notebooks/legacy/pretrained-models.html#transfer-learning",
    "title": "Torchvision",
    "section": "Transfer Learning",
    "text": "Transfer Learning\n\nfrom torchvision.datasets import ImageFolder\nimport albumentations as A\nfrom albumentations.pytorch.transforms import ToTensorV2\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader\nimport torchmetrics\nimport time\nfrom torchinfo import summary\n\n\nclass Transforms:\n    def __init__(self, transform: A.Compose):\n        self.transform = transform\n\n    def __call__(self, image):\n        image = np.array(image)\n        return self.transform(image=image)[\"image\"]\n\n\ntrain_transforms = A.Compose(\n    [A.Resize(256, 256), A.ToFloat(), ToTensorV2()]\n)\nvalidation_transforms = A.Compose(\n    [A.Resize(256, 256), A.ToFloat(), ToTensorV2()]\n)\n\n\ntrain_data = ImageFolder(\n    \"CATS_DOGS/train\",\n    transform=Transforms(train_transforms),\n)\nvalidation_data = ImageFolder(\n    \"CATS_DOGS/validation\",\n    transform=Transforms(validation_transforms),\n)\n\nprint(f\"Elementos en Entrenamiento: {len(train_data)}\")\nprint(f\"Elementos en Validación: {len(validation_data)}\")\n\nElementos en Entrenamiento: 18743\nElementos en Validación: 6251\n\n\n\ntrain_data.class_to_idx\n\n{'CAT': 0, 'DOG': 1}\n\n\n\nidx_to_class_dict = {v: k for k, v in train_data.class_to_idx.items()}\nidx_to_class_dict\n\n{0: 'CAT', 1: 'DOG'}\n\n\n\ntrain_data[0]\n\n(tensor([[[0.7961, 0.8000, 0.8118,  ..., 0.9569, 0.9412, 0.9373],\n          [0.7961, 0.8000, 0.8118,  ..., 0.9569, 0.9451, 0.9373],\n          [0.7961, 0.8000, 0.8118,  ..., 0.9529, 0.9451, 0.9373],\n          ...,\n          [0.6000, 0.6039, 0.6078,  ..., 0.0078, 0.0078, 0.0078],\n          [0.6000, 0.6000, 0.6039,  ..., 0.0078, 0.0078, 0.0078],\n          [0.5922, 0.5961, 0.5961,  ..., 0.0039, 0.0039, 0.0039]],\n \n         [[0.6431, 0.6471, 0.6588,  ..., 0.7961, 0.7882, 0.7804],\n          [0.6431, 0.6471, 0.6588,  ..., 0.7961, 0.7922, 0.7843],\n          [0.6431, 0.6471, 0.6588,  ..., 0.8039, 0.7922, 0.7843],\n          ...,\n          [0.4784, 0.4824, 0.4863,  ..., 0.0078, 0.0078, 0.0078],\n          [0.4784, 0.4784, 0.4824,  ..., 0.0078, 0.0078, 0.0078],\n          [0.4706, 0.4745, 0.4745,  ..., 0.0039, 0.0039, 0.0039]],\n \n         [[0.3412, 0.3451, 0.3569,  ..., 0.4745, 0.4784, 0.4706],\n          [0.3412, 0.3451, 0.3569,  ..., 0.4745, 0.4824, 0.4745],\n          [0.3412, 0.3451, 0.3569,  ..., 0.4784, 0.4824, 0.4784],\n          ...,\n          [0.2157, 0.2196, 0.2235,  ..., 0.0000, 0.0000, 0.0000],\n          [0.2157, 0.2157, 0.2196,  ..., 0.0000, 0.0000, 0.0000],\n          [0.2078, 0.2118, 0.2118,  ..., 0.0000, 0.0000, 0.0000]]]),\n 0)\n\n\n\nidx = np.random.randint(0, len(train_data))\n\n\n## Es importante cambiar el orden de los canales para poder mostrar la imagen...\ndef plot_images(idx, data):\n    plt.imshow(data[idx][0].permute(1, 2, 0))\n    class_label = data[idx][1]\n    plt.title(data.classes[class_label])\n    plt.axis(\"off\")\n\n\nplot_images(idx, train_data)\n\n\n\n\n\n\n\n\n\ntorchvision.models.alexnet(weights=\"IMAGENET1K_V1\")\n\nAlexNet(\n  (features): Sequential(\n    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n    (1): ReLU(inplace=True)\n    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n    (4): ReLU(inplace=True)\n    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (7): ReLU(inplace=True)\n    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (9): ReLU(inplace=True)\n    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (11): ReLU(inplace=True)\n    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n  (classifier): Sequential(\n    (0): Dropout(p=0.5, inplace=False)\n    (1): Linear(in_features=9216, out_features=4096, bias=True)\n    (2): ReLU(inplace=True)\n    (3): Dropout(p=0.5, inplace=False)\n    (4): Linear(in_features=4096, out_features=4096, bias=True)\n    (5): ReLU(inplace=True)\n    (6): Linear(in_features=4096, out_features=1000, bias=True)\n  )\n)\n\n\n\nclass CNN(nn.Module):\n    def __init__(self, in_channels=3, n_outputs=1, ks=3):\n        super().__init__()\n        self.conv1 = self.CNN_block(in_channels, 32, k=ks)\n        self.conv2 = self.CNN_block(32, 16, k=ks)\n        self.conv3 = self.CNN_block(16, 8, k=ks)\n        self.flatten = nn.Flatten()\n        self.fc1 = nn.LazyLinear(4096)\n        # self.fc1 = nn.Linear(32 * 5 * 5, 16)  # filtros x tamaño\n        self.fc2 = nn.Linear(4096, n_outputs)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.conv2(x)\n        x = self.conv3(x)\n        x = self.flatten(x)\n        x = self.fc1(x)\n        x = self.fc2(x)\n        return x\n\n    @staticmethod\n    def CNN_block(c_in, c_out, k=3, p=0, s=1, pk=2, ps=2):\n        return nn.Sequential(\n            nn.Conv2d(\n                in_channels=c_in,\n                out_channels=c_out,\n                kernel_size=k,\n                padding=p,\n                stride=s,\n            ),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=pk, stride=ps),\n        )\n\n\nclass Alexnet(nn.Module):\n    def __init__(self, backbone, output_dim, frozen=False):\n        super().__init__()\n        self.backbone = backbone\n        # Modificar la Prediction Head para que permite Clasificación Binaria\n        self.backbone.classifier[6] = nn.LazyLinear(output_dim)\n\n        if frozen:\n            self.backbone.features.requires_grad_(False)\n\n    def forward(self, x):\n        x = self.backbone(x)\n        return x\n\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n# device = torch.device(\"cpu\")\n\n\ndef train_model(\n    train_data,\n    val_data,\n    model,\n    training_params,\n    criterion=nn.CrossEntropyLoss(),\n):\n    print(f\"Making {torch.cuda.get_device_name(0)} go brrruuummmmm....\")\n    model.to(device)\n    optimizer = torch.optim.Adam(\n        model.parameters(),\n        lr=training_params[\"learning_rate\"],\n    )\n\n    train_dataloader = DataLoader(\n        train_data,\n        batch_size=training_params[\"batch_size\"],\n        shuffle=True,\n        num_workers=12,\n        pin_memory=True,\n    )\n    val_dataloader = DataLoader(\n        val_data,\n        batch_size=training_params[\"batch_size\"],\n        shuffle=False,\n        num_workers=12,\n        pin_memory=True,\n    )\n\n    train_metric = torchmetrics.Precision(task=\"binary\").to(device)\n    val_metric = torchmetrics.Precision(task=\"binary\").to(device)\n\n    train_loss = []\n    val_loss = []\n    for e in range(training_params[\"num_epochs\"]):\n        start_time = time.time()\n        train_batch_loss = []\n        val_batch_loss = []\n        model.train()\n        for batch in train_dataloader:\n            X, y = batch\n            X, y = X.to(device), y.float().unsqueeze(1).to(device)\n\n            optimizer.zero_grad()\n            y_hat = model(X)\n            loss = criterion(y_hat, y)\n            loss.backward()\n            optimizer.step()\n            tr_acc = train_metric(y_hat, y)\n            train_batch_loss.append(loss.item())\n\n        tr_acc = train_metric.compute()\n        train_epoch_loss = np.mean(train_batch_loss)\n\n        model.eval()\n        with torch.no_grad():\n            for batch in val_dataloader:\n                X, y = batch\n                X, y = X.to(device), y.float().unsqueeze(1).to(device)\n\n                y_hat = model(X)\n                loss = criterion(y_hat, y)\n                val_acc = val_metric(y_hat, y)\n                val_batch_loss.append(loss.item())\n\n        val_acc = val_metric.compute()\n        val_epoch_loss = np.mean(val_batch_loss)\n\n        end_time = time.time()\n        elapsed_time = end_time - start_time\n        print(\n            f\"Epoch: {e+1}: Time: {elapsed_time:.2f} - Train Loss: {train_epoch_loss:.4f} - Validation Loss: {val_epoch_loss:.4f} - Train Precision: {tr_acc:.4f} - Validation Precision: {val_acc:.4f}\"\n        )\n        train_loss.append(train_epoch_loss)\n        val_loss.append(val_epoch_loss)\n\n    return model, train_loss, val_loss\n\n\ntraining_params = dict(\n    learning_rate=3e-4,\n    batch_size=64,\n    num_epochs=3,\n)\nvanilla_model = CNN(in_channels=3, n_outputs=1).to(device)\n\nsummary(vanilla_model, input_size=(1, 3, 256, 256))\nvanilla_model, train_loss, val_loss = train_model(\n    train_data,\n    validation_data,\n    model=vanilla_model,\n    training_params=training_params,\n    criterion=nn.BCEWithLogitsLoss(),\n)\n\nMaking NVIDIA GeForce RTX 2070 with Max-Q Design go brrruuummmmm....\n\n\n/home/datacuber/miniconda3/lib/python3.12/site-packages/PIL/TiffImagePlugin.py:900: UserWarning: Truncated File Read\n  warnings.warn(str(msg))\n\n\nEpoch: 1: Time: 28.16 - Train Loss: 0.6229 - Validation Loss: 0.5685 - Train Precision: 0.6580 - Validation Precision: 0.7332\n\n\n/home/datacuber/miniconda3/lib/python3.12/site-packages/PIL/TiffImagePlugin.py:900: UserWarning: Truncated File Read\n  warnings.warn(str(msg))\n\n\nEpoch: 2: Time: 27.84 - Train Loss: 0.5356 - Validation Loss: 0.5340 - Train Precision: 0.7012 - Validation Precision: 0.7305\n\n\n/home/datacuber/miniconda3/lib/python3.12/site-packages/PIL/TiffImagePlugin.py:900: UserWarning: Truncated File Read\n  warnings.warn(str(msg))\n\n\nEpoch: 3: Time: 27.93 - Train Loss: 0.5076 - Validation Loss: 0.5361 - Train Precision: 0.7216 - Validation Precision: 0.7446\n\n\n\nsummary(vanilla_model, input_size=(1, 3, 256, 256))\n\n==========================================================================================\nLayer (type:depth-idx)                   Output Shape              Param #\n==========================================================================================\nCNN                                      [1, 1]                    --\n├─Sequential: 1-1                        [1, 32, 127, 127]         --\n│    └─Conv2d: 2-1                       [1, 32, 254, 254]         896\n│    └─ReLU: 2-2                         [1, 32, 254, 254]         --\n│    └─MaxPool2d: 2-3                    [1, 32, 127, 127]         --\n├─Sequential: 1-2                        [1, 16, 62, 62]           --\n│    └─Conv2d: 2-4                       [1, 16, 125, 125]         4,624\n│    └─ReLU: 2-5                         [1, 16, 125, 125]         --\n│    └─MaxPool2d: 2-6                    [1, 16, 62, 62]           --\n├─Sequential: 1-3                        [1, 8, 30, 30]            --\n│    └─Conv2d: 2-7                       [1, 8, 60, 60]            1,160\n│    └─ReLU: 2-8                         [1, 8, 60, 60]            --\n│    └─MaxPool2d: 2-9                    [1, 8, 30, 30]            --\n├─Flatten: 1-4                           [1, 7200]                 --\n├─Linear: 1-5                            [1, 4096]                 29,495,296\n├─Linear: 1-6                            [1, 1]                    4,097\n==========================================================================================\nTotal params: 29,506,073\nTrainable params: 29,506,073\nNon-trainable params: 0\nTotal mult-adds (Units.MEGABYTES): 163.73\n==========================================================================================\nInput size (MB): 0.79\nForward/backward pass size (MB): 18.78\nParams size (MB): 118.02\nEstimated Total Size (MB): 137.59\n==========================================================================================\n\n\n\ntraining_params = dict(\n    learning_rate=3e-4,\n    batch_size=256,\n    num_epochs=3,\n)\nfrozen_alexnet = Alexnet(\n    backbone=torchvision.models.alexnet(weights=\"IMAGENET1K_V1\"),\n    output_dim=1,\n    frozen=True,\n).to(device)\n\nsummary(frozen_alexnet, input_size=(1, 3, 256, 256))\nfrozen_alexnet, train_loss, val_loss = train_model(\n    train_data,\n    validation_data,\n    model=frozen_alexnet,\n    training_params=training_params,\n    criterion=nn.BCEWithLogitsLoss(),\n)\n\nMaking NVIDIA GeForce RTX 2070 with Max-Q Design go brrruuummmmm....\n\n\n/home/datacuber/miniconda3/lib/python3.12/site-packages/PIL/TiffImagePlugin.py:900: UserWarning: Truncated File Read\n  warnings.warn(str(msg))\n\n\nEpoch: 1: Time: 18.64 - Train Loss: 0.2144 - Validation Loss: 0.1692 - Train Precision: 0.9140 - Validation Precision: 0.9594\n\n\n/home/datacuber/miniconda3/lib/python3.12/site-packages/PIL/TiffImagePlugin.py:900: UserWarning: Truncated File Read\n  warnings.warn(str(msg))\n\n\nEpoch: 2: Time: 19.05 - Train Loss: 0.1446 - Validation Loss: 0.1470 - Train Precision: 0.9288 - Validation Precision: 0.9493\n\n\n/home/datacuber/miniconda3/lib/python3.12/site-packages/PIL/TiffImagePlugin.py:900: UserWarning: Truncated File Read\n  warnings.warn(str(msg))\n\n\nEpoch: 3: Time: 18.95 - Train Loss: 0.1293 - Validation Loss: 0.1491 - Train Precision: 0.9355 - Validation Precision: 0.9525\n\n\n\ntraining_params = dict(\n    learning_rate=3e-4,\n    batch_size=256,\n    num_epochs=3,\n)\nft_alexnet = Alexnet(\n    backbone=torchvision.models.alexnet(weights=\"IMAGENET1K_V1\"),\n    output_dim=1,\n    frozen=False,\n).to(device)\n\nsummary(ft_alexnet, input_size=(1, 3, 256, 256))\nft_alexnet, train_loss, val_loss = train_model(\n    train_data,\n    validation_data,\n    model=ft_alexnet,\n    training_params=training_params,\n    criterion=nn.BCEWithLogitsLoss(),\n)\n\nMaking NVIDIA GeForce RTX 2070 with Max-Q Design go brrruuummmmm....\n\n\n/home/datacuber/miniconda3/lib/python3.12/site-packages/PIL/TiffImagePlugin.py:900: UserWarning: Truncated File Read\n  warnings.warn(str(msg))\n\n\nEpoch: 1: Time: 25.42 - Train Loss: 0.2199 - Validation Loss: 0.1031 - Train Precision: 0.9122 - Validation Precision: 0.9493\n\n\n/home/datacuber/miniconda3/lib/python3.12/site-packages/PIL/TiffImagePlugin.py:900: UserWarning: Truncated File Read\n  warnings.warn(str(msg))\n\n\nEpoch: 2: Time: 25.65 - Train Loss: 0.0879 - Validation Loss: 0.1166 - Train Precision: 0.9396 - Validation Precision: 0.9666\n\n\n/home/datacuber/miniconda3/lib/python3.12/site-packages/PIL/TiffImagePlugin.py:900: UserWarning: Truncated File Read\n  warnings.warn(str(msg))\n\n\nEpoch: 3: Time: 25.53 - Train Loss: 0.0468 - Validation Loss: 0.0963 - Train Precision: 0.9542 - Validation Precision: 0.9601\n\n\n\nfrom mpl_toolkits.axes_grid1 import ImageGrid\nfrom pathlib import Path\n\n\ndef predict(model, image, transform):\n    image = np.array(Image.open(image))\n    pic = transform(image=image)[\"image\"]\n\n    model.eval()\n    with torch.no_grad():\n        new_prediction = model(pic.view(1, 3, 256, 256).to(device))\n        prob = new_prediction.sigmoid().item()\n\n    new_prediction = torch.where(new_prediction &gt; 0, 1, 0).item()\n\n    return idx_to_class_dict[new_prediction], prob\n\n\ndef prediction_grid(model, image_list, transform, grid_size=(20, 40)):\n\n    fig = plt.figure(1, grid_size)\n    grid = ImageGrid(\n        fig,\n        111,\n        nrows_ncols=(3, 4),\n        axes_pad=0.6,\n    )\n\n    for img, axes in zip(image_list, grid):\n        pred, proba = predict(model, img, transform)\n        image_name = Path(img).name\n        axes.set_title(\n            f\"{image_name} predicted as {pred}, \\n with a probability of {proba:.2f}\",\n            fontdict=None,\n            loc=\"center\",\n            color=\"k\",\n            fontsize=20,\n        )\n        axes.axis(\"off\")\n        axes.imshow(Image.open(img))\n\n    return plt.show()\n\n\ntorch.cuda.is_available()\n\nTrue\n\n\n\nimport glob\n\nimages = glob.glob(\"CATS_DOGS/test/*\")\n\ntest_transform = A.Compose([A.Resize(256, 256), A.ToFloat(), ToTensorV2()])\nprediction_grid(\n    vanilla_model,\n    reversed(images),\n    transform=test_transform,\n    grid_size=(30, 70),\n)\n\n\n\n\n\n\n\n\n\nprediction_grid(\n    frozen_alexnet,\n    reversed(images),\n    transform=test_transform,\n    grid_size=(30, 70),\n)\n\n\n\n\n\n\n\n\n\nprediction_grid(\n    ft_alexnet,\n    reversed(images),\n    transform=test_transform,\n    grid_size=(30, 70),\n)"
  },
  {
    "objectID": "tics579/notebooks/legacy/Intro_pytorch_2.html",
    "href": "tics579/notebooks/legacy/Intro_pytorch_2.html",
    "title": "Clases UAI",
    "section": "",
    "text": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\n\nimport numpy as np\n\nSEED = 1\ntorch.manual_seed(SEED)\nnp.random.seed(SEED)\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\ndevice\n\n'cuda'\n\n\n\nfrom sklearn.model_selection import train_test_split\n\nX_numpy = np.random.randn(1000, 10)\ny_numpy = np.random.randint(0, 2, 1000)\n\nX_train, X_val, y_train, y_val = train_test_split(\n    X_numpy, y_numpy, test_size=0.25, random_state=42\n)\nX_train.shape, X_val.shape, y_train.shape, y_val.shape\n\n((750, 10), (250, 10), (750,), (250,))\n\n\n\nclass MyData(Dataset):\n    def __init__(self, X, y):\n        self.X = torch.from_numpy(X)\n        self.y = torch.from_numpy(y)\n\n    def __len__(self):\n        return len(self.X)\n\n    def __getitem__(self, idx):\n        return dict(\n            features=self.X[idx].float(), target=self.y[idx].float()\n        )\n\n\ndataset = MyData(X_numpy, y_numpy)\ndataset[0][\"target\"]\n\ntensor(1.)\n\n\n\nclass MyFFN(nn.Module):\n    def __init__(self, n_features, hidden_dim_1, hidden_dim_2, out_dim):\n        super().__init__()\n        self.w1 = nn.Linear(\n            in_features=n_features, out_features=hidden_dim_1\n        )\n        self.relu_1 = nn.ReLU()\n        self.w2 = nn.Linear(\n            in_features=hidden_dim_1, out_features=hidden_dim_2\n        )\n        self.relu_2 = nn.ReLU()\n        self.w3 = nn.Linear(hidden_dim_2, out_dim)\n\n    def forward(self, x):\n        x = self.w1(x)\n        x = self.relu_1(x)\n        x = self.w2(x)\n        x = self.relu_2(x)\n        x = self.w3(x)\n        return x\n\n\nmodel = MyFFN(n_features=10, hidden_dim_1=32, hidden_dim_2=32, out_dim=1)\n\n\nfrom tqdm.notebook import tqdm\n\n\ndef training_loop(\n    model, X_train, y_train, X_val, y_val, batch_size=32, epochs=50\n):\n    EPOCHS = epochs\n    model.to(device)\n\n    print(f\"Modelo entrenándose en {next(model.parameters()).device}\")\n    criterion = nn.BCEWithLogitsLoss()\n    optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n    train_data = MyData(X_train, y_train)\n    val_data = MyData(X_val, y_val)\n\n    train_dataloader = DataLoader(\n        train_data,\n        batch_size=batch_size,\n        pin_memory=True,\n        num_workers=10,\n        shuffle=True,\n        drop_last=True,  ## Opcional... se supone que genera más estabilidad en los Gradientes.\n    )\n    val_dataloader = DataLoader(\n        val_data,\n        batch_size=batch_size,\n        pin_memory=True,\n        num_workers=10,\n        shuffle=False,\n        drop_last=False,  # Debe ser falso para validar, sino no estamos calculando un Loss para todos los puntos.\n    )\n    train_loss = []\n    val_loss = []\n\n    for e in tqdm(range(1, EPOCHS + 1)):\n        train_batch_loss = []\n        val_batch_loss = []\n        model.train()\n        for batch in train_dataloader:\n            features, target = batch[\"features\"].to(device), batch[\n                \"target\"\n            ].to(device)\n\n            optimizer.zero_grad()\n            output = model(features)\n            ## Por qué no va acá una sigmoide a la salida?\n            loss = criterion(output, target.unsqueeze(1))\n            loss.backward()\n            optimizer.step()\n            train_batch_loss.append(loss.item())\n        train_epoch_loss = np.mean(train_batch_loss)\n        if e % 50 == 0:\n            print(f\"Training Loss for Epoch {e}: {train_epoch_loss}\")\n        train_loss.append(train_epoch_loss)\n\n        model.eval()\n        with torch.no_grad():\n            for batch in val_dataloader:\n                features, target = batch[\"features\"].to(device), batch[\n                    \"target\"\n                ].to(device)\n\n                output = model(features)\n                loss = criterion(output, target.unsqueeze(1))\n                val_batch_loss.append(loss.item())\n        val_epoch_loss = np.mean(val_batch_loss)\n        if e % 50 == 0:\n            print(f\"Validation Loss for Epoch {e}: {val_epoch_loss}\")\n        val_loss.append(val_epoch_loss)\n\n    return model, train_loss, val_loss\n\n\nimport matplotlib.pyplot as plt\n\n\ndef plot_validation_curve(train_loss, val_loss, epoch=50):\n    plt.plot(range(epoch), train_loss, label=\"Train Loss\")\n    plt.plot(range(epoch), val_loss, label=\"Validation Loss\")\n    plt.title(\"Validation Curve\")\n    plt.legend()\n    plt.show()\n\n\nEPOCHS = 50\nmodel = MyFFN(n_features=10, hidden_dim_1=64, hidden_dim_2=64, out_dim=1)\nmodel, train_loss, val_loss = training_loop(\n    model, X_train, y_train, X_val, y_val, batch_size=32, epochs=EPOCHS\n)\nplot_validation_curve(train_loss, val_loss)\nprint(f\"Min Loss: {min(val_loss)}\")\n\nModelo entrenándose en cuda:0\n\n\n\n\n\nTraining Loss for Epoch 50: 0.616158355837283\nValidation Loss for Epoch 50: 0.7319772690534592\n\n\n\n\n\n\n\n\n\nMin Loss: 0.6952822953462601\n\n\n\nEPOCHS = 100\nmodel = MyFFN(n_features=10, hidden_dim_1=64, hidden_dim_2=64, out_dim=1)\nmodel, train_loss, val_loss = training_loop(\n    model, X_train, y_train, batch_size=128, epochs=EPOCHS\n)\nplot_validation_curve(train_loss, val_loss, epoch=EPOCHS)\nprint(f\"Min Loss: {min(val_loss)}\")\n\n\n\n\nTraining Loss for Epoch 50: 0.6657268881797791\nValidation Loss for Epoch 50: 0.7142947316169739\nTraining Loss for Epoch 100: 0.6180922746658325\nValidation Loss for Epoch 100: 0.7341216802597046\n\n\n\n\n\n\n\n\n\nMin Loss: 0.6952072083950043\n\n\n\nfrom torchinfo import summary\n\nsummary(model)\n\n=================================================================\nLayer (type:depth-idx)                   Param #\n=================================================================\nMyFFN                                    --\n├─Linear: 1-1                            704\n├─ReLU: 1-2                              --\n├─Linear: 1-3                            4,160\n├─ReLU: 1-4                              --\n├─Linear: 1-5                            65\n=================================================================\nTotal params: 4,929\nTrainable params: 4,929\nNon-trainable params: 0\n=================================================================\n\n\n\nEPOCHS = 20\nmodel = MyFFN(n_features=10, hidden_dim_1=32, hidden_dim_2=32, out_dim=1)\nmodel, train_loss, val_loss = training_loop(\n    model, X_train, y_train, batch_size=64, epochs=EPOCHS\n)\nplot_validation_curve(train_loss, val_loss, epoch=EPOCHS)\nprint(f\"Min Loss: {min(val_loss)}\")\n\n\n\n\n\n\n\n\n\n\n\nMin Loss: 0.6932080686092377\n\n\n\nsummary(model)\n\n=================================================================\nLayer (type:depth-idx)                   Param #\n=================================================================\nMyFFN                                    --\n├─Linear: 1-1                            352\n├─ReLU: 1-2                              --\n├─Linear: 1-3                            1,056\n├─ReLU: 1-4                              --\n├─Linear: 1-5                            33\n=================================================================\nTotal params: 1,441\nTrainable params: 1,441\nNon-trainable params: 0\n=================================================================\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "tics579/notebooks/Emb_grad.html",
    "href": "tics579/notebooks/Emb_grad.html",
    "title": "Derivación a Mano",
    "section": "",
    "text": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nX = torch.tensor([0, 3, 4, 3]).reshape(-1, 1)\nm = X.shape[0]\ny = torch.tensor([1, 0, 1, 0]).reshape(-1, 1).float()\n\nE = torch.tensor(\n    [\n        [0.1, 0.2, 0.3],\n        [0, 0.1, -0.1],\n        [-0.2, 0, 0.2],\n        [0.4, 0, -0.1],\n        [0.2, -0.2, 0.1],\n    ],\n    requires_grad=True,\n)\n\nS = F.one_hot(X.squeeze(-1)).float()\nW1 = torch.tensor([0.5, -0.25, 0.1]).reshape(-1, 1)\nb = torch.tensor([0.1])\ne = E[X.squeeze(-1)]\ne\n\ntensor([[ 0.1000,  0.2000,  0.3000],\n        [ 0.4000,  0.0000, -0.1000],\n        [ 0.2000, -0.2000,  0.1000],\n        [ 0.4000,  0.0000, -0.1000]], grad_fn=&lt;IndexBackward0&gt;)\nphi1 = e @ W1\nphi1\n\ntensor([[0.0300],\n        [0.1900],\n        [0.1600],\n        [0.1900]], grad_fn=&lt;MmBackward0&gt;)\nZ = phi1 + b\nZ\n\ntensor([[0.1300],\n        [0.2900],\n        [0.2600],\n        [0.2900]], grad_fn=&lt;AddBackward0&gt;)\np = torch.sigmoid(Z)\np\n\ntensor([[0.5325],\n        [0.5720],\n        [0.5646],\n        [0.5720]], grad_fn=&lt;SigmoidBackward0&gt;)\nS.T @ (p - y) @ W1.T / m\n\ntensor([[-0.0584,  0.0292, -0.0117],\n        [ 0.0000, -0.0000,  0.0000],\n        [ 0.0000, -0.0000,  0.0000],\n        [ 0.1430, -0.0715,  0.0286],\n        [-0.0544,  0.0272, -0.0109]], grad_fn=&lt;DivBackward0&gt;)"
  },
  {
    "objectID": "tics579/notebooks/Emb_grad.html#derivación-en-pytorch",
    "href": "tics579/notebooks/Emb_grad.html#derivación-en-pytorch",
    "title": "Derivación a Mano",
    "section": "Derivación en Pytorch",
    "text": "Derivación en Pytorch\n\nclass EmbeddingMLP(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.emb = nn.Embedding(5, 3)\n        self.emb.weight.data = E\n        self.fc = nn.Linear(5, 1)\n        self.fc.weight.data = W1.T\n        self.fc.bias.data = b\n\n    def forward(self, x):\n        x = self.emb(x)\n        x = self.fc(x)\n        return x\n\n\nmodel = EmbeddingMLP()\ncriterion = nn.BCEWithLogitsLoss()\nlogits = model(X)\nloss = criterion(logits, y.unsqueeze(-1))\nloss.backward()\n\n\nmodel.emb.weight.grad\n\ntensor([[-0.0584,  0.0292, -0.0117],\n        [ 0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000],\n        [ 0.1430, -0.0715,  0.0286],\n        [-0.0544,  0.0272, -0.0109]])"
  },
  {
    "objectID": "tics579/notebooks/Intro_Pytorch.html",
    "href": "tics579/notebooks/Intro_Pytorch.html",
    "title": "Introducción de Pytorch",
    "section": "",
    "text": "%%capture\n!pip install torchinfo\nimport torch\nimport torch.nn as nn\nfrom sklearn.datasets import load_iris\ntorch.manual_seed(0)\n\ndata = load_iris(as_frame=True)\ndf = data[\"data\"]\ndf[\"target\"] = data[\"target\"]\ndf = df.sample(frac=1,random_state = 1)\ndf\n\n\n    \n\n\n\n\n\n\nsepal length (cm)\nsepal width (cm)\npetal length (cm)\npetal width (cm)\ntarget\n\n\n\n\n14\n5.8\n4.0\n1.2\n0.2\n0\n\n\n98\n5.1\n2.5\n3.0\n1.1\n1\n\n\n75\n6.6\n3.0\n4.4\n1.4\n1\n\n\n16\n5.4\n3.9\n1.3\n0.4\n0\n\n\n131\n7.9\n3.8\n6.4\n2.0\n2\n\n\n...\n...\n...\n...\n...\n...\n\n\n133\n6.3\n2.8\n5.1\n1.5\n2\n\n\n137\n6.4\n3.1\n5.5\n1.8\n2\n\n\n72\n6.3\n2.5\n4.9\n1.5\n1\n\n\n140\n6.7\n3.1\n5.6\n2.4\n2\n\n\n37\n4.9\n3.6\n1.4\n0.1\n0\n\n\n\n\n150 rows × 5 columns\nX = df.drop(columns=\"target\").to_numpy()\ny = df.target.values\nprint(X.shape)\nprint(y.shape)\n\n(150, 4)\n(150,)\nX = torch.from_numpy(X).float()\ny = torch.from_numpy(y).float()\nX, y\n\n(tensor([[5.8000, 4.0000, 1.2000, 0.2000],\n         [5.1000, 2.5000, 3.0000, 1.1000],\n         [6.6000, 3.0000, 4.4000, 1.4000],\n         [5.4000, 3.9000, 1.3000, 0.4000],\n         [7.9000, 3.8000, 6.4000, 2.0000],\n         [6.3000, 3.3000, 4.7000, 1.6000],\n         [6.9000, 3.1000, 5.1000, 2.3000],\n         [5.1000, 3.8000, 1.9000, 0.4000],\n         [4.7000, 3.2000, 1.6000, 0.2000],\n         [6.9000, 3.2000, 5.7000, 2.3000],\n         [5.6000, 2.7000, 4.2000, 1.3000],\n         [5.4000, 3.9000, 1.7000, 0.4000],\n         [7.1000, 3.0000, 5.9000, 2.1000],\n         [6.4000, 3.2000, 4.5000, 1.5000],\n         [6.0000, 2.9000, 4.5000, 1.5000],\n         [4.4000, 3.2000, 1.3000, 0.2000],\n         [5.8000, 2.6000, 4.0000, 1.2000],\n         [5.6000, 3.0000, 4.5000, 1.5000],\n         [5.4000, 3.4000, 1.5000, 0.4000],\n         [5.0000, 3.2000, 1.2000, 0.2000],\n         [5.5000, 2.6000, 4.4000, 1.2000],\n         [5.4000, 3.0000, 4.5000, 1.5000],\n         [6.7000, 3.0000, 5.0000, 1.7000],\n         [5.0000, 3.5000, 1.3000, 0.3000],\n         [7.2000, 3.2000, 6.0000, 1.8000],\n         [5.7000, 2.8000, 4.1000, 1.3000],\n         [5.5000, 4.2000, 1.4000, 0.2000],\n         [5.1000, 3.8000, 1.5000, 0.3000],\n         [6.1000, 2.8000, 4.7000, 1.2000],\n         [6.3000, 2.5000, 5.0000, 1.9000],\n         [6.1000, 3.0000, 4.6000, 1.4000],\n         [7.7000, 3.0000, 6.1000, 2.3000],\n         [5.6000, 2.5000, 3.9000, 1.1000],\n         [6.4000, 2.8000, 5.6000, 2.1000],\n         [5.8000, 2.8000, 5.1000, 2.4000],\n         [5.3000, 3.7000, 1.5000, 0.2000],\n         [5.5000, 2.3000, 4.0000, 1.3000],\n         [5.2000, 3.4000, 1.4000, 0.2000],\n         [6.5000, 2.8000, 4.6000, 1.5000],\n         [6.7000, 2.5000, 5.8000, 1.8000],\n         [6.8000, 3.0000, 5.5000, 2.1000],\n         [5.1000, 3.5000, 1.4000, 0.3000],\n         [6.0000, 2.2000, 5.0000, 1.5000],\n         [6.3000, 2.9000, 5.6000, 1.8000],\n         [6.6000, 2.9000, 4.6000, 1.3000],\n         [7.7000, 2.6000, 6.9000, 2.3000],\n         [5.7000, 3.8000, 1.7000, 0.3000],\n         [5.0000, 3.6000, 1.4000, 0.2000],\n         [4.8000, 3.0000, 1.4000, 0.3000],\n         [5.2000, 2.7000, 3.9000, 1.4000],\n         [5.1000, 3.4000, 1.5000, 0.2000],\n         [5.5000, 3.5000, 1.3000, 0.2000],\n         [7.7000, 3.8000, 6.7000, 2.2000],\n         [6.9000, 3.1000, 5.4000, 2.1000],\n         [7.3000, 2.9000, 6.3000, 1.8000],\n         [6.4000, 2.8000, 5.6000, 2.2000],\n         [6.2000, 2.8000, 4.8000, 1.8000],\n         [6.0000, 3.4000, 4.5000, 1.6000],\n         [7.7000, 2.8000, 6.7000, 2.0000],\n         [5.7000, 3.0000, 4.2000, 1.2000],\n         [4.8000, 3.4000, 1.6000, 0.2000],\n         [5.7000, 2.5000, 5.0000, 2.0000],\n         [6.3000, 2.7000, 4.9000, 1.8000],\n         [4.8000, 3.0000, 1.4000, 0.1000],\n         [4.7000, 3.2000, 1.3000, 0.2000],\n         [6.5000, 3.0000, 5.8000, 2.2000],\n         [4.6000, 3.4000, 1.4000, 0.3000],\n         [6.1000, 3.0000, 4.9000, 1.8000],\n         [6.5000, 3.2000, 5.1000, 2.0000],\n         [6.7000, 3.1000, 4.4000, 1.4000],\n         [5.7000, 2.8000, 4.5000, 1.3000],\n         [6.7000, 3.3000, 5.7000, 2.5000],\n         [6.0000, 3.0000, 4.8000, 1.8000],\n         [5.1000, 3.8000, 1.6000, 0.2000],\n         [6.0000, 2.2000, 4.0000, 1.0000],\n         [6.4000, 2.9000, 4.3000, 1.3000],\n         [6.5000, 3.0000, 5.5000, 1.8000],\n         [5.0000, 2.3000, 3.3000, 1.0000],\n         [6.3000, 3.3000, 6.0000, 2.5000],\n         [5.5000, 2.5000, 4.0000, 1.3000],\n         [5.4000, 3.7000, 1.5000, 0.2000],\n         [4.9000, 3.1000, 1.5000, 0.2000],\n         [5.2000, 4.1000, 1.5000, 0.1000],\n         [6.7000, 3.3000, 5.7000, 2.1000],\n         [4.4000, 3.0000, 1.3000, 0.2000],\n         [6.0000, 2.7000, 5.1000, 1.6000],\n         [6.4000, 2.7000, 5.3000, 1.9000],\n         [5.9000, 3.0000, 5.1000, 1.8000],\n         [5.2000, 3.5000, 1.5000, 0.2000],\n         [5.1000, 3.3000, 1.7000, 0.5000],\n         [5.8000, 2.7000, 4.1000, 1.0000],\n         [4.9000, 3.1000, 1.5000, 0.1000],\n         [7.4000, 2.8000, 6.1000, 1.9000],\n         [6.2000, 2.9000, 4.3000, 1.3000],\n         [7.6000, 3.0000, 6.6000, 2.1000],\n         [6.7000, 3.0000, 5.2000, 2.3000],\n         [6.3000, 2.3000, 4.4000, 1.3000],\n         [6.2000, 3.4000, 5.4000, 2.3000],\n         [7.2000, 3.6000, 6.1000, 2.5000],\n         [5.6000, 2.9000, 3.6000, 1.3000],\n         [5.7000, 4.4000, 1.5000, 0.4000],\n         [5.8000, 2.7000, 3.9000, 1.2000],\n         [4.5000, 2.3000, 1.3000, 0.3000],\n         [5.5000, 2.4000, 3.8000, 1.1000],\n         [6.9000, 3.1000, 4.9000, 1.5000],\n         [5.0000, 3.4000, 1.6000, 0.4000],\n         [6.8000, 2.8000, 4.8000, 1.4000],\n         [5.0000, 3.5000, 1.6000, 0.6000],\n         [4.8000, 3.4000, 1.9000, 0.2000],\n         [6.3000, 3.4000, 5.6000, 2.4000],\n         [5.6000, 2.8000, 4.9000, 2.0000],\n         [6.8000, 3.2000, 5.9000, 2.3000],\n         [5.0000, 3.3000, 1.4000, 0.2000],\n         [5.1000, 3.7000, 1.5000, 0.4000],\n         [5.9000, 3.2000, 4.8000, 1.8000],\n         [4.6000, 3.1000, 1.5000, 0.2000],\n         [5.8000, 2.7000, 5.1000, 1.9000],\n         [4.8000, 3.1000, 1.6000, 0.2000],\n         [6.5000, 3.0000, 5.2000, 2.0000],\n         [4.9000, 2.5000, 4.5000, 1.7000],\n         [4.6000, 3.2000, 1.4000, 0.2000],\n         [6.4000, 3.2000, 5.3000, 2.3000],\n         [4.3000, 3.0000, 1.1000, 0.1000],\n         [5.6000, 3.0000, 4.1000, 1.3000],\n         [4.4000, 2.9000, 1.4000, 0.2000],\n         [5.5000, 2.4000, 3.7000, 1.0000],\n         [5.0000, 2.0000, 3.5000, 1.0000],\n         [5.1000, 3.5000, 1.4000, 0.2000],\n         [4.9000, 3.0000, 1.4000, 0.2000],\n         [4.9000, 2.4000, 3.3000, 1.0000],\n         [4.6000, 3.6000, 1.0000, 0.2000],\n         [5.9000, 3.0000, 4.2000, 1.5000],\n         [6.1000, 2.9000, 4.7000, 1.4000],\n         [5.0000, 3.4000, 1.5000, 0.2000],\n         [6.7000, 3.1000, 4.7000, 1.5000],\n         [5.7000, 2.9000, 4.2000, 1.3000],\n         [6.2000, 2.2000, 4.5000, 1.5000],\n         [7.0000, 3.2000, 4.7000, 1.4000],\n         [5.8000, 2.7000, 5.1000, 1.9000],\n         [5.4000, 3.4000, 1.7000, 0.2000],\n         [5.0000, 3.0000, 1.6000, 0.2000],\n         [6.1000, 2.6000, 5.6000, 1.4000],\n         [6.1000, 2.8000, 4.0000, 1.3000],\n         [7.2000, 3.0000, 5.8000, 1.6000],\n         [5.7000, 2.6000, 3.5000, 1.0000],\n         [6.3000, 2.8000, 5.1000, 1.5000],\n         [6.4000, 3.1000, 5.5000, 1.8000],\n         [6.3000, 2.5000, 4.9000, 1.5000],\n         [6.7000, 3.1000, 5.6000, 2.4000],\n         [4.9000, 3.6000, 1.4000, 0.1000]]),\n tensor([0., 1., 1., 0., 2., 1., 2., 0., 0., 2., 1., 0., 2., 1., 1., 0., 1., 1.,\n         0., 0., 1., 1., 1., 0., 2., 1., 0., 0., 1., 2., 1., 2., 1., 2., 2., 0.,\n         1., 0., 1., 2., 2., 0., 2., 2., 1., 2., 0., 0., 0., 1., 0., 0., 2., 2.,\n         2., 2., 2., 1., 2., 1., 0., 2., 2., 0., 0., 2., 0., 2., 2., 1., 1., 2.,\n         2., 0., 1., 1., 2., 1., 2., 1., 0., 0., 0., 2., 0., 1., 2., 2., 0., 0.,\n         1., 0., 2., 1., 2., 2., 1., 2., 2., 1., 0., 1., 0., 1., 1., 0., 1., 0.,\n         0., 2., 2., 2., 0., 0., 1., 0., 2., 0., 2., 2., 0., 2., 0., 1., 0., 1.,\n         1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 2., 0., 0., 2., 1., 2.,\n         1., 2., 2., 1., 2., 0.]))"
  },
  {
    "objectID": "tics579/notebooks/Intro_Pytorch.html#feed-forward-networks-en-pytorch",
    "href": "tics579/notebooks/Intro_Pytorch.html#feed-forward-networks-en-pytorch",
    "title": "Introducción de Pytorch",
    "section": "Feed Forward Networks en Pytorch",
    "text": "Feed Forward Networks en Pytorch\n\nfc1 = nn.Linear(in_features = 4, out_features=12)\nphi1_py = fc1(X)\nphi1_py\n\ntensor([[ 0.2620, -0.5313,  0.3907,  ..., -0.0451, -1.2113, -2.9476],\n        [-1.2096, -0.2586, -0.1372,  ...,  0.1342, -1.1130, -1.4764],\n        [-1.7676, -0.3754, -0.3786,  ...,  0.2964, -1.2234, -1.6176],\n        ...,\n        [-2.1432, -0.3500, -0.5168,  ...,  0.3048, -1.1075, -1.1932],\n        [-2.6030,  0.0033, -0.6494,  ...,  0.8202, -1.6117, -1.0077],\n        [ 0.1126, -0.4532,  0.3573,  ...,  0.0660, -1.0688, -2.4856]],\n       grad_fn=&lt;AddmmBackward0&gt;)\n\n\n\nW1 = fc1.weight.data\nb1 = fc1.bias.data\n\nW1.shape, b1.shape\n\n(torch.Size([12, 4]), torch.Size([12]))\n\n\n\nphi1 = X@W1.T + b1\nprint(phi1.shape)\nphi1\n\ntorch.Size([150, 12])\n\n\ntensor([[ 0.2620, -0.5313,  0.3907,  ..., -0.0451, -1.2113, -2.9476],\n        [-1.2096, -0.2586, -0.1372,  ...,  0.1342, -1.1130, -1.4764],\n        [-1.7676, -0.3754, -0.3786,  ...,  0.2964, -1.2234, -1.6176],\n        ...,\n        [-2.1432, -0.3500, -0.5168,  ...,  0.3048, -1.1075, -1.1932],\n        [-2.6030,  0.0033, -0.6494,  ...,  0.8202, -1.6117, -1.0077],\n        [ 0.1126, -0.4532,  0.3573,  ...,  0.0660, -1.0688, -2.4856]])\n\n\n\ntorch.equal(phi1_py, phi1)\n\nTrue\n\n\n\n## Si creamos más capas\nrelu = nn.ReLU()\nz1 = relu(phi1_py)\nfc2 = nn.Linear(12,20)\nphi2_py = fc2(z1)\nrelu2 = nn.ReLU()\nz2 = relu2(phi2_py)\nfc3 = nn.Linear(20,1)\nz = fc3(z2)\nz\n\ntensor([[0.0850],\n        [0.1158],\n        [0.1566],\n        [0.0927],\n        [0.2101],\n        [0.1749],\n        [0.1780],\n        [0.1111],\n        [0.0875],\n        [0.1876],\n        [0.1431],\n        [0.1079],\n        [0.1764],\n        [0.1703],\n        [0.1568],\n        [0.0786],\n        [0.1356],\n        [0.1595],\n        [0.0958],\n        [0.0805],\n        [0.1339],\n        [0.1579],\n        [0.1655],\n        [0.0855],\n        [0.1789],\n        [0.1475],\n        [0.0927],\n        [0.0964],\n        [0.1454],\n        [0.1455],\n        [0.1592],\n        [0.1807],\n        [0.1270],\n        [0.1677],\n        [0.1730],\n        [0.0929],\n        [0.1187],\n        [0.0888],\n        [0.1514],\n        [0.1430],\n        [0.1736],\n        [0.0900],\n        [0.1135],\n        [0.1655],\n        [0.1514],\n        [0.1747],\n        [0.1051],\n        [0.0871],\n        [0.0843],\n        [0.1457],\n        [0.0904],\n        [0.0880],\n        [0.2179],\n        [0.1765],\n        [0.1688],\n        [0.1699],\n        [0.1546],\n        [0.1765],\n        [0.1714],\n        [0.1549],\n        [0.0912],\n        [0.1499],\n        [0.1511],\n        [0.0821],\n        [0.0808],\n        [0.1797],\n        [0.0874],\n        [0.1639],\n        [0.1772],\n        [0.1592],\n        [0.1480],\n        [0.1977],\n        [0.1634],\n        [0.0973],\n        [0.1044],\n        [0.1513],\n        [0.1682],\n        [0.1127],\n        [0.2040],\n        [0.1336],\n        [0.0932],\n        [0.0867],\n        [0.0922],\n        [0.1885],\n        [0.0770],\n        [0.1495],\n        [0.1565],\n        [0.1666],\n        [0.0918],\n        [0.0980],\n        [0.1359],\n        [0.0856],\n        [0.1628],\n        [0.1517],\n        [0.1817],\n        [0.1753],\n        [0.1148],\n        [0.1973],\n        [0.2119],\n        [0.1443],\n        [0.1055],\n        [0.1398],\n        [0.0755],\n        [0.1205],\n        [0.1652],\n        [0.0952],\n        [0.1488],\n        [0.1006],\n        [0.0988],\n        [0.2011],\n        [0.1616],\n        [0.1898],\n        [0.0869],\n        [0.0984],\n        [0.1725],\n        [0.0835],\n        [0.1564],\n        [0.0875],\n        [0.1696],\n        [0.1412],\n        [0.0823],\n        [0.1862],\n        [0.0677],\n        [0.1573],\n        [0.0784],\n        [0.1177],\n        [0.0900],\n        [0.0870],\n        [0.0843],\n        [0.1211],\n        [0.0690],\n        [0.1613],\n        [0.1546],\n        [0.0893],\n        [0.1653],\n        [0.1524],\n        [0.1139],\n        [0.1670],\n        [0.1564],\n        [0.0975],\n        [0.0891],\n        [0.1415],\n        [0.1435],\n        [0.1634],\n        [0.1231],\n        [0.1523],\n        [0.1727],\n        [0.1327],\n        [0.1852],\n        [0.0836]], grad_fn=&lt;AddmmBackward0&gt;)\n\n\n\nclass NNet(nn.Module):\n  def __init__(self, n, d1=12, d2=20, k=1):\n    super().__init__()\n    self.fc1 = nn.Linear(n, d1)\n    self.fc2 = nn.Linear(d1,d2)\n    self.fc3 = nn.Linear(d2, k)\n    self.relu1 = nn.ReLU(inplace = True)\n    self.relu2 = nn.ReLU(inplace = True)\n\n  def forward(self,x):\n    x = self.fc1(x)\n    x = self.relu1(x)\n    x = self.fc2(x)\n    x = self.relu2(x)\n    x = self.fc3(x)\n    return x\n\nmodel = NNet(n=4)\nmodel(X)\n\ntensor([[0.4225],\n        [0.3099],\n        [0.4244],\n        [0.3862],\n        [0.5377],\n        [0.4182],\n        [0.4358],\n        [0.3707],\n        [0.3167],\n        [0.4410],\n        [0.3486],\n        [0.3905],\n        [0.4519],\n        [0.4207],\n        [0.3808],\n        [0.2955],\n        [0.3573],\n        [0.3610],\n        [0.3648],\n        [0.3387],\n        [0.3516],\n        [0.3486],\n        [0.4267],\n        [0.3441],\n        [0.4791],\n        [0.3598],\n        [0.4078],\n        [0.3664],\n        [0.3981],\n        [0.3786],\n        [0.3935],\n        [0.4814],\n        [0.3439],\n        [0.3998],\n        [0.3508],\n        [0.3738],\n        [0.3278],\n        [0.3528],\n        [0.4068],\n        [0.4307],\n        [0.4275],\n        [0.3512],\n        [0.3751],\n        [0.4109],\n        [0.4209],\n        [0.4984],\n        [0.4038],\n        [0.3504],\n        [0.3104],\n        [0.3223],\n        [0.3482],\n        [0.3832],\n        [0.5226],\n        [0.4387],\n        [0.4878],\n        [0.3950],\n        [0.3841],\n        [0.4044],\n        [0.5107],\n        [0.3713],\n        [0.3318],\n        [0.3410],\n        [0.3853],\n        [0.3159],\n        [0.3131],\n        [0.4110],\n        [0.3173],\n        [0.3880],\n        [0.4202],\n        [0.4357],\n        [0.3651],\n        [0.4308],\n        [0.3818],\n        [0.3680],\n        [0.3675],\n        [0.4083],\n        [0.4207],\n        [0.2951],\n        [0.4059],\n        [0.3323],\n        [0.3797],\n        [0.3225],\n        [0.3870],\n        [0.4364],\n        [0.2862],\n        [0.3840],\n        [0.3978],\n        [0.3757],\n        [0.3587],\n        [0.3446],\n        [0.3702],\n        [0.3234],\n        [0.4800],\n        [0.3959],\n        [0.5014],\n        [0.4184],\n        [0.3843],\n        [0.4071],\n        [0.4771],\n        [0.3584],\n        [0.4290],\n        [0.3623],\n        [0.2731],\n        [0.3332],\n        [0.4469],\n        [0.3426],\n        [0.4300],\n        [0.3464],\n        [0.3354],\n        [0.4121],\n        [0.3441],\n        [0.4349],\n        [0.3365],\n        [0.3613],\n        [0.3855],\n        [0.3050],\n        [0.3586],\n        [0.3178],\n        [0.4101],\n        [0.2957],\n        [0.3084],\n        [0.4098],\n        [0.2840],\n        [0.3637],\n        [0.2827],\n        [0.3348],\n        [0.2927],\n        [0.3516],\n        [0.3198],\n        [0.2940],\n        [0.3236],\n        [0.3795],\n        [0.3906],\n        [0.3423],\n        [0.4344],\n        [0.3649],\n        [0.3702],\n        [0.4594],\n        [0.3586],\n        [0.3681],\n        [0.3249],\n        [0.4128],\n        [0.3846],\n        [0.4782],\n        [0.3537],\n        [0.4073],\n        [0.4174],\n        [0.3947],\n        [0.4221],\n        [0.3450]], grad_fn=&lt;AddmmBackward0&gt;)"
  },
  {
    "objectID": "tics579/notebooks/Intro_Pytorch.html#el-nn.module",
    "href": "tics579/notebooks/Intro_Pytorch.html#el-nn.module",
    "title": "Introducción de Pytorch",
    "section": "El nn.Module",
    "text": "El nn.Module\nEl nn.Module permite generar modelos modularizados y reutilizables.\nEl nn.Module tiene dos componentes, el __init__() y el forward().\n\nEl __init__() es lo que se llama un constructor. Es donde se inicializarán todos las capas que serán utilizadas por el modelo.\nEl forward() se encarga de indicar como se conecta cada capa.\n\n\nclass MLP(nn.Module):\n  def __init__(self, in_features, out_features):\n    super().__init__()\n    self.fc1 = nn.Linear(in_features, out_features)\n\n\n    ## Esto permite iniciar las capas con una matriz de parámetros arbitraria.\n    self.fc1.weight.data = W1\n    self.fc1.bias.data = b1\n  def forward(self,x):\n    x = self.fc1(x)\n    return x\n\nmodel = MLP(in_features=4, out_features = 12)\nmodel(X)\n\ntensor([[ 0.2620, -0.5313,  0.3907,  ..., -0.0451, -1.2113, -2.9476],\n        [-1.2096, -0.2586, -0.1372,  ...,  0.1342, -1.1130, -1.4764],\n        [-1.7676, -0.3754, -0.3786,  ...,  0.2964, -1.2234, -1.6176],\n        ...,\n        [-2.1432, -0.3500, -0.5168,  ...,  0.3048, -1.1075, -1.1932],\n        [-2.6030,  0.0033, -0.6494,  ...,  0.8202, -1.6117, -1.0077],\n        [ 0.1126, -0.4532,  0.3573,  ...,  0.0660, -1.0688, -2.4856]],\n       grad_fn=&lt;AddmmBackward0&gt;)\n\n\n\nLa gracia de poder utilizar el nn.Module es poder combinar Módulos para crear Módulos más grandes.\n\n\nclass MLP2(nn.Module):\n  def __init__(self, in_features, out_features):\n    super().__init__()\n    self.fc1 = nn.Linear(in_features, out_features)\n    self.relu = nn.ReLU(inplace = True)\n    self.fc2 = nn.Linear(out_features, 1)\n\n  def forward(self,x):\n    x = self.fc1(x)\n    x = self.relu(x)\n    x = self.fc2(x)\n    return x\n\nclass SuperMLP(nn.Module):\n  def __init__(self):\n    super().__init__()\n    self.mlp1 = MLP(in_features=4, out_features=12)\n    self.mlp2 = MLP2(in_features=12, out_features=8)\n  def forward(self, x):\n    x = self.mlp1(x)\n    x = self.mlp2(x)\n    return x\n\nsuper_model = SuperMLP()\nlogits = super_model(X)\nlogits.shape\n\ntorch.Size([150, 1])\n\n\n\np = torch.sigmoid(logits)\np\n\ntensor([[0.5518],\n        [0.5677],\n        [0.5614],\n        [0.5608],\n        [0.5575],\n        [0.5630],\n        [0.5629],\n        [0.5700],\n        [0.5631],\n        [0.5624],\n        [0.5650],\n        [0.5660],\n        [0.5612],\n        [0.5624],\n        [0.5640],\n        [0.5612],\n        [0.5641],\n        [0.5655],\n        [0.5627],\n        [0.5560],\n        [0.5648],\n        [0.5663],\n        [0.5615],\n        [0.5603],\n        [0.5600],\n        [0.5648],\n        [0.5566],\n        [0.5626],\n        [0.5622],\n        [0.5638],\n        [0.5631],\n        [0.5597],\n        [0.5645],\n        [0.5636],\n        [0.5676],\n        [0.5586],\n        [0.5656],\n        [0.5575],\n        [0.5619],\n        [0.5627],\n        [0.5622],\n        [0.5609],\n        [0.5636],\n        [0.5631],\n        [0.5608],\n        [0.5620],\n        [0.5613],\n        [0.5591],\n        [0.5622],\n        [0.5673],\n        [0.5595],\n        [0.5544],\n        [0.5593],\n        [0.5619],\n        [0.5607],\n        [0.5640],\n        [0.5640],\n        [0.5644],\n        [0.5606],\n        [0.5643],\n        [0.5628],\n        [0.5665],\n        [0.5635],\n        [0.5570],\n        [0.5593],\n        [0.5635],\n        [0.5641],\n        [0.5643],\n        [0.5634],\n        [0.5612],\n        [0.5643],\n        [0.5639],\n        [0.5648],\n        [0.5613],\n        [0.5625],\n        [0.5618],\n        [0.5622],\n        [0.5671],\n        [0.5652],\n        [0.5656],\n        [0.5579],\n        [0.5604],\n        [0.5572],\n        [0.5624],\n        [0.5610],\n        [0.5637],\n        [0.5631],\n        [0.5649],\n        [0.5590],\n        [0.5697],\n        [0.5632],\n        [0.5578],\n        [0.5603],\n        [0.5626],\n        [0.5606],\n        [0.5636],\n        [0.5621],\n        [0.5654],\n        [0.5616],\n        [0.5657],\n        [0.5621],\n        [0.5642],\n        [0.5620],\n        [0.5650],\n        [0.5601],\n        [0.5666],\n        [0.5602],\n        [0.5716],\n        [0.5666],\n        [0.5652],\n        [0.5670],\n        [0.5625],\n        [0.5587],\n        [0.5651],\n        [0.5652],\n        [0.5624],\n        [0.5656],\n        [0.5624],\n        [0.5632],\n        [0.5689],\n        [0.5612],\n        [0.5647],\n        [0.5564],\n        [0.5652],\n        [0.5621],\n        [0.5647],\n        [0.5668],\n        [0.5583],\n        [0.5590],\n        [0.5675],\n        [0.5566],\n        [0.5647],\n        [0.5630],\n        [0.5601],\n        [0.5611],\n        [0.5647],\n        [0.5631],\n        [0.5597],\n        [0.5656],\n        [0.5601],\n        [0.5609],\n        [0.5635],\n        [0.5633],\n        [0.5595],\n        [0.5648],\n        [0.5622],\n        [0.5626],\n        [0.5624],\n        [0.5636],\n        [0.5572]], grad_fn=&lt;SigmoidBackward0&gt;)"
  },
  {
    "objectID": "tics579/notebooks/Intro_Pytorch.html#entrenamiento-de-un-modelo",
    "href": "tics579/notebooks/Intro_Pytorch.html#entrenamiento-de-un-modelo",
    "title": "Introducción de Pytorch",
    "section": "Entrenamiento de un Modelo",
    "text": "Entrenamiento de un Modelo\n\nfrom torchinfo import summary\nsummary(super_model)\n\n=================================================================\nLayer (type:depth-idx)                   Param #\n=================================================================\nSuperMLP                                 --\n├─MLP: 1-1                               --\n│    └─Linear: 2-1                       60\n├─MLP2: 1-2                              --\n│    └─Linear: 2-2                       104\n│    └─ReLU: 2-3                         --\n│    └─Linear: 2-4                       9\n=================================================================\nTotal params: 173\nTrainable params: 173\nNon-trainable params: 0\n=================================================================\n\n\n\nsuper_model\n\nSuperMLP(\n  (mlp1): MLP(\n    (fc1): Linear(in_features=4, out_features=12, bias=True)\n  )\n  (mlp2): MLP2(\n    (fc1): Linear(in_features=12, out_features=8, bias=True)\n    (relu): ReLU(inplace=True)\n    (fc2): Linear(in_features=8, out_features=1, bias=True)\n  )\n)\n\n\n\ncriterion = nn.BCEWithLogitsLoss()\noptimizer = torch.optim.Adam(super_model.parameters(), lr = 3e-4)\n\n\nepochs = 50\nloss_history = []\nfor e in range(epochs):\n  print(\"Epoch: \", e+1)\n  # Define el modo del Modelo\n  super_model.train()\n  optimizer.zero_grad()\n\n  ## Forward Pass\n  logits = super_model(X)\n  print(\"Logits Shape: \", logits.shape)\n  print(\"Target Shape: \", y.shape)\n  loss = criterion(logits, y.unsqueeze(-1))\n  ## Calcula los gradientes (Backward Pass)\n  loss.backward()\n\n  # Actualización de los Pesos.\n  optimizer.step()\n  loss_history.append(loss.item())\n\nEpoch:  1\nLogits Shape:  torch.Size([150, 1])\nTarget Shape:  torch.Size([150])\nEpoch:  2\nLogits Shape:  torch.Size([150, 1])\nTarget Shape:  torch.Size([150])\nEpoch:  3\nLogits Shape:  torch.Size([150, 1])\nTarget Shape:  torch.Size([150])\nEpoch:  4\nLogits Shape:  torch.Size([150, 1])\nTarget Shape:  torch.Size([150])\nEpoch:  5\nLogits Shape:  torch.Size([150, 1])\nTarget Shape:  torch.Size([150])\nEpoch:  6\nLogits Shape:  torch.Size([150, 1])\nTarget Shape:  torch.Size([150])\nEpoch:  7\nLogits Shape:  torch.Size([150, 1])\nTarget Shape:  torch.Size([150])\nEpoch:  8\nLogits Shape:  torch.Size([150, 1])\nTarget Shape:  torch.Size([150])\nEpoch:  9\nLogits Shape:  torch.Size([150, 1])\nTarget Shape:  torch.Size([150])\nEpoch:  10\nLogits Shape:  torch.Size([150, 1])\nTarget Shape:  torch.Size([150])\nEpoch:  11\nLogits Shape:  torch.Size([150, 1])\nTarget Shape:  torch.Size([150])\nEpoch:  12\nLogits Shape:  torch.Size([150, 1])\nTarget Shape:  torch.Size([150])\nEpoch:  13\nLogits Shape:  torch.Size([150, 1])\nTarget Shape:  torch.Size([150])\nEpoch:  14\nLogits Shape:  torch.Size([150, 1])\nTarget Shape:  torch.Size([150])\nEpoch:  15\nLogits Shape:  torch.Size([150, 1])\nTarget Shape:  torch.Size([150])\nEpoch:  16\nLogits Shape:  torch.Size([150, 1])\nTarget Shape:  torch.Size([150])\nEpoch:  17\nLogits Shape:  torch.Size([150, 1])\nTarget Shape:  torch.Size([150])\nEpoch:  18\nLogits Shape:  torch.Size([150, 1])\nTarget Shape:  torch.Size([150])\nEpoch:  19\nLogits Shape:  torch.Size([150, 1])\nTarget Shape:  torch.Size([150])\nEpoch:  20\nLogits Shape:  torch.Size([150, 1])\nTarget Shape:  torch.Size([150])\nEpoch:  21\nLogits Shape:  torch.Size([150, 1])\nTarget Shape:  torch.Size([150])\nEpoch:  22\nLogits Shape:  torch.Size([150, 1])\nTarget Shape:  torch.Size([150])\nEpoch:  23\nLogits Shape:  torch.Size([150, 1])\nTarget Shape:  torch.Size([150])\nEpoch:  24\nLogits Shape:  torch.Size([150, 1])\nTarget Shape:  torch.Size([150])\nEpoch:  25\nLogits Shape:  torch.Size([150, 1])\nTarget Shape:  torch.Size([150])\nEpoch:  26\nLogits Shape:  torch.Size([150, 1])\nTarget Shape:  torch.Size([150])\nEpoch:  27\nLogits Shape:  torch.Size([150, 1])\nTarget Shape:  torch.Size([150])\nEpoch:  28\nLogits Shape:  torch.Size([150, 1])\nTarget Shape:  torch.Size([150])\nEpoch:  29\nLogits Shape:  torch.Size([150, 1])\nTarget Shape:  torch.Size([150])\nEpoch:  30\nLogits Shape:  torch.Size([150, 1])\nTarget Shape:  torch.Size([150])\nEpoch:  31\nLogits Shape:  torch.Size([150, 1])\nTarget Shape:  torch.Size([150])\nEpoch:  32\nLogits Shape:  torch.Size([150, 1])\nTarget Shape:  torch.Size([150])\nEpoch:  33\nLogits Shape:  torch.Size([150, 1])\nTarget Shape:  torch.Size([150])\nEpoch:  34\nLogits Shape:  torch.Size([150, 1])\nTarget Shape:  torch.Size([150])\nEpoch:  35\nLogits Shape:  torch.Size([150, 1])\nTarget Shape:  torch.Size([150])\nEpoch:  36\nLogits Shape:  torch.Size([150, 1])\nTarget Shape:  torch.Size([150])\nEpoch:  37\nLogits Shape:  torch.Size([150, 1])\nTarget Shape:  torch.Size([150])\nEpoch:  38\nLogits Shape:  torch.Size([150, 1])\nTarget Shape:  torch.Size([150])\nEpoch:  39\nLogits Shape:  torch.Size([150, 1])\nTarget Shape:  torch.Size([150])\nEpoch:  40\nLogits Shape:  torch.Size([150, 1])\nTarget Shape:  torch.Size([150])\nEpoch:  41\nLogits Shape:  torch.Size([150, 1])\nTarget Shape:  torch.Size([150])\nEpoch:  42\nLogits Shape:  torch.Size([150, 1])\nTarget Shape:  torch.Size([150])\nEpoch:  43\nLogits Shape:  torch.Size([150, 1])\nTarget Shape:  torch.Size([150])\nEpoch:  44\nLogits Shape:  torch.Size([150, 1])\nTarget Shape:  torch.Size([150])\nEpoch:  45\nLogits Shape:  torch.Size([150, 1])\nTarget Shape:  torch.Size([150])\nEpoch:  46\nLogits Shape:  torch.Size([150, 1])\nTarget Shape:  torch.Size([150])\nEpoch:  47\nLogits Shape:  torch.Size([150, 1])\nTarget Shape:  torch.Size([150])\nEpoch:  48\nLogits Shape:  torch.Size([150, 1])\nTarget Shape:  torch.Size([150])\nEpoch:  49\nLogits Shape:  torch.Size([150, 1])\nTarget Shape:  torch.Size([150])\nEpoch:  50\nLogits Shape:  torch.Size([150, 1])\nTarget Shape:  torch.Size([150])\n\n\n\nimport matplotlib.pyplot as plt\n\nplt.plot(loss_history)\nprint(loss_history[-1])\n\n0.4633480906486511"
  },
  {
    "objectID": "tics579/clase-11.html#transformers-attention-is-all-you-need-2017",
    "href": "tics579/clase-11.html#transformers-attention-is-all-you-need-2017",
    "title": "TICS-579-Deep Learning",
    "section": "Transformers (Attention is all you need, 2017)",
    "text": "Transformers (Attention is all you need, 2017)\n\n\n\nTransformers\n\nCorresponden a la arquitectura más moderna diseñada al día de hoy. Está basado en mecanismos de atención y posee hasta 4 tipos de atención distintos.\n\n\n\n\n\nVentajas\n\n\n\nNo tiene problemas de “memoria” para modelar dependencias de largo plazo.\nPermite procesamiento en paralelo.\nSu bajísimo inductive bias le permite adaptarse a distintos dominios.\nNo es necesario utilizar el transformer completo para un problema en específico.\n\n\n\n\n\n\n\nDesventajas\n\n\n\nApto sólo para datos secuenciales.\nLas secuencias deben de ser del mismo largo.\nAlta demanda de recursos computacionales GPU y/o TPUs para entrenamiento distribuido.\nData hungry.\nLimitaciones de secuencias muy largas por restricciones de memoria computacional."
  },
  {
    "objectID": "tics579/clase-11.html#encoder",
    "href": "tics579/clase-11.html#encoder",
    "title": "TICS-579-Deep Learning",
    "section": "Encoder",
    "text": "Encoder\n\n\n\n\n\n\n\n\n\n\n\nObjetivo\n\n\nCodificar y comprimir información en Logits que puedan ser usados para clasificar o para ser utilizados por un Decoder.\n\n\n\n\n\n\nForward Pass en el Encoder\n\n\n\nEl embedding asociado a una secuencia se bifurca en 4 ramas:\n\nResidual Connection\nQuery\nKey\nValue\n\nQuery, Key y Value ingresan al Multihead Attention.\nLa salida del Multihead Attention + el Residual Connection pasan por un LayerNorm.\nNueva bifurcación.\n\nUna parte entra a un MLP\nOtra va como skip connection.\n\nLa salida del MLP + la Residual Connection pasan por un segundo LayerNorm para generar la salida del Encoder."
  },
  {
    "objectID": "tics579/clase-11.html#decoder",
    "href": "tics579/clase-11.html#decoder",
    "title": "TICS-579-Deep Learning",
    "section": "Decoder",
    "text": "Decoder\n\n\n\n\n\n\n\n\n\n\n\nObjetivo\n\n\nTomar información de entrada y generar una salida fijándose sólo en tokens pasados.\n\n\n\n\n\n\nForward Pass en el Decoder\n\n\n\nEl embedding asociado a una secuencia se bifurca en 4 ramas:\n\nResidual Connection\nQuery\nKey\nValue\n\nQuery, Key y Value ingresan al Masked (Causal) Multihead Attention.\nLa salida del Masked Multihead Attention + el Residual Connection pasan por LayerNorm.\nSe pasa por un Cross Attention (esto podría ser opcional).\n\nKey y Value provienen del Encoder como contexto.\nLa salida del Causal Multihead Attention se utiliza como Query.\n\nNueva bifurcación.\n\nUna parte entra a un MLP\nOtra va como skip connection.\n\nLa salida del MLP + la Residual Connection pasan por LayerNorm para generar el Output."
  },
  {
    "objectID": "tics579/clase-11.html#ejemplo",
    "href": "tics579/clase-11.html#ejemplo",
    "title": "TICS-579-Deep Learning",
    "section": "Ejemplo",
    "text": "Ejemplo\nSupongamos que tenemos la siguiente frase:\n\nMe gusta la pizza de Pepperoni\n\n\nTokenización\n\n\nAplicaremos un proceso de Tokenización simple, donde cada palabra es un Token.\n\n\n\n\n\n\n\n\n\nYa sabemos que esto no tiene por qué ser así. De hecho cada modelo tiene su propio tipo de tokenización, e incluso se pueden entrenar Tokenizaciones nuevas. Más información al respecto pueden encontrarla acá.\n\n\n\n\n\n\n\n\n\nLa documentación de Tokenizers de HuggingFace la traduje yo, así que si encuentran algo me dicen para corregir.\n\n\n\nLuego la secuencia tokenizada de largo \\(L=6\\) será:\n\n[105,6587,5475,301,708,358]\n\n\n\n\n\n\n\nRecordar que dependiendo del modelo se pueden agregar al inicio o al final tokens especiales. Hablaremos de eso más adelante."
  },
  {
    "objectID": "tics579/clase-11.html#embedding",
    "href": "tics579/clase-11.html#embedding",
    "title": "TICS-579-Deep Learning",
    "section": "Embedding",
    "text": "Embedding\n\n\n\nEmbedding\n\nNo es más que una Lookup Table. Es una tabla de parámetros entrenables que permitirá transformar índices enteros en vectores de una dimensión determinada.\n\n\nnn.Embedding(num_embeddings, embedding_dim)\n\n\n\n\n\n\nEsta clase permite el ingreso de tensores de cualquier tamaño \\((*)\\) y devuelve tensores de tamaño \\((*,H)\\). Donde \\(H\\) es el embedding_dim.\n\n\n\n\n\n\n\n\n\nLa sección 3.1 del paper se refiere al tamaño del embedding como \\(d_{model}=512\\).\n\n\n\n\n\n\n\n\n\nEn la sección 3.4 del paper se menciona que los parámetros de los embeddings son multiplicados por \\(\\sqrt{d_{model}}\\)."
  },
  {
    "objectID": "tics579/clase-11.html#embedding-1",
    "href": "tics579/clase-11.html#embedding-1",
    "title": "TICS-579-Deep Learning",
    "section": "Embedding",
    "text": "Embedding\n\n\n\n\n\n\n\n\n\n\n\nCada token está representado por un Embedding de \\(d_{model}\\) dimensiones."
  },
  {
    "objectID": "tics579/clase-11.html#positional-encoder",
    "href": "tics579/clase-11.html#positional-encoder",
    "title": "TICS-579-Deep Learning",
    "section": "Positional Encoder",
    "text": "Positional Encoder\n\n\n\n\n\n\n\n\nUn potencial problema que puede tener un transformer es reconocer el orden de las frases.\n\n\n\n\n\n\n\n\n\nNo es lo mismo decir “El perro del papá mordió al niño” que “El perro del niño mordió al papá”. Las palabras usadas en ambas frases son exactamente las mismas, pero en un orden distinto implican desenlaces distintos. ¿Cómo podemos entender el concepto de orden si no tenemos recurrencia?\n\n\n\n\n\n\n\n\n\nIncluso algunos órdenes no tienen tanto sentido lógico: “El niño del perro mordió al papá”.\n\n\n\n\nPositional Encoder\n\n\nCorresponden a una manera en la que se pueden generar un vector único que representa el orden en el que aparece cada token."
  },
  {
    "objectID": "tics579/clase-11.html#positional-encoder-1",
    "href": "tics579/clase-11.html#positional-encoder-1",
    "title": "TICS-579-Deep Learning",
    "section": "Positional Encoder",
    "text": "Positional Encoder\n\n\n\\[PE_{(pos,2i)} = sin\\left(\\frac{pos}{10000^{2i/d_{model}}}\\right)\\] \\[PE_{(pos,2i+1)} = cos\\left(\\frac{pos}{10000^{2i/d_{model}}}\\right)\\]\n\n\n\n\n\n\\(pos\\) corresponde a la posición del Token en la secuencia, y \\(2i\\) y \\(2i+1\\) corresponden a las posiciones pares e impares respectivamente del embedding dimension de cada token, en este caso llamado \\(d_{model}\\) (\\(i\\) comienza en 0).\n\n\n\n\n\n\n\n\n\n\nUna forma más clara de ver esto es que la posición está definida por sinusoidales de periodo \\(2\\pi \\cdot 10000^{i/d_{model}/2}\\).\n\n\n\n\n\n\n\n\n\n\nEl positional encoder debe tener el mismo tamaño que el Embedding para que se puedan sumar.\n\n\n\n\n\n\nEstabilidad numérica\n\n\nPor temas de estabilidad el argumento del \\(sin(\\cdot)\\) y \\(cos(\\cdot)\\) se suele implementar como: \\[pos \\cdot exp\\left[-\\frac{2i}{d_{model}} log(10000)\\right]\\]\n\n\n\n\n\n\nRegularización\n\n\nLa sección 5.4 menciona que se aplica Dropout posterior a sumar los Embeddings con el Positional Encoding. Se utilizo un \\(P_{drop}=0.1\\)."
  },
  {
    "objectID": "tics579/clase-11.html#positional-encoder-ejemplo",
    "href": "tics579/clase-11.html#positional-encoder-ejemplo",
    "title": "TICS-579-Deep Learning",
    "section": "Positional Encoder: Ejemplo",
    "text": "Positional Encoder: Ejemplo\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImplementación Eficiente\n\n\nEl Positional Encoding se implementa como una matriz de tamaño \\((L,d_{model})\\) en la que cada fila es un embedding de \\(d_{model}\\) dimensiones asociado a cada token.\n\n\n\n\n\n\nImportante\n\n\nLa suma del Embedding con el Positional Encoder codifica la información del token y su posición relativa dentro de la secuencia."
  },
  {
    "objectID": "tics579/clase-11.html#encoder-self-attention",
    "href": "tics579/clase-11.html#encoder-self-attention",
    "title": "TICS-579-Deep Learning",
    "section": "Encoder: Self-Attention",
    "text": "Encoder: Self-Attention\n\n\n\n\n\n\n\n\\[Attention(Q,K,V) = Softmax\\left(\\frac{Q \\cdot K^T}{\\sqrt{d_k}}\\right) V\\]\n\n\n\nEjemplo\n\n\n“La sopa se cocinó en la olla y estaba rica”. Rica podría estar refiriéndose a olla o a sopa. Sabemos que se refiere a la sopa.\n\n\n\n\n\n\n\n\n\n\nEl Scaled Dot-Product, más conocido como Self-Attention, es el mecanismo clave en las redes neuronales modernas. Permite determinar la atención/relación que existe entre palabras de una misma secuencia.\n\n\n\n\n\n\n\n\n\n\nEstá compuesto por 3 proyecciones lineales las cuales reciben los nombres de Query (Q), Key (K) y Value (V).\nEstás 3 proyecciones se combinan para poder determinar la atención/relación que cada Token tiene con los otros tokens de una misma secuencia.\nVarios procesos de Self-Attention dan pie al Multihead Attention.\n\n\n\n\n\n\n\n\n\n\n\nEl Self-Attention tiene la capacidad de acceder a toda la secuencia, por ende modelar relaciones a larga distancia.\nEl Causal Self-Attention, una variante que se utiliza en el Decoder sólo puede ver la relación con tokens pasados.\n\n\n\n\n\n\n\n\n\n\n\nSu característica más importante es que el Multihead Attention es paralelizable y no secuencial como las RNN.\nTiene capacidad de escalabilidad para secuencias largas."
  },
  {
    "objectID": "tics579/clase-11.html#encoder-self-attention-1",
    "href": "tics579/clase-11.html#encoder-self-attention-1",
    "title": "TICS-579-Deep Learning",
    "section": "Encoder: Self-Attention",
    "text": "Encoder: Self-Attention\n\n\n\n\n\n\n\nSupongamos que tenemos la secuencia “Me gusta la Pizza de Pepperoni”.\nUtilizaremos \\(d_{model} = 512\\) y \\(h=8\\).\nEl paper utiliza \\(d_k=d_v=d_{model}/h=64\\) para el cálculo de los Attention Weights.\n\n\n\n\n\n\n\\[\n\\begin{array}{c c}\nX = \\left[\n\\begin{array}{c c c}\n[1,...,64]\\\\\n[1,...,64]\\\\\n[1,...,64]\\\\\n[1,...,64]\\\\\n[1,...,64]\\\\\n[1,...,64]\\\\\n\\end{array}\n\\right]\n\\begin{array}{c c c}Me\\\\gusta\\\\la\\\\pizza\\\\de\\\\pepperoni \\end{array} &\n\\end{array}\n\\]\n\n\n\n\n👀 Ojito\n\n\nEsto se debe aplicar a cada secuencia. Por lo tanto se debe agregar una dimensión (como unsqueeze(0)) que contabilice el número de secuencias para \\(Q\\), \\(K\\), y \\(V\\).\n\n\n\n\n\n\n\n\nMatrices de Proyección\n\n\nDefiniremos 3 matrices de Proyección. Una matriz de proyección permite llevar transportar un vector \\(X\\) a otro espacio (es decir, son entrenables). En este caso crearemos matrices que puedan multiplicarse con \\(X\\). Por lo tanto irán desde \\(d_{model}\\) hasta \\(d_q=d_k\\) y \\(d_v\\) respectivamente.\n\n\\(W_q = (d_{model}, d_k)\\)\n\\(W_k = (d_{model}, d_k)\\)\n\\(W_v = (d_{model}, d_v)\\)\n\n\n\n\n\n\n\nDimensiones de Q,K y V\n\n\n\n\\(Q = (L, d_k)\\)\n\\(K = (L, d_k)\\)\n\\(V = (L, d_v)\\)\n\\(L\\) corresponde a largo de la secuencia (es decir, el número de Tokens)\n\n\n\n\n\n:::"
  },
  {
    "objectID": "tics579/clase-11.html#encoder-self-attention-2",
    "href": "tics579/clase-11.html#encoder-self-attention-2",
    "title": "TICS-579-Deep Learning",
    "section": "Encoder: Self-Attention",
    "text": "Encoder: Self-Attention\n\nSiguiendo nuestro ejemplo: \\(d_k = d_v = 64\\)\n\n\n\n\n\n\nQuery (6,64)\n\n\n\\[\n\\begin{array}{c c}\nQ = \\left[\n\\begin{array}{c c c}\n[1,...,64]\\\\\n[1,...,64]\\\\\n[1,...,64]\\\\\n[1,...,64]\\\\\n[1,...,64]\\\\\n[1,...,64]\\\\\n\\end{array}\n\\right]\n\\end{array}\n\\]\n\n\n\n\n\n\n\nKey (6,64)\n\n\n\\[\n\\begin{array}{c c}\nK = \\left[\n\\begin{array}{c c c}\n[1,...,64]\\\\\n[1,...,64]\\\\\n[1,...,64]\\\\\n[1,...,64]\\\\\n[1,...,64]\\\\\n[1,...,64]\\\\\n\\end{array}\n\\right]\n\\end{array}\n\\]\n\n\n\n\n\n\n\nValue (6,64)\n\n\n\\[\n\\begin{array}{c c}\nV = \\left[\n\\begin{array}{c c c}\n[1,...,64]\\\\\n[1,...,64]\\\\\n[1,...,64]\\\\\n[1,...,64]\\\\\n[1,...,64]\\\\\n[1,...,64]\\\\\n\\end{array}\n\\right]\n\\end{array}\n\\]\n\n\n\n\n\n\n\n\n👀 Ojito\n\n\nComo esto se aplica a una sola secuencia, la dimensión real de estos tensores debería ser \\((1,6,64)\\). Ese 1 cambiará si tenemos más secuencias. Pero, todas las secuencias deben ser del mismo largo."
  },
  {
    "objectID": "tics579/clase-11.html#encoder-self-attention-scale-dot-product",
    "href": "tics579/clase-11.html#encoder-self-attention-scale-dot-product",
    "title": "TICS-579-Deep Learning",
    "section": "Encoder: Self-Attention (Scale Dot Product)",
    "text": "Encoder: Self-Attention (Scale Dot Product)\n\n\n\\[\\frac{Q \\cdot K^T}{\\sqrt{d_k}}\\]\n\n\n\nSimilaridad\n\n\n\n\\(Q \\cdot K^T\\) representa el producto punto entre \\(Q\\) (un token de referencia que está consultando la atención contra otros tokens) y \\(K\\) (otro token que se compara contra la “query”).\n\n\n\n\n\n\n\nControl de Gradientes\n\n\n\\(\\sqrt{d_k}\\) es un factor que reduce la escala de los valores para el control de los gradientes. Recordar que esta matriz es de parámetros entrenables.\n\n\n\n\n\n\n\n\n\n\n\n\n\nAttention\n\n\nDado que el rango de estos valores van de \\(-\\infty\\) a \\(\\infty\\), es más común aplicar una softmax para poder garantizar que la suma de las atenciones para cada palabra “query” sume 1."
  },
  {
    "objectID": "tics579/clase-11.html#encoder-self-attention-scale-dot-product-1",
    "href": "tics579/clase-11.html#encoder-self-attention-scale-dot-product-1",
    "title": "TICS-579-Deep Learning",
    "section": "Encoder: Self-Attention (Scale Dot Product)",
    "text": "Encoder: Self-Attention (Scale Dot Product)\n\n\n\n\n\n\n\n\nAttention Weights\n\n\n\nEsta matriz indica cuánta atención (en términos porcentuales) entrega cada palabra “query” a cada palabra “key”.\nEsta matriz permitirá crear embeddings contextualizados, que incluyen la información de la palabra y su contexto de atención."
  },
  {
    "objectID": "tics579/clase-11.html#encoder-self-attention-scale-dot-product-2",
    "href": "tics579/clase-11.html#encoder-self-attention-scale-dot-product-2",
    "title": "TICS-579-Deep Learning",
    "section": "Encoder: Self-Attention (Scale Dot Product)",
    "text": "Encoder: Self-Attention (Scale Dot Product)\n\\[Attention(Q,K,V) = Softmax\\left(\\frac{Q \\cdot K^T}{\\sqrt{d_k}}\\right) V\\]\n\n\n\n\n\n\n\n\nOJO\n\n\n\nA modo de ejemplo, el elemento en Rojo representa una suma ponderada de la primera dimensión de cada proyección de tokens.\nEl resultado de cada dimensión es una combinación lineal de las dimensiones de cada token.\nCada fila corresponde a un embedding contextualizado que tiene información sobre el token y su contexto combinado.\n\n\n\n\n\n\n\n¿Y, estamos seguros que las atenciones/relaciones obtenidas por este algoritmos son (las) únicas/más correctas?"
  },
  {
    "objectID": "tics579/clase-11.html#encoder-multihead-attention",
    "href": "tics579/clase-11.html#encoder-multihead-attention",
    "title": "TICS-579-Deep Learning",
    "section": "Encoder: Multihead Attention",
    "text": "Encoder: Multihead Attention\n\n\n\n\n\n\n\n\nMultihead Attention\n\n\nEs una extensión del Self-Attention. En lugar de calcular sólo “una atención” sobre el input, genera distintas “atenciones” en múltiples “cabezas” independientes. Cada Attention Head se encarga de aprender relaciones diferentes, lo que mejora la capacidad del modelo de captar patrones cada vez más complejos.\n\n\n\n\n\n\n\n\n\nNormalmente se calculan entre \\(h=8\\) y \\(h=12\\) attention heads, las cuales se concatenan para luego pasar por una proyección lineal."
  },
  {
    "objectID": "tics579/clase-11.html#encoder-multihead-attention-1",
    "href": "tics579/clase-11.html#encoder-multihead-attention-1",
    "title": "TICS-579-Deep Learning",
    "section": "Encoder: Multihead Attention",
    "text": "Encoder: Multihead Attention\n\n\n\nSi queremos calcular \\(h=8\\) attention heads. Necesitamos 8 \\(Q\\), 8 \\(K\\) y 8 \\(V\\). Por lo tanto, necesitamos 8 matrices de proyección. ¿Cómo lo paralelizamos?\n\n\n\n\n\n\n\n\nImplementación en paralelo\n\n\nPodemos definir en realidad todas las matrices de manera análoga rescribiendo las matrices de proyección para \\(Q\\), \\(K\\) y \\(V\\) como una subdivisión de cada embedding en \\(h\\) cabezas.\n\nPor lo tanto si \\(d_k=d_v=64\\) y \\(h=8\\) tendríamos una dimensión total de 512.\n\\(dim(Q) = dim(K) = (N,h \\cdot d_k) = (6, 512)\\)\n\\(dim(V) = (N, h \\cdot d_v) = (6, 512)\\)\n\\(dim(W_q) = (d_{model}, h, d_k)\\)\n\\(dim(W_k) = (d_{model}, h, d_k)\\)\n\\(dim(W_v) = (d_{model}, h, d_v)\\)\n\n\n\n\n\n\n\n\nDimensiones de Q, K y V\n\n\n\n\\(Q = X \\cdot W_q = (6,512) \\cdot (512,\\overbrace{8,64}^{512}) = (6,8,512)\\)\n\\(K = X \\cdot W_k = (6,512) \\cdot (512,\\overbrace{8,64}^{512}) = (6,8,512)\\)\n\\(V = X \\cdot W_v = (6,512) \\cdot (512,\\overbrace{8,64}^{512}) = (6,8,512)\\)"
  },
  {
    "objectID": "tics579/clase-11.html#encoder-multihead-attention-independencia",
    "href": "tics579/clase-11.html#encoder-multihead-attention-independencia",
    "title": "TICS-579-Deep Learning",
    "section": "Encoder: Multihead Attention (Independencia)",
    "text": "Encoder: Multihead Attention (Independencia)\n\n\n\n\n\nIndependent Heads\n\n\nEs importante mencionar que cada cabeza debe ser independiente una de otra para que se pueda paralelizar. Para ello basta con transponer las dos primeras dimensiones.\n\n\n\n\n\n\nQuery/Key/Value (6, 8, 64) (Previo a Transponer)\n\n\n\\[\n\\begin{array}{c c}\nQ/K/V = \\left[\n\\begin{array}{c c c}\n\\overbrace{[1,...,64]}^{Head 1}, \\overbrace{[65,...,128]}^{Head 2}, ..., \\overbrace{[449,...,512]}^{Head 8}\\\\\n[1,...,64],[65,..., 128],...[449,...,512]\\\\\n[1,...,64],[65,..., 128],...[449,...,512]\\\\\n[1,...,64],[65,..., 128],...[449,...,512]\\\\\n[1,...,64],[65,..., 128],...[449,...,512]\\\\\n[1,...,64],[65,..., 128],...[449,...,512]\\\\\n\\end{array}\n\\right]\n\\end{array}\n\\]\n\n\n\n\n\n\nOJO\n\n\nEsto permite calcular cada Head en paralelo. Este procedimiento se aplica a cada secuencia. Por lo tanto, un Multihead Attention recibe Tensores de dimensión \\((N,L,h \\cdot d_i)\\) con \\(i=k,v\\).\n\n\n\n\n\n\n\nQuery/Key/Value (8,6, 64) (Luego de Transponer)\n\n\n\\[\n\\begin{array}{c c}\n\\left[\n\\begin{array}{c c c}\n\\text{Head1}\\left\\{\n\\begin{array}{c c c}\n\\begin{bmatrix}\n[1,...,64]\\\\\n[1,...,64]\\\\\n[1,...,64]\\\\\n[1,...,64]\\\\\n[1,...,64]\\\\\n[1,...,64]\\\\\n\\end{bmatrix}\n\\end{array}\n\\right. \\\\\n\\vdots \\\\\n\\vdots \\\\\n\\text{Head8}\\left\\{\n\\begin{array}{c c c}\n\\begin{bmatrix}\n[449,...,512]\\\\\n[449,...,512]\\\\\n[449,...,512]\\\\\n[449,...,512]\\\\\n[449,...,512]\\\\\n[449,...,512]\\\\\n\\end{bmatrix}\n\\end{array}\n\\right. \\\\\n\\end{array}\n\\right]\n\\end{array}\n\\]"
  },
  {
    "objectID": "tics579/clase-11.html#encoder-multihead-attention-concatenación",
    "href": "tics579/clase-11.html#encoder-multihead-attention-concatenación",
    "title": "TICS-579-Deep Learning",
    "section": "Encoder: Multihead Attention (Concatenación)",
    "text": "Encoder: Multihead Attention (Concatenación)\n\n\n\n\n\nSelf-Attentions (aka Multihead Attention) (6,8,64)\n\n\n\\[\n\\begin{array}{c c}\n\\left[\n\\begin{array}{c c c}\n\\text{Head1}\\left\\{\n\\begin{array}{c c c}\n\\begin{bmatrix}\n[SA_1,...,SA_{64}]\\\\\n[SA_1,...,SA_{64}]\\\\\n[SA_1,...,SA_{64}]\\\\\n[SA_1,...,SA_{64}]\\\\\n[SA_1,...,SA_{64}]\\\\\n[SA_1,...,SA_{64}]\\\\\n\\end{bmatrix}\n\\end{array}\n\\right. \\\\\n\\vdots \\\\\n\\vdots \\\\\n\\text{Head8}\\left\\{\n\\begin{array}{c c c}\n\\begin{bmatrix}\n[SA_{449},...,SA_{512}]\\\\\n[SA_{449},...,SA_{512}]\\\\\n[SA_{449},...,SA_{512}]\\\\\n[SA_{449},...,SA_{512}]\\\\\n[SA_{449},...,SA_{512}]\\\\\n[SA_{449},...,SA_{512}]\\\\\n\\end{bmatrix}\n\\end{array}\n\\right. \\\\\n\\end{array}\n\\right]\n\\end{array}\n\\]\n\n\n\n\n\n\n\nSelf-Attention Transpuesto (6,8,64)\n\n\n\\[\n\\begin{array}{c c}\n\\left[\n\\begin{array}{c c c}\n\\overbrace{[SA_1,...,SA_{64}]}^{Head 1}, \\overbrace{[SA_{65},...,SA_{128}}^{Head 2}, ..., \\overbrace{[SA_{449},...,SA_{512}]}^{Head 8}\\\\\n[SA_1,...,SA_{128}],[SA_{65},..., SA_{128}],...[SA_{449},...,SA_{512}]\\\\\n[SA_1,...,SA_{128}],[SA_{65},..., SA_{128}],...[SA_{449},...,SA_{512}]\\\\\n[SA_1,...,SA_{128}],[SA_{65},..., SA_{128}],...[SA_{449},...,SA_{512}]\\\\\n[SA_1,...,SA_{128}],[SA_{65},..., SA_{128}],...[SA_{449},...,SA_{512}]\\\\\n[SA_1,...,SA_{128}],[SA_{65},..., SA_{128}],...[SA_{449},...,SA_{512}]\\\\\n\\end{array}\n\\right]\n\\end{array}\n\\]\n\n\n\n\n\n\nSelf-Attention Concatenado (6,512)\n\n\n\\[\n\\begin{array}{c c}\n\\left[\n\\begin{array}{c c c}\n[SA_1,.....,SA_{512}]\\\\\n[SA_1,.....,SA_{512}]\\\\\n[SA_1,.....,SA_{512}]\\\\\n[SA_1,.....,SA_{512}]\\\\\n[SA_1,.....,SA_{512}]\\\\\n[SA_1,.....,SA_{512}]\\\\\n\\end{array}\n\\right]\n\\end{array}\n\\]"
  },
  {
    "objectID": "tics579/clase-11.html#encoder-multihead-attention-output",
    "href": "tics579/clase-11.html#encoder-multihead-attention-output",
    "title": "TICS-579-Deep Learning",
    "section": "Encoder: Multihead Attention (Output)",
    "text": "Encoder: Multihead Attention (Output)\n\n\n\nHead Mixing\n\n\nLos outputs de cada cabeza ahora están uno al lado del otro. Por lo tanto, si aplicamos una capa lineal \\(W^O \\in \\mathbb{R}^{d_v \\cdot h \\times d_{model}}\\), estos parámetros entrenables se encargarán de aprender una combinación lineal que mezcla la información aprendida por cada Attention Head de manera óptima.\n\n\n\n\n\n\nMultihead Attention Output (6,512)\n\n\n\\[\nMultihead(Q,K,V) = \\begin{array}{c c}\n\\left[\n\\begin{array}{c c c}\n[SA_1,.....,SA_{512}]\\\\\n[SA_1,.....,SA_{512}]\\\\\n[SA_1,.....,SA_{512}]\\\\\n[SA_1,.....,SA_{512}]\\\\\n[SA_1,.....,SA_{512}]\\\\\n[SA_1,.....,SA_{512}]\\\\\n\\end{array}\n\\right]\n\\end{array}\n\\cdot W^O\n\\]\n\n\n\n\n\n\n\n\n\n\\(W^O\\) se encarga de retornar a la dimensión del Input original para poder realizar la Residual Connection (similar al downsample de la Resnet)."
  },
  {
    "objectID": "tics579/clase-11.html#encoder-add-layernorm",
    "href": "tics579/clase-11.html#encoder-add-layernorm",
    "title": "TICS-579-Deep Learning",
    "section": "Encoder: Add + LayerNorm",
    "text": "Encoder: Add + LayerNorm\n\n\n\n\n\n\n\n\n\n\n\nResidual Connection (Add&Norm)\n\n\nCorresponde a una conexión residual. Combina la información de entrada al Multihead y su salida para luego aplicar LayerNorm.\n\\[Add\\&Norm = LayerNorm(X + Multihead(Q,K,V))\\]\n\n\n\n\n\n\nLayerNorm\n\n\nEl LayerNorm calcula el promedio y la varianza por token normalizando las dimensiones del embedding de cada token.\n\\[X_{norm} = \\frac{x - \\mu}{\\sqrt{\\sigma^2 + \\epsilon}}\\cdot \\gamma + \\beta\\]\n\n\n\n\n\n\n\n\n\n\n\\(\\gamma\\) y \\(\\beta\\) son parámetros entrenables.\n\n\n\n\n\n\n\nRegularización\n\n\nLa sección 5.4 menciona que se aplica Dropout posterior a cada sublayer del Encoder (y el Decoder) con \\(P_{drop}=0.1\\)."
  },
  {
    "objectID": "tics579/clase-11.html#encoder-feed-forward-mlp",
    "href": "tics579/clase-11.html#encoder-feed-forward-mlp",
    "title": "TICS-579-Deep Learning",
    "section": "Encoder: Feed Forward (MLP)",
    "text": "Encoder: Feed Forward (MLP)\n\n\n\n\n\n\n\n\nLa sección 3.3 del paper define el bloque Feed Forward de la siguiente manera:\n\\[FFN(x) = max(0,x \\cdot W_1+b_1)W_2 + b_2\\]\nDonde \\(W_1 \\in \\mathbb{R}^{d_{model} \\times {d_{ff}}}\\) y \\(W_2 \\in \\mathbb{R}^{d_{ff} \\times {d_{model}}}\\).\n\n\n\nArquitectura\n\n\n\n2 capas Feed Forward con bias.\nUna RelU como activación intermedia.\nDe acuerdo a la sección 5.4, a la salida incluiría un Dropout con \\(P_{drop}=0.1\\).\n\n\n\n\n\n\n\nResidual Connection (Add&Norm)\n\n\nAl igual que en el Multihead Attention, se la salida de esta capa se une con una conexión residual y se pasa por un LayerNorm."
  },
  {
    "objectID": "tics579/clase-11.html#encoder-output-final",
    "href": "tics579/clase-11.html#encoder-output-final",
    "title": "TICS-579-Deep Learning",
    "section": "Encoder: Output Final",
    "text": "Encoder: Output Final\n\n\n\n\n\n\n\n\n\n\n\nEncoder Layers\n\n\n\nLa combinación de todos los pasos anteriores constituyen un (1) Encoder. En el caso del paper el Transformer está compuesto de \\(N=6\\) Encoder Layers uno después del otro.\n\n\n\n\n\n\n\n👀 Ojito\n\n\n\nSólo antes de la primera Encoder Layer se aplica el Input Embedding y el Positional Encoding.\n\n\n\n\n\n\n\nArquitectura Encoder-Decoder\n\n\nEn el caso de estas arquitecturas, entonces el output del Encoder sirve como Keys y Values para el proceso de Cross Attention."
  },
  {
    "objectID": "tics579/clase-11.html#decoder-causal-self-attention",
    "href": "tics579/clase-11.html#decoder-causal-self-attention",
    "title": "TICS-579-Deep Learning",
    "section": "Decoder: Causal Self-Attention",
    "text": "Decoder: Causal Self-Attention\n\n\n\n\n\n\n\n\n\\[Attention(Q,K,V) = Softmax\\left(\\frac{Q \\cdot K^T + Mask}{\\sqrt{d_k}}\\right) V\\]\n\n\n\n\n\n\n\nCorresponde a una variante del Self-Attention en el cuál sólo se presta atención a Tokens pasados, esto para preservar las propiedades auto-regresivas."
  },
  {
    "objectID": "tics579/clase-11.html#decoder-cross-attention",
    "href": "tics579/clase-11.html#decoder-cross-attention",
    "title": "TICS-579-Deep Learning",
    "section": "Decoder: Cross Attention",
    "text": "Decoder: Cross Attention\n\n\n\n\n\n\n\n\n\n\n\n\n\nOpcionalmente podría utilizar una Máscara en caso de querer evitar el Look Ahead.\n\n\n\n\n\n\n\nCross Attention\n\n\nEste mecanismo permite generar relaciones/atenciones entre dos secuencias de datos distintos. En este caso se relaciona una secuencia “query” con elementos “key” y “values” de otra secuencia. Además limita la generación del Decoder.\n\n\n\n\n\n\nDimensiones de Q, K y V\n\n\n\n\\(Q = X_{decoder} \\cdot W_q = (F,512) \\cdot (512,\\overbrace{8,64}^{512}) = (6,8,512)\\)\n\\(K = X_{encoder} \\cdot W_k = (6,512) \\cdot (512,\\overbrace{8,64}^{512}) = (6,8,512)\\)\n\\(V = X_{encoder} \\cdot W_v = (6,512) \\cdot (512,\\overbrace{8,64}^{512}) = (6,8,512)\\)\n\n\n\n\n\n\\[Attention(Q_{decoder},K_{encoder},V_{encoder}) = Softmax\\left(\\frac{Q_{decoder} \\cdot K_{encoder}^T + Mask}{\\sqrt{d_k}}\\right) V_{encoder}\\]"
  },
  {
    "objectID": "tics579/clase-11.html#prediction-head",
    "href": "tics579/clase-11.html#prediction-head",
    "title": "TICS-579-Deep Learning",
    "section": "Prediction Head",
    "text": "Prediction Head\n\n\n\n\n\n\n\n\n\n\n\nArquitectura\n\n\nCorresponde a una capa Feed Forward que proyecta desde \\(d_{model}\\) hasta \\(vocab\\_size\\) seguida de una Softmax.\n\n\n\n\n\n\n¿Por qué es necesaria?\n\n\nPor que la salida del Decoder tiene dimensiones \\((N, L, d_{model})\\). Es decir, tenemos \\(N\\) secuencias de largo \\(L\\), donde cada token está representado como un embedding de \\(d_{model}\\) dimensiones, lo cuál no es interpretable por humanos.\nEsta capa tiene el objetivo de estimar la probabilidad de que ocurra el siguiente token, de este modo predecir de manera autoregresiva."
  },
  {
    "objectID": "tics579/notebooks/CNNs.html",
    "href": "tics579/notebooks/CNNs.html",
    "title": "Generación de los Datos",
    "section": "",
    "text": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport numpy as np\n\ntorch.manual_seed(42)\n\nX = torch.randint(1, 10, (1, 1, 6, 6)).float()\nprint(\"=\"*60)\nprint(\"X shape:\", X.shape)\nprint(\"Una Imagen, de 1 canal de tamaño 6x6\")\nprint(\"=\"*60)\nX\n\n============================================================\nX shape: torch.Size([1, 1, 6, 6])\nUna Imagen, de 1 canal de tamaño 6x6\n============================================================\n\n\ntensor([[[[7., 6., 8., 5., 1., 3.],\n          [8., 6., 5., 3., 5., 5.],\n          [9., 1., 1., 5., 3., 5.],\n          [4., 5., 5., 9., 2., 6.],\n          [9., 5., 3., 1., 2., 2.],\n          [4., 4., 8., 8., 9., 8.]]]])\nprint(\"=\"*60)\nprint(\"Hiperparámetros de la Convolución\")\nC_out = 2\nN, C_in, H, W = X.shape\nkH, kW = (3,3)\n\nprint(\"=\"*60)\nprint(f\"Número de Feature Maps (C_out): {C_out}\")\nprint(f\"Tamaño del Kernel de la Convolución: {kH,kW}\")\n\n============================================================\nHiperparámetros de la Convolución\n============================================================\nNúmero de Feature Maps (C_out): 2\nTamaño del Kernel de la Convolución: (3, 3)\nprint(\"=\"*60)\nprint(\"Parámetros de la convolución: \")\nprint(\"Se va a aplicar 2 filtros de tamaño 3x3 y un bias para cada filtro\")\nprint(\"=\"*60)\ngiven_w = torch.randint(-1,2, (C_out, C_in, kH,kW)).float()\ngiven_bias = torch.tensor([1.,1.]) # (2,)\nprint(\"W_conv: \", end=\"\")\nprint(given_w)\nprint(\"=\"*60)\nprint(\"bias_conv: \", end=\"\")\nprint(given_bias)\nprint(\"=\"*60)\n\n============================================================\nParámetros de la convolución: \nSe va a aplicar 2 filtros de tamaño 3x3 y un bias para cada filtro\n============================================================\nW_conv: tensor([[[[ 1.,  1.,  0.],\n          [-1.,  1., -1.],\n          [ 0., -1., -1.]]],\n\n\n        [[[ 1.,  1.,  0.],\n          [-1.,  1., -1.],\n          [-1.,  0., -1.]]]])\n============================================================\nbias_conv: tensor([1., 1.])\n============================================================"
  },
  {
    "objectID": "tics579/notebooks/CNNs.html#pytorch-nn.module",
    "href": "tics579/notebooks/CNNs.html#pytorch-nn.module",
    "title": "Generación de los Datos",
    "section": "Pytorch nn.Module",
    "text": "Pytorch nn.Module\n\nprint(\"=\"*60)\nprint(\"Definición del Modelo en Pytorch utilizando nn.Module\")\nprint(\"=\"*60)\nclass Conv(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv = nn.Conv2d(in_channels=1, out_channels=2, kernel_size=3, bias=True)\n        self.conv.weight.data = given_w\n        self.conv.bias.data = given_bias\n        self.max_pool = nn.MaxPool2d(kernel_size=2, return_indices=True)\n        self.fc = nn.Linear(8, 1)\n        nn.init.ones_(self.fc.weight)\n        nn.init.ones_(self.fc.bias)\n        self.flatten = nn.Flatten()\n\n    def forward(self, x):\n        x = self.conv(x)\n        print(x)\n        x, self.indices = self.max_pool(x)\n        x = self.flatten(x)\n        x = self.fc(x)\n        return x\n\nmodel = Conv()\ncriterion = nn.BCEWithLogitsLoss()\ny = torch.zeros([N,1])\n\n# Forward con PyTorch (referencia)\nlogits = model(X)\nloss = criterion(logits, y)\n\nprint(\"=\"*60)\nprint(\"y: \", end=\"\")\nprint(y)\nprint(\"=\"*60)\nprint(f\"Loss obtenido: {loss}\")\nprint(\"=\"*60)\nprint(f\"Logits: {logits}\")\nprint(\"=\"*60)\n\n============================================================\nDefinición del Modelo en Pytorch utilizando nn.Module\n============================================================\ntensor([[[[  5.,   5.,  -1.,  -4.],\n          [ -4.,  -7.,  -1.,  -6.],\n          [ -1., -10.,   6.,  -8.],\n          [ -9.,  -8.,  -6.,  -6.]],\n\n         [[ -3.,   5.,   3.,  -6.],\n          [ -3.,  -7.,   3., -13.],\n          [ -5., -12.,   4.,  -7.],\n          [ -9.,  -4.,  -6.,  -5.]]]], grad_fn=&lt;ConvolutionBackward0&gt;)\n============================================================\ny: tensor([[0.]])\n============================================================\nLoss obtenido: 18.0\n============================================================\nLogits: tensor([[18.]], grad_fn=&lt;AddmmBackward0&gt;)\n============================================================"
  },
  {
    "objectID": "tics579/notebooks/CNNs.html#forward-pass-manual",
    "href": "tics579/notebooks/CNNs.html#forward-pass-manual",
    "title": "Generación de los Datos",
    "section": "Forward Pass Manual",
    "text": "Forward Pass Manual\n\ndef calculate_out(X, k_size=(3,3), stride=1, dilation=1, padding=0):\n  kH, kW = k_size\n  N, in_channels, H_in, W_in = X.shape\n  out_H = np.floor((H_in +2*padding-dilation*(kH-1)-1)/stride + 1)\n  out_W = np.floor((W_in +2*padding-dilation*(kW-1)-1)/stride + 1)\n  return int(out_H), int(out_W)\n\nH_out, W_out = calculate_out(X, k_size = (kH,kW))\nprint(\"=\"*60)\nprint(f\"Tamaño resultante post-convolución: {H_out, W_out}\")\nprint(\"=\"*60)\n\n============================================================\nTamaño resultante post-convolución: (4, 4)\n============================================================\n\n\n\nprint(\"=\"*60)\nprint(\"Implementación básica de la Convolución: Muy Ineficiente\")\nprint(\"=\"*60)\nO = torch.zeros((N, C_out, H_out, W_out))\nfor n in range(N):\n    for co in range(C_out):\n        for i in range(H_out):\n            for j in range(W_out):\n                patch = X[n, :, i:i+kH, j:j+kW]       # submatriz de tamaño kH x kW\n                O[n, co, i, j] = (patch * given_w[co]).sum() + given_bias[co]\n\n\nprint(\"O:\", end=\"\")\nprint(O)\nprint(\"=\"*60)\n\n============================================================\nImplementación básica de la Convolución: Muy Ineficiente\n============================================================\nO:tensor([[[[  5.,   5.,  -1.,  -4.],\n          [ -4.,  -7.,  -1.,  -6.],\n          [ -1., -10.,   6.,  -8.],\n          [ -9.,  -8.,  -6.,  -6.]],\n\n         [[ -3.,   5.,   3.,  -6.],\n          [ -3.,  -7.,   3., -13.],\n          [ -5., -12.,   4.,  -7.],\n          [ -9.,  -4.,  -6.,  -5.]]]])\n============================================================\n\n\n\n# im2col: Convierte ventanas deslizantes en columnas\nprint(\"=\"*60)\nprint(\"Implementación Algoritmo im2col: \")\nprint(\"=\"*60)\nX_col = F.unfold(X, kernel_size=(kH, kW))  # (1, 9, 16) (N,kH*kW,n_patches)\nprint(f\"Cada columna es una ventana 3x3 aplanada\")\nprint(f\"Tenemos 16 patches (4x4 posiciones de salida) para una imagen\")\nprint(\"X_col: \", end=\"\")\nprint(X_col)\nprint(\"=\"*60)\nprint(f\"X_col shape: {X_col.shape}\")\nprint(\"=\"*60)\n\n============================================================\nImplementación Algoritmo im2col: \n============================================================\nCada columna es una ventana 3x3 aplanada\nTenemos 16 patches (4x4 posiciones de salida) para una imagen\nX_col: tensor([[[7., 6., 8., 5., 8., 6., 5., 3., 9., 1., 1., 5., 4., 5., 5., 9.],\n         [6., 8., 5., 1., 6., 5., 3., 5., 1., 1., 5., 3., 5., 5., 9., 2.],\n         [8., 5., 1., 3., 5., 3., 5., 5., 1., 5., 3., 5., 5., 9., 2., 6.],\n         [8., 6., 5., 3., 9., 1., 1., 5., 4., 5., 5., 9., 9., 5., 3., 1.],\n         [6., 5., 3., 5., 1., 1., 5., 3., 5., 5., 9., 2., 5., 3., 1., 2.],\n         [5., 3., 5., 5., 1., 5., 3., 5., 5., 9., 2., 6., 3., 1., 2., 2.],\n         [9., 1., 1., 5., 4., 5., 5., 9., 9., 5., 3., 1., 4., 4., 8., 8.],\n         [1., 1., 5., 3., 5., 5., 9., 2., 5., 3., 1., 2., 4., 8., 8., 9.],\n         [1., 5., 3., 5., 5., 9., 2., 6., 3., 1., 2., 2., 8., 8., 9., 8.]]])\n============================================================\nX_col shape: torch.Size([1, 9, 16])\n============================================================\n\n\n\nprint(\"=\"*60)\nprint(\"Implementación de la Convolución utilizando im2col:\")\nprint(\"=\"*60)\n# Reshape de pesos\n\nW_row = given_w.reshape(C_out, -1)  # (2, 9)\nprint(f\"Cada fila es un filtro 3x3 aplanado\")\nprint(f\"W_row shape: {W_row.shape}\")\nprint(\"W_row: \", end=\"\")\nprint(W_row)\nprint(\"=\"*60)\n\n\n# Multiplicación matricial y corregimos dimensiones...\nH_col = W_row @ X_col + given_bias.reshape(-1, 1)  # (1,2,16) # (N, C_out, n_patches)\n_, _, n_patches = H_col.shape\nH = H_col.reshape(N, C_out, H_out, W_out)  # (1, 2, 4, 4)\nprint(f\"H shape: {H.shape}\")\nprint(\"=\"*60)\nprint(\"Corresponde a un imagen de 2 Feature Maps de Salida.\")\nprint(\"Cada Feature Map es de 4x4\")\nprint(\"=\"*60)\nprint(\"H: \", end=\"\")\nprint(H)\nprint(\"=\"*60)\n\n============================================================\nImplementación de la Convolución utilizando im2col:\n============================================================\nCada fila es un filtro 3x3 aplanado\nW_row shape: torch.Size([2, 9])\nW_row: tensor([[ 1.,  1.,  0., -1.,  1., -1.,  0., -1., -1.],\n        [ 1.,  1.,  0., -1.,  1., -1., -1.,  0., -1.]])\n============================================================\nH shape: torch.Size([1, 2, 4, 4])\n============================================================\nCorresponde a un imagen de 2 Feature Maps de Salida.\nCada Feature Map es de 4x4\n============================================================\nH: tensor([[[[  5.,   5.,  -1.,  -4.],\n          [ -4.,  -7.,  -1.,  -6.],\n          [ -1., -10.,   6.,  -8.],\n          [ -9.,  -8.,  -6.,  -6.]],\n\n         [[ -3.,   5.,   3.,  -6.],\n          [ -3.,  -7.,   3., -13.],\n          [ -5., -12.,   4.,  -7.],\n          [ -9.,  -4.,  -6.,  -5.]]]])\n============================================================\n\n\n\nH_pool, W_pool = calculate_out(H, k_size=(2,2),stride=2)\nprint(\"=\"*60)\nprint(f\"Tamaño resultante post-pooling: {H_pool, W_pool}\")\nprint(\"=\"*60)\n\n============================================================\nTamaño resultante post-pooling: (2, 2)\n============================================================\n\n\n\nprint(\"=\"*60)\nprint(\"Forward Pass Pooling usando im2col: \")\nprint(\"=\"*60)\npool_size = 2\n\nh_col = F.unfold(H, kernel_size=pool_size, stride=pool_size)  # (1, 8, 4)\nprint(f\"Shape h_col: {h_col.shape}\")\nprint(\"=\"*60)\nprint(\"h_col: \", end=\"\")\nprint(h_col)\nprint(\"=\"*60)\nh_col_reshaped = h_col.view(N, C_out, pool_size*pool_size, -1)  # (1, 2, 4, 4)\nprint(f\"Shape h_col_reshaped: {h_col_reshaped.shape}\")\nprint(\"=\"*60)\nprint(h_col_reshaped)\nprint(\"=\"*60)\nM_flat, pool_indices = h_col_reshaped.max(dim=2)\nprint(\"=\"*60)\nprint(\"M_flat: \", end=\"\")\nprint(M_flat)\nprint(\"=\"*60)\nM = M_flat.reshape(N, C_out, H_pool, W_pool)\nprint(\"Reconstrucción a Feature Map\")\nprint(\"M: \", end=\"\")\nprint(M)\nprint(\"=\"*60)\n\n============================================================\nForward Pass Pooling usando im2col: \n============================================================\nShape h_col: torch.Size([1, 8, 4])\n============================================================\nh_col: tensor([[[  5.,  -1.,  -1.,   6.],\n         [  5.,  -4., -10.,  -8.],\n         [ -4.,  -1.,  -9.,  -6.],\n         [ -7.,  -6.,  -8.,  -6.],\n         [ -3.,   3.,  -5.,   4.],\n         [  5.,  -6., -12.,  -7.],\n         [ -3.,   3.,  -9.,  -6.],\n         [ -7., -13.,  -4.,  -5.]]])\n============================================================\nShape h_col_reshaped: torch.Size([1, 2, 4, 4])\n============================================================\ntensor([[[[  5.,  -1.,  -1.,   6.],\n          [  5.,  -4., -10.,  -8.],\n          [ -4.,  -1.,  -9.,  -6.],\n          [ -7.,  -6.,  -8.,  -6.]],\n\n         [[ -3.,   3.,  -5.,   4.],\n          [  5.,  -6., -12.,  -7.],\n          [ -3.,   3.,  -9.,  -6.],\n          [ -7., -13.,  -4.,  -5.]]]])\n============================================================\n============================================================\nM_flat: tensor([[[ 5., -1., -1.,  6.],\n         [ 5.,  3., -4.,  4.]]])\n============================================================\nReconstrucción a Feature Map\nM: tensor([[[[ 5., -1.],\n          [-1.,  6.]],\n\n         [[ 5.,  3.],\n          [-4.,  4.]]]])\n============================================================\n\n\n\nprint(\"=\"*60)\nprint(\"Flatten\")\nprint(\"=\"*60)\nf = M.view(N, -1)  # (1, 8)\nprint(f\"Shape post-Flatten: {f.shape}\")\n\n\nprint(\"=\"*60)\nprint(\"Feed Forward\")\nprint(\"=\"*60)\nprint(\"Parámetros: \")\nprint(\"W_fc: \", end=\"\")\nW_fc = torch.ones(8, 1)\nprint(W_fc)\nb_fc = torch.ones(1)\nprint(\"=\"*60)\nprint(\"b_fc: \", end=\"\")\nprint(b_fc)\nZ = f @ W_fc + b_fc\nprint(\"=\"*60)\nprint(\"Logits: \", end=\"\")\nprint(Z)\nprint(\"=\"*60)\n\n\n============================================================\nFlatten\n============================================================\nShape post-Flatten: torch.Size([1, 8])\n============================================================\nFeed Forward\n============================================================\nParámetros: \nW_fc: tensor([[1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.]])\n============================================================\nb_fc: tensor([1.])\n============================================================\nLogits: tensor([[18.]])\n============================================================"
  },
  {
    "objectID": "tics579/notebooks/CNNs.html#backward-pass-manual",
    "href": "tics579/notebooks/CNNs.html#backward-pass-manual",
    "title": "Generación de los Datos",
    "section": "Backward Pass Manual",
    "text": "Backward Pass Manual\n\nprint(\"=\"*60)\nprint(\"Debido a que partimos derivando desde atrás, \\nlas derivadas son muy sencillas y se realizan de forma idéntica a lo visto en clases\")\nprint(\"Sólo nos interesa calcular las derivadas respecto a W_conv que son parámetros que no conocemos...\")\nprint(\"=\"*60)\nprint(\"Derivada del BCEwithLogitLoss: \")\ndZ = torch.sigmoid(Z) - y  # (1, 1)\nprint(\"dZ: \", dZ)\nprint(\"=\"*60)\nprint(\"Derivada hasta f\")\ndf = dZ @ W_fc.T           # (1, 8)\nprint(\"df: \", df)\nprint(\"=\"*60)\nprint(\"El gradiente hasta M es el inverso del Flatten, es decir recobramos la forma original\")\n\ndM = df.reshape(N, C_out, pool_size, pool_size)\nprint(\"dM: \", dM)\nprint(f\"Shape de dM: {dM.shape}\")\nprint(\"Una imagen de 2 canales de tamaño 2x2\")\nprint(\"=\"*60)\n\n============================================================\nDebido a que partimos derivando desde atrás, \nlas derivadas son muy sencillas y se realizan de forma idéntica a lo visto en clases\nSólo nos interesa calcular las derivadas respecto a W_conv que son parámetros que no conocemos...\n============================================================\nDerivada del BCEwithLogitLoss: \ndZ:  tensor([[1.]])\n============================================================\nDerivada hasta f\ndf:  tensor([[1., 1., 1., 1., 1., 1., 1., 1.]])\n============================================================\nEl gradiente hasta M es el inverso del Flatten, es decir recobramos la forma original\ndM:  tensor([[[[1., 1.],\n          [1., 1.]],\n\n         [[1., 1.],\n          [1., 1.]]]])\nShape de dM: torch.Size([1, 2, 2, 2])\nUna imagen de 2 canales de tamaño 2x2\n============================================================\n\n\n\nprint(\"=\"*60)\nprint(\"Gradiente del Pooling hasta h_col\")\ndh_col = torch.zeros_like(h_col_reshaped)\ndh_col.scatter_(2, pool_indices.unsqueeze(2), dM.reshape(N, C_out, 1, -1))\nprint(\"=\"*60)\nprint(\"h_col:\", h_col_reshaped)\nprint(\"=\"*60)\nprint(\"Se puede notar que el gradiente del Max Pooling coloca un 1 en la fila de cada columna en la que se encontró el máximo y cero en otro caso\")\nprint(\"Para poder restaurar esta información fue necesario guardar los índices del Máximo en el Forward Pass..\")\nprint(\"dh_col: \", dh_col)\nprint(\"=\"*60)\n\n============================================================\nGradiente del Pooling hasta h_col\n============================================================\nh_col: tensor([[[[  5.,  -1.,  -1.,   6.],\n          [  5.,  -4., -10.,  -8.],\n          [ -4.,  -1.,  -9.,  -6.],\n          [ -7.,  -6.,  -8.,  -6.]],\n\n         [[ -3.,   3.,  -5.,   4.],\n          [  5.,  -6., -12.,  -7.],\n          [ -3.,   3.,  -9.,  -6.],\n          [ -7., -13.,  -4.,  -5.]]]])\n============================================================\nSe puede notar que el gradiente del Max Pooling coloca un 1 en la fila de cada columna en la que se encontró el máximo y cero en otro caso\nPara poder restaurar esta información fue necesario guardar los índices del Máximo en el Forward Pass..\ndh_col:  tensor([[[[1., 1., 1., 1.],\n          [0., 0., 0., 0.],\n          [0., 0., 0., 0.],\n          [0., 0., 0., 0.]],\n\n         [[0., 1., 0., 1.],\n          [1., 0., 0., 0.],\n          [0., 0., 0., 0.],\n          [0., 0., 1., 0.]]]])\n============================================================\n\n\n\nprint(\"=\"*60)\nprint(\"Gradiente hasta H\")\nprint(\"Debido a que pasamos de h_col a H, es necesario calcular el Gradiente el im2col\")\nprint(\"El gradiente es el Algoritmo inverso: col2im\")\nprint(\"=\"*60)\nprint(\"Primero debemos juntar los canales, que es lo que es pera de resultado el im2col\")\ndh_col_flat = dh_col.reshape(N, C_out * 4, -1)\nprint(dh_col_flat)\nprint(\"=\"*60)\nprint(\"Aplicamos col2im: \")\nprint(\"Acá debemos reconstruir utilizando el Kernel y el Stride utilizado (Los del Pooling)\")\nprint(\"Luego debemos ingresar el tamaño resultante, que sería el de la entrada al Pooling (Salida de la Convolución)\")\ndH = F.fold(dh_col_flat, output_size=(H_out, W_out), kernel_size=2, stride=2)\nprint(\"dH\", dH)\nprint(\"=\"*60)\nprint(f\"Shape dH: {dH.shape}\")\nprint(\"=\"*60)\n\ndH_col = dH.view(N, C_out, -1)  # (N, C_out, num_patches)\n\n============================================================\nGradiente hasta H\nDebido a que pasamos de h_col a H, es necesario calcular el Gradiente el im2col\nEl gradiente es el Algoritmo inverso: col2im\n============================================================\nPrimero debemos juntar los canales, que es lo que es pera de resultado el im2col\ntensor([[[1., 1., 1., 1.],\n         [0., 0., 0., 0.],\n         [0., 0., 0., 0.],\n         [0., 0., 0., 0.],\n         [0., 1., 0., 1.],\n         [1., 0., 0., 0.],\n         [0., 0., 0., 0.],\n         [0., 0., 1., 0.]]])\n============================================================\nAplicamos col2im: \nAcá debemos reconstruir utilizando el Kernel y el Stride utilizado (Los del Pooling)\nLuego debemos ingresar el tamaño resultante, que sería el de la entrada al Pooling (Salida de la Convolución)\ndH tensor([[[[1., 0., 1., 0.],\n          [0., 0., 0., 0.],\n          [1., 0., 1., 0.],\n          [0., 0., 0., 0.]],\n\n         [[0., 1., 1., 0.],\n          [0., 0., 0., 0.],\n          [0., 0., 1., 0.],\n          [0., 1., 0., 0.]]]])\n============================================================\nShape dH: torch.Size([1, 2, 4, 4])\n============================================================\n\n\n\nprint(\"=\"*60)\nprint(\"El gradiente de W_conv es similar al de una Linear Layer pero con un truquito de shapes para poder hacer multiplicaciones válidas...\")\nprint(\"=\"*60)\ndH_reshaped = dH.permute(1,0,2,3).reshape(C_out, -1) # (C_out, N*n_patches)\nX_reshaped = X_col.reshape(C_in*kH*kW,-1) # (C_in*kH*kW, N*n_patches)\nprint(\"=\"*60)\ndW_conv_flat = dH_reshaped @ X_reshaped.T  # (C_out, C_in*kH*kW)\nprint(\"dW_conv_flat: \", dW_conv_flat)\nprint(\"=\"*60)\ndW_conv = dW_conv_flat.reshape(C_out, C_in, kH, kW)\nprint(\"dW_conv: \", dW_conv)\nprint(\"=\"*60)\n\n============================================================\nEl gradiente de W_conv es similar al de una Linear Layer pero con un truquito de shapes para poder hacer multiplicaciones válidas...\n============================================================\n============================================================\ndW_conv_flat:  tensor([[25., 17., 13., 22., 23., 17., 22., 12.,  9.],\n        [20., 23., 18., 21., 20., 11.,  9., 15., 18.]])\n============================================================\ndW_conv:  tensor([[[[25., 17., 13.],\n          [22., 23., 17.],\n          [22., 12.,  9.]]],\n\n\n        [[[20., 23., 18.],\n          [21., 20., 11.],\n          [ 9., 15., 18.]]]])\n============================================================\n\n\n\nprint(\"=\"*60)\nprint(\"El Gradiente del Bias: \")\nprint(\"=\"*60)\ndBias_conv = torch.ones(n_patches)@dH_col.transpose(-1,-2)\nprint(\"dbias_conv: \", dBias_conv)\n\n============================================================\nEl Gradiente del Bias: \n============================================================\ndbias_conv:  tensor([[4., 4.]])"
  },
  {
    "objectID": "tics579/notebooks/CNNs.html#gradientes-calculados-con-pytorch-nn.module",
    "href": "tics579/notebooks/CNNs.html#gradientes-calculados-con-pytorch-nn.module",
    "title": "Generación de los Datos",
    "section": "Gradientes calculados con Pytorch nn.Module",
    "text": "Gradientes calculados con Pytorch nn.Module\n\nloss.backward()\nprint(\"=\"*60)\nprint(\"Gradientes Calculados utilizando nn.Module\")\nprint(\"=\"*60)\nprint(\"dW_conv_pytorch: \",  model.conv.weight.grad)\nprint(\"=\"*60)\nprint(\"dbias_conv_pytorch: \",  model.conv.bias.grad)\nprint(\"=\"*60)\n\n============================================================\nGradientes Calculados utilizando nn.Module\n============================================================\ndW_conv_pytorch:  tensor([[[[25., 17., 13.],\n          [22., 23., 17.],\n          [22., 12.,  9.]]],\n\n\n        [[[20., 23., 18.],\n          [21., 20., 11.],\n          [ 9., 15., 18.]]]])\n============================================================\ndbias_conv_pytorch:  tensor([4., 4.])\n============================================================"
  },
  {
    "objectID": "tics579/notebooks/reg_log.html",
    "href": "tics579/notebooks/reg_log.html",
    "title": "Implementación en Pytorch usando nn.Module",
    "section": "",
    "text": "from sklearn.datasets import load_breast_cancer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nimport numpy as np\nimport torch\nimport torch.nn as nn\n\nSEED = 42\ntorch.manual_seed(SEED)\n\ndata = load_breast_cancer()\nX = data[\"data\"]\ny = data[\"target\"]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = SEED)\n\n\ny\n\narray([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n       0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n       1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n       1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n       0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n       1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n       0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n       1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n       1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n       0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n       1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n       1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n       1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1])\n\n\n\nalpha = 3e-4\n\n\nX_t = torch.from_numpy(X_train).float()\ny_t = torch.from_numpy(y_train).float()\nX_te = torch.from_numpy(X_test).float()\ny_te = torch.from_numpy(y_test).float()\n\nm = X_t.shape[0]\nn = X_t.shape[1]\ntheta = torch.rand(30).float()\n\n\ntheta\n\ntensor([0.7047, 0.2545, 0.3994, 0.2122, 0.4089, 0.1481, 0.1733, 0.6659, 0.3514,\n        0.8087, 0.3396, 0.1332, 0.4118, 0.2576, 0.3470, 0.0240, 0.7797, 0.1519,\n        0.7513, 0.7269, 0.8572, 0.1165, 0.8596, 0.2636, 0.6855, 0.9696, 0.4295,\n        0.4961, 0.3849, 0.0825])\n\n\n\n## Parámetros Iniciales\ntheta_init = theta\ntheta_init\n\ntensor([0.8823, 0.9150, 0.3829, 0.9593, 0.3904, 0.6009, 0.2566, 0.7936, 0.9408,\n        0.1332, 0.9346, 0.5936, 0.8694, 0.5677, 0.7411, 0.4294, 0.8854, 0.5739,\n        0.2666, 0.6274, 0.2696, 0.4414, 0.2969, 0.8317, 0.1053, 0.2695, 0.3588,\n        0.1994, 0.5472, 0.0062])\n\n\n\n## Vamos a entrenar la Regresión Logística por 1000 epochs\n\nepochs = 1000\nfor e in range(epochs):\n  theta = theta - alpha/m * X_t.T @ (torch.sigmoid(X_t @ theta) - y_t)\ntheta\n\ntensor([ 0.9026,  0.8531,  0.4552,  0.1514,  0.3904,  0.5996,  0.2544,  0.7928,\n         0.9407,  0.1332,  0.9315,  0.5864,  0.8410,  0.0941,  0.7411,  0.4290,\n         0.8849,  0.5738,  0.2664,  0.6274,  0.2897,  0.3517,  0.3309, -0.2771,\n         0.1051,  0.2656,  0.3538,  0.1980,  0.5466,  0.0059])\n\n\n\n## Transformar probabilidades a clases\ndef predict(X_te, theta):\n  p = torch.sigmoid(X_te @ theta).numpy()\n  y_pred = np.where(p &gt;=0.5, 1, 0)\n  return y_pred\n\ny_pred = predict(X_te, theta)\nprint(\"Accuracy Score: \", accuracy_score(y_test, y_pred))\n\nAccuracy Score:  0.9300699300699301\n\n\n\nclass LogReg(nn.Module):\n  def __init__(self,n):\n    super().__init__()\n    self.fc = nn.Linear(n, 1, bias = False)\n    self.fc.weight.data = theta_init.reshape(1,-1)\n\n  def forward(self, x):\n    x = self.fc(x)\n    return x\n\nmodel = LogReg(n)\noptimizer = torch.optim.SGD(model.parameters(), lr = alpha)\ncriterion = nn.BCEWithLogitsLoss()\n\nloss_history = []\nfor e in range(epochs):\n  model.train()\n  optimizer.zero_grad()\n  logits = model(X_t)\n  loss = criterion(logits, y_t.unsqueeze(-1))\n  loss.backward()\n  optimizer.step()\n  loss_history.append(loss.item())\n\ndef predict_pytorch(X_te):\n  ## Se debe colocar el modelo en Modo Evaluación\n  model.eval()\n  with torch.no_grad():\n    p = model(X_te).detach().numpy()\n  y_pred = np.where(p &gt;=0.5, 1, 0)\n  return y_pred\n\ny_pred = predict_pytorch(X_te)\nprint(\"Accuracy Score: \", accuracy_score(y_test, y_pred))\n\nAccuracy Score:  0.9300699300699301\n\n\n\n## Los pesos obtenidos por Pytorch son idénticos a los obtenidos de manera teórica.\nmodel.fc.weight.data\n\ntensor([[ 0.9028,  0.8534,  0.4561,  0.1524,  0.3904,  0.5996,  0.2544,  0.7928,\n          0.9407,  0.1332,  0.9315,  0.5864,  0.8410,  0.0932,  0.7411,  0.4290,\n          0.8849,  0.5738,  0.2664,  0.6274,  0.2898,  0.3521,  0.3317, -0.2781,\n          0.1051,  0.2656,  0.3538,  0.1980,  0.5466,  0.0060]])\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "tics579/notebooks/legacy/control-5.html",
    "href": "tics579/notebooks/legacy/control-5.html",
    "title": "Control 5",
    "section": "",
    "text": "¿Qué significa desenrrollar (unrollment) la RNN?\n¿Qué es el problema de Vanishing/Exploding Gradients?\n¿Cuáles son las 4 Gates de una LSTM?\n¿Cuál es la diferencia entre Cell State y Hidden State?\n¿Qué es una RNN bidireccional?\n¿Qué es la nn.Embedding en Pytorch y por qué es necesarios en tareas de Texto?\n\n\n\n\n Back to top"
  },
  {
    "objectID": "tics579/notebooks/legacy/transformers.html",
    "href": "tics579/notebooks/legacy/transformers.html",
    "title": "Input Example",
    "section": "",
    "text": "import torch\nimport torch.nn as nn\nimport math\n\nSEED = 10\ntorch.manual_seed(SEED)\ntorch.cuda.manual_seed(SEED)\nx = torch.randint(0, 100, (1, 6))\nx\n\ntensor([[37,  5, 32, 67, 32,  5]])"
  },
  {
    "objectID": "tics579/notebooks/legacy/transformers.html#embeddings",
    "href": "tics579/notebooks/legacy/transformers.html#embeddings",
    "title": "Input Example",
    "section": "Embeddings",
    "text": "Embeddings\n\nclass InputEmbeddings(nn.Module):\n    def __init__(self, d_model, vocab_size):\n        super().__init__()\n        self.d_model = d_model\n        self.vocab_size = vocab_size\n        self.embedding = nn.Embedding(vocab_size, d_model)\n\n    def forward(self, x):\n        return self.embedding(x) * math.sqrt(self.d_model)\n\n\nembedding_encoder = InputEmbeddings(d_model=4, vocab_size=100)\noutput = embedding_encoder(x)\noutput\n\ntensor([[[-1.8799, -0.8493,  3.3999,  1.4201],\n         [-0.1888,  0.1051,  0.4773, -3.1130],\n         [ 1.2626,  1.2161, -2.1373, -4.4780],\n         [-1.1958,  3.4485, -0.8264, -0.4976],\n         [ 1.2626,  1.2161, -2.1373, -4.4780],\n         [-0.1888,  0.1051,  0.4773, -3.1130]]], grad_fn=&lt;MulBackward0&gt;)"
  },
  {
    "objectID": "tics579/notebooks/legacy/transformers.html#positional-encoding",
    "href": "tics579/notebooks/legacy/transformers.html#positional-encoding",
    "title": "Input Example",
    "section": "Positional Encoding",
    "text": "Positional Encoding\n\nclass PositionalEncoding(nn.Module):\n    def __init__(self, d_model, seq_len, dropout):\n        super().__init__()\n        self.d_model = d_model\n        self.seq_len = seq_len\n        self.dropout = nn.Dropout(p=dropout)\n\n        ## (L,d_model)\n        pe = torch.zeros(seq_len, d_model)\n        ## (L, 1)\n        position = torch.arange(0, seq_len, dtype=torch.float).unsqueeze(1)\n        div_term = torch.exp(\n            torch.arange(0, d_model, 2, dtype=torch.float)\n            * (-math.log(10000.0) / d_model)\n        )\n        pe[:, 0::2] = torch.sin(position * div_term)\n        pe[:, 1::2] = torch.cos(position * div_term)\n\n        # (N, L, d_model)\n        pe = pe.unsqueeze(0)\n\n        ## Register Buffer\n        self.register_buffer(\"pe\", pe)\n\n    def forward(self, x):\n        ## x = x + self.pe[:, : x.shape[1], :].requires_grad_(False)\n        x = x + self.pe\n        return self.dropout(x)\n\n\npe_encoder = PositionalEncoding(d_model=4, seq_len=6, dropout=0.1)\noutput_pe = pe_encoder(output)\noutput_pe\n\ntensor([[[-2.0888,  0.1674,  3.7777,  0.0000],\n         [ 0.7252,  0.7172,  0.5414, -2.3479],\n         [ 0.0000,  0.8888, -0.0000, -3.8646],\n         [-1.1719,  2.7317, -0.8849,  0.5577],\n         [ 0.5620,  0.6249, -2.3304, -3.8653],\n         [-1.2753,  0.4320,  0.5858, -2.3492]]], grad_fn=&lt;MulBackward0&gt;)"
  },
  {
    "objectID": "tics579/notebooks/legacy/transformers.html#multihead-attention",
    "href": "tics579/notebooks/legacy/transformers.html#multihead-attention",
    "title": "Input Example",
    "section": "Multihead Attention",
    "text": "Multihead Attention\n\nclass MultiHeadAttentionBlock(nn.Module):\n    def __init__(self, d_model, h, dropout):\n        super().__init__()\n        assert d_model % h == 0, \"d_model is not divisible by h\"\n        self.d_k = d_model // h\n        self.h = h\n        self.d_model = d_model\n        ## Tensores empaquetados\n        self.W_q = nn.Linear(d_model, self.d_k * h)\n        self.W_k = nn.Linear(d_model, self.d_k * h)\n        self.W_v = nn.Linear(d_model, self.d_k * h)\n\n        self.w_o = nn.Linear(self.d_k * h, d_model)\n        self.dropout = nn.Dropout(p=dropout)\n\n    @staticmethod\n    def scale_dot_prod(Q, K, V, mask=None, dropout=None):\n        d_k = Q.shape[-1]\n\n        # (N, h, L, L)\n        attention_scores = Q @ K.transpose(-2, -1) / math.sqrt(d_k)\n        if mask is not None:\n            attention_scores.masked_fill_(mask == 0, -1e9)\n\n        attention_scores = attention_scores.softmax(dim=-1)\n        if dropout is not None:\n            attention_scores = dropout(attention_scores)\n\n        ## (N, h, L, d_v)\n        return attention_scores @ V, attention_scores\n\n    def forward(self, q, k, v, mask=None):\n        ## (N, L, d_k*h)\n        Q = self.W_q(q)\n        K = self.W_k(k)\n        ## (N, L, d_v*h)\n        V = self.W_v(v)\n\n        # (N, L, h, d_k) --&gt; (N,h,L,d_k)\n        Q = Q.view(q.shape[0], -1, self.h, self.d_k).transpose(1, 2)\n        # (N, L, h, d_k) --&gt; (N,h,L,d_k)\n        K = K.view(k.shape[0], -1, self.h, self.d_k).transpose(1, 2)\n        # (N, L, h, d_k) --&gt; (N,h,L,d_k)\n        V = V.view(v.shape[0], -1, self.h, self.d_k).transpose(1, 2)\n\n        x, self.attention_scores = self.scale_dot_prod(\n            Q, K, V, mask, self.dropout\n        )\n        x = x.transpose(1, 2).reshape(q.shape[0], -1, self.h * self.d_k)\n        return self.w_o(x)\n\n\nmh_attention = MultiHeadAttentionBlock(d_model=4, h=2, dropout=0.1)\noutput_mh = mh_attention(output, output, output)\noutput_mh\n\ntensor([[[-0.0834, -0.5228,  0.0203, -0.0140],\n         [ 0.0389, -0.4723, -0.1963, -0.0514],\n         [ 0.1011, -0.5052, -0.5318, -0.1051],\n         [-0.0349, -0.4584, -0.4303, -0.1006],\n         [ 0.1187, -0.5545, -0.5845, -0.1033],\n         [ 0.0778, -0.5032, -0.2475, -0.0361]]], grad_fn=&lt;ViewBackward0&gt;)"
  },
  {
    "objectID": "tics579/notebooks/legacy/transformers.html#addnorm",
    "href": "tics579/notebooks/legacy/transformers.html#addnorm",
    "title": "Input Example",
    "section": "Add&Norm",
    "text": "Add&Norm\n\nclass LayerNormalization(nn.Module):\n    def __init__(self, eps=1e-6):\n        super().__init__()\n        self.eps = eps\n        ## Multiplicative\n        self.alpha = nn.Parameter(torch.ones(1))\n        ## Additive\n        self.bias = nn.Parameter(torch.zeros(1))\n\n    def forward(self, x):\n        mean = x.mean(dim=-1, keepdim=True)\n        var = x.var(dim=-1, unbiased=False, keepdim=True)\n        return (x - mean) / torch.sqrt(\n            var + self.eps\n        ) * self.alpha + self.bias\n\n\nclass ResidualConnection(nn.Module):\n    def __init__(self, dropout):\n        super().__init__()\n        self.dropout = nn.Dropout(p=dropout)\n        self.norm = LayerNormalization()\n\n    def forward(self, x, sublayer):\n        output = sublayer(x)\n        output = self.dropout(output)\n        return self.norm(x + output)\n\n\nresidual_mh = ResidualConnection(dropout=0.1)\nmh_attention = MultiHeadAttentionBlock(d_model=4, h=2, dropout=0.1)\noutput = residual_mh(output_pe, lambda x: mh_attention(x, x, x))\noutput\n\ntensor([[[-0.9388, -0.2235,  1.6751, -0.5128],\n         [ 0.5153,  0.6049,  0.6106, -1.7308],\n         [ 0.5091,  0.6443,  0.5766, -1.7301],\n         [-1.0167,  1.4599, -0.8285,  0.3853],\n         [ 1.0495,  0.7769, -0.3532, -1.4732],\n         [-0.1209,  0.5691,  1.1103, -1.5585]]], grad_fn=&lt;AddBackward0&gt;)"
  },
  {
    "objectID": "tics579/notebooks/legacy/transformers.html#feed-forward",
    "href": "tics579/notebooks/legacy/transformers.html#feed-forward",
    "title": "Input Example",
    "section": "Feed Forward",
    "text": "Feed Forward\n\nclass FeedForward(nn.Module):\n    def __init__(self, d_model, d_ff):\n        super().__init__()\n        self.w1 = nn.Linear(d_model, d_ff)\n        self.w2 = nn.Linear(d_ff, d_model)\n        self.relu = nn.ReLU(inplace=True)\n\n    def forward(self, x):\n        x = self.w1(x)\n        x = self.relu(x)\n        x = self.w2(x)\n        return x\n\n\nresidual_ffn = ResidualConnection(dropout=0.1)\nffn = FeedForward(d_model=4, d_ff=8)\noutput = residual_ffn(output, ffn)\noutput\n\ntensor([[[-1.2459,  0.4804,  1.3635, -0.5981],\n         [ 0.1829,  0.9943,  0.4803, -1.6575],\n         [ 0.1813,  1.0141,  0.4568, -1.6523],\n         [-1.3174,  1.4358, -0.3721,  0.2538],\n         [ 0.8782,  0.8883, -0.2200, -1.5464],\n         [-0.4689,  1.0912,  0.7833, -1.4056]]], grad_fn=&lt;AddBackward0&gt;)"
  },
  {
    "objectID": "tics579/notebooks/legacy/transformers.html#encoder",
    "href": "tics579/notebooks/legacy/transformers.html#encoder",
    "title": "Input Example",
    "section": "Encoder",
    "text": "Encoder\n\nclass EncoderBlock(nn.Module):\n    def __init__(self, d_model, d_ff, h, dropout):\n        super().__init__()\n        self.mh_attention = MultiHeadAttentionBlock(d_model, h, dropout)\n\n        self.ffn = FeedForward(d_model, d_ff)\n        self.residuals = nn.ModuleDict(\n            dict(\n                mh=ResidualConnection(dropout),\n                ffn=ResidualConnection(dropout),\n            )\n        )\n\n    def forward(self, x):\n        x = self.residuals[\"mh\"](x, lambda x: self.mh_attention(x, x, x))\n        x = self.residuals[\"ffn\"](x, self.ffn)\n        return x\n\n\nencoder = EncoderBlock(d_model=4, d_ff=8, h=2, dropout=0.1)\nencoder(output_pe)\n\ntensor([[[-1.4794, -0.3560,  0.9296,  0.9059],\n         [ 0.9185,  0.6873,  0.0322, -1.6380],\n         [ 0.9489,  0.8417, -0.2676, -1.5230],\n         [-0.6131,  1.1944, -1.2978,  0.7165],\n         [ 1.2573,  0.6877, -0.8072, -1.1378],\n         [-0.3268,  1.6067, -0.1436, -1.1363]]], grad_fn=&lt;AddBackward0&gt;)\n\n\n\nclass TransformerEncoder(nn.Module):\n    def __init__(self, N, d_model, d_ff, h, dropout):\n        super().__init__()\n        self.d_model = d_model\n        self.d_ff = d_ff\n        self.h = h\n        self.dropout = dropout\n        self.encoders = nn.ModuleList(\n            [\n                EncoderBlock(self.d_model, self.d_ff, self.h, self.dropout)\n                for _ in range(N)\n            ]\n        )\n\n    def forward(self, x):\n        for encoder in self.encoders:\n            x = encoder(x)\n        return x\n\n\ntransformer_encoder = TransformerEncoder(\n    N=6, d_model=4, d_ff=8, h=2, dropout=0.1\n)\nencoder_output = transformer_encoder(output_pe)\nencoder_output\n\ntensor([[[-1.1471, -0.7726,  1.3095,  0.6102],\n         [ 0.8043, -1.5599,  0.9410, -0.1854],\n         [ 0.7972, -1.3047,  1.1294, -0.6219],\n         [-1.2670,  0.3383, -0.4971,  1.4258],\n         [ 1.5233,  0.1592, -1.1868, -0.4956],\n         [-0.3347, -1.1785,  1.5795, -0.0662]]], grad_fn=&lt;AddBackward0&gt;)"
  },
  {
    "objectID": "tics579/notebooks/legacy/transformers.html#decoder",
    "href": "tics579/notebooks/legacy/transformers.html#decoder",
    "title": "Input Example",
    "section": "Decoder",
    "text": "Decoder\n\nx_decoder = torch.randint(0, 200, (2, 6))\nembedding_decoder = InputEmbeddings(d_model=4, vocab_size=200)\noutput_decoder = embedding_decoder(x_decoder)\n\npe_decoder = PositionalEncoding(d_model=4, seq_len=6, dropout=0.1)\noutput_pe_decoder = pe_decoder(output_decoder)\noutput_pe_decoder\n\ntensor([[[ 1.4902, -0.1060, -0.2673,  0.9572],\n         [ 0.0000, -1.3015,  3.5659, -0.9811],\n         [ 1.9236, -4.7471,  1.0052, -0.0000],\n         [-1.0813,  1.5492, -0.6965,  2.6818],\n         [ 0.9349,  2.8193,  0.6835,  5.1822],\n         [-0.1522, -3.9696,  1.0385, -1.7455]],\n\n        [[-0.0000, -1.7481, -0.6793,  2.1605],\n         [-1.4601, -2.3530, -0.7971,  0.4837],\n         [-1.2516,  0.9073, -2.5760, -1.4898],\n         [ 3.9898, -2.8120, -0.0000, -0.0000],\n         [-2.0904,  3.8685,  0.0390,  1.1420],\n         [-2.1899, -2.4715,  0.2579,  1.6673]]], grad_fn=&lt;MulBackward0&gt;)\n\n\n\nclass DecoderBlock(nn.Module):\n    def __init__(self, d_model, d_ff, h, dropout):\n        super().__init__()\n        self.causal_mh_attention = MultiHeadAttentionBlock(\n            d_model, h, dropout\n        )\n        self.cross_attention = MultiHeadAttentionBlock(d_model, h, dropout)\n        self.ffn = FeedForward(d_model, d_ff)\n        self.residuals = nn.ModuleDict(\n            dict(\n                causal=ResidualConnection(dropout),\n                cross=ResidualConnection(dropout),\n                ffn=ResidualConnection(dropout),\n            )\n        )\n\n    def forward(self, x, encoder_output, src_mask=None, tgt_mask=None):\n        x = self.residuals[\"causal\"](\n            x, lambda x: self.causal_mh_attention(x, x, x, tgt_mask)\n        )\n        x = self.residuals[\"cross\"](\n            x,\n            lambda x: self.cross_attention(\n                x, encoder_output, encoder_output, src_mask\n            ),\n        )\n        x = self.residuals[\"ffn\"](x, self.ffn)\n        return x\n\n\nclass TransformerDecoder(nn.Module):\n    def __init__(self, N, d_model, d_ff, h, dropout):\n        super().__init__()\n        self.layers = N\n        self.decoders = nn.ModuleList(\n            [DecoderBlock(d_model, d_ff, h, dropout) for _ in range(N)]\n        )\n\n    def forward(self, x, encoder_output, src_mask=None, tgt_mask=None):\n        for decoder in self.decoders:\n            x = decoder(x, encoder_output, src_mask, tgt_mask)\n\n        return x\n\n\ntransformer_decoder = TransformerDecoder(\n    N=6, d_model=4, d_ff=8, h=2, dropout=0.1\n)\ndecoder_output = transformer_decoder(output_pe_decoder, encoder_output)\ndecoder_output\n\ntensor([[[ 0.2385,  1.3848, -0.2166, -1.4066],\n         [-0.2838,  0.8749,  0.9249, -1.5160],\n         [ 1.2895, -0.1632,  0.3523, -1.4786],\n         [-0.9994,  1.6398, -0.5515, -0.0889],\n         [-0.1921,  1.5629, -0.1464, -1.2244],\n         [ 1.0752, -0.8200,  0.9065, -1.1617]],\n\n        [[ 0.1356,  0.0096, -1.4816,  1.3365],\n         [-1.2769,  0.2926,  1.4407, -0.4565],\n         [-0.6868,  1.6583, -0.0942, -0.8773],\n         [ 0.7595,  1.1732, -0.6672, -1.2655],\n         [-0.8131,  1.6748, -0.1457, -0.7160],\n         [-1.2560,  0.6754,  1.2384, -0.6578]]], grad_fn=&lt;AddBackward0&gt;)"
  },
  {
    "objectID": "tics579/notebooks/legacy/transformers.html#projection-layer",
    "href": "tics579/notebooks/legacy/transformers.html#projection-layer",
    "title": "Input Example",
    "section": "Projection Layer",
    "text": "Projection Layer\n\nclass ProjectionLayer(nn.Module):\n    def __init__(self, d_model, vocab_size):\n        super().__init__()\n        self.linear_proj = nn.Linear(d_model, vocab_size)\n\n    def forward(self, x):\n        x = self.linear_proj(x)\n        ## En general esto no se hace ya que el Loss puede incluir el Softmax\n        ## (batch, vocab_size)\n        return x.softmax(dim=-1)\n\n\nproj_layer = ProjectionLayer(d_model=4, vocab_size=200)\nlogits = proj_layer(decoder_output)\nlogits.shape\n\ntorch.Size([2, 6, 200])\n\n\n\n## Secuencias Predichas\ntorch.argmax(logits, dim=-1)\n\ntensor([[ 21, 188,  33, 180,  21,  27],\n        [  9,  80, 188,  33, 188,  80]])"
  },
  {
    "objectID": "tics579/notebooks/legacy/CNN-pytorch.html",
    "href": "tics579/notebooks/legacy/CNN-pytorch.html",
    "title": "Clases UAI",
    "section": "",
    "text": "import torch\nimport torch.nn as nn\nfrom torchinfo import summary\n\nSEED = 10\n\ntorch.manual_seed(SEED)\ntorch.cuda.manual_seed(SEED)\n\n\nfrom sklearn.datasets import fetch_openml\n\ndf, target = fetch_openml(\"mnist_784\", return_X_y=True)\nprint(f\"Shape X: {df.shape}\")\nprint(f\"Shape y: {target.shape}\")\n\nShape X: (70000, 784)\nShape y: (70000,)\n\n\n\ndf\n\n\n\n\n\n\n\n\npixel1\npixel2\npixel3\npixel4\npixel5\npixel6\npixel7\npixel8\npixel9\npixel10\n...\npixel775\npixel776\npixel777\npixel778\npixel779\npixel780\npixel781\npixel782\npixel783\npixel784\n\n\n\n\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n2\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n3\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n4\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n69995\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n69996\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n69997\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n69998\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n69999\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n\n\n70000 rows × 784 columns\n\n\n\n\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\n\nX_train, X_test, y_train, y_test = train_test_split(\n    df, target, test_size=0.25, random_state=SEED\n)\n\n\ntorch.randn(100).view(10, 10).shape\n\ntorch.Size([10, 10])\n\n\n\nfrom torch.utils.data import DataLoader, Dataset\n\n\nclass MNIST(Dataset):\n\n    def __init__(self, X, y):\n\n        self.X = X.to_numpy()\n        self.y = y.values\n\n    def __len__(self):\n        return len(self.X)\n\n    def __getitem__(self, idx):\n        return dict(\n            X=torch.tensor(self.X[idx], dtype=torch.float32)\n            .view(28, 28)\n            .unsqueeze(0),\n            y=torch.tensor(int(self.y[idx]), dtype=torch.long),\n        )\n\n\ntrain_set = MNIST(X_train, y_train)\ntest_set = MNIST(X_test, y_test)\n\n\ntrain_set[0][\"X\"].shape\n\ntorch.Size([1, 28, 28])\n\n\n\ndef plot_number(X, y, tensor=True):\n\n    if tensor:\n        X = X.numpy().squeeze(0)\n        y = y.item()\n\n    plt.imshow(X, cmap=\"gray\")\n    plt.title(f\"Label: {y:.0f}\")\n    plt.show()\n\n\nidx = torch.randint(0, len(train_set), (1,)).item()\nplot_number(train_set[idx][\"X\"], train_set[idx][\"y\"])\n\n\n\n\n\n\n\n\n\ntrain_set[0][\"X\"].shape, train_set[0][\"y\"].shape\n\n(torch.Size([1, 28, 28]), torch.Size([]))\n\n\n\nclass CNN(nn.Module):\n    def __init__(self, in_channels=1, n_outputs=10, ks=3):\n        super().__init__()\n        self.conv1 = self.CNN_block(in_channels, 64, k=ks)\n        self.conv2 = self.CNN_block(64, 32, k=ks)\n        self.flatten = nn.Flatten()\n        # self.fc1 = nn.LazyLinear(16)\n        self.fc1 = nn.Linear(32 * 5 * 5, 16)  # filtros x tamaño\n        self.fc2 = nn.Linear(16, n_outputs)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.conv2(x)\n        x = self.flatten(x)\n        x = self.fc1(x)\n        x = self.fc2(x)\n        return x\n\n    @staticmethod\n    def CNN_block(c_in, c_out, k=3, p=0, s=1, pk=2, ps=2):\n        return nn.Sequential(\n            nn.Conv2d(\n                in_channels=c_in,\n                out_channels=c_out,\n                kernel_size=k,\n                padding=p,\n                stride=s,\n            ),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=pk, stride=ps),\n        )\n\n\nmodel = CNN(in_channels=1, n_outputs=10)\nsummary(model, input_size=(1, 1, 28, 28))\n\n==========================================================================================\nLayer (type:depth-idx)                   Output Shape              Param #\n==========================================================================================\nCNN                                      [1, 10]                   --\n├─Sequential: 1-1                        [1, 64, 13, 13]           --\n│    └─Conv2d: 2-1                       [1, 64, 26, 26]           640\n│    └─ReLU: 2-2                         [1, 64, 26, 26]           --\n│    └─MaxPool2d: 2-3                    [1, 64, 13, 13]           --\n├─Sequential: 1-2                        [1, 32, 5, 5]             --\n│    └─Conv2d: 2-4                       [1, 32, 11, 11]           18,464\n│    └─ReLU: 2-5                         [1, 32, 11, 11]           --\n│    └─MaxPool2d: 2-6                    [1, 32, 5, 5]             --\n├─Flatten: 1-3                           [1, 800]                  --\n├─Linear: 1-4                            [1, 16]                   12,816\n├─Linear: 1-5                            [1, 10]                   170\n==========================================================================================\nTotal params: 32,090\nTrainable params: 32,090\nNon-trainable params: 0\nTotal mult-adds (Units.MEGABYTES): 2.68\n==========================================================================================\nInput size (MB): 0.00\nForward/backward pass size (MB): 0.38\nParams size (MB): 0.13\nEstimated Total Size (MB): 0.51\n==========================================================================================\n\n\n\nimport torchmetrics\nimport numpy as np\nimport time\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n# device = torch.device(\"cpu\")\nprint(f\"Training in {device}\")\nmodel = CNN(in_channels=1, n_outputs=10).to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n\nEPOCHS = 100\n\ntrain_dataloader = DataLoader(\n    train_set,\n    batch_size=1024,\n    shuffle=True,\n    pin_memory=True,\n    num_workers=10,\n    drop_last=True,\n)\ntest_dataloader = DataLoader(\n    test_set, batch_size=32, shuffle=False, pin_memory=True, num_workers=10\n)\n\ntrain_metric = torchmetrics.Recall(task=\"multiclass\", num_classes=10).to(\n    device\n)\ntest_metric = torchmetrics.Recall(task=\"multiclass\", num_classes=10).to(\n    device\n)\ntrain_losses = []\ntest_losses = []\n\nfor e in range(EPOCHS):\n    start_time = time.time()\n    train_batch_losses = []\n    test_batch_losses = []\n    for batch in train_dataloader:\n        X, y = batch[\"X\"].to(device), batch[\"y\"].to(device)\n\n        optimizer.zero_grad()\n        y_pred = model(X)\n        loss = criterion(y_pred, y)\n        loss.backward()\n        optimizer.step()\n        tm = train_metric(y_pred, y)\n        train_batch_losses.append(loss.item())\n\n    tm = train_metric.compute()\n    train_epoch_loss = np.mean(train_batch_losses)\n\n    with torch.no_grad():\n        for batch in test_dataloader:\n            X, y = batch[\"X\"].to(device), batch[\"y\"].to(device)\n            y_pred = model(X)\n            loss = criterion(y_pred, y)\n            tst_m = test_metric(y_pred, y)\n            test_batch_losses.append(loss.item())\n    tst_m = test_metric.compute()\n    test_epoch_loss = np.mean(test_batch_losses)\n    end_time = time.time()\n\n    train_losses.append(train_epoch_loss)\n    test_losses.append(test_epoch_loss)\n\n    epoch_time = end_time - start_time\n    ## Logging\n    print(\n        f\"Epoch: {e+1}- time: {epoch_time:.2f} - Train Loss: {train_epoch_loss:.4f} - Test Loss: {test_epoch_loss:.4f}- Train Recall: {tm:.4f} - Test Recall: {tst_m:.4f}\"\n    )\n\nTraining in cuda\nEpoch: 1- time: 2.36 - Train Loss: 2.5542 - Test Loss: 0.5054- Train Recall: 0.6231 - Test Recall: 0.8648\nEpoch: 2- time: 2.33 - Train Loss: 0.3456 - Test Loss: 0.2863- Train Recall: 0.7620 - Test Recall: 0.8933\nEpoch: 3- time: 2.29 - Train Loss: 0.2156 - Test Loss: 0.2080- Train Recall: 0.8205 - Test Recall: 0.9091\nEpoch: 4- time: 2.33 - Train Loss: 0.1617 - Test Loss: 0.1729- Train Recall: 0.8534 - Test Recall: 0.9195\nEpoch: 5- time: 2.36 - Train Loss: 0.1331 - Test Loss: 0.1467- Train Recall: 0.8748 - Test Recall: 0.9270\nEpoch: 6- time: 2.39 - Train Loss: 0.1108 - Test Loss: 0.1281- Train Recall: 0.8900 - Test Recall: 0.9328\nEpoch: 7- time: 2.36 - Train Loss: 0.0968 - Test Loss: 0.1171- Train Recall: 0.9014 - Test Recall: 0.9375\nEpoch: 8- time: 2.33 - Train Loss: 0.0863 - Test Loss: 0.1056- Train Recall: 0.9104 - Test Recall: 0.9413\nEpoch: 9- time: 2.29 - Train Loss: 0.0770 - Test Loss: 0.0987- Train Recall: 0.9177 - Test Recall: 0.9446\nEpoch: 10- time: 2.32 - Train Loss: 0.0699 - Test Loss: 0.0916- Train Recall: 0.9237 - Test Recall: 0.9474\nEpoch: 11- time: 2.32 - Train Loss: 0.0625 - Test Loss: 0.0880- Train Recall: 0.9289 - Test Recall: 0.9499\nEpoch: 12- time: 2.32 - Train Loss: 0.0581 - Test Loss: 0.0834- Train Recall: 0.9333 - Test Recall: 0.9520\nEpoch: 13- time: 2.37 - Train Loss: 0.0543 - Test Loss: 0.0846- Train Recall: 0.9371 - Test Recall: 0.9537\nEpoch: 14- time: 2.32 - Train Loss: 0.0506 - Test Loss: 0.0759- Train Recall: 0.9405 - Test Recall: 0.9554\nEpoch: 15- time: 2.35 - Train Loss: 0.0452 - Test Loss: 0.0761- Train Recall: 0.9435 - Test Recall: 0.9569\nEpoch: 16- time: 2.35 - Train Loss: 0.0427 - Test Loss: 0.0731- Train Recall: 0.9462 - Test Recall: 0.9583\nEpoch: 17- time: 2.34 - Train Loss: 0.0406 - Test Loss: 0.0706- Train Recall: 0.9486 - Test Recall: 0.9595\nEpoch: 18- time: 2.36 - Train Loss: 0.0364 - Test Loss: 0.0691- Train Recall: 0.9509 - Test Recall: 0.9606\nEpoch: 19- time: 2.35 - Train Loss: 0.0348 - Test Loss: 0.0700- Train Recall: 0.9529 - Test Recall: 0.9616\nEpoch: 20- time: 2.33 - Train Loss: 0.0323 - Test Loss: 0.0684- Train Recall: 0.9547 - Test Recall: 0.9625\nEpoch: 21- time: 2.34 - Train Loss: 0.0314 - Test Loss: 0.0656- Train Recall: 0.9564 - Test Recall: 0.9634\nEpoch: 22- time: 2.33 - Train Loss: 0.0285 - Test Loss: 0.0667- Train Recall: 0.9580 - Test Recall: 0.9642\nEpoch: 23- time: 2.35 - Train Loss: 0.0270 - Test Loss: 0.0634- Train Recall: 0.9595 - Test Recall: 0.9649\nEpoch: 24- time: 2.28 - Train Loss: 0.0250 - Test Loss: 0.0655- Train Recall: 0.9608 - Test Recall: 0.9656\nEpoch: 25- time: 2.41 - Train Loss: 0.0240 - Test Loss: 0.0635- Train Recall: 0.9621 - Test Recall: 0.9662\nEpoch: 26- time: 2.28 - Train Loss: 0.0232 - Test Loss: 0.0619- Train Recall: 0.9633 - Test Recall: 0.9668\nEpoch: 27- time: 2.19 - Train Loss: 0.0203 - Test Loss: 0.0618- Train Recall: 0.9644 - Test Recall: 0.9674\nEpoch: 28- time: 2.30 - Train Loss: 0.0190 - Test Loss: 0.0618- Train Recall: 0.9655 - Test Recall: 0.9679\nEpoch: 29- time: 2.27 - Train Loss: 0.0181 - Test Loss: 0.0681- Train Recall: 0.9665 - Test Recall: 0.9684\nEpoch: 30- time: 2.42 - Train Loss: 0.0179 - Test Loss: 0.0610- Train Recall: 0.9674 - Test Recall: 0.9689\nEpoch: 31- time: 2.46 - Train Loss: 0.0165 - Test Loss: 0.0624- Train Recall: 0.9683 - Test Recall: 0.9693\nEpoch: 32- time: 2.51 - Train Loss: 0.0152 - Test Loss: 0.0614- Train Recall: 0.9692 - Test Recall: 0.9698\nEpoch: 33- time: 2.40 - Train Loss: 0.0149 - Test Loss: 0.0608- Train Recall: 0.9700 - Test Recall: 0.9702\nEpoch: 34- time: 2.38 - Train Loss: 0.0137 - Test Loss: 0.0610- Train Recall: 0.9708 - Test Recall: 0.9705\nEpoch: 35- time: 2.36 - Train Loss: 0.0132 - Test Loss: 0.0605- Train Recall: 0.9715 - Test Recall: 0.9709\nEpoch: 36- time: 2.38 - Train Loss: 0.0122 - Test Loss: 0.0603- Train Recall: 0.9722 - Test Recall: 0.9713\nEpoch: 37- time: 2.42 - Train Loss: 0.0107 - Test Loss: 0.0601- Train Recall: 0.9729 - Test Recall: 0.9716\nEpoch: 38- time: 2.47 - Train Loss: 0.0110 - Test Loss: 0.0645- Train Recall: 0.9735 - Test Recall: 0.9719\nEpoch: 39- time: 2.23 - Train Loss: 0.0107 - Test Loss: 0.0616- Train Recall: 0.9741 - Test Recall: 0.9722\nEpoch: 40- time: 2.27 - Train Loss: 0.0103 - Test Loss: 0.0620- Train Recall: 0.9747 - Test Recall: 0.9725\nEpoch: 41- time: 2.35 - Train Loss: 0.0089 - Test Loss: 0.0630- Train Recall: 0.9753 - Test Recall: 0.9728\nEpoch: 42- time: 2.54 - Train Loss: 0.0078 - Test Loss: 0.0634- Train Recall: 0.9758 - Test Recall: 0.9730\nEpoch: 43- time: 2.36 - Train Loss: 0.0075 - Test Loss: 0.0620- Train Recall: 0.9763 - Test Recall: 0.9733\nEpoch: 44- time: 2.39 - Train Loss: 0.0066 - Test Loss: 0.0614- Train Recall: 0.9769 - Test Recall: 0.9735\nEpoch: 45- time: 2.28 - Train Loss: 0.0070 - Test Loss: 0.0630- Train Recall: 0.9773 - Test Recall: 0.9737\nEpoch: 46- time: 2.33 - Train Loss: 0.0067 - Test Loss: 0.0636- Train Recall: 0.9778 - Test Recall: 0.9739\nEpoch: 47- time: 2.42 - Train Loss: 0.0056 - Test Loss: 0.0651- Train Recall: 0.9783 - Test Recall: 0.9742\nEpoch: 48- time: 2.26 - Train Loss: 0.0062 - Test Loss: 0.0672- Train Recall: 0.9787 - Test Recall: 0.9743\nEpoch: 49- time: 2.27 - Train Loss: 0.0056 - Test Loss: 0.0630- Train Recall: 0.9791 - Test Recall: 0.9746\nEpoch: 50- time: 2.36 - Train Loss: 0.0046 - Test Loss: 0.0646- Train Recall: 0.9795 - Test Recall: 0.9748\nEpoch: 51- time: 2.35 - Train Loss: 0.0043 - Test Loss: 0.0625- Train Recall: 0.9799 - Test Recall: 0.9749\nEpoch: 52- time: 2.41 - Train Loss: 0.0040 - Test Loss: 0.0659- Train Recall: 0.9803 - Test Recall: 0.9751\nEpoch: 53- time: 2.29 - Train Loss: 0.0037 - Test Loss: 0.0637- Train Recall: 0.9806 - Test Recall: 0.9753\nEpoch: 54- time: 2.30 - Train Loss: 0.0034 - Test Loss: 0.0648- Train Recall: 0.9810 - Test Recall: 0.9755\nEpoch: 55- time: 2.26 - Train Loss: 0.0032 - Test Loss: 0.0660- Train Recall: 0.9813 - Test Recall: 0.9756\nEpoch: 56- time: 2.22 - Train Loss: 0.0029 - Test Loss: 0.0654- Train Recall: 0.9817 - Test Recall: 0.9758\nEpoch: 57- time: 2.21 - Train Loss: 0.0028 - Test Loss: 0.0672- Train Recall: 0.9820 - Test Recall: 0.9759\nEpoch: 58- time: 2.37 - Train Loss: 0.0027 - Test Loss: 0.0662- Train Recall: 0.9823 - Test Recall: 0.9761\nEpoch: 59- time: 2.34 - Train Loss: 0.0025 - Test Loss: 0.0650- Train Recall: 0.9826 - Test Recall: 0.9762\nEpoch: 60- time: 2.32 - Train Loss: 0.0024 - Test Loss: 0.0657- Train Recall: 0.9829 - Test Recall: 0.9764\nEpoch: 61- time: 2.28 - Train Loss: 0.0023 - Test Loss: 0.0658- Train Recall: 0.9832 - Test Recall: 0.9765\nEpoch: 62- time: 2.29 - Train Loss: 0.0021 - Test Loss: 0.0676- Train Recall: 0.9834 - Test Recall: 0.9767\nEpoch: 63- time: 2.44 - Train Loss: 0.0019 - Test Loss: 0.0675- Train Recall: 0.9837 - Test Recall: 0.9768\nEpoch: 64- time: 2.47 - Train Loss: 0.0019 - Test Loss: 0.0686- Train Recall: 0.9839 - Test Recall: 0.9769\nEpoch: 65- time: 2.42 - Train Loss: 0.0016 - Test Loss: 0.0705- Train Recall: 0.9842 - Test Recall: 0.9770\nEpoch: 66- time: 2.38 - Train Loss: 0.0016 - Test Loss: 0.0685- Train Recall: 0.9844 - Test Recall: 0.9772\nEpoch: 67- time: 2.29 - Train Loss: 0.0014 - Test Loss: 0.0684- Train Recall: 0.9847 - Test Recall: 0.9773\nEpoch: 68- time: 2.21 - Train Loss: 0.0014 - Test Loss: 0.0685- Train Recall: 0.9849 - Test Recall: 0.9774\nEpoch: 69- time: 2.29 - Train Loss: 0.0013 - Test Loss: 0.0688- Train Recall: 0.9851 - Test Recall: 0.9775\nEpoch: 70- time: 2.21 - Train Loss: 0.0012 - Test Loss: 0.0709- Train Recall: 0.9853 - Test Recall: 0.9776\nEpoch: 71- time: 2.34 - Train Loss: 0.0011 - Test Loss: 0.0694- Train Recall: 0.9855 - Test Recall: 0.9777\nEpoch: 72- time: 2.35 - Train Loss: 0.0012 - Test Loss: 0.0703- Train Recall: 0.9857 - Test Recall: 0.9778\nEpoch: 73- time: 2.24 - Train Loss: 0.0011 - Test Loss: 0.0724- Train Recall: 0.9859 - Test Recall: 0.9779\nEpoch: 74- time: 2.23 - Train Loss: 0.0011 - Test Loss: 0.0711- Train Recall: 0.9861 - Test Recall: 0.9780\nEpoch: 75- time: 2.20 - Train Loss: 0.0009 - Test Loss: 0.0719- Train Recall: 0.9863 - Test Recall: 0.9781\nEpoch: 76- time: 2.18 - Train Loss: 0.0008 - Test Loss: 0.0720- Train Recall: 0.9865 - Test Recall: 0.9782\nEpoch: 77- time: 2.20 - Train Loss: 0.0008 - Test Loss: 0.0730- Train Recall: 0.9866 - Test Recall: 0.9783\nEpoch: 78- time: 2.19 - Train Loss: 0.0008 - Test Loss: 0.0741- Train Recall: 0.9868 - Test Recall: 0.9784\nEpoch: 79- time: 2.26 - Train Loss: 0.0007 - Test Loss: 0.0733- Train Recall: 0.9870 - Test Recall: 0.9785\nEpoch: 80- time: 2.30 - Train Loss: 0.0007 - Test Loss: 0.0741- Train Recall: 0.9871 - Test Recall: 0.9786\nEpoch: 81- time: 2.25 - Train Loss: 0.0007 - Test Loss: 0.0739- Train Recall: 0.9873 - Test Recall: 0.9786\nEpoch: 82- time: 2.22 - Train Loss: 0.0006 - Test Loss: 0.0738- Train Recall: 0.9875 - Test Recall: 0.9787\nEpoch: 83- time: 2.27 - Train Loss: 0.0006 - Test Loss: 0.0744- Train Recall: 0.9876 - Test Recall: 0.9788\nEpoch: 84- time: 2.41 - Train Loss: 0.0006 - Test Loss: 0.0742- Train Recall: 0.9878 - Test Recall: 0.9789\nEpoch: 85- time: 2.42 - Train Loss: 0.0005 - Test Loss: 0.0753- Train Recall: 0.9879 - Test Recall: 0.9790\nEpoch: 86- time: 2.31 - Train Loss: 0.0005 - Test Loss: 0.0749- Train Recall: 0.9880 - Test Recall: 0.9790\nEpoch: 87- time: 2.26 - Train Loss: 0.0005 - Test Loss: 0.0760- Train Recall: 0.9882 - Test Recall: 0.9791\nEpoch: 88- time: 2.43 - Train Loss: 0.0005 - Test Loss: 0.0760- Train Recall: 0.9883 - Test Recall: 0.9792\nEpoch: 89- time: 2.29 - Train Loss: 0.0005 - Test Loss: 0.0763- Train Recall: 0.9884 - Test Recall: 0.9792\nEpoch: 90- time: 2.35 - Train Loss: 0.0004 - Test Loss: 0.0764- Train Recall: 0.9886 - Test Recall: 0.9793\nEpoch: 91- time: 2.21 - Train Loss: 0.0004 - Test Loss: 0.0772- Train Recall: 0.9887 - Test Recall: 0.9794\nEpoch: 92- time: 2.25 - Train Loss: 0.0004 - Test Loss: 0.0772- Train Recall: 0.9888 - Test Recall: 0.9795\nEpoch: 93- time: 2.25 - Train Loss: 0.0004 - Test Loss: 0.0773- Train Recall: 0.9889 - Test Recall: 0.9795\nEpoch: 94- time: 2.31 - Train Loss: 0.0004 - Test Loss: 0.0786- Train Recall: 0.9891 - Test Recall: 0.9796\nEpoch: 95- time: 2.38 - Train Loss: 0.0004 - Test Loss: 0.0775- Train Recall: 0.9892 - Test Recall: 0.9796\nEpoch: 96- time: 2.27 - Train Loss: 0.0004 - Test Loss: 0.0788- Train Recall: 0.9893 - Test Recall: 0.9797\nEpoch: 97- time: 2.37 - Train Loss: 0.0003 - Test Loss: 0.0788- Train Recall: 0.9894 - Test Recall: 0.9798\nEpoch: 98- time: 2.22 - Train Loss: 0.0003 - Test Loss: 0.0789- Train Recall: 0.9895 - Test Recall: 0.9798\nEpoch: 99- time: 2.22 - Train Loss: 0.0003 - Test Loss: 0.0794- Train Recall: 0.9896 - Test Recall: 0.9799\nEpoch: 100- time: 2.30 - Train Loss: 0.0003 - Test Loss: 0.0796- Train Recall: 0.9897 - Test Recall: 0.9799\n\n\n\ndef plot_training_curves(train_loss, validation_loss, n_epochs, title=\"\"):\n    plt.plot(\n        range(1, n_epochs + 1),\n        train_loss,\n        label=\"Train Loss\",\n    )\n    plt.plot(\n        range(1, n_epochs + 1),\n        validation_loss,\n        label=\"Validation Loss\",\n    )\n    plt.title(title)\n    plt.legend()\n    plt.show()\n\n\nplot_training_curves(train_losses, test_losses, EPOCHS)\n\n\n\n\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "tics579/clase-2.html#machine-learning-vs-deep-learning",
    "href": "tics579/clase-2.html#machine-learning-vs-deep-learning",
    "title": "TICS-579-Deep Learning",
    "section": "Machine Learning vs Deep Learning",
    "text": "Machine Learning vs Deep Learning\n\nEs sabido que la mejor manera de mejorar el performance de un algoritmo en partícular no es con ajuste de Hiperparámetros sino crear features que sean representativas del problema.\n\n\n\n\n\n\n\n\n\n🤓 ¿Cómo se mejora un modelo?\n\n\n\nNormalmente el Machine Learning busca generar features de manera manual.\nDeep Learning busca que el Algoritmo genere esas features de manera automática."
  },
  {
    "objectID": "tics579/clase-2.html#cómo-se-crean-features",
    "href": "tics579/clase-2.html#cómo-se-crean-features",
    "title": "TICS-579-Deep Learning",
    "section": "¿Cómo se crean features?",
    "text": "¿Cómo se crean features?\n\n\nNormalmente un approach es agregar features externas/exógenas, pero también es completamente válido crear features nuevas por medio de las existentes.\n\n\n\n\n\n\n\nEjemplo\n\n\nSi \\(X_1\\) es el Largo de un objeto y \\(X_2\\) es el ancho, entonces una feature nueva podría ser \\(X_3 = X_1 \\cdot X_2\\), que es el área del objeto.\n\n\n\n\n\n\n¿Cómo podríamos crear nuevas features pero de manera automática?\n\n\n\nUna opción es hacer una combinación lineal de features existentes.\n\nEsto lo podemos realizar con operaciones matriciales.\n\n\nPor ejemplo un set de nuevas features \\(\\phi(X)\\) podría ser:\n\\(\\phi(X) = X W\\) donde \\(W \\in \\mathbb{R}^{n \\times d}\\), donde \\(d\\) es el número de nuevas features resultantes luego del proceso de creación.\n\nEsto implica que si \\(X\\) tiene \\(n\\) features, entonces \\(\\phi(X)\\) tendrá \\(d\\) features que son combinaciones de las anteriores.\n\n\n\n\n\n\n\n\n\n\nEs decir:\n\\[f_j^{(i)} = (\\bar{x}^{(i)})^T W_{:,j} = \\sum_{k=1}^n x_k^{(i)} W_{k,j}\\]\nDonde \\(j=1,...,d\\) y \\(i=1,...,m\\)."
  },
  {
    "objectID": "tics579/clase-2.html#regresión-logística-features",
    "href": "tics579/clase-2.html#regresión-logística-features",
    "title": "TICS-579-Deep Learning",
    "section": "Regresión Logística + Features",
    "text": "Regresión Logística + Features\n\n\n\n\n😱 ¿Y si combinamos ambas ideas?\n\n\nPerfectamente podemos crear una Regresión logística con nuestras nuevas features y combinar todo en un sólo modelo:\n\\[h_\\theta(X) = p = \\sigma(\\phi(X) \\theta) = \\sigma(X W \\theta)\\]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n🤓 Nuestra Notación\n\n\n\nCada nodo se le conoce como Neurona o Activación.\nCada conjunto de vértices, se les conoce como Capa o Capa de Parámetros.\n\nOjo: Las capas no son los conjuntos de Nodos.\n\n\n\n\n\n\n\n\n\n\n\n👀 Ojo\n\n\n\nExisten convenciones donde cada conjunto de nodos es una capa.\n\nA la primera capa de nodos se le llama Capa de Entrada/Input Layer.\nA la última capa de nodos se le llama Capa de Salida/Output Layer.\nA las capas intermedias se les llama Hidden Layers."
  },
  {
    "objectID": "tics579/clase-2.html#y-si-hacemos-nuestro-modelo-más-profundo",
    "href": "tics579/clase-2.html#y-si-hacemos-nuestro-modelo-más-profundo",
    "title": "TICS-579-Deep Learning",
    "section": "¿Y si hacemos nuestro modelo más profundo?",
    "text": "¿Y si hacemos nuestro modelo más profundo?\nPodemos hacer nuestro modelo más profundo, agregando más capas de features. Por ejemplo:\n\n\n\\[h_\\theta(X) = \\sigma(X W_1 W_2 \\theta)\\]\nDonde \\(X \\in \\mathbb{R}^{m \\times n}\\), \\(W_1 \\in \\mathbb{R}^{n \\times d}\\), \\(W_2 \\in \\mathbb{R}^{d \\times k}\\) y \\(\\theta \\in \\mathbb{R}^{k \\times 1}\\).\n\n\n\n🤔 El problema\n\n\nLamentablemente agregar capas no soluciona el problema de la linealidad. Agregar muchas capas lineales siguen siendo una transformación lineal.\n\\[ h_\\theta(X) = \\sigma(X W_1 W_2 \\theta) = \\sigma(X \\tilde{\\theta})\\]\nDonde \\(\\tilde{\\theta} \\in \\mathbb{R}^{n \\times 1}\\) es sólo otra matriz de parámetros.\n\n\n\n\n\n\n\n\n\nAtención: En este caso \\(\\sigma(\\cdot)\\) tiene como único propósito acotar la salida entre 0 y 1."
  },
  {
    "objectID": "tics579/clase-2.html#el-problema-de-una-hipótesis-lineal",
    "href": "tics579/clase-2.html#el-problema-de-una-hipótesis-lineal",
    "title": "TICS-579-Deep Learning",
    "section": "El problema de una Hipótesis Lineal",
    "text": "El problema de una Hipótesis Lineal\n\n\n\n\n\nEsto Funciona\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEsto no Funciona\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n😞 No podemos salir del Origen\n\n\nPor definición de una transformación lineal, si \\(X=0\\) entonces \\(h_\\theta(X)=0\\). Eso lamentablemente limita las posibilidades de un modelo de poder generar una buena separación entre clases."
  },
  {
    "objectID": "tics579/clase-2.html#entonces-cómo-solucionamos-este-problema",
    "href": "tics579/clase-2.html#entonces-cómo-solucionamos-este-problema",
    "title": "TICS-579-Deep Learning",
    "section": "¿Entonces cómo solucionamos este problema?",
    "text": "¿Entonces cómo solucionamos este problema?\n\n\n\n\n\n\n\nHaremos una transformación Affine. Es decir, agregaremos un bias a nuestra transformación lineal.\n\n\n\\[\\phi_{L+1}(X) = \\phi_L(X) W_{L+1} + b_{L+1}^T\\]\n\nDonde:\n\nDonde \\(\\phi(X)_{L+1}\\) corresponde a las activaciones de la capa \\(L+1\\). \\(L=0,...,L_{net}-1\\).\n\nNotar que \\(\\phi_0(X) = X\\).\nAsimismo, \\(\\phi_{L_{net}}(X)\\) corresponde a las activaciones de la capa de salida, es decir, las predicciones del modelo.\n\n\\(W_{L+1}\\) es la matrix de pesos/parámetros que lleva de \\(n_L\\) a \\(n_{L+1}\\) dimensiones.\n\\(b_{L+1}^T\\in \\mathbb{R}^{1 \\times n_{L+1}}\\) es el vector de bias de la capa \\(L\\) (Esto no es un error).\n\n\n\n\n\n\n\n\n\n¡Pero esto es una operación inválida! 🙄 No. Gracias al Broadcasting, esto es equivalente a hacer \\(1_m \\bar{b}^T\\), donde \\(1_m\\) es un vector columna de unos de tamaño \\(m x 1\\) Esto implica que cada componente de \\(\\bar{b}\\) se suma igual a todas las muestras.\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\nVamos a utilizar funciones no lineales. Cualquiera sirve tal que:\n\\[\\phi_{L+1}(X) = \\sigma_{L+1}(\\phi_L(X) W_{L+1} + b_{L+1}^T)\\]\n\nDonde \\(\\sigma_{L+1}\\) es una función no lineal que aplica a cada elemento de la matriz \\(X W_{L+1} + b_{L+1}^T\\).\n\\(\\sigma_{L+1}\\) puede ser cualquier función no lineal, pero normalmente utilizamos funciones diferenciables."
  },
  {
    "objectID": "tics579/clase-2.html#formalmente-una-red-neuronal-profunda",
    "href": "tics579/clase-2.html#formalmente-una-red-neuronal-profunda",
    "title": "TICS-579-Deep Learning",
    "section": "Formalmente: Una Red Neuronal Profunda",
    "text": "Formalmente: Una Red Neuronal Profunda\nVamos a definir una Red Neuronal Profunda como:\n\\[h_\\theta(X) = \\sigma_{L+1}(\\phi_L(X) W_{L+1} + b_{L+1}^T)\\]\ncon \\(L=0,...,L_{net}-1\\).\n\n\n\n\n\n\n\nImportante\n\n\n\n\\(L_{net}\\) es el número de capas de parámetros ocultas de la red neuronal.\n\nNotar que \\(\\phi_0(X) = X\\).\nExisten \\(L_{net} + 1\\) capas de activación. Una que es la capa de entrada \\(\\phi_0(X)\\) y \\(L_{net}\\) capas “calculadas”."
  },
  {
    "objectID": "tics579/clase-2.html#entrenemos-una-red-neuronal-a-mano",
    "href": "tics579/clase-2.html#entrenemos-una-red-neuronal-a-mano",
    "title": "TICS-579-Deep Learning",
    "section": "Entrenemos una Red Neuronal a mano",
    "text": "Entrenemos una Red Neuronal a mano\n\n\n\\(W_1 \\in \\mathbb{R}^{n \\times d1}\\)\n\\(\\bar{b_1}^T \\in \\mathbb{R}^{1 \\times d1}\\)\n\\(W_2 \\in \\mathbb{R}^{d1 \\times d2}\\)\n\\(\\bar{b_2}^T \\in \\mathbb{R}^{1 \\times d2}\\)\n\\[u=X W_1\\] \\[\\phi_1 = u + 1_m\\bar{b_1}^T\\] \\[Z_1 = \\sigma(\\phi_1)\\] \\[v=Z_1 W_2\\] \\[\\phi_2 = v + 1_m\\bar{b_2}^T\\] \\[p = \\sigma(\\phi_2)\\] \\[L = -\\frac{1}{m}\\left[y^T log(p) + (1-y)^T log(1-p)\\right]\\]"
  },
  {
    "objectID": "tics579/clase-2.html#entrenemos-una-red-neuronal-a-mano-1",
    "href": "tics579/clase-2.html#entrenemos-una-red-neuronal-a-mano-1",
    "title": "TICS-579-Deep Learning",
    "section": "Entrenemos una Red Neuronal a mano",
    "text": "Entrenemos una Red Neuronal a mano\nSi \\(L=-[y^T log(p) + (1-y)^T log(1-p)]\\) entonces:\n\n\n\\[\\frac{\\partial L}{\\partial p} = -\\frac{1}{m} \\left[\\frac{y^T}{p} - \\frac{1 -y)^T}{(1-p)}\\right] = \\frac{1}{m} \\left[\\frac{p-y}{p(1-p)}\\right]\\]\n\\[\\frac{\\partial L}{\\partial \\phi_2} = \\frac{\\partial L}{\\partial p} \\frac{\\partial p}{\\partial \\phi_2} = \\frac{1}{m} \\left[\\frac{p-y}{p(1-p)}\\right] p (1-p) = \\frac{1}{m} \\left[p-y\\right]\\]\n\\[\\frac{\\partial L}{\\partial b_2} = \\frac{\\partial L}{\\partial \\phi_2} \\frac{\\partial \\phi_2}{\\partial b_2} = \\frac{1}{m} 1_m^T \\left[p-y\\right]\\]\n\\[\\frac{\\partial L}{\\partial v} = \\frac{\\partial L}{\\partial \\phi_2} \\frac{\\partial \\phi_2}{\\partial v} = \\frac{\\partial L}{\\partial \\phi_2}\\]\n\\[\\frac{\\partial L}{\\partial W_2} = \\frac{\\partial L}{\\partial v} \\frac{\\partial v}{\\partial W_2} = \\frac{\\partial L}{\\partial v} \\cdot Z_1= \\frac{1}{m} Z_1^T \\left[p-y\\right]\\]\n\n\n\n\nUpdate Rule para \\(b_2\\)\n\n\n\\[b_2^T = b_2^T - \\alpha \\frac{1}{m} 1_m^T \\left[p-y\\right]\\]\n\n\n\n\n\n\nUpdate Rule para \\(W_2\\)\n\n\n\\[W_2 = W_2 - \\alpha \\frac{1}{m} Z_1^T \\left[p-y\\right]\\]"
  },
  {
    "objectID": "tics579/clase-2.html#entrenemos-una-red-neuronal-a-mano-2",
    "href": "tics579/clase-2.html#entrenemos-una-red-neuronal-a-mano-2",
    "title": "TICS-579-Deep Learning",
    "section": "Entrenemos una Red Neuronal a mano",
    "text": "Entrenemos una Red Neuronal a mano\n\\[\\frac{\\partial L}{\\partial Z_1} =\\frac{\\partial L}{\\partial \\phi_2} \\frac{\\partial \\phi_2}{\\partial Z_1}=  \\frac{\\partial L}{\\partial \\phi_2} \\cdot W_2^T = \\frac{1}{m}[p-y] W_2^T \\]\n\\[\\frac{\\partial L}{\\partial \\phi_1} = \\frac{\\partial L}{\\partial Z_1} \\frac{\\partial Z_1}{\\partial \\phi_1}= \\frac{\\partial L}{\\partial Z_1} \\cdot \\sigma'(\\phi_1) = \\frac{1}{m}[p-y] W_2^T \\odot [Z_1  \\odot (1-Z_1)]\\]\n\\[\\frac{\\partial L}{\\partial b_1} =\\frac{\\partial L}{\\partial \\phi_1} \\frac{\\partial \\phi_1}{\\partial \\phi_1}{\\partial b_1}=  \\frac{\\partial L}{\\partial \\phi_1} \\cdot 1_m = \\frac{1_m^T}{m} [p-y] W_2^T \\odot [Z_1  \\odot (1-Z_1)]\\]\n\\[\\frac{\\partial L}{\\partial u} = \\frac{\\partial L}{\\partial \\phi_1} \\frac{\\partial \\phi_1}{\\partial u} = \\frac{\\partial L}{\\partial \\phi_1}\\]\n\\[\\frac{\\partial L}{\\partial W_1} = \\frac{\\partial L}{\\partial u} \\frac{\\partial u}{\\partial W_1} = \\frac{\\partial L}{\\partial u} \\cdot X = \\frac{1}{m} X^T [p-y] W_2^T \\odot [Z_1  \\odot (1-Z_1)]\\]\n\n\n\n\n\nUpdate Rule para \\(b_1\\)\n\n\n\\[b_1^T = b_1^T - \\alpha \\frac{1_m^T}{m} [p-y] W_2^T \\odot [Z_1  \\odot (1-Z_1)]\\]\n\n\n\n\n\n\n\nUpdate Rule para \\(W_1\\)\n\n\n\\[W_1 = W_1 - \\alpha \\frac{1}{m} X^T [p-y] W_2^T \\odot [Z_1  \\odot (1-Z_1)]\\]"
  },
  {
    "objectID": "tics579/clase-2.html#entrenamiento-de-una-red-neuronal",
    "href": "tics579/clase-2.html#entrenamiento-de-una-red-neuronal",
    "title": "TICS-579-Deep Learning",
    "section": "Entrenamiento de una Red Neuronal",
    "text": "Entrenamiento de una Red Neuronal\n\n\n\n\n➡️ Forward Pass\n\n\n\nCorresponde al proceso de calcular las activaciones de cada capa para una matriz de diseño \\(X\\).\nEl forward pass permitirá calcular las variables intermedias que son necesarias para el cálculo del Backward Pass las cuales van variando a medida que los parámetros del modelo se actualizan.\n\n\n\n\n\n\n\n\n\n⬅️ Backward Pass\n\n\n\nCorresponde al proceso de calcular las derivadas de cada una de las variables del modelo con respecto a la función de pérdida.\nNotar que muchos calculos del Backward Pass dependen de los resultados del Forward Pass.\n\n\n\n\n\n\n\n\n\n👀 Backpropagation\n\n\nLa combinación del Forward Pass y el Backward Pass se conoce como Backpropagation o Retropropagación."
  },
  {
    "objectID": "tics579/clase-2.html#broadcasting-rules",
    "href": "tics579/clase-2.html#broadcasting-rules",
    "title": "TICS-579-Deep Learning",
    "section": "Broadcasting Rules",
    "text": "Broadcasting Rules\n\n\n\n\n\n\n\nBroadcasting\n\n\nCorresponde a una replica de una dimensión de manera de permitir alguna operación que requiera que ciertas dimensiones calcen.\n\n\n\n\n\n\n\n\n\nBroadcasting Rules\n\n\n\nCada tensor debe tener al menos una dimensión.\nMoviéndose de derecha a izquierda por cada dimensión una vez alineadas a la derecha, las dimensiones deben:\n\nSer iguales,\niguales a 1,\no no debe existir.\n\n\n\n\n\n\n\n\n\n\n\nEl Broadcasting evita que se tenga que almacenar información repetida, lo cual permite que las implementaciones sean más eficientes en términos de memoria. Siempre que se pueda se debe utilizar Broadcasting para simplificar un cálculo.\n\n\n\nMás info ver: Numpy Docs"
  },
  {
    "objectID": "tics579/clase-7.html#arquitecturas-famosas",
    "href": "tics579/clase-7.html#arquitecturas-famosas",
    "title": "TICS-579-Deep Learning",
    "section": "Arquitecturas Famosas",
    "text": "Arquitecturas Famosas\n\nCrear arquitecturas de CNN desde cero es una tarea compleja y que requiere de mucho conocimiento y experiencia. Afortunadamente, existen diversas arquitecturas famosas que han sido probadas y testeadas en el tiempo, las cuáles pueden ser utilizadas como backbones para distintas tareas de Visión por Computador."
  },
  {
    "objectID": "tics579/clase-7.html#lenet-5-lecun-et-al.-1998",
    "href": "tics579/clase-7.html#lenet-5-lecun-et-al.-1998",
    "title": "TICS-579-Deep Learning",
    "section": "LeNet-5 (LeCun et al., 1998)",
    "text": "LeNet-5 (LeCun et al., 1998)\n\nProbablemente la primera arquitectura famosa en poder realizar tareas importantes de reconocimiento de imagen. Diseñada especialmente para reconocimiento de dígitos, introduce los bloques de convolución más pooling para luego conectarse con FFN.\n\n\n\n\n\n\n\n\n\nAdaptive Pooling\n\n\nLa mayoría de arquitecturas más modernas utiliza una capa llamada Adaptive Pooling antes del proceso de Flatten. El Adaptive Pooling es una especie de Pooling inverso, donde uno define el tamaño del output, y automáticamente se calcula el Kernel, Stride, Padding, etc. necesario para obtener ese tamaño.\nEso garantiza que cualquier tamaño de imagen puede pasar por la red sin romper las dimensiones necesarias para la transición al MLP."
  },
  {
    "objectID": "tics579/clase-7.html#alexnext-krizhevsky-sutskever-y-hinton-2012",
    "href": "tics579/clase-7.html#alexnext-krizhevsky-sutskever-y-hinton-2012",
    "title": "TICS-579-Deep Learning",
    "section": "AlexNext (Krizhevsky, Sutskever y Hinton, 2012)",
    "text": "AlexNext (Krizhevsky, Sutskever y Hinton, 2012)\n\nGanó el concurso Imagenet (ILSVRC) en 2012 por un largo margen (algo impensado para ese tiempo). Introdujo los conceptos de ReLU, Dropout y Aceleración por GPU. Esta arquitectura está disponible en torchvision.\n\n\n\n\n\n\nimport torchvision\ntorchvision.models.alexnet(weights = \"IMAGENET1K_V1\")\n\n\n\n\n\n\nLa arquitectura de Torchvision está inspirada en una versión alternativa de Alexnet. Esto probablemente no será corregido ya que no es una arquitectura que se utilice comunmente en la actualidad."
  },
  {
    "objectID": "tics579/clase-7.html#vggnet-simonyan-zisserman-2014",
    "href": "tics579/clase-7.html#vggnet-simonyan-zisserman-2014",
    "title": "TICS-579-Deep Learning",
    "section": "VGGNet (Simonyan, Zisserman, 2014)",
    "text": "VGGNet (Simonyan, Zisserman, 2014)\n\nPresentaron las primeras redes relativamente profundas con Kernels pequeños de \\(3 \\times 3\\). Su propuesta incluye Redes de hasta 19 capas.\n\n\n\n\n\n\n\n\n\nimport torchvision\ntorchvision.models.vgg16(weights = \"IMAGENET1K_V1\")\n## Versión con Batchnorm\ntorchvision.models.vgg16_bn(weights = \"IMAGENET1K_V1\")\n\n\n\n\n\n\ntorchvision incluye las arquitecturas de 11, 13, 16 y 19 capas, además de variantes que incluyen Batchnorm (que en eltiempo del paper no existían aún)."
  },
  {
    "objectID": "tics579/clase-7.html#googlenetinception-szegedy-et-al.-2014",
    "href": "tics579/clase-7.html#googlenetinception-szegedy-et-al.-2014",
    "title": "TICS-579-Deep Learning",
    "section": "GoogleNet/Inception (Szegedy et al., 2014)",
    "text": "GoogleNet/Inception (Szegedy et al., 2014)\n\n\n\nIntroduce las “Pointwise Convolutions” (Convoluciones de 1x1) que permiten reducir la complejidad de canales (mediante una combinación lineal) manteniendo las dimensiones de la imagen. Además introduce los Inception Modules, que combinan resultados de Kernels de distinto tamaño. Fue la Arquitectura ganadora de ILSVRC 2014.\n\nimport torchvision\ntorchvision.models.googlenet(weights = \"IMAGENET1K_V1\")\n\n\n\n\n\n\n\n\n\n1x1 Convolutions\n\n\nLas convoluciones de 1×1 representan una de las principales novedades de este paper. Para cada posición espacial (h, w), la convolución no combina píxeles adyacentes, sino que realiza una combinación lineal entre los diferentes canales de entrada."
  },
  {
    "objectID": "tics579/clase-7.html#resnet-he-et-al.-2015",
    "href": "tics579/clase-7.html#resnet-he-et-al.-2015",
    "title": "TICS-579-Deep Learning",
    "section": "Resnet (He et al., 2015)",
    "text": "Resnet (He et al., 2015)\n\n\n\n\n\n\n\n\n\nIntroduce las conexiones residuales, lo cual permite evitar el problema del vanishing gradient para redes muy profundas. Es la Arquitectura ganadora de ILSVRC 2015.\n\n\n\n\n\n\n\nEsta arquitectura se puede encontrar tanto en torchvision como timm. Recomiendo timm, ya que hay muchas más variantes, mejor mantención y procesos de entrenamiento actualizados.\n\n\n\nimport timm\nmodel = timm.create_model(\"resnet50\", pretrained = True)\n\n## Listar todas las versiones de Resnet disponibles\ntimm.list_models(\"resnet*\")\n\nConexiones Residuales"
  },
  {
    "objectID": "tics579/clase-7.html#efficientnet-tan-le-2019",
    "href": "tics579/clase-7.html#efficientnet-tan-le-2019",
    "title": "TICS-579-Deep Learning",
    "section": "EfficientNet (Tan, Le, 2019)",
    "text": "EfficientNet (Tan, Le, 2019)\n\nIntroducen el concepto de Compound Scaling que permite cambiar la escala de profundidad (número de capas en la red), ancho (número de canales en cada capa) y resolución (dimensiones de la imagen) para poder mejorar la performance. Permite crear resultados al nivel del estado del arte con muchísimos menos parámetros.\n\n\n\n\n\n\nimport timm\nmodel = timm.create_model(\"efficientnet_b0\", pretrained = True)\n\n## Listar todas las versiones de Resnet disponibles\ntimm.list_models(\"efficientnet*\")"
  },
  {
    "objectID": "tics579/clase-7.html#pre-training",
    "href": "tics579/clase-7.html#pre-training",
    "title": "TICS-579-Deep Learning",
    "section": "Pre-training",
    "text": "Pre-training\n\nImagenet\n\nEs un dataset que contiene aproximadamente 14 millones de imágenes anotadas manualmente. Fue empleado en la competencia ImageNet Large Scale Visual Recognition Challenge (ILSVRC) entre los años 2010 y 2017, la cual impulsó importantes avances en el estado del arte del reconocimiento visual.\n\n\nLas imágenes presentan resoluciones variadas, que van desde \\(4288 \\times 2848\\) hasta \\(75 \\times 56\\) píxeles. Además, se encuentran normalizadas restando la media por canal \\([0.485,0.456,0.406]\\) y dividiendo por la desviación estándar correspondiente \\([0.229,0.224,0.225]\\).\n\n\n\n🤔\n\n\nLas dos variantes más conocidas son ImageNet-1K, que contiene 1.281.167, 50.000 y 100.000 imágenes para los conjuntos de train, validation y test, respectivamente, distribuidas en 1000 categorías; y ImageNet-21K, que incluye 14.197.122 imágenes organizadas en 21.841 clases.\n\n\n\n\n\n\n\n\n\nDebido a la relevancia y complejidad de este conjunto de datos, la mayoría de los backbones han sido preentrenados en él. Gracias a esto, las distintas arquitecturas “aprenden a ver” a partir del conocimiento adquirido mediante este dataset.\n\n\n\n\n\n\n\n\n\nDebido a que muchas arquitecturas pueden/saben ver en un dataset tan complejo como Imagenet. ¿Sería posible utilizar ese conocimiento en otro dataset?\n\n\n\n\nEntering Transfer Learning"
  },
  {
    "objectID": "tics579/clase-7.html#transfer-learning",
    "href": "tics579/clase-7.html#transfer-learning",
    "title": "TICS-579-Deep Learning",
    "section": "Transfer Learning",
    "text": "Transfer Learning\n\n\n\n\n\n\n\n\n\n\n\nDataset Público/alta complejidad\n\n\nNormalmente se utilizan datos públicos y de alta complejidad y se utiliza para pre-entrenar una arquitectura.\n\n\n\n\n\n\nPre-entrenamiento\n\n\nSe entrena una arquitectura para una tarea en específico con los detalles del dataset a utilizar.\n\n\n\n\n\n\nFine-Tuning\n\n\nSe carga la arquitectura pre-entrenada, con los pesos obtenidos en el pre-entrenamiento y se ajusta el prediction head para la nueva tarea y se vuelve a entrenar el modelo.\n\n\n\n\n\n\nFreezing Layers\n\n\nSe refiere a congelar los parámetros del backbone pre-entrenado, es decir, estos no se actualizan. Este paso es opcional, y en ocasiones puede funcionar de mejor manera que un Full-Fine-Tuning"
  },
  {
    "objectID": "tics579/clase-7.html#image-preprocessing-y-data-augmentation",
    "href": "tics579/clase-7.html#image-preprocessing-y-data-augmentation",
    "title": "TICS-579-Deep Learning",
    "section": "Image Preprocessing y Data Augmentation",
    "text": "Image Preprocessing y Data Augmentation\n\nEn general el proceso de Preprocesamiento de Imágenes es bastante más engorroso que el de datos tabulares. Afortunadamente Pytorch tiene algunos utilities que permiten hacer el proceso más sencillo:\n\n\nImageFolder\n\nPermite cargar imágenes de un Path en específico. Dentro de esa carpeta ImageFolder considerará cada carpeta como una clase y los elementos (imágenes) dentro de dicha clase como instancia de la clase en cuestión.\n\n\nfrom torchvision.dataset import ImageFolder\n\ntrain_data = ImageFolder(\"path/to/train/images\", transform = None)\nvalidation_data = ImageFolder(\"path/to/validation/images\", transform = None)\ntest_data = ImageFolder(\"path/to/test/images\", transform = None)\n\n\n\n\n\n\nAdemás ImageFolder posee un parámetro llamado transform en el cuál se pueden ingresar transformaciones a los datos para realizar procesos de Data Augmentation.\n\n\n\n\n\n\nOjo\n\n\nImageFolder entrega los datos como una Imagen PIL. Por lo tanto, es necesario aplicar procesamientos que permitan su transformación en Tensor."
  },
  {
    "objectID": "tics579/clase-7.html#data-augmentation",
    "href": "tics579/clase-7.html#data-augmentation",
    "title": "TICS-579-Deep Learning",
    "section": "Data Augmentation",
    "text": "Data Augmentation\n\n\nCorresponde a un proceso de generación de datos sintéticos. Este proceso se puede utilizar para:\n\nPermite la generación de datos adicionales debido a escasez por costo o disponibilidad de ellos. Ejemplo: Datos médicos.\nGenera variedad de datos, que entrega al modelo un mayor poder de generalización en datos no vistos.\nAl introducir mayor variabilidad en los datos entrega una mayor robustez ante el overfitting (Regularización).\nSimular condiciones adversas para el modelo en la cuál se quiera generar robustez.\n\nEj: Se tiene un modelo de reconocimiento de vehículos, pero que tiene que funcionar en condiciones de niebla.\n\n\n\n\n\n\n\n\n\n\n\n\nAlbumentations\n\n\nExisten diversas librerías que permiten generar Aumento de Datos. La librerías más famosas son Albumentations y Kornia. Albumentations, permite transformaciones extremadamente eficientes en CPU, mientras que Kornia hace lo mismo pero en GPU. Debido a las limitaciones de GPU que contamos, utilizaremos Albumentations, de manera tal de balancear procesamiento tanto en CPU como en GPU.\n\n\n\n\n\n\n\n\n\nNormalmente este tipo de transformaciones entrega mejores resultados cuando se generan de manera aleatoria y on-the-fly. Es decir, se genera el aumento de datos en la carga de datos durante el entrenamiento."
  },
  {
    "objectID": "tics579/clase-7.html#transformaciones-básicas",
    "href": "tics579/clase-7.html#transformaciones-básicas",
    "title": "TICS-579-Deep Learning",
    "section": "Transformaciones Básicas",
    "text": "Transformaciones Básicas\nimport albumentations as A\nfrom albumentations.pytorch.transforms import ToTensorV2\n\n\n\n\n\n\nAlbumentations espera que la imagen venga como Numpy Array. Además es una librería bastante quisquillosa, por lo que toma un rato acostumbrarse. Pero su eficiencia y utilidad hace que valga la pena.\n\n\n\n\nA.Compose()\n\nPermite generar Pipelines de Transformación. Es decir, irá aplicando transformaciones una a una.\n\nA.ToFloat()\n\nTransforma los datos en tipo Float. Esto a veces es necesario cuando hay incompatibilidad de data types en ciertos módulos.\n\nToTensorV2()\n\nTransforma a Tensor de Pytorch. Existe una versión ToTensor() pero está deprecada y no debería usarse.\n\nA.Normalize()\n\nPermite normalizar imágenes según su proceso de pre-entrenamiento. Normalmente estos provienen de pre-entrenamiento en Imagenet por lo que se debe normalizar con \\(mean=[0.485,0.456,0.406]\\) y \\(SD=[0.229,0.224,0.225]\\).\n\nA.Resize()\n\nSe utiliza para estandarizar el tamaño de las imágenes. Imágenes más grandes permiten mejores resultados pero son computacionalmente más costosas."
  },
  {
    "objectID": "tics579/clase-7.html#transformaciones-probabilísticas",
    "href": "tics579/clase-7.html#transformaciones-probabilísticas",
    "title": "TICS-579-Deep Learning",
    "section": "Transformaciones Probabilísticas",
    "text": "Transformaciones Probabilísticas\n\n\n\n\n\n\nComo su nombre lo indica, la transformación se aplicará con una cierta probabilidad, lo que permitirá que cada epoch haya mayor variabilidad.\n\n\n\n\nA.CenterCrop/A.RandomCrop\n\nGenera un Crop de la imagen o al centro o Random. Esto logrará que los elementos de la imagen cambien de posición.\n\nA.VerticalFlip\n\nGenera Flip Vertical.\n\nA.HorizontalFlip\n\nGenera Flip Horizontal.\n\nA.Rotate\n\nGenera rotaciones aleatorias entre un ángulo mínimo y máximo.\n\n\n\n\n\n\n\n\nExisten un sinnúmero de transformaciones que se pueden aplicar. La lista completa se puede encontrar acá. Y existen transformaciones que incluso permiten simular niebla, lluvia, nieve, sepia, Zoom, y variados otros efectos.\n\n\n\n\n\n\n\n\n\nAplicar estas transformaciones es de extremo cuidado ya que para tareas más complejas como Semantic Segmentation, Object Detection, Keypoint Detection, se debe aplicar dichas transformaciones también a las etiquetas."
  },
  {
    "objectID": "tics579/clase-4.html#entrenamiento-de-la-red",
    "href": "tics579/clase-4.html#entrenamiento-de-la-red",
    "title": "TICS-579-Deep Learning",
    "section": "Entrenamiento de la Red",
    "text": "Entrenamiento de la Red\n\nA diferencia de un Modelo de Machine Learning, las Redes Neuronales se entrenan de manera progresiva (se espera una mejora en cada Epoch). Si nuestra Arquitectura es apropiada nosotros deberíamos esperar que el Loss de nuestra red siempre disminuya. ¿Por qué?\n\n\n\n\n\n💡 Dado que el entrenamiento es progresivo, el modelo puede retomar su entrenamiento desde un set de pesos dados.\n\n\n\n\n\n\n\n\n\n\n\n¿Siempre buscamos la Red que tenga el mejor Loss de Entrenamiento? ¿Cuál es la diferencia entre el Loss y el Rendimento del Modelo?\n\n\n\n\n\n\n\n\n\n\n\nAl igual que en los modelos de Machine Learning debemos evitar a toda costa el Overfitting. ¿Qué es el overfitting?"
  },
  {
    "objectID": "tics579/clase-4.html#entrenamiento-de-la-red-1",
    "href": "tics579/clase-4.html#entrenamiento-de-la-red-1",
    "title": "TICS-579-Deep Learning",
    "section": "Entrenamiento de la Red",
    "text": "Entrenamiento de la Red\n\nBias-Variance Tradeoff (Dilema Sesgo-Varianza)\n\n\nProbablemente el concepto más importante para determinar si un modelo tiene potencial o no. Corresponden a dos tipos de errores que pueden sufrir los modelos de ML.\n\n\n\n\n\n\n\n\nBias\n\n\nCorresponde al sesgo, y tiene que ver con la diferencia entre el valor real y el valor predicho. Bajo sesgo implica una mejor predicción.\n\n\n\n\n\n\n\nVariance\n\n\nCorresponde a la varianza y tiene que ver con la dispersión de los valores predichos. Baja Varianza implica un modelo más estable y menos flexible.\n\n\n\n\n\n\n\nEn general hay que buscar el equilibrio entre ambos tipos de errores:\n\n\n\nAlto Sesgo y baja Varianza: Underfitting.\nBajo Sesgo y Alta Varianza: Overfitting."
  },
  {
    "objectID": "tics579/clase-4.html#model-validation",
    "href": "tics579/clase-4.html#model-validation",
    "title": "TICS-579-Deep Learning",
    "section": "Model Validation",
    "text": "Model Validation\n\nValidación Cruzada\n\n\nSe refiere al proceso de entrenar un modelo en una cierta porción de los datos, pero validar sus rendimiento y capacidad de generalización en un set de datos no vistos por el modelo al momento de entrenar.\n\n\n\n\n\n\n\n¿Qué es la Generalización?\n\n\n\n\n\n\n\n\n\nLos dos métodos más populares que se usan en Machine Learning son Holdout y K-Fold. Más métodos se pueden encontrar en los docs de Scikit-Learn.\n\n\n\n\n\n\n\n\n\nDebido a los volúmenes de datos utilizados, el esquema de validación más utilizado es el Holdout."
  },
  {
    "objectID": "tics579/clase-4.html#model-validation-holdout",
    "href": "tics579/clase-4.html#model-validation-holdout",
    "title": "TICS-579-Deep Learning",
    "section": "Model Validation: Holdout",
    "text": "Model Validation: Holdout\n\n\n\n\n\n\n\n\n\n\n\nTrain\n\n\nCorresponde a la porción de utilizado para que el modelo aprenda.\n\n\n\n\n\n\nValidation\n\n\nCorresponde a la porción de datos no vistos por el modelo durante el entrenamiento. Se utiliza para medir el nivel de generalización del modelo.\n\n\n\n\n\n\nTest\n\n\nSe utiliza para evaluar reportando una métrica de diseño del Modelo.\n\n\n\n\n\n\n\n\n\nA diferencia de un modelo de Machine Learning el proceso de validación del modelo se realiza en conjunto con el entrenamiento. Es decir, se entrena y valida el modelo Epoch a Epoch."
  },
  {
    "objectID": "tics579/clase-4.html#model-validation-k-fold",
    "href": "tics579/clase-4.html#model-validation-k-fold",
    "title": "TICS-579-Deep Learning",
    "section": "Model Validation: K-Fold",
    "text": "Model Validation: K-Fold\n\n\n\n\n\n\n\n\n\n\n\nCorresponde al proceso de Holdout pero repetido \\(K\\) veces. No es tan utilizado en Deep Learning debido a los altos costos computacionales."
  },
  {
    "objectID": "tics579/clase-4.html#pytorch",
    "href": "tics579/clase-4.html#pytorch",
    "title": "TICS-579-Deep Learning",
    "section": "Pytorch",
    "text": "Pytorch\n\nEs una librería de manipulación de Tensores especializada en Deep Learning. Provee principalmente, manipulación de tensores (igual que Numpy, pero en GPU), además de Autograd (calcula derivadas de manera automática).\n\nPara poder comenzar a utilizarlo se requieren normalmente 3 imports:\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\n\n👀\n\n\n\ntorch es donde se encuentran la mayoría de funciones básicas para manipular tensores.\ntorch.nn es donde se encuentran los módulos necesarios para poder crear redes neuronales (neural networks). Cada módulo es una clase en Python.\ntorch.nn.functional es donde se encontrarán utility functions además de versiones funcionales de elementos de torch.nn.\n\n\n\n\n\n\n\n\n\n\n👀 Una versión funcional es capaz de replicar la operación de un módulo pero no tiene la capacidad de almacenar los parámetros aprendidos."
  },
  {
    "objectID": "tics579/clase-4.html#pytorch-modelo",
    "href": "tics579/clase-4.html#pytorch-modelo",
    "title": "TICS-579-Deep Learning",
    "section": "Pytorch: Modelo",
    "text": "Pytorch: Modelo\n\n\n\n\n\n\nUna capa en Pytorch\n\n\n\nSon elementos importados desde torch.nn.\nEstos módulos deben ser instanciados para luego ser utilizados.\nCada capa tiene guarda sus parámetros como atributos:\n\n.weight.data y .bias.data (para los pesos y bias respectivos).\nOjo: Pytorch utiliza los parámetros de manera transpuesta a como lo aprendimos en clases.\n\n\n\n\n\n\n## Ejemplo de un capa de parámetros en Pytorch\n## Proyecta desde 4 dimensiones a 12 dimensiones\nfc1 = nn.Linear(in_features = 4, out_features=12)\n\n## Forward Pass:\n## Calcula las activaciones de la capa\nfc1(X)\n\n\n\n\nOutput: Activaciones de la capa\n\n\n\n\n\n\n\n\ntensor([[ 0.2620, -0.5313, 0.3907, …, -0.0451, -1.2113, -2.9476], [-1.2096, -0.2586, -0.1372, …, 0.1342, -1.1130, -1.4764], [-1.7676, -0.3754, -0.3786, …, 0.2964, -1.2234, -1.6176], …, [-2.1432, -0.3500, -0.5168, …, 0.3048, -1.1075, -1.1932], [-2.6030, 0.0033, -0.6494, …, 0.8202, -1.6117, -1.0077], [ 0.1126, -0.4532, 0.3573, …, 0.0660, -1.0688, -2.4856]], grad_fn=)\n:::\n:::{.column}\n\n::: {.callout-tip style=\"font-size: 90%;\" icon=false appearance=\"default\"} \n## Un clase en Pytorch permite crear redes más complejas y poseen 2 métodos principales:\n  * Todas las clases deben heredar de `nn.Module`.\n\n* `__init__()`:\n  * Se inicializan los módulos con `super().__init__()`.\n  * Se definen las capas de la red como atributos de la clase.\n    * self.nombre_de_la_capa = nn.Capa(...)\n    * self.funcion = nn.Funcion(...)\n* `forward()`:\n  * Define como se conectan las capas en el Forward Pass.\n\n:::\n\n```{.python style=\"font-size: 110%;\"}\nclass MLP(nn.Module):\n  def __init__(self, in_features, out_features):\n    super().__init__()\n    \n    ## Defincición de capas\n    self.fc1 = nn.Linear(in_features, out_features)\n\n  def forward(self,x):\n    x = self.fc1(x)\n    return x\n\nmodel = MLP(in_features=4, out_features = 12)\nmodel(X)"
  },
  {
    "objectID": "tics579/clase-4.html#pytorch-crear-modelos-más-complejos",
    "href": "tics579/clase-4.html#pytorch-crear-modelos-más-complejos",
    "title": "TICS-579-Deep Learning",
    "section": "Pytorch: Crear modelos más complejos",
    "text": "Pytorch: Crear modelos más complejos\n\n\nclass MLP2(nn.Module):\n  def __init__(self, in_features, out_features):\n    super().__init__()\n    self.fc1 = nn.Linear(in_features, out_features)\n    self.relu = nn.ReLU(inplace = True)\n    self.fc2 = nn.Linear(out_features, 1)\n\n  def forward(self,x):\n    x = self.fc1(x)\n    x = self.relu(x)\n    x = self.fc2(x)\n    return x\n\nclass SuperMLP(nn.Module):\n  def __init__(self):\n    super().__init__()\n    self.mlp1 = MLP(in_features=4, out_features=12)\n    self.mlp2 = MLP2(in_features=12, out_features=8)\n  def forward(self, x):\n    x = self.mlp1(x)\n    x = self.mlp2(x)\n    return x\n\nsuper_model = SuperMLP()\nlogits = super_model(X)\nlogits.shape\n\n\n\n\n\nEs posible combinar distintos nn.Module en un sólo modelo.\n\n\n\n\n\n\n\n\n\n\n\n\nsuper_model\nSuperMLP(\n  (mlp1): MLP(\n    (fc1): Linear(in_features=4, out_features=12, bias=True)\n  )\n  (mlp2): MLP2(\n    (fc1): Linear(in_features=12, out_features=8, bias=True)\n    (relu): ReLU()\n    (fc2): Linear(in_features=8, out_features=1, bias=True)\n  )\n)"
  },
  {
    "objectID": "tics579/clase-4.html#pytorch-visualización-del-modelo",
    "href": "tics579/clase-4.html#pytorch-visualización-del-modelo",
    "title": "TICS-579-Deep Learning",
    "section": "Pytorch: Visualización del Modelo",
    "text": "Pytorch: Visualización del Modelo\n\n\n\n\n\n\n\n\nsuper_model\nSuperMLP(\n  (mlp1): MLP(\n    (fc1): Linear(in_features=4, out_features=12, bias=True)\n  )\n  (mlp2): MLP2(\n    (fc1): Linear(in_features=12, out_features=8, bias=True)\n    (relu): ReLU()\n    (fc2): Linear(in_features=8, out_features=1, bias=True)\n  )\n)\nfrom torchinfo import summary\nsummary(super_model)\n=================================================================\nLayer (type:depth-idx)                   Param #\n=================================================================\nSuperMLP                                 --\n├─MLP: 1-1                               --\n│    └─Linear: 2-1                       60\n├─MLP2: 1-2                              --\n│    └─Linear: 2-2                       104\n│    └─ReLU: 2-3                         --\n│    └─Linear: 2-4                       9\n=================================================================\nTotal params: 173\nTrainable params: 173\nNon-trainable params: 0\n================================================================="
  },
  {
    "objectID": "tics579/clase-4.html#pytorch-optimizador-y-loss-function",
    "href": "tics579/clase-4.html#pytorch-optimizador-y-loss-function",
    "title": "TICS-579-Deep Learning",
    "section": "Pytorch: Optimizador y Loss Function",
    "text": "Pytorch: Optimizador y Loss Function\n\n\n\nLoss Function\n\n\n\nEl Loss Function a utilizar le llamaremos criterion.\n\n\n\n\ncriterion = nn.BCEWithLogitsLoss()\n\n\n\nOptimizer\n\n\n\nEl Optimizador lo llamaremos optimizer y se importa desde torch.optim.\nAdemás el optimizador debe ser instanciado junto con los parámetros del modelo y la tasa de aprendizaje lr (learning rate).\n\n\n\n\noptimizer = torch.optim.Adam(super_model.parameters(), lr = 3e-4)"
  },
  {
    "objectID": "tics579/clase-4.html#pytorch-training-loop",
    "href": "tics579/clase-4.html#pytorch-training-loop",
    "title": "TICS-579-Deep Learning",
    "section": "Pytorch: Training Loop",
    "text": "Pytorch: Training Loop\n\n\nloss_history = []\nfor e in range(epochs):\n  # Definición del modo del Modelo\n  super_model.train()\n  optimizer.zero_grad()\n\n  # Forward Pass\n  logits = super_model(X)\n  loss = criterion(logits, y)\n  ## Calcula los gradientes (Backward Pass)\n  loss.backward()\n\n  # Actualización de los Pesos\n  optimizer.step()\n\n  # Log del Modelo\n  loss_history.append(loss.item())\n\n\n\n\n\n\n\n\n\n\n\nElementos clave del Training Loop\n\n\n\nPytorch requiere fijar el Modo de la Red. Para entrenar se utiliza model.train().\n\nPytorch tiene la costumbre de Acumular Gradientes. Por lo tanto, antes de cada Loop, se deben reiniciar los gradientes a cero utilizando optimizer.zero_grad().\n\nEl Forward Pass lo llamaremos con logits = super_model(X). Esto permite calcular los Logits y las variables intermedias necesarias para el Backward Pass.\nEl error/loss de la red lo calculamos con loss = criterion(logits, y).\nEl cálculo de gradientes lo llamaremos loss.backward(). Esto calcula los gradientes y los acumula en cada parámetro del modelo.\nEl optimizador lo llamaremos optimizer. Y llamaremos al proceso de actualizar pesos como optimizer.step()."
  },
  {
    "objectID": "tics579/clase-4.html#pytorch-validation-loop",
    "href": "tics579/clase-4.html#pytorch-validation-loop",
    "title": "TICS-579-Deep Learning",
    "section": "Pytorch: Validation Loop",
    "text": "Pytorch: Validation Loop\n\n\nloss_history = []\nval_loss_history = []\nfor e in range(epochs):\n  # Definición del modo del Modelo\n  super_model.train()\n  optimizer.zero_grad()\n\n  # Forward Pass\n  logits = super_model(X)\n  loss = criterion(logits, y)\n  ## Calcula los gradientes (Backward Pass)\n  loss.backward()\n\n  # Actualización de los Pesos\n  optimizer.step()\n\n  # Log de Entrenamiento\n  loss_history.append(loss.item())\n\n  # Validation Loop\n  super_model.eval()\n\n  # Evita cálculo de gradientes\n  with torch.no_grad():\n    val_logits = super_model(X_val)\n    val_loss = criterion(val_logits, y_val)\n    # Log de Validación\n    val_loss_history.append(val_loss.item())\n\n\n\n\n\n\n\n\n\n\nElementos clave del Validation Loop\n\n\n\nSe debe fijar el modo del modelo a evaluación con model.eval(). No es necesario calcular gradientes en Validación ya que no hay actualización de parámetros.\n\nwith torch.no_grad(): desactiva el cálculo de gradientes.\n\nEl Forward Pass lo llamaremos con val_logits = super_model(X_val). Esto permite calcular los Logits para poder calcular el loss de Validación.\nEl error/loss de la red lo calculamos como val_loss = criterion(val_logits, y_val)."
  },
  {
    "objectID": "tics579/clase-4.html#pytorch-model-evaluation",
    "href": "tics579/clase-4.html#pytorch-model-evaluation",
    "title": "TICS-579-Deep Learning",
    "section": "Pytorch: Model Evaluation",
    "text": "Pytorch: Model Evaluation\n\n\nNos referimos a la evaluación del modelo como la medición de la performance esperada por nuestro modelo. La Evaluación del Modelo se realiza en torno a una métrica definida a priori por el modelador. La métrica a utilizar está íntimamente ligada al problema a resolver.\n\n\n\n\nClasificación\n\n\\(Accuracy = \\frac{1}{m} \\sum_{i = 1}^m 1\\{y_i = \\hat{y_i}\\}\\)\n\\(Precision = \\frac{TP}{TP + FP}\\)\n\\(Recall = \\frac{TP}{TP + FN}\\)\n\\(F1-Score = 2 \\cdot \\frac{Precision \\cdot Recall}{Precision + Recall}\\)\n\n\nRegresión\n\n\\(RMSE = \\frac{1}{m} \\sum_{i=1}^m (y_i-\\hat{y_i})^2\\)\n\\(MAE = \\frac{1}{m} \\sum_{i=1}^m |y_i - \\hat{y_i}|\\)\n\\(MAPE = 100 \\cdot \\frac{1}{m} \\sum_{i=1}^m \\frac{|y_i-\\hat{y_i}|}{max(\\epsilon,y_i)}\\)\n\\(SMAPE = \\frac{2}{m} \\sum_{i=1}^2 \\frac{|y_i - \\hat{y_i}  |}{max(|y_i + \\hat{y_i}|,\\epsilon)}\\)\n\n\n\n\n\n🤓\n\n\nLas métricas presentadas son las básicas para clasificación y regresión. Existen otras más específicas según el campo:\n\nIoU en segmentación semántica,\nMAP@k en recomendación,\nBLEU o ROUGE en NLP, etc.\nUna lista extensa puede consultarse en Torchmetrics ."
  },
  {
    "objectID": "tics579/clase-4.html#pytorch-training-validation-loop-evaluación",
    "href": "tics579/clase-4.html#pytorch-training-validation-loop-evaluación",
    "title": "TICS-579-Deep Learning",
    "section": "Pytorch: Training-Validation Loop + Evaluación",
    "text": "Pytorch: Training-Validation Loop + Evaluación\n\n\nloss_history, val_loss_history = [], []\ntrain_metric_history, val_metric_history = [], []\nfor e in range():\n  train_metric = BinaryAccuracy()\n  val_metric = BinaryAccuracy()\n\n  ## Training Loop\n  super_model.train()\n  optimizer.zero_grad()\n  logits = super_model(X)\n  loss = criterion(logits, y)\n  loss.backward()\n  optimizer.step()\n  loss_history.append(loss.item())\n  acc = train_metric(logits, y)\n  train_metric_history.append(acc)\n  tr_acc = train_metric.compute()\n\n  # Validation Loop\n  super_model.eval()\n  with torch.no_grad():\n    val_logits = super_model(X_val)\n    val_loss = criterion(val_logits, y_val)\n    val_loss_history.append(val_loss.item())\n    acc = train_metric(val_logits, y_val)\n    val_metric_history.append(acc)\n    val_acc = test_metric.compute()\n\n\n\n\n\n\n\n\n\n\nElementos clave de este loop\n\n\n\nAdicional al cálculo de Loss se calcula alguna métrica de interés para el problema.\nSe pueden loguear cuantas métricas se deseen."
  },
  {
    "objectID": "tics579/clase-4.html#monitoreo-de-un-modelo-validation-curve",
    "href": "tics579/clase-4.html#monitoreo-de-un-modelo-validation-curve",
    "title": "TICS-579-Deep Learning",
    "section": "Monitoreo de un Modelo: Validation Curve",
    "text": "Monitoreo de un Modelo: Validation Curve\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEs importante ser capaz de identificar el momento exacto en el cual el momento comienza su overfitting. Para ello se utiliza el “Checkpointing”.\n\n\n\n\n\n\n\n\n\nCheckpoint\n\n\n\nCorresponde a un snapshot del modelo a un cierto punto. En la práctica se almacenan los parámetros del mejor modelo y del último Epoch.\n\n\n\n\n\n\n\n\n\n\nEarlyStopping\n\n\n\nTeoricamente, una vez que la red Neuronal alcanza el punto de Overfitting ya no tiene sentido seguir el entrenamiento. Por lo tanto es posible detener el entrenamiento bajo una cierta condición."
  },
  {
    "objectID": "tics579/clase-4.html#entrenamiento-eficiente-gpu",
    "href": "tics579/clase-4.html#entrenamiento-eficiente-gpu",
    "title": "TICS-579-Deep Learning",
    "section": "Entrenamiento Eficiente: GPU",
    "text": "Entrenamiento Eficiente: GPU\nLa principal ventaja de frameworks como Pytorch es su ejecución en GPU, la cual ofrece una enorme capacidad de cómputo por la gran cantidad de núcleos.\n\n\n\n\n🤓 Las GPUs usan CUDA (una variante compleja de C++), por lo que los errores suelen ser crípticos. Por ello se recomienda desarrollar en CPU y pasar a GPU solo cuando el código ya funcione correctamente y sea necesario entrenar.\n\n\n\n\n\n\n\n## Permite automáticamente reconocer si es que existe GPU en el sistema \n## y de existir lo asigna como el dispositivo de entrenamiento.\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n\n\n\n🖥️ El código anterior es particularmente útil para plataformas como Google Colab donde se permite activar o desactivar el uso de GPU.\n\n\n\n\n\n\n\n## Fija el dispositivo de entrenamiento a CPU\ndevice = torch.device(\"cpu\")"
  },
  {
    "objectID": "tics579/clase-4.html#entrenamiento-eficiente-pytorch-dataset",
    "href": "tics579/clase-4.html#entrenamiento-eficiente-pytorch-dataset",
    "title": "TICS-579-Deep Learning",
    "section": "Entrenamiento Eficiente: Pytorch Dataset",
    "text": "Entrenamiento Eficiente: Pytorch Dataset\nPytorch posee varias estrategias para hacer más eficiente el entrenamiento de Redes Neuronales. Dentro de las estrategias más comunes está el entrenamiento en GPU en Mini Batches.\n\n\n\nPytorch Dataset\n\n\nCorresponde a una clase que hereda de torch.utils.data.Dataset, la cual define la forma en que se cargan los datos. Su principal ventaja es que permite realizar una carga perezosa (lazy loading), es decir, los datos se leen únicamente en el momento en que son requeridos.\n\n\n\n\n\nfrom torch.utils.data import Dataset\n\nclass ExampleDataset(Dataset):\n  def __init__(self, x,y):\n    ## Convertimos a numpy arrays\n    self.X = x.to_numpy()\n    self.y = y.values\n\n  def __len__(self):\n    return len(self.X)\n\n  def __getitem__(self, idx):\n    return dict(\n        ## Tranformarmos cada índice en Tensor de Floats.\n        x=torch.from_numpy(self.X)[idx].float(),\n        y=torch.from_numpy(self.y)[idx].float()\n        )\n\ntrain_data = ExampleDataset(X_train, y_train)\nval_data = ExampleDataset(X_val, y_val)\n\n\n\n\n__init__: Inicializa el dataset solicitando los datos requeridos.\n\n\n\n\n\n\n\n\n\n__len__: Define como se calcula la cantidad de muestras del dataset.\n\n\n\n\n\n\n\n\n\n__getitem__: Define qué devuelve el elemento \\(i\\) del dataset. Es decir train_data[i] o val_data[i]."
  },
  {
    "objectID": "tics579/clase-4.html#entrenamiento-eficiente-pytorch-dataloader",
    "href": "tics579/clase-4.html#entrenamiento-eficiente-pytorch-dataloader",
    "title": "TICS-579-Deep Learning",
    "section": "Entrenamiento Eficiente: Pytorch Dataloader",
    "text": "Entrenamiento Eficiente: Pytorch Dataloader\n\n\n\nPytorch Dataloader\n\n\nCorresponde a una clase que permite cargar los datos por batch. Además permite paralelizar la carga de datos utilizando múltiples workers y controlar aspectos como qué hacer con el último batch (si es que no es completo) o si es necesario mezclar los datos (shuffling). La instancia del Dataloader también es lazy.\n\n\n\nfrom torch.utils.data import DataLoader\ntrain_loader=DataLoader(train_data, batch_size=32, num_workers=10, pin_memory=True, drop_last=True, shuffle=True)\nval_loader=DataLoader(val_data, batch_size=32, num_workers=10, pin_memory=True, shuffle=False)\n\n\nbatch_size: Tamaño del mini-batch.\nnum_workers: Número de procesos a utilizar para cargar los datos.\npin_memory: Si es True, las GPU destinan un espacio especial en memoria para acelerar la transferencia de datos.\ndrop_last: Si es True, se descarta el último batch si no es completo.\nshuffle: Si es True, se mezclan los datos en cada epoch.\n\n\n\n\n\nPara entrenar en GPU es necesario que el modelo y los datos estén GPU.\n\n\n\n\n\n\n\n\n\nPara pasar el modelo a la GPU se utiliza super_model.to(device).\n\n\n\n\n\n\n\n\n\nPara pasar los datos a la GPU se utiliza X.to(device) o y.to(device)."
  },
  {
    "objectID": "tics579/clase-4.html#pytorch-training-validation-loop-dataloader",
    "href": "tics579/clase-4.html#pytorch-training-validation-loop-dataloader",
    "title": "TICS-579-Deep Learning",
    "section": "Pytorch: Training-Validation Loop + Dataloader",
    "text": "Pytorch: Training-Validation Loop + Dataloader\n\n\n  epoch_loss=dict(train=[], val=[])\n  epoch_metric=dict(train=[], val=[])\n  super_model.to(device)\n  for e in range(epochs):\n    train_metric, val_metric = BinaryAccuracy(), BinaryAccuracy()\n    batch_loss=dict(train=[], val=[])\n\n    model.train()\n    for batch in train_loader:\n      X, y = batch[\"x\"].to(device), batch[\"y\"].to(device)\n      optimizer.zero_grad()\n      logits = super_model(X)\n      loss = criterion(logits, y)\n      loss.backward()\n      acc = train_metric(logits, y)\n      optimizer.step()\n      batch_loss[\"train\"].append(loss.item())\n\n    tr_acc = train_metric.compute()\n    train_epoch_loss = np.mean(batch_loss[\"train\"])\n    epoch_metric[\"train\"].append(tr_acc)\n\n    model.eval()\n    with torch.no_grad():\n      for batch in val_loader:\n        X, y = batch[\"x\"].to(device), batch[\"y\"].to(device)\n        logits = super_model(X)\n        loss = criterion(logits, y)\n        batch_loss[\"val\"].append(loss.item())\n        acc = val_metric(logits, y)\n\n      val_acc = val_metric.compute()\n      val_epoch_loss = np.mean(batch_loss[\"val\"])\n      epoch_metric[\"val\"].append(val_acc)\n\n    epoch_loss[\"train\"].append(train_epoch_loss)\n    epoch_loss[\"val\"].append(val_epoch_loss)\n\n\n\n\n\n👀 Detalles clave de este loop\n\n\n\nTanto para el Training Loop como para el Validation Loop se itera sobre el DataLoader en la GPU.\nSe definen métricas dentro de la Epoch. Las cuales serán utilizadas para calcular por batch y por epoch (utilizando .compute()).\nSe definen métricas separadas para entrenamiento y validación.\nNormalmente se loguean el Loss y una o más métricas por Epoch para construir las curvas de validación.\n\n\n\n\n\n\n\n\n\n\n\n\nDetach\n\n\nEn ocasiones no es posible convertir un tensor a un valor numérico (float, int, etc) si es que el tensor requiere gradientes. En estos casos es necesario “desconectar” el tensor del grafo de cómputo utilizando .detach() y luego conviertiendolo a Numpy.\n\n\n\n\ndata.detach().numpy()"
  },
  {
    "objectID": "tics579/clase-4.html#categorical-variables-one-hot-encoding",
    "href": "tics579/clase-4.html#categorical-variables-one-hot-encoding",
    "title": "TICS-579-Deep Learning",
    "section": "Categorical Variables: One Hot Encoding",
    "text": "Categorical Variables: One Hot Encoding\nHasta ahora hemos asumido que las variables de entrada son numéricas. Pero en la práctica es muy común encontrarse con variables categóricas. En Deep Learning existen dos técnicas para lidiar con este tipo de variables: One-Hot-Encoding y el uso de Embeddings.\n\n\n\n\n\n📋 One-Hot-Encoding\n\n\n\nPermite una representación dispersa (sparse) de las variables categóricas. Consiste en crear una columna por cada categoría, y asignar un 1 o un 0 dependiendo si la instancia pertenece o no a dicha categoría.\nEs una representación estática sin parámetros entrenables asociados.\nGenera tantas columnas/features nuevas como categorías existan en la variable original. Por lo tanto, puede generar problemas de dimensionalidad si existen muchas categorías."
  },
  {
    "objectID": "tics579/clase-4.html#categorical-variables-embeddings",
    "href": "tics579/clase-4.html#categorical-variables-embeddings",
    "title": "TICS-579-Deep Learning",
    "section": "Categorical Variables: Embeddings",
    "text": "Categorical Variables: Embeddings\n\n\n\n\n\n🗞️ Embeddings\n\n\n\nUn embedding es una representación numérica de un objeto (palabra, imagen, nodo, etc.) en un espacio vectorial de menor dimensión que captura sus características y relaciones de manera útil para un modelo de machine learning.\nEn lugar de trabajar con las categorías crudas, los embeddings convierten esos datos en vectores de números reales. De esta forma, objetos similares quedan representados por vectores cercanos.\nLos vectores son aprendidos por el modelo durante el entrenamiento, de tal manera que la representación aprendida es la optima para el problema específico a resolver. Es decir, agrega parámetros entrenables al modelo."
  },
  {
    "objectID": "tics579/clase-4.html#aplicación-en-pytorch",
    "href": "tics579/clase-4.html#aplicación-en-pytorch",
    "title": "TICS-579-Deep Learning",
    "section": "Aplicación en Pytorch",
    "text": "Aplicación en Pytorch\n\n\n\n\n\nOne Hot Encoding\n\n\nSe puede utilizar directamente en Pytorch utilizando F.one_hot(). En general esto se hace fuera del modelo y no es una capa entrenable.\n\n\n\n\n\n\nEmbedding\n\n\nEste caso sí es una capa entrenable y se aplica en Pytorch como una capa más del modelo utilizando nn.Embedding().\n\n\n\nnn.Embedding(num_embeddings, embedding_dim)\n\nnum_embeddings: Corresponde al número de categórías.\nembedding_dim: El número de dimensiones en el cual se quiere representar.\n\n\n\n\n\n\n\n\n\n\n🤓 Projection Layer\n\n\nEn algunos casos se agrega una Projection Layer (capa lineal) en las variables numéricas a una nueva dimensión (Esto ya que el Embedding lleva a las variables categóricas a una dimensión diferente). Esto permite que el modelo aprenda una representación conjunta de las variables numéricas y categóricas. Luego las capas de proyección y embedding se concatenan y se pasan a las capas siguientes."
  },
  {
    "objectID": "tics579/clase-4.html#embedding-ejemplo",
    "href": "tics579/clase-4.html#embedding-ejemplo",
    "title": "TICS-579-Deep Learning",
    "section": "Embedding: Ejemplo",
    "text": "Embedding: Ejemplo\n\n\n\\[e=Emb(X)\\] \\[\\phi1 = e \\cdot W1\\] \\[Z = \\phi_1 = + 1_m b^T\\] \\[p = \\sigma(Z)\\] \\[L = \\frac{-1}{m}\\left[y^T log(p) + (1-y)^T log(1-p)\\right]\\]\n\n\n\n🤓 No haremos la derivación completa, sólo nos enfocaremos en el Gradiente del Embedding."
  },
  {
    "objectID": "tics579/clase-4.html#embedding-ejemplo-1",
    "href": "tics579/clase-4.html#embedding-ejemplo-1",
    "title": "TICS-579-Deep Learning",
    "section": "Embedding: Ejemplo",
    "text": "Embedding: Ejemplo\n\\[\\frac{\\partial L}{\\partial Z} = \\frac{1}{m} \\cdot [p - y]\\] \\[\\frac{\\partial L}{\\partial \\phi_1} = \\frac{1}{m} \\cdot [p - y]\\] \\[\\frac{\\partial L}{\\partial e} = \\frac{\\partial L}{\\partial \\phi_1} \\cdot \\frac{\\partial \\phi_1}{\\partial e}= \\frac{1}{m}[p-y] \\cdot W_1^T \\] \\[\\frac{\\partial}{\\partial E} = \\frac{\\partial L}{\\partial e} \\cdot \\frac{\\partial e}{\\partial E} = \\frac{1}{m} [p-y] \\cdot W_1^T \\cdot \\frac{\\partial e}{\\partial E}\\]\n\n\n\n¿Cuánto vale \\(\\frac{\\partial e}{\\partial E}\\)?\n\n\n\\[\\frac{\\partial e}{\\partial E} = S^T\\]\nDonde \\(S\\) es es la matriz One-Hot-Encoding de tamaño \\(m \\times C\\) donde C es el número de categorías."
  },
  {
    "objectID": "tics579/clase-4.html#embedding-ejemplo-numérico",
    "href": "tics579/clase-4.html#embedding-ejemplo-numérico",
    "title": "TICS-579-Deep Learning",
    "section": "Embedding: Ejemplo Numérico",
    "text": "Embedding: Ejemplo Numérico\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\[\ne = \\begin{bmatrix}\n0.1000 & 0.2000 & 0.3000 \\\\\n0.4000 & 0.0000 & -0.1000 \\\\\n0.2000 & -0.2000 & 0.1000 \\\\\n0.4000 & 0.0000 & -0.1000\n\\end{bmatrix}\n\\]"
  },
  {
    "objectID": "tics579/clase-4.html#embedding-ejemplo-numérico-1",
    "href": "tics579/clase-4.html#embedding-ejemplo-numérico-1",
    "title": "TICS-579-Deep Learning",
    "section": "Embedding: Ejemplo Numérico",
    "text": "Embedding: Ejemplo Numérico\n\n\n\\[\n\\phi_1 = \\begin{bmatrix}\n0.0300 \\\\\n0.1900 \\\\\n0.1600 \\\\\n0.1900\n\\end{bmatrix}\n\\]\n\\[\nZ = \\begin{bmatrix}\n0.1300 \\\\\n0.2900 \\\\\n0.2600 \\\\\n0.2900\n\\end{bmatrix}\n\\]\n\\[\np = \\begin{bmatrix}\n0.5325 \\\\\n0.5720 \\\\\n0.5646 \\\\\n0.5720\n\\end{bmatrix}\n\\]\n\n\\[\n\\begin{align}\n\\frac{\\partial L}{\\partial E} &= \\frac{1}{m} S^T \\cdot [p - y] \\cdot W_1^T\\\\\n&= \\frac{1}{4} \\cdot\n\\begin{bmatrix}\n1 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 0 \\\\\n0 & 1 & 0 & 1 \\\\\n0 & 0 & 1 & 0\n\\end{bmatrix} \\cdot\n\\left[\\begin{bmatrix}\n0.5325 \\\\\n0.5720 \\\\\n0.5646 \\\\\n0.5720\n\\end{bmatrix} -\n\\begin{bmatrix}\n1.0 \\\\\n0.0 \\\\\n1.0 \\\\\n0.0\n\\end{bmatrix}\n\\right] \\cdot \\begin{bmatrix}\n0.5 & -0.25 & 0.1\n\\end{bmatrix}\\\\\n&=\\begin{bmatrix}\n-0.0584 & 0.0292 & -0.0117 \\\\\n0.0000 & -0.0000 & 0.0000 \\\\\n0.0000 & -0.0000 & 0.0000 \\\\\n0.1430 & -0.0715 & 0.0286 \\\\\n-0.0544 & 0.0272 & -0.0109\n\\end{bmatrix}\n\\end{align}\n\\]"
  },
  {
    "objectID": "tics579/clase-3.html#feed-forward-networks-1",
    "href": "tics579/clase-3.html#feed-forward-networks-1",
    "title": "TICS-579-Deep Learning",
    "section": "Feed Forward Networks",
    "text": "Feed Forward Networks\n\nSon redes neuronales que se caracterizan por tener una arquitectura en la que la información fluye en una sola dirección, desde las entradas hasta las salidas. En general todas las neuronas de una capa están conectadas a todas las neuronas de la siguiente capa, sin ciclos ni conexiones recurrentes.\n\n\nTeorema de aproximación Universal\n\n\nUna red neuronal feedforward con al menos una capa oculta y un número finito de neuronas, usando funciones de activación no lineales (como sigmoide, tanh o ReLU), puede aproximar cualquier función continua definida en un conjunto compacto (acotado y cerrado) de \\(\\mathbb{R}^n\\) a cualquier nivel de precisión, siempre que se utilicen suficientes neuronas y se ajusten adecuadamente los pesos y sesgos.\n\n\n\n\n\n\n\n\n\nImportante\n\n\n\nEl teorema dice que es posible encontrar aproximar cualquier función.\nEl teorema no dice ni cómo se hace ni los recursos necesarios para hacerlo (Número de Neuronas, capas, Hiperparámetros, etc.).\n\n\n\n\n\n\n\n\n\n\n\nBásicamente nos están diciendo que tienes la mejor herramienta que existe, pero es tu responsabilidad saber cómo utilizarla y qué recursos necesitas para lograrlo."
  },
  {
    "objectID": "tics579/clase-3.html#feed-forward-networks-ffn",
    "href": "tics579/clase-3.html#feed-forward-networks-ffn",
    "title": "TICS-579-Deep Learning",
    "section": "Feed Forward Networks (FFN)",
    "text": "Feed Forward Networks (FFN)\n\n\n\n\n\n\nEste tipo de Redes tiene distintos nombres que son usados de manera intercambiable:\n\nCapas Lineales: Probablemente por su denominación en Pytorch.\nCapas/Redes Densas: Probablemente por su denominación en Tensorflow.\nMultilayer Perceptron: O también conocido como MLP, debido a que es la generalización del Perceptrón, la primera propuesta de Redes Neuronales de Rosenblatt en 1958.\nProjection Layers: Probablemente por su denominación en algunos papers. Se usa en el contexto de proyectar de \\(n\\) dimensiones a \\(d\\) dimensiones.\n\n\n\n\n\n\n\n\n\n\n\n\nDe ahora en adelante utilizaremos las siguiente notación para referirnos a una Red Neuronal Feed Forward:\n\\[h_\\theta(X) = \\sigma_s(Z)\\]\n\n\n\nLogits\n\n\nDefiniremos \\(Z=\\phi_L(X) W_{L+1} + b_{L+1}^T\\) como Logits y corresponden a las activaciones de la última capa antes de aplicar la función de activación de salida \\(\\sigma_s(.)\\)."
  },
  {
    "objectID": "tics579/clase-3.html#hiperparámetros-de-una-red-neuronal",
    "href": "tics579/clase-3.html#hiperparámetros-de-una-red-neuronal",
    "title": "TICS-579-Deep Learning",
    "section": "Hiperparámetros de una Red Neuronal",
    "text": "Hiperparámetros de una Red Neuronal\n\nHiperparámetros\n\n\nSon las configuraciones externas que no se aprenden durante el entrenamiento, sino que se definen antes de entrenar el modelo y controlan su comportamiento y rendimiento.\n\n\n\n\n\n\n\n🤓 Hiperparámetros de una Red Neuronal\n\n\n\nLearning Rate (Karpathy Constant: 3e-4), valores entre [1e-5, 1e-1] son comunes.\nNúmero de Capas y sus respectivas dimensiones (Para Pesos/Weights y Sesgos/Biases).\nFunciones de Activación para cada capa.\nFunción de Pérdida (Loss Function) a utilizar.\nOptimizador a utilizar.\nPunto de Partida de los Parámetros (Inicialización de Pesos y Sesgos).\n¿Cuánto tiempo debo entrenar mi modelo? ¿Cómo sabemos si es que convergió o no?"
  },
  {
    "objectID": "tics579/clase-3.html#output-de-una-red-neuronal",
    "href": "tics579/clase-3.html#output-de-una-red-neuronal",
    "title": "TICS-579-Deep Learning",
    "section": "Output de una Red Neuronal",
    "text": "Output de una Red Neuronal\n\nEn el aprendizaje supervisado se abordan principalmente dos tipos de problemas: clasificación y regresión. Según el tipo de problema, la hipótesis debe adoptar una forma distinta en la capa de salida.\n\n\n\n\n\n⚠️ Dimensión de Salida\n\n\nEstá definida por el número de valores a predecir para cada observación. Denominaremos \\(k\\) como la dimensión de salida.\nPara una red de dos capas:\n\\[\\phi_0(X) = X\\] \\[\\phi_1(X) = \\sigma_1(W_1 \\cdot \\phi_0(X) + \\bar{b_1}^T)\\] \\[\\phi_2(X) = \\sigma_2(W_2 \\cdot \\phi_1(X) + \\bar{b_2}^T)\\]\nDonde \\(W_1 \\in \\mathbb{R}^{n \\times d_1}\\) y \\(W_2 \\in \\mathbb{R}^{d_1 \\times k}\\) y \\(b_1 \\in \\mathbb{R}^{d_1}\\) y \\(b_2 \\in \\mathbb{R}^{k}\\).\n\n\n\n\n\n\n\n\n✅ Activación de la Salida\n\n\nSegún el tipo de problema, la capa de salida puede necesitar una función de activación particular que ajuste los resultados al formato correcto. En este sentido, \\(\\sigma_2\\) estará determinada por la naturaleza del problema a resolver."
  },
  {
    "objectID": "tics579/clase-3.html#consejos-para-el-output-de-una-red",
    "href": "tics579/clase-3.html#consejos-para-el-output-de-una-red",
    "title": "TICS-579-Deep Learning",
    "section": "Consejos para el Output de una Red",
    "text": "Consejos para el Output de una Red\n\n\n\n\n\nClasificación Binaria\n\n\nEl approach más común utiliza \\(k=1\\) con una Sigmoide para calcular la probabilidad de la clase 1. Otros approach utilizan \\(k=2\\) para calcular la probabilidad de ambas clases (Activando con Softmax).\n\n\n\n\n\n\nClasificación Multiclase\n\n\nUtiliza \\(k=C\\) donde C es el número de clases a clasificar. Se usa una función Softmax para transformar el output en una distribución de probabilidades.\n\n\n\n\n\n\nClasificación Multilabel\n\n\nSe requiere un \\(k=C\\) donde C es el número de clases a clasificar. Se usa una función Sigmoide para transformar cada clase en probabilidades.\n\n\n\n\n\n\n\nRegresión Simple\n\n\nSe requiere un \\(k=1\\). Típicamente no requiere de funciones adicionales aunque a veces se agregan funciones para acotar la salida.\n\n\n\n\n\n\nRegresión Multiple\n\n\nSe requiere un \\(k=V\\) con V el número de valores a predecir. Se deben tener las mismas consideraciones para acotar la salida.\n\n\n\n\n\n\n\n\n👀 Muy Importante\n\n\nEn la mayoría de las implementaciones en Código la activación de la salida va embebida en la Loss Function. Por lo tanto, no es necesario aplicar una función de activación explícita en la capa de salida. Aunque sí deben aplicarse al momento de la Predicción del modelo."
  },
  {
    "objectID": "tics579/clase-3.html#funciones-de-activación",
    "href": "tics579/clase-3.html#funciones-de-activación",
    "title": "TICS-579-Deep Learning",
    "section": "Funciones de Activación",
    "text": "Funciones de Activación\n\nActivation Functions\n\nCorresponden a las funciones que agregarán características no lineales a cada activación, impidiendo la composición de transformaciones Affine.\n\n\n\n\n\n🤓 Convención para Código\n\n\nEn Pytorch, nunca aplicaremos una función de activación a la capa de salida.\n\n\n\n\n\n\n\n\n\nCuidado\n\n\nOtros frameworks como Tensorflow, Keras, etc. utilizan una convención distinta y aplican funciones de activación a la capa de salida.\n\n\n\n\n\n\n¿Puedo aplicar distintas Funciones de Activación a cada Neurona?\n\n\nPuedo, pero no se hace. Complicaría muchísimo la implementación.\n\n\n\nActivation Functions in Pytorch."
  },
  {
    "objectID": "tics579/clase-3.html#funciones-de-activación-1",
    "href": "tics579/clase-3.html#funciones-de-activación-1",
    "title": "TICS-579-Deep Learning",
    "section": "Funciones de Activación",
    "text": "Funciones de Activación\nSigmoide\n\n\n\n\n\n\n\n\n\n\n\n\nDefinición\n\n\n\\[\\sigma(z) = \\frac{1}{1 + e^{-z}}\\]\n\n\n\n\n\n\n\nPropiedades\n\n\n\nAcota la salida entre 0 y 1.\nSu derivada es \\(\\sigma'(z) = \\sigma(z)(1 - \\sigma(z))\\).\nSu gradiente es general es muy pequeño, lo que lleva a problemas de Vanishing Gradient.\nSu principal uso es en la capa de salida para problemas de clasificación binaria y Clasificación Multilabel."
  },
  {
    "objectID": "tics579/clase-3.html#funciones-de-activación-2",
    "href": "tics579/clase-3.html#funciones-de-activación-2",
    "title": "TICS-579-Deep Learning",
    "section": "Funciones de Activación",
    "text": "Funciones de Activación\nSoftmax\n\n\n\n\n\n\n\n\n\n\n\n\nDefinición\n\n\n\\[S_i(z) = \\frac{e^{z_i}}{\\sum_{j=1}^k e^{z_j}}\\]\n\n\n\n\n\n\n\nPropiedades\n\n\n\nTransofrma un vector en una distribución de probabilidad.\nSu principal uso es en la capa de salida para problemas de clasificación multiclase. Es por lejos la función de activación más utilizada en la salida, pero en casos más avanzados también en Mecanismos de Atención."
  },
  {
    "objectID": "tics579/clase-3.html#funciones-de-activación-3",
    "href": "tics579/clase-3.html#funciones-de-activación-3",
    "title": "TICS-579-Deep Learning",
    "section": "Funciones de Activación",
    "text": "Funciones de Activación\nTanh\n\n\n\n\n\n\n\n\n\n\n\n\nDefinición\n\n\n\\[Tanh(z) = \\frac{e^z - e^{-z}}{e^z + e^{-z}}\\]\n\n\n\n\n\n\n\nPropiedades\n\n\n\nAcota su salida entre -1 y 1.\nSu derivada es \\(Tanh'(z) = 1 - Tanh^2(z)\\).\nSu gradiente normalmente es más grande que el de la Sigmoide, pero aún así puede llevar a problemas de Vanishing Gradient.\nA pesar de estar un poco en desuso, tiene un rol protagónico en las Redes Recurrentes (RNNs)."
  },
  {
    "objectID": "tics579/clase-3.html#funciones-de-activación-4",
    "href": "tics579/clase-3.html#funciones-de-activación-4",
    "title": "TICS-579-Deep Learning",
    "section": "Funciones de Activación",
    "text": "Funciones de Activación\nReLU (Rectified Linear Unit)\n\n\n\n\n\n\n\n\n\n\n\n\nDefinición\n\n\n\\[ReLU(z) = max(0, z)\\]\n\n\n\n\n\n\n\nPropiedades\n\n\n\nAcota su salida entre 0 e \\(\\infty\\).\nSu derivada es \\(ReLU'(z) = \\begin{cases}\n1,  & \\text{if $z \\ge$ 0} \\\\\n0 & \\text{if $z &lt; 0$}\n\\end{cases}\\)\nEs la función de activación más utilizada en la actualidad, principalmente en las capas ocultas de las Redes Neuronales.\nSe hizo extremadamente popular por su simplicidad y efectividad en Redes Convolucionales (CNNs)."
  },
  {
    "objectID": "tics579/clase-3.html#funciones-de-activación-modernas",
    "href": "tics579/clase-3.html#funciones-de-activación-modernas",
    "title": "TICS-579-Deep Learning",
    "section": "Funciones de Activación Modernas",
    "text": "Funciones de Activación Modernas\n\n\nLeaky ReLU\n\n\n\n\n\n\\[g(z) = max(0.1z, z)\\]\n\nParametrized ReLU (PReLU)\n\n\n\n\n\n\\[g(z) = max(az, z)\\]"
  },
  {
    "objectID": "tics579/clase-3.html#funciones-de-activación-5",
    "href": "tics579/clase-3.html#funciones-de-activación-5",
    "title": "TICS-579-Deep Learning",
    "section": "Funciones de Activación",
    "text": "Funciones de Activación\n\n\nELU\n \\(g(z) =\n\\begin{cases}\nz,  & \\text{if $z \\ge$ 0} \\\\[2ex]\n\\alpha(e^{z}-1), & \\text{if $z &lt; 0$}\n\\end{cases}\\)\n\nGELU\n \\[\\begin{align} g(z) &= z \\cdot \\Phi(z) \\\\\ng(z)&= 0.5 \\cdot z \\cdot \\left(1 + Tanh\\left(\\sqrt{2/\\pi}\\right) \\cdot \\left(z + 0.044715 \\cdot z^3\\right)\\right)\\end{align}\\]"
  },
  {
    "objectID": "tics579/clase-3.html#funciones-de-activación-6",
    "href": "tics579/clase-3.html#funciones-de-activación-6",
    "title": "TICS-579-Deep Learning",
    "section": "Funciones de Activación",
    "text": "Funciones de Activación\n\n\nSELU\n \\[ g(z) = scale \\cdot (max(0,z) + min(0,\\alpha(e^z - 1)))\\]\ncon \\(\\alpha=1.6732632423543772848170429916717\\) y \\(scale = 1.0507009873554804934193349852946\\)\n\nSwish\n \\[g(z) = z \\cdot sigmoid(z)\\]"
  },
  {
    "objectID": "tics579/clase-3.html#loss-functions-clasificación",
    "href": "tics579/clase-3.html#loss-functions-clasificación",
    "title": "TICS-579-Deep Learning",
    "section": "Loss Functions: Clasificación",
    "text": "Loss Functions: Clasificación\n\nSon las encargadas de medir el error entre la predicción del modelo y el valor real. En general, se busca minimizar la Loss Function durante el entrenamiento del modelo.\n\n\n\n\n\nClasificación Binaria: Binary Cross Entropy\n\n\n\\[BCE(Z) = - \\frac{1}{m}\\left[y^T log(\\sigma(Z)) + (1-y)^T log(1-\\sigma(Z))\\right]\\]\nDonde \\(Z\\) corresponden a los Logits del Modelo.\n\n\n\n\n\n\n\n\n\n\nEn Pytorch esta función se llama BCEWithLogitsLoss.\n\n\n\n\n\n\n\n🤓 Logits\n\n\nSe refiere a las activaciones finales del modelo antes de aplicar la función de activación.\n\n\n\n\n\n\n\n\n\n\n👊 Clasificación Multilabel: BCEWithLogitsLoss\n\n\nEn Pytorch se suele utilizar BCEWithLogitsLoss ya que combina una sigmoide a cada activación de la salida."
  },
  {
    "objectID": "tics579/clase-3.html#loss-functions-clasificación-1",
    "href": "tics579/clase-3.html#loss-functions-clasificación-1",
    "title": "TICS-579-Deep Learning",
    "section": "Loss Functions: Clasificación",
    "text": "Loss Functions: Clasificación\n\n\n\n\nClasificación Multiclase: CrossEntropy\n\n\n\\[CE(Z)= -\\frac{1}{m}Tr(Y^T Log(\\hat{Y}))\\]\nDonde \\(Tr(.)\\) es la traza de una matriz e \\(Y \\in \\{0,1\\}^{m \\times k}\\) es la codificación One-Hot de las etiquetas e \\(\\hat{Y} = Softmax(Z)\\), donde \\(Z\\) son los Logits del modelo.\n\n\n\n\n\n\n\n\n🤓 Traza (\\(Tr(.)\\))\n\n\nCorresponde a la suma de los elementos de la diagonal principal de una matriz.\n\n\n\n\n\n\n\n\nDerivada\n\n\n\\[\\frac{\\partial CE(X)}{\\partial Z} = \\frac{1}{m}\\left(\\hat{Y} - Y\\right)\\]\n\n\n\n\n\n\n\n\n\n\nEn Pytorch se suele utilizar CrossEntropyLoss ya que combina aplica una función Softmax a la capa de salida además de ser una clase numericamente más estable."
  },
  {
    "objectID": "tics579/clase-3.html#ejemplo-de-cálculo-cross-entropy-loss",
    "href": "tics579/clase-3.html#ejemplo-de-cálculo-cross-entropy-loss",
    "title": "TICS-579-Deep Learning",
    "section": "Ejemplo de Cálculo Cross Entropy Loss",
    "text": "Ejemplo de Cálculo Cross Entropy Loss\n\n\n\n\n\n\n\n\\[Y = \\begin{bmatrix}\n1 & 0 & 0 \\\\\n0 & 1 & 0 \\\\\n0 & 0 & 1 \\\\\n0 & 1 & 0\n\\end{bmatrix}\\]\n\n\\[Log(\\hat{Y}) = \\begin{bmatrix}\n-0.1054 & -2.9957 & -2.9957 \\\\\n-4.6052 & -0.2357 & -1.6094 \\\\\n-0.1054 & -2.9957 & -2.9957 \\\\\n-4.6052 & -0.0202 & -4.6052\n\\end{bmatrix}\n\\]\n\\[Y^T \\cdot Log(\\hat{Y}) = \\begin{bmatrix}\n-0.1054 & ... & ... \\\\\n... & -0.2357 - 0.0202 & ... \\\\\n... & ... & -2.9957\n\\end{bmatrix}\n\\]\n\n\n\n\nAtención\n\n\nCada elemento de la diagonal acumula la contribución a la pérdida correspondiente a esa clase por parte de cada registro. Por ejemplo: la columna 1 contiene únicamente la pérdida del primer registro; la columna 2 acumula la pérdida del segundo y cuarto registro; y la columna 3 contiene solo la pérdida del tercer registro.\nSPOILER: El logaritmo de los logits corresponde a la pérdida de cada registro.\nLa pérdida total la da la Traza de la matriz resultante. Luego la pérdida es: \\(\\frac{1}{4} [-0.1054 + (-0.2357 - 0.0202) + (-2.9957)] = 0.8392\\)."
  },
  {
    "objectID": "tics579/clase-3.html#loss-functions-regresión",
    "href": "tics579/clase-3.html#loss-functions-regresión",
    "title": "TICS-579-Deep Learning",
    "section": "Loss Functions: Regresión",
    "text": "Loss Functions: Regresión\n\n\n\n\nRegresión: Mean Squared Error (MSELoss)\n\n\n\\[MSE(Z) = \\frac{1}{m}||Z - \\bar{y}||^2\\]\nDonde \\(||.||\\) corresponde a la norma Euclideana e \\(\\bar{y} \\in \\mathbb{R}^{m \\times 1}\\).\n\n\n\n\n\n\n\n\nDerivada\n\n\n\\[\\frac{\\partial MSE(Z)}{\\partial Z} = \\frac{2}{m}(Z - \\bar{y})\\]"
  },
  {
    "objectID": "tics579/clase-3.html#loss-functions-regresión-1",
    "href": "tics579/clase-3.html#loss-functions-regresión-1",
    "title": "TICS-579-Deep Learning",
    "section": "Loss Functions: Regresión",
    "text": "Loss Functions: Regresión\n\n\n\n\nRegresión: Mean Absolute Error (L1Loss)\n\n\n\\[L1Loss(Z) = \\frac{1}{m}|Z - \\bar{y}|\\]\nDonde \\(||.||\\) corresponde a la norma Euclideana y \\(\\bar{y} \\in \\mathbb{R}^{m \\times 1}\\).\n\n\n\n\n\n\n\n\nDerivada\n\n\n\\[\\frac{\\partial L1Loss(Z)}{\\partial Z} = \\frac{1}{m}sign(Z-\\bar{y})\\]\n\\[\\operatorname{sign}(z) =\n\\begin{cases}\n+1 & \\text{si  z &gt; 0},\\\\[2mm]\n0 & \\text{si z = 0},\\\\[1mm]\n-1 & \\text{si z &lt; 0}\n\\end{cases}\\]"
  },
  {
    "objectID": "tics579/clase-3.html#optimizers-gradient-descent",
    "href": "tics579/clase-3.html#optimizers-gradient-descent",
    "title": "TICS-579-Deep Learning",
    "section": "Optimizers: Gradient Descent",
    "text": "Optimizers: Gradient Descent\n\n\nGradient Descent corresponde al algoritmo de Optimización más popular, pero no necesariamente el más eficiente. Distintas variantes han ido apareciendo para ir mejorando eventuales deficiencias de la proposición inicial.\n\n\n\n\n\nEpochs\n\n\nCorresponden a la cantidad de iteraciones que se realizan a la Update Rule para que el modelo se optimize.\n\n\n\n\n\n\n\nStandard Gradient Descent\n\n\n\\[\\theta := \\theta - \\frac{\\alpha}{m}\\nabla_\\theta L\\]\n\n\n\n\n\n\n\n\n\n\nImportante\n\n\n\nEn Deep Learning, los conjuntos de datos suelen ser tan grandes que calcular el gradiente sobre todos ellos es inviable por memoria y tiempo de cómputo.\nAdicionalmente no basta con calcular el gradiente una vez, sino que se debe hacer varias veces según el número de Epochs definido.\nPracticar Standard Gradient Descent en la práctica es muy poco común, ya que no es eficiente."
  },
  {
    "objectID": "tics579/clase-3.html#minibatch-gradient-descent",
    "href": "tics579/clase-3.html#minibatch-gradient-descent",
    "title": "TICS-579-Deep Learning",
    "section": "Minibatch Gradient Descent",
    "text": "Minibatch Gradient Descent\n\n\n\n\n\n\nLos minibatches permiten estimar el gradiente con un subconjunto de datos, manteniendo la dirección correcta para actualizar los parámetros de manera más eficiente. Se realiza en un subconjunto de \\(B\\) datos donde \\(B &lt;&lt; m\\).\n\n\n\n\\[\\theta := \\theta - \\frac{\\alpha}{B}\\nabla_\\theta L\\]\n\n\n\n👀 Importante\n\n\n\n\\(X \\in \\mathbb{R}^{B \\times n}\\) e \\(y \\in \\mathbb{R}^{B \\times 1}\\) son versiones reducidas de los datos totales. Se deben hacer suficientes minibatches para utilizar todos los datos. El minibatch se implementa en Pytorch utilizando el DataLoader. Cada actualización de parámetros ahora se le denomina step.\nCuando todos los minibatches han sido utilizados, se dice que se ha completado una epoch.\nEs común utilizar un minibatch de tamaño 32, 64, 128, etc.\nA veces se deshecha el último minibatch (remanente) si no tiene el tamaño completo para evitar problemas de estabilidad de gradientes.\n\n\n\n\n\n\n\nPros\n\n\n\nPermite optimizar utilizando menos recursos computacionales.\nAl actualizar los parámetros de manera más frecuente, se puede converger más rápido.\n\n\n\n\n\n\n\nContras\n\n\n\nSi \\(B\\) es muy pequeño, el gradiente puede ser muy ruidoso y no converger.\nEl entrenamiento toma más tiempo que el Standard Gradient Descent."
  },
  {
    "objectID": "tics579/clase-3.html#sgd-with-momentum",
    "href": "tics579/clase-3.html#sgd-with-momentum",
    "title": "TICS-579-Deep Learning",
    "section": "SGD with Momentum",
    "text": "SGD with Momentum\n\n\nUpdate Rule\n\\[\\theta_{t+1} = \\theta_t - \\alpha v_{t + 1}\\] \\[v_{t+1} = \\beta v_{t} + (1-\\beta) \\nabla_\\theta L(\\theta_{t+1})\\]\ndonde \\(0&lt;\\beta&lt;1\\), pero normalmente \\(\\beta=0.9\\).\n\n\n\n\n\n\n\n\n\n\n☝️ Intuición\n\n\n\nEste cálculo se denomina un Exponential Moving Average de los Gradientes. Y se puede interpretar como una especie de velocidad del gradiente. Su objetivo es ponderar con un cierto porcentaje el gradiente actual y el gradiente anterior.\n\\(v_{0} = 0\\)\n\n\n\n\n\\[\\begin{align} v_{t+1}&=(1-\\beta)\\nabla_\\theta L(\\theta_{t}) + \\beta v_t \\\\\nv_{t+1}&=(1-\\beta)\\nabla_\\theta L(\\theta_{t}) + \\beta \\left[(1-\\beta) \\nabla_\\theta L(\\theta_{t-1}) + \\beta v_{t-1}\\right] \\\\\nv_{t+1}&=(1-\\beta)\\nabla_\\theta L(\\theta_{t}) + \\beta (1-\\beta) \\nabla_\\theta L(\\theta_{t-1}) + \\beta^2 (1-\\beta) \\nabla_\\theta L(\\theta_{t-2})... \\\\\n\\end{align}\\]"
  },
  {
    "objectID": "tics579/clase-3.html#sgd-with-nesterov-momentum",
    "href": "tics579/clase-3.html#sgd-with-nesterov-momentum",
    "title": "TICS-579-Deep Learning",
    "section": "SGD with Nesterov Momentum",
    "text": "SGD with Nesterov Momentum\n\n\n\\[\\theta_{t+1} = \\theta_t - \\alpha u_{t + 1}\\] \\[v_{t + 1} = \\beta v_t + (1-\\beta) \\nabla_\\theta f(\\theta_{t+1} + \\beta v_t)\\]\ndonde \\(0&lt;\\beta&lt;1\\), pero normalmente \\(\\beta=0.9\\).\n\n\n\n\n\n\n\n\n\n\n☝️ Intuición\n\n\nEl método de Nesterov “mira hacia adelante” en la dirección del momentum antes de calcular el gradiente, lo que le da una corrección más precisa y evita en parte el sobrepaso de mínimos. En este caso \\(\\theta_{t+1} + \\beta v_t\\) es el punto “futuro” para calcular el gradiente."
  },
  {
    "objectID": "tics579/clase-3.html#efecto-del-momentum-en-el-update-rule",
    "href": "tics579/clase-3.html#efecto-del-momentum-en-el-update-rule",
    "title": "TICS-579-Deep Learning",
    "section": "Efecto del Momentum en el Update Rule",
    "text": "Efecto del Momentum en el Update Rule\n\n\n\n\n\n\n\n\n☝️ Intuición\n\n\n\nEl SGD tiende a ser más oscilante.\nEl SGD con Momentum tiende a ser más suave y rápido debido a la inercia recibida por el término de momentum."
  },
  {
    "objectID": "tics579/clase-3.html#métodos-adaptativos-adagrad",
    "href": "tics579/clase-3.html#métodos-adaptativos-adagrad",
    "title": "TICS-579-Deep Learning",
    "section": "Métodos Adaptativos: Adagrad",
    "text": "Métodos Adaptativos: Adagrad\n\n\n\n☝️ Intuición\n\n\n¿Qué tal, si el learning rate se va adaptando en el tiempo y deja de ser estática?\n\n\n\n\\[r_{t+1} = r_t + \\nabla_\\theta f(\\theta_t)^2\\] \\[\\theta_{t+1} = \\theta_t - \\frac{\\alpha}{\\sqrt{r_{t+1}}}\\nabla_\\theta f(\\theta_t)\\]\n\n\n\nEfecto\n\n\n\nParámetros con gradientes grandes \\(\\rightarrow\\) tasa de aprendizaje disminuye más rápido.\nParámetros con gradientes pequeños \\(\\rightarrow\\) tasa de aprendizaje se mantiene más alta.\n\n\n\n\n\n\n\nPros\n\n\n\nUtil cuando hay parámetros que se actualizan con distinta frecuencia.\nAcelera la convergencia en direcciones poco exploradas.\n\n\n\n\n\n\n\nContras\n\n\n\nComo el denominador acumula gradientes al cuadrado, la tasa de aprendizaje puede llegar a volverse muy pequeña \\(\\rightarrow\\) el entrenamiento se “frena” antes de llegar al óptimo."
  },
  {
    "objectID": "tics579/clase-3.html#métodos-adaptativos-rmsprop",
    "href": "tics579/clase-3.html#métodos-adaptativos-rmsprop",
    "title": "TICS-579-Deep Learning",
    "section": "Métodos Adaptativos: RMSProp",
    "text": "Métodos Adaptativos: RMSProp\n\n\n\n☝️ Intuición\n\n\n\nNormalizar por el Exponential Moving Average de los Gradientes al cuadrado para controlar el efecto de reducción del learning rate.\n\n\n\n\n\\[s_{t+1} = \\beta r_t + (1-\\beta) \\nabla_\\theta f(\\theta_t)^2\\] \\[\\theta_{t+1} = \\theta_t - \\frac{\\alpha}{\\sqrt{s_{t+1}}}\\nabla_\\theta f(\\theta_t)\\]\n\n\n\nPros\n\n\n\nNormalización adaptativa: cada parámetro tiene su propia tasa de aprendizaje ajustada dinámicamente.\nA diferencia de Adagrad, el denominador no crece indefinidamente porque el promedio exponencial “olvida” gradientes antiguos. Esto permite seguir aprendiendo incluso después de muchos pasos.\n\n\n\n\n\n\n\nContras\n\n\n\nDepende mucho de la elección de su hiperparámetro \\(\\beta\\)"
  },
  {
    "objectID": "tics579/clase-3.html#métodos-adaptativos-adam",
    "href": "tics579/clase-3.html#métodos-adaptativos-adam",
    "title": "TICS-579-Deep Learning",
    "section": "Métodos Adaptativos: Adam",
    "text": "Métodos Adaptativos: Adam\n\n\n\n☝️ Intuición\n\n\nSe mantiene el Exponential Moving average para: Los gradientes (como utilizando momentum), los gradientes al cuadrado (como RMSprop).\n\n\n\n\n\n\\[v_{t+1} = \\beta_1 v_t + (1-\\beta_1) \\nabla_\\theta f(\\theta_t)\\] \\[s_{t+1} = \\beta_2 s_t + (1-\\beta_2) \\nabla_\\theta f(\\theta_t)^2\\] \\[\\theta_{t+1} = \\theta_t - \\frac{\\alpha}{\\sqrt{s'_{t+1}}} v'_{t+1}\\]\n\nCorrecciones Iniciales\n\\[v'_{t+1} = \\frac{v_{t+1}}{1-\\beta_1^{t+1}}\\] \\[s'_{t+1} = \\frac{s_{t+1}}{1-\\beta_2^{t+1}}\\]\n\n\n\n\nPros\n\n\n\nCombina momentum + RMSprop + corrección \\(\\rightarrow\\) rápido, estable.\nEs por lejos el optimizador más usado.\n\n\n\n\n\n\n\nContras\n\n\n\nSensible a la elección de sus hiperparámetros \\(\\beta_1\\) y \\(\\beta_2\\). Pytorch utiliza 0.9 y 0.999 como valores de \\(\\beta_1\\) y \\(\\beta_2\\) respectivamente."
  },
  {
    "objectID": "tics579/clase-1.html#modelo-básico-de-clasificación-binaria",
    "href": "tics579/clase-1.html#modelo-básico-de-clasificación-binaria",
    "title": "TICS-579-Deep Learning",
    "section": "Modelo Básico de Clasificación Binaria",
    "text": "Modelo Básico de Clasificación Binaria\nSupongamos el siguiente problema de clasificación binaria:\n\n\n\n\n\n\n\nSea \\(\\mathcal{y} \\sim \\text{Bernoulli}(p)\\), es decir:\n\n\n\\[P(y) = \\begin{cases}\np,  & \\text{si y = 1} \\\\\n1-p, & \\text{si y=0}\n\\end{cases}\n\\]\n\n\n\n\n\n\n\n\n\n\n\nPero Ojo 👀\n\n\n¿Cómo estimamos la probabilidad \\(p\\) para asignar una clase?\n\nEsta clase puede ser cualquier cosa, por ejemplo, si un correo es spam o no, si es un gato o u perro, etc.\n\n\n\n\n\n\n\n\n\n\n\n\nRegresión Lineal\n\n\nUna manera es utilizar una combinación lineal de features (inputs) y parámetros (pesos). Es decir:\n\\[\\hat{y} = \\theta_0 x_0 + \\theta_1 x_1 + ... + \\theta_n x_n\\]"
  },
  {
    "objectID": "tics579/clase-1.html#modelo-básico-de-clasificación-binaria-1",
    "href": "tics579/clase-1.html#modelo-básico-de-clasificación-binaria-1",
    "title": "TICS-579-Deep Learning",
    "section": "Modelo Básico de Clasificación Binaria",
    "text": "Modelo Básico de Clasificación Binaria\n\nPero tenemos el problema de que \\(y\\) puede tomar cualquier valor real (no está acotada), y necesitamos que \\(p\\) esté entre 0 y 1. Para ello podemos aplicar la función Logística o Sigmoide.\n\n\n\n\n\n\n\n\n\n\n\n\n👍 Propiedades de la función Sigmoide\n\n\n\nAcotada entre 0 y 1.\nPunto de Inflexión en \\(x=0\\), lo que se transforma en \\(p=0.5\\).\n\\(\\sigma(z)'= \\sigma(z)(1-\\sigma(z))\\).\n\n\n\n\n\n\n\nEstimación de la probabilidad\n\n\n\\[ p = \\sigma(\\hat{y}) = \\sigma(\\theta_0 x_1 + \\theta_1 x_1 + ... + \\theta_n x_n)\\]\ndonde \\(\\sigma(x) = \\frac{1}{1 + e^{-x}}\\) es la función sigmoide."
  },
  {
    "objectID": "tics579/clase-1.html#modelo-básico-de-clasificación-binaria-2",
    "href": "tics579/clase-1.html#modelo-básico-de-clasificación-binaria-2",
    "title": "TICS-579-Deep Learning",
    "section": "Modelo Básico de Clasificación Binaria",
    "text": "Modelo Básico de Clasificación Binaria\n\n\n\n\n\n\n\n\n\n\n\n🤓 Más definiciones\n\n\n\nLlamaremos parámetros a los valores \\(\\theta_j\\), \\(j=0,...,n\\).\nLlamaremos “Capas” a un conjunto de parámetros utilizado para generar un resultado.\n\n\n\n\n\n\n\n\n\n🤓 Definiciones\n\n\n\nDefiniremos \\((\\bar{x}^{(i)})^T = (x_1^{(i)}, x_2^{(i)}, ..., x_n^{(i)})\\) como el vector de features del punto \\(i\\).\nAsimismo \\(y^{(i)}\\) será el label/etiqueta del punto \\(i\\).\nEn este caso particular \\(m=3\\) observaciones y \\(n=2\\) features.\n\n\n\n\n\n\n\n\n\n\n\nRedes Neuronales\n\n\nEl término Red Neuronal es un término marketero, lo único que hace es mostrar de manera gráfica lo que nosotros acabamos de definir."
  },
  {
    "objectID": "tics579/clase-1.html#red-neuronal-básica-regresión-logística",
    "href": "tics579/clase-1.html#red-neuronal-básica-regresión-logística",
    "title": "TICS-579-Deep Learning",
    "section": "Red Neuronal Básica: Regresión Logística",
    "text": "Red Neuronal Básica: Regresión Logística\nFinalmente, por conveniencia, podemos escribir nuestra Regresión Logísitca en notación matricial:\n\n\n\n\n\n\n\nUna observación\n\n\n\\[p^{(i)} = \\sigma((\\bar{x}^{(i)})^T \\cdot \\theta)\\]\n\n\n\n\n\n\n\n\n\n\n\nMuchas Observaciones\n\n\n\\[\\bar{p} = \\sigma(X \\cdot \\theta)\\]\nDonde X es el la Matriz de Diseño/Design Matrix, que contiene todos los vectores de features. Además utilizaremos la definición inicial, en la que si \\(p\\ge 0.5\\) entonces \\(y=1\\) y si \\(p &lt; 0.5\\) entonces \\(y=0\\)."
  },
  {
    "objectID": "tics579/clase-1.html#los-ingredientes-de-un-algoritmo-de-aprendizaje",
    "href": "tics579/clase-1.html#los-ingredientes-de-un-algoritmo-de-aprendizaje",
    "title": "TICS-579-Deep Learning",
    "section": "Los Ingredientes de un Algoritmo de Aprendizaje",
    "text": "Los Ingredientes de un Algoritmo de Aprendizaje\n\nHipótesis\n\n\nUna función que describe como mapear inputs (features) con outputs (labels) por medio de parámetros. En nuestro caso inicial diremos que \\(h_\\theta(X) = \\sigma(X \\theta)\\), donde \\(\\sigma\\) es la función sigmoide.\n\n\nLoss Function\n\n\nUna función que especifica cuanta información se pierde. Mayor pérdida implica más error de estimación.\n\n\nMétodo de Optimización\n\n\nEs el responsable de combinar la hipótesis y la loss function. Corresponde a un procedimiento para determinar los parámetros de la hipótesis, minimizando la suma de las pérdidas en un set de entrenamiento."
  },
  {
    "objectID": "tics579/clase-1.html#regresión-logística-loss-function",
    "href": "tics579/clase-1.html#regresión-logística-loss-function",
    "title": "TICS-579-Deep Learning",
    "section": "Regresión Logística: Loss Function",
    "text": "Regresión Logística: Loss Function\n\nNuestra definición inicial de la Distribución Bernoulli puede ser rescrita de la siguiente manera:\n\n\n\\[P(y) = \\begin{cases}\np,  & \\text{si y = 1} \\\\\n1-p, & \\text{si y=0}\n\\end{cases}\n\\]\n\n\\[P(y|X) = p^{y} (1-p)^{1-y}\\]\n\n\n\n\n\n\n\n\n\nMaximum Likelihood Estimation\n\n\nPermite calcular los parámetros \\(\\theta\\) que maximizan la probabilidad de observar los datos (que los datos se ajusten a la distribución esperada por el modelo).\n\\[\\mathcal{L}(\\theta) = \\prod_{i=1}^m P(y^{(i)}|X^{(i)}) = \\prod_{i=1}^m p^{y^{(i)}} (1-p)^{1-y^{(i)}}\\]\n\n\n\n\n\n\n\n\n\n\n\nNegative Log Likelihood\n\n\n\nLa Productoria no es amigable.\nEs más común minimizar que maximizar.\nAplicamos Logaritmo a la función de verosimilitud y cambiamos el signo.\n\n\\[\\mathcal{l}(\\theta) = -\\log(\\mathcal{L}(\\theta)) = -\\sum_{i=1}^m \\left(y^{(i)} \\log(p^{(i)}) + (1-y^{(i)}) \\log(1-p^{(i)})\\right)\\]"
  },
  {
    "objectID": "tics579/clase-1.html#regresión-logística-loss-function-1",
    "href": "tics579/clase-1.html#regresión-logística-loss-function-1",
    "title": "TICS-579-Deep Learning",
    "section": "Regresión Logística: Loss Function",
    "text": "Regresión Logística: Loss Function\n\n\n\nFunción de Pérdida/Loss Function en notación matricial\n\n\n\\[L(\\theta) = -\\frac{1}{m}\\left[y^T \\log(\\bar{p}) + (1-y)^T \\log(1-\\bar{p})\\right]\\]\ndonde \\(\\bar{p} = \\sigma(X\\theta)\\) es el vector de probabilidades estimadas por el modelo.\n\nAtención: Es más común calcular la pérdida promedio, es decir, dividir por \\(m\\).\n\n\n\n\n\n\n\nPropiedades\n\n\n\nSi \\(y^{(i)} = 1\\), entonces \\(L(\\theta) = -\\frac{1}{m}log(p^{(i)})\\).\n\nLuego si la probabilidad es cercana a 1, que significa que el modelo predijo correctamente la clase, entonces la pérdida es cercana a 0.\nPero si la probabilidad es cercana a 0, entonces la pérdida es alta.\n\nSi \\(y^{(i)} = 0\\), entonces \\(L(\\theta) = -\\frac{1}{m}log(1-p^{(i)})\\).\n\nLuego si la probabilidad es cercana a 0, que significa que el modelo predijo correctamente la clase, entonces la pérdida es cercana a 0.\nPero si la probabilidad es cercana a 1, entonces la pérdida es alta.\n\n\n\n\n\n\n\n\nConclusión\n\n\n\nLa Función de Pérdida mide cuánta información se pierde al estimar los parámetros \\(\\theta\\). En otras palabras, mide el error de estimación de nuestro modelo. Por lo tanto, una Loss Function más baja implica un mejor modelo.\nSi minimizamos nuestra función de pérdida, entonces estamos maximizando la probabilidad de observar los datos. Por lo tanto, minimizamos el error de estimación del modelo.\nA veces está ecuación aparece como la pérdida promedio (es decir, está multiplicada por \\(\\frac{1}{m}\\))."
  },
  {
    "objectID": "tics579/clase-1.html#regresión-logística-método-de-optimización",
    "href": "tics579/clase-1.html#regresión-logística-método-de-optimización",
    "title": "TICS-579-Deep Learning",
    "section": "Regresión Logística: Método de Optimización",
    "text": "Regresión Logística: Método de Optimización\n\n\n\n\n🤘 La parámetros óptimos del problema están dados por:\n\n\n\\[\\underset{\\theta}{argmin} = L(\\theta)\\]\n\nLo cuál puede ser resuelto fácilmente utilizando un método de optimización como el Gradient Descent.\n\n\n\n\n\n\n\n\n\n\n\nParámetros óptimos se encuentran con:\n\n\n\\[\\theta = \\theta - \\alpha \\nabla_\\theta L(\\theta)\\]\n\n\n\n\n\n\n\n😇 ¿Cuánto vale el gradiente de la Función de Pérdida?\n\n\n\n\nVamos a calcular el gradiente haciendo trampa. Puede que algunos se enojen, pero para nosotros es suficiente."
  },
  {
    "objectID": "tics579/clase-1.html#regresión-logísitca-gradiente",
    "href": "tics579/clase-1.html#regresión-logísitca-gradiente",
    "title": "TICS-579-Deep Learning",
    "section": "Regresión Logísitca: Gradiente",
    "text": "Regresión Logísitca: Gradiente\n\n\nSupongamos lo siguiente:\n\n\\(a= X \\theta\\)\n\\(b = \\sigma(a)\\)\n\\(c = log(b)\\)\n\\(d = log(1-b)\\)\n\\(e = y^T c\\)\n\\(f = (1-y)^T d\\)\n\\(L* = e + f\\)\n\\(L = -\\frac{1}{m} L*\\)"
  },
  {
    "objectID": "tics579/clase-1.html#regresión-logísitca-calculando-el-gradiente",
    "href": "tics579/clase-1.html#regresión-logísitca-calculando-el-gradiente",
    "title": "TICS-579-Deep Learning",
    "section": "Regresión Logísitca: Calculando el Gradiente",
    "text": "Regresión Logísitca: Calculando el Gradiente\n\\[\n\\begin{align*}\n\\frac{\\partial L*}{\\partial f} &= \\frac{\\partial L}{\\partial e} = 1 \\\\\n\\frac{\\partial L*}{\\partial d} &= \\frac{\\partial L}{\\partial f} \\cdot \\frac{\\partial f}{\\partial d} = (1 - y)^T \\\\\n\\frac{\\partial L*}{\\partial c} &= \\frac{\\partial L}{\\partial e} \\cdot \\frac{\\partial e}{\\partial c} = y^T \\\\\n  \\frac{\\partial L*}{\\partial b} &= \\frac{\\partial L}{\\partial c} \\cdot \\frac{\\partial c}{\\partial b}  + \\frac{\\partial L}{\\partial d} \\cdot \\frac{\\partial d}{\\partial b}= \\frac{y^T}{b} - \\frac{(1-y)^T}{1-b} \\\\\n\\frac{\\partial L*}{\\partial a} &= \\frac{\\partial L}{\\partial b} \\cdot \\frac{\\partial b}{\\partial a} = \\left[\\frac{y^T}{b} - \\frac{(1-y)^T}{1-b}\\right] \\cdot \\sigma(a)' \\\\\n\\frac{\\partial L*}{\\partial \\theta} &= \\frac{\\partial L}{\\partial a} \\cdot \\frac{\\partial a}{\\partial \\theta} = \\left[\\frac{y^T}{b} - \\frac{(1-y)^T}{1-b}\\right] \\cdot \\sigma(a)' \\cdot X\\\\\n\\frac{\\partial L*}{\\partial \\theta} &=\\left[\\frac{y^T (1-b) + b (1-y)^T}{b(1-b)}\\right] \\cdot \\sigma(a)' \\cdot X\\\\\n\\frac{\\partial L*}{\\partial \\theta} &=\\left[\\frac{y^T - b}{b(1-b)}\\right] \\cdot \\sigma(a)' \\cdot X\\\\\n\\end{align*}\n\\]"
  },
  {
    "objectID": "tics579/clase-1.html#regresión-logísitca-gradiente-1",
    "href": "tics579/clase-1.html#regresión-logísitca-gradiente-1",
    "title": "TICS-579-Deep Learning",
    "section": "Regresión Logísitca: Gradiente",
    "text": "Regresión Logísitca: Gradiente\n\\[\\frac{\\partial L*}{\\partial \\theta} =\\left[\\frac{y^T - b}{b(1-b)}\\right] \\cdot \\sigma(a)' \\cdot X\\]\nLuego reemplazamos que \\(b=\\sigma(a)\\) y \\(\\sigma(a)'=\\sigma(a)(1-\\sigma(a))\\):\nObtenemos que:\n\\[\\frac{\\partial L}{\\partial \\theta} = \\frac{1}{m}\\left[\\sigma(X\\theta)_{m \\times 1} - y^T_{1 \\times m}\\right]X_{m \\times (n+1)}\\]\n\n\n\n\n\n😅Ojo con las dimensiones.\n\n\nDebemos modificar nuestro cálculo de modo que las dimensiones sean compatibles. Luego:\n\\[\\frac{\\partial L}{\\partial \\theta}_{(n+1) \\times 1} = \\frac{1}{m}  X^T_{(n+1) \\times m} \\cdot \\left[\\sigma(X\\theta) - y\\right]_{m \\times 1}\\]\n\nTengo que tener un gradiente para cada parámetro (¿por qué son \\(n+1\\)?)"
  },
  {
    "objectID": "tics579/clase-1.html#regresión-logística-update-rule",
    "href": "tics579/clase-1.html#regresión-logística-update-rule",
    "title": "TICS-579-Deep Learning",
    "section": "Regresión Logística: Update Rule",
    "text": "Regresión Logística: Update Rule\n\nLlamaremos Update Rule al Algoritmo que permite entrenar un modelo. En el caso de la Regresión Logística, el Update Rule es:\n\n\n\\[\\theta_{n+1 \\times 1} = \\theta_{n+1 \\times 1} - \\frac{\\alpha}{m} \\cdot X^T_{(n+1) \\times m} \\cdot \\left[\\sigma(X\\theta) - y\\right]_{m \\times 1}\\]\n\n\n\n\n🤫 Resumen\n\n\n\nAplicando este procedimiento es posible definir cualquier update rule de aprendizaje supervisado. Tan sólo se requiere:\nUna Hipótesis: En el caso de la Regresión Logística es \\(h_{\\theta}(X) = \\sigma(X \\theta)\\).\nUna Loss Function: En el caso de la regresión Logística es \\(L(\\theta) = -\\left[y^T \\log(h_{\\theta}) + (1-y)^T \\log(1-h_\\theta)\\right]\\)\nEncontrar los gradientes de la Loss Function.\n\n\n\n\n\n\n\n😱Entrenamiento\n\n\n\nLlamaremos al proceso de encontrar los parámetros óptimos del modelo “Entrenamiento”. Es decir, el proceso de encontrar los parámetros \\(\\theta\\) que minimizan la Loss Function \\(L(\\theta)\\).\nUn modelo que ya está entrenado, puede ser utilizado para hacer predicciones en nuevos datos. Es fin último de un modelo de Machine Learning es utilizarse en producción, no sólo presentar métricas."
  },
  {
    "objectID": "tics579/clase-10.html#datos-de-texto",
    "href": "tics579/clase-10.html#datos-de-texto",
    "title": "TICS-579-Deep Learning",
    "section": "Datos de Texto",
    "text": "Datos de Texto\nLos datos de texto corresponden a un caso particular de datos secuenciales. En este caso, dependiendo del idioma, las dependencias pueden venir tanto del pasado como del futuro. Consideramos texto libre como una secuencia de Strings, el cuál es inteligible para seres humanos pero no necesariamente para un computador.\n\n\n\n\n\n\nEs probablemente el tipo de dato más abundante, aunque también uno de los más sensible al ruido (variabilidad, idioma, tono, formalidad, etc.).\n\n\n\n\n\n\n\n\nEl problema\n\n\nLos computadores, y por ende los modelos, no pueden entender strings. El computador sólo puede entender datos numéricos.\n\n\n\n\n\n\n\n\n\nPara poder manipular texto dentro de un modelo será necesario un pre-procesamiento que permita transformar el texto en datos numéricos que un modelo pueda entender.\n\n\n\n\n\n\n\n\n\nLa disciplina encargada de desarrollar modelos asociado a lenguaje/texto es conocida como Procesamiento de Lenguaje Natural (NLP en inglés)."
  },
  {
    "objectID": "tics579/clase-10.html#tareas-asociadas-a-nlp",
    "href": "tics579/clase-10.html#tareas-asociadas-a-nlp",
    "title": "TICS-579-Deep Learning",
    "section": "Tareas asociadas a NLP",
    "text": "Tareas asociadas a NLP"
  },
  {
    "objectID": "tics579/clase-10.html#proceso-de-tokenización-y-embedding",
    "href": "tics579/clase-10.html#proceso-de-tokenización-y-embedding",
    "title": "TICS-579-Deep Learning",
    "section": "Proceso de Tokenización y Embedding",
    "text": "Proceso de Tokenización y Embedding\n\n\n\n\n\nTokenización\n\n\nEl proceso de Tokenización permite transformar texto en datos numéricos. Cada dato numérico se mapea con un “trozo de texto”. Normalmente los modelos van asociados a la tokenización con la que fueron entrenados. Cambiar la tokenización puede generar gran degradación.\n\n\n\n\n\n\nEmbedding\n\n\nCorresponde el proceso en el que los Tokens se transforman en vectores densos en las cuales la distancia entre ellos representa una noción de similaridad.\n\n\n\n\n\n\n\nEn este caso la frase “Frog on a log”  es separada en Tokens (en este caso cada token es una palabra).\nLuego cada Token es mapeado a un Token id proveniente de un vocabulario. ¿Qué es un vocabulario?\nLos embeddings en este caso representan una secuencia de largo 7 con 3 dimensiones."
  },
  {
    "objectID": "tics579/clase-10.html#embeddings",
    "href": "tics579/clase-10.html#embeddings",
    "title": "TICS-579-Deep Learning",
    "section": "Embeddings",
    "text": "Embeddings\n\n\n\n\n\n\n\n\n\n\n\n¿Por qué es tan importante el uso de Embeddings?\n\n\n\nPrimero porque son entrenables. Es decir la red puede aprender cuál es la mejor manera de representar palabras.\nExisten embeddings pre-entrenados, es decir, se puede hacer transfer learning de embeddings.\nLa red puede aprender relaciones semánticas entre palabras, algo imposible utilizando otras representaciones."
  },
  {
    "objectID": "tics579/clase-10.html#problema-de-las-rnn",
    "href": "tics579/clase-10.html#problema-de-las-rnn",
    "title": "TICS-579-Deep Learning",
    "section": "Problema de las RNN",
    "text": "Problema de las RNN\n\n\n\n\n\n\nA pesar de las habilidades de las RNN, estas no son suficientes para distintas tareas de NLP.\n\n\n\n\n\n\n\n\nLas RNN inicialmente toman cada elemento de una secuencia y generan un output para cada entrada. Esto potencialmente genera ciertas limitantes. Una de ellas es el proceso llamado Machine Translation.\n\n\n\n\n\n\nEste es un ejemplo de Modelamiento seq2seq en el que se utiliza una secuencia de entrada pero se espera también una secuencia de salida."
  },
  {
    "objectID": "tics579/clase-10.html#machine-translation-ejemplo-del-inglés",
    "href": "tics579/clase-10.html#machine-translation-ejemplo-del-inglés",
    "title": "TICS-579-Deep Learning",
    "section": "Machine Translation: Ejemplo del Inglés",
    "text": "Machine Translation: Ejemplo del Inglés\nSupongamos que necesitamos hacer la siguiente traducción:\n\nInglés\n\n\nHi, my name is Alfonso\n\n\n\n\n\nEspañol\n\n\nHola, mi nombre es Alfonso\n\n\n\n\n\n\n\n\n\nEste tipo de traducción es uno a uno. Cada input puede tener asociado una salida de manera directa puede realizarse de manera directa con una RNN."
  },
  {
    "objectID": "tics579/clase-10.html#machine-translation-ejemplo-del-inglés-1",
    "href": "tics579/clase-10.html#machine-translation-ejemplo-del-inglés-1",
    "title": "TICS-579-Deep Learning",
    "section": "Machine Translation: Ejemplo del Inglés",
    "text": "Machine Translation: Ejemplo del Inglés\n\nInglés\n\n\nWould you help me prepare something for tomorrow?\n\n\n\n\n\nEspañol\n\n\n¿Me ayudarías a preparar algo para mañana?\n\n\n\n\n\n\n\n\n\nProblemas\n\n\n\nLa traducción no es uno. De hecho en inglés se utilizan 8 palabras y 1 signo de puntuación. En español se traduce en 7 palabras y 2 signos de puntuación.\n“Would” no tiene equivalente en español.\n“a” no tiene equivalente en el inglés.\n“Me” se traduce como “me” en inglés pero en vez de ir al inicio, va al final de “help”.\n“¿” no existe en inglés.\n\n\n\n\n\n\n\n\n\n\n\nOtros idiomas como el Alemán o el Ruso, tienen fusión de palabras o declinaciones que hacen la traducción mucho más difícil.\nEs por ello que se requiere una cierta libertad entre los tokens de entradas y los tokens de salida."
  },
  {
    "objectID": "tics579/clase-10.html#soluciones-redes-convolucionales",
    "href": "tics579/clase-10.html#soluciones-redes-convolucionales",
    "title": "TICS-579-Deep Learning",
    "section": "Soluciones: Redes Convolucionales",
    "text": "Soluciones: Redes Convolucionales\nUna potencial solución se puede dar por medio de Redes Convolucionales de 1D. En este caso las redes convolucionales tienen la ventaja de poder mirar tanto al pasado como al futuro de manera móvil.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVentajas\n\n\n\nPueden tomar contexto desde el inicio y desde el final.\n\n\n\n\n\n\n\n\n\n\nDesventajas\n\n\n\nSu campo receptivo es mucho más acotado y depende del número de capas y el largo del Kernel lo cual repercute directamente en el número de parámetros del modelo.\nNo tienen estado latente (o memoria) que almacena contexto.\nNo es útil para modelos de generación (ya que ve contexto desde el futuro)."
  },
  {
    "objectID": "tics579/clase-10.html#soluciones-arquitecturas-encoder-decoder",
    "href": "tics579/clase-10.html#soluciones-arquitecturas-encoder-decoder",
    "title": "TICS-579-Deep Learning",
    "section": "Soluciones: Arquitecturas Encoder-Decoder",
    "text": "Soluciones: Arquitecturas Encoder-Decoder\n\nEncoder\n\nCorresponde a una arquitectura que permitirá tomar datos de entrada y codificarlos en una representación numérica (normalmente como hidden states o como embeddings).\n\nDecoder\n\nCorresponde a una arquitectura que toma una representación codificada de datos (normalmente generado por un encoder) y la transforma nuevamente en una salida con un formato comprensible y no solamente una “simple etiqueta”.\n\n\n\n\n\n\n\n\n\n\n\n\n\nEste tipo de arquitecturas son quizás las más populares hoy en día y tienen aplicaciones en distintos dominios."
  },
  {
    "objectID": "tics579/clase-10.html#soluciones-arquitecturas-encoder-decoder-1",
    "href": "tics579/clase-10.html#soluciones-arquitecturas-encoder-decoder-1",
    "title": "TICS-579-Deep Learning",
    "section": "Soluciones: Arquitecturas Encoder-Decoder",
    "text": "Soluciones: Arquitecturas Encoder-Decoder\n\n\n\n\n\n\nUna arquitectura Encoder-Decoder convolucional permite devolver una imagen como salida. Este ejemplo se conoce como Segmentación Semántica."
  },
  {
    "objectID": "tics579/clase-10.html#soluciones-arquitecturas-encoder-decoder-2",
    "href": "tics579/clase-10.html#soluciones-arquitecturas-encoder-decoder-2",
    "title": "TICS-579-Deep Learning",
    "section": "Soluciones: Arquitecturas Encoder-Decoder",
    "text": "Soluciones: Arquitecturas Encoder-Decoder\n\n\n\n\n\n\nUna arquitectura recurrente permite devolver una secuencia como salida. La cual puede utilizarse para generación o traducción de texto.\n\n\n\n\n\n\n\n\n\n\n\nVentajas\n\n\n\nPermite “desligarse” de la predicción uno a uno.\nLa salida de este tipo de modelos depende principalmente del contexto almacenado en el Hidden State/Bottleneck.\n\n\n\n\n\n\n\nDesventajas\n\n\n\nDado los problemas de Vanishing/Exploding Gradients es ingenuo pensar que todo el contexto de una frase vive en el último hidden state."
  },
  {
    "objectID": "tics579/clase-10.html#soluciones-arquitecturas-encoder-decoder-3",
    "href": "tics579/clase-10.html#soluciones-arquitecturas-encoder-decoder-3",
    "title": "TICS-579-Deep Learning",
    "section": "Soluciones: Arquitecturas Encoder-Decoder",
    "text": "Soluciones: Arquitecturas Encoder-Decoder\n\n\n\n\n\n\n\n\nOjo\n\n\nEl último Hidden State del Encoder se utilizará como Hidden State inicial del Decoder."
  },
  {
    "objectID": "tics579/clase-10.html#entrenamiento-de-una-arquitectura-encoder-decoder",
    "href": "tics579/clase-10.html#entrenamiento-de-una-arquitectura-encoder-decoder",
    "title": "TICS-579-Deep Learning",
    "section": "Entrenamiento de una Arquitectura Encoder-Decoder",
    "text": "Entrenamiento de una Arquitectura Encoder-Decoder\n\n\n\n\n\n\n\n\n\n\n\nArquitectura\n\n\n\nRNN Bidireccional\nCon un Encoder (colores pastel) y un Decoder independientes (colores más oscuros).\n\n\n\n\n\n\n\n\nTenemos dos frases una en inglés (input) y una en español (output). Ambas frases son claramente de tamaños distintos.\nTenemos el token especial &lt;eos&gt; (end of sentence) que separa el input del output.\n\n\n\n\n\n\n\n\nLos últimos Hidden States del Encoder son los Hidden States iniciales del Decoder. Estos también se conocen como Context Vectors.\n\n\n\n\n\n\n\nEntrenamiento\n\n\nAl momento de entrenarse, las salidas \\(y1\\) e \\(y2\\) pueden ser distintas al valor esperado y deben ir ajustándose epoch a epoch."
  },
  {
    "objectID": "tics579/clase-10.html#inferencia-de-una-arquitectura-encoder-decoder",
    "href": "tics579/clase-10.html#inferencia-de-una-arquitectura-encoder-decoder",
    "title": "TICS-579-Deep Learning",
    "section": "Inferencia de una Arquitectura Encoder-Decoder",
    "text": "Inferencia de una Arquitectura Encoder-Decoder\n\n\n\n\n\n\n\n\n\n\n\nPredicción\n\n\n\nLa predicción se va realizando de manera autoregresiva. Es decir, la predicción del primer step corresponde a la entrada del segundo step y así sucesivamente.\n\n\n\n\n\n\n\n\nLa primera entrada siempre será el token especial &lt;eos&gt; (otros modelos pueden utilizar otros tokens especiales).\n\n\n\n\n\n\n\n\nEl modelo irá prediciendo de manera autoregresiva hasta predecir el token &lt;eos&gt;.\n\n\n\n\n\n\n\n\n\n\nProblema\n\n\n\nPensar que todo el contexto se puede almacenar en el último hidden state es un poco ingenuo.\nEl último hidden state tiene más influencia de las palabras más cercanas y menos de las palabras iniciales (debido al problema de vanishing/exploding gradients)."
  },
  {
    "objectID": "tics579/clase-10.html#mecanismo-de-atención-bahdanau-et-al-2015",
    "href": "tics579/clase-10.html#mecanismo-de-atención-bahdanau-et-al-2015",
    "title": "TICS-579-Deep Learning",
    "section": "Mecanismo de Atención (Bahdanau et al, (2015))",
    "text": "Mecanismo de Atención (Bahdanau et al, (2015))\n\n\n\n\n\n\n\n\n\nAtención\n\nSe refiere a cualquier mecanismo en el que los hidden states se ponderan y combinan para poder utilizarlos como contexto. En otras palabras, el mecanismo busca a qué inputs iniciales debe poner más “atención” para poder generar la predicción.\n\n\n\\[c_i = \\sum_{t=1}^T a_{i,t} \\cdot h_t\\]\nDonde \\(c_i\\) corresponde al contexto para la predicción del output \\(i\\) y \\(a_{i,t}\\) (que van entre 0 y 1) corresponden a cuánta atención le presta el output \\(i\\) al token \\(t\\).\n\n\n\n\n\n\nOjo\n\n\nEn el paper original, se interpreta \\(a_{i,t}\\) como cuánto se “alínea” o se parece el estado \\(h_t\\) con \\(S_{t-1}\\)."
  },
  {
    "objectID": "tics579/clase-10.html#atención-de-bahdanau",
    "href": "tics579/clase-10.html#atención-de-bahdanau",
    "title": "TICS-579-Deep Learning",
    "section": "Atención de Bahdanau",
    "text": "Atención de Bahdanau\n\\[a_{i,t} = align(h_t, S_{i-1})\\] \n\\[[a_{i,1},...,a_{i,T}] = Softmax([\\tilde{a_{i,1}},...\\tilde{a_{i,T}}])\\]"
  },
  {
    "objectID": "tics579/clase-10.html#otras-formas-de-atención",
    "href": "tics579/clase-10.html#otras-formas-de-atención",
    "title": "TICS-579-Deep Learning",
    "section": "Otras formas de Atención",
    "text": "Otras formas de Atención\n\n\n\n1. Proyecciones Lineales\n\n\n\\[k_t = W_k \\cdot h_t\\] \\[q_{i-1} = W_q \\cdot S_{i-1}\\]\n\n\n\n\n\n\n2. Similaridad: Producto Punto es equivalente al Cosine Similarity\n\n\n\\[\\tilde{a}_{i,t} = k_t^T \\cdot q_{i-1}\\]\n\n\n\n\n\n\n3. Normalización:\n\n\n\\[[a_{i,1},...,a_{i,T}] = Softmax([\\tilde{a}_{i,1},...\\tilde{a}_{i,T}])\\]"
  },
  {
    "objectID": "tics579/clase-10.html#transformers-arquitectura",
    "href": "tics579/clase-10.html#transformers-arquitectura",
    "title": "TICS-579-Deep Learning",
    "section": "Transformers: Arquitectura",
    "text": "Transformers: Arquitectura\n\nTransformer\n\nCorresponde a la Arquitectura más avanzada que tenemos hoy en día. Está basada en distintos mecanismos de atención.\n\n\n\n\n\n\n\n\n\n\n\n\n\nDetalles de la Arquitectura\n\n\n\nCorresponde a un Encoder + un Decoder.\nCada uno contiene una capa de Embeddings.\nAdemás posee un Positional Encoding para entender el orden de la secuencia.\nEl decoder funciona de manera autoregresiva.\nPosee 4 tipos de atención."
  },
  {
    "objectID": "tics579/clase-10.html#transformers-self-y-multihead-attention",
    "href": "tics579/clase-10.html#transformers-self-y-multihead-attention",
    "title": "TICS-579-Deep Learning",
    "section": "Transformers: Self y Multihead Attention",
    "text": "Transformers: Self y Multihead Attention\n\n\n\n\n\n\n\n\n\n\n\nDetalles\n\n\n\nEl self-attention pone atención (aprendiendo la relación) existente entre datos de una misma secuencia. La gran ventaja es que permite la paralelización de cálculos.\nEl Multihead Attention corresponde a la concatenación de varios Self-Attention. Esto permite no “sesgarse” con sólo una forma de poner atención, permitiendo aprender relaciones en distintas direcciones."
  },
  {
    "objectID": "tics579/clase-10.html#transformers-causal-self-attention",
    "href": "tics579/clase-10.html#transformers-causal-self-attention",
    "title": "TICS-579-Deep Learning",
    "section": "Transformers: Causal Self Attention",
    "text": "Transformers: Causal Self Attention\n\n\n\n\n\n\n\n\n\n\n\nDetalles\n\n\n\nCorresponde a un tipo particular de Self Attention, en el cuál sólo se puede poner atención a valores de secuencia previa (no puede ver al futuro). Esto es particularmente necesario para tareas de generación autoregresiva."
  },
  {
    "objectID": "tics579/clase-10.html#transformers-cross-attention",
    "href": "tics579/clase-10.html#transformers-cross-attention",
    "title": "TICS-579-Deep Learning",
    "section": "Transformers: Cross Attention",
    "text": "Transformers: Cross Attention\n\n\n\n\n\n\n\n\n\n\n\nDetalles\n\n\n\nCorresponde a la atención que relaciona información proveniente tanto del Encoder como del Decoder. Muy similar al concepto original de Atención."
  },
  {
    "objectID": "tics579/clase-P2.html#derivadas",
    "href": "tics579/clase-P2.html#derivadas",
    "title": "TICS-579-Deep Learning",
    "section": "Derivadas",
    "text": "Derivadas\n\nLa derivada corresponde a la razón de cambio de una función con respecto a una variable de entrada \\(x\\). Es decir, cuánto cambia el valor de la función \\(f(x)\\) cuando cambiamos el valor de \\(x\\) en una cantidad infinitesimal \\(h\\).\n\n\n\n\n\n\n\n\n\nLa definición formal de la derivada\n\n\nPara una función \\(f: \\mathbb{R} \\rightarrow \\mathbb{R}\\), la derivada se define como: \\[\\frac{df(x)}{dx} = \\lim_{h \\to 0} \\frac{f(x+h) - f(x)}{h}\\]\n\n\n\n\n\n\n\n\n\nPropiedades\n\n\n\n\\(f(x + h) \\approx f(x) + f'(x) \\cdot h\\), cuando \\(h \\to 0\\).\nSi la derivada existe en \\(x\\), decimos que la función es derivable o diferenciable en \\(x\\).\nSi las derivadas laterales no existen o no son iguales, entonces \\(f\\) no es derivable en \\(x\\).\nSi \\(f\\) es derivable, entonces \\(f\\) es continua.\n\n\n\n\n\n\n\n\n\n\n\nOtra interpretación\n\n\nEsto se puede interpretar como la pendiente de la recta tangente a la curva de \\(f(x)\\) en el punto \\(x\\)."
  },
  {
    "objectID": "tics579/clase-P2.html#derivadas-ejemplos",
    "href": "tics579/clase-P2.html#derivadas-ejemplos",
    "title": "TICS-579-Deep Learning",
    "section": "Derivadas: Ejemplos",
    "text": "Derivadas: Ejemplos\n\n\n\n\\((c)'= 0\\)\n\\((cx)' = c\\)\n\\((x^n)' = n x^{n-1}\\)\n\n\n\n\\((\\sqrt{x})' = \\frac{1}{2\\sqrt{x}}\\)\n\\((\\frac{1}{x})' = -\\frac{1}{x^2}\\)\n\n\n\n\\((e^x)' = e^x\\)\n\\((ln(x))' = \\frac{1}{x}\\)\n\\((log_a(x))' = \\frac{1}{x ln(a)}\\)\n\n\nReglas de Cálculo\n\n\\((f+g)' = f' + g'\\)\n\\((fg)' = f'g + fg'\\)\n\\((\\frac{f}{g})' = \\frac{f'g - fg'}{g^2}\\)\n\\((\\alpha f)' = \\alpha f'\\)\n\\(f(x) = h(g(x)) \\Rightarrow f'(x) = h'(g(x)) g'(x)\\), conocida como la regla de la cadena."
  },
  {
    "objectID": "tics579/clase-P2.html#caso-multivariado",
    "href": "tics579/clase-P2.html#caso-multivariado",
    "title": "TICS-579-Deep Learning",
    "section": "Caso Multivariado",
    "text": "Caso Multivariado\n\n\n\n\n\n\n\nOjo\n\n\nSi tenemos una función \\(f: \\mathbb{R}^n \\rightarrow \\mathbb{R}\\). ¿Cómo se define la derivada?\n\nSe requiere una dirección para derivar. Dado por un vector \\(\\bar{v} \\in \\mathbb{R}^n\\) y la recta que define.\n\n\n\n\n\n\n\n\n\n\nLa definición formal de la derivada direccional\n\n\nPara una función \\(f: \\mathbb{R} \\rightarrow \\mathbb{R}\\), la derivada en torno a \\(\\bar{x}\\) en dirección \\(\\bar{v}\\) (\\(\\bar{v}\\) es un vector unitario) se define como: \\[\\nabla_{\\bar{v}}f(x) = \\lim_{h \\to 0} \\frac{f(\\bar{x}+h\\bar{v}) - f(\\bar{x})}{h}\\]\n\n\n\n\n\n\n\n\n\nProblema\n\n\nEste cálculo en general es poco práctico debido a que existen infinitas direcciones posibles. Por lo tanto, ¿cuál debería tomar?"
  },
  {
    "objectID": "tics579/clase-P2.html#derivadas-parciales",
    "href": "tics579/clase-P2.html#derivadas-parciales",
    "title": "TICS-579-Deep Learning",
    "section": "Derivadas Parciales",
    "text": "Derivadas Parciales\nSi \\(f: \\mathbb{R}^n \\rightarrow \\mathbb{R}\\), se define la derivada parcial de \\(f\\) en torno a \\(\\bar{x}=(x_1,...,x_n)\\) con respecto a la variable \\(x_i\\) como como la derivada direccional en la dirección del vector unitario \\(\\bar{e_i}\\).\n\\[\\frac{\\partial f(x)}{\\partial_{x_i}} = \\lim_{h \\to 0} \\frac{f(x_1, ..., x_i + h, ..., x_n) - f(x_1, ..., x_i, ...x_n)}{h}\\]\n\n\n\n\n\n\n\nGradiente: Función Escalar\n\n\nDefinimos el gradiente de \\(f\\) como:\n\\[\n\\begin{align}\n\\nabla f: \\mathbb{R}^n &\\rightarrow \\mathbb{R}^{1 \\times n} \\\\\n\\bar{x}  &\\rightarrow \\nabla f(\\bar{x}) = \\begin{bmatrix}\\frac{\\partial f}{\\partial x_1} & \\dots & \\frac{\\partial f}{\\partial x_n}\\end{bmatrix}\n\\end{align}\n\\]\n\n\n\n\n\n\n\n\n\n\n\nEl gradiente podríamos considerarlo como un vector fila o columna según conveniencia. Por simplicidad lo dejaremos como un vector fila.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDerivada Direccional en función del Gradiente. ¿Cuál es la dirección en la que la Derivada Direccional es máxima?\n\n\n\\[\\nabla_{\\bar{v}}f(x) = \\nabla f(x) \\cdot \\bar{v}\\]"
  },
  {
    "objectID": "tics579/clase-P2.html#gradiente-ejemplo",
    "href": "tics579/clase-P2.html#gradiente-ejemplo",
    "title": "TICS-579-Deep Learning",
    "section": "Gradiente: Ejemplo",
    "text": "Gradiente: Ejemplo\n\\[f(x,y) = 3x^2 + 2xy + y^2 + 5x + 4\\]\nConsideremos entonces que \\(\\bar{x} = (x,y)\\). Es decir, va de \\(\\mathbb{R}^2\\) a \\(\\mathbb{R}\\).\n\n\n\n\n\n\n\nGradiente de \\(f\\)\n\n\n\\[\\nabla f(\\bar{x}) = \\nabla f(x,y) = \\begin{bmatrix}\\partial f_x & \\partial f_y\\end{bmatrix} = \\begin{bmatrix} 6x + 2y + 5 & 2x + 2y\\end{bmatrix}\\]"
  },
  {
    "objectID": "tics579/clase-P2.html#jacobiano-función-vectorial",
    "href": "tics579/clase-P2.html#jacobiano-función-vectorial",
    "title": "TICS-579-Deep Learning",
    "section": "Jacobiano: Función Vectorial",
    "text": "Jacobiano: Función Vectorial\nSea \\(f: \\mathbb{R}^n \\rightarrow \\mathbb{R}^k\\), el Jacobiano de \\(f\\) es la generalización del Gradiente y corresponderá a la matriz que contiene las derivadas parciales de una \\(f\\) multivariada respecto a cada una de sus variables de entrada.\nEs decir, si \\(f=(f_1(\\bar{x}),...,f_k(\\bar{x}))^T\\)\nEntonces,\n\\[\nJ = \\begin{bmatrix}\n- \\nabla f_1(\\bar{x}) -\\\\\n\\vdots \\\\\n- \\nabla f_k(\\bar{x}) -\\\\\n\\end{bmatrix}\n\\]\n\n\n\n\n\n\n\nImportante\n\n\nPodemos pensar el Jacobiano como el “vector de Gradientes” stackeados hacia abajo para cada componente de la función multivariada. Como cada componente es un vector de \\(1 \\times n\\), el Jacobiano tendrá dimensiones \\(k \\times n\\)."
  },
  {
    "objectID": "tics579/clase-P2.html#matrices-como-transformaciones-lineales",
    "href": "tics579/clase-P2.html#matrices-como-transformaciones-lineales",
    "title": "TICS-579-Deep Learning",
    "section": "Matrices como Transformaciones Lineales",
    "text": "Matrices como Transformaciones Lineales\nSupongamos:\n\\[f(x) = A \\cdot \\bar{x}\\]\n\n\n\n\n\n\n\nCaution\n\n\n\nSi \\(\\bar{x} \\in \\mathbb{R}^n\\) y \\(A \\in \\mathbb{R}^{m \\times n}\\), entonces \\(f(x) \\in \\mathbb{R}^m\\). Es decir, \\(f\\) es una tranformación que lleva al vector \\(\\bar{x}\\) de \\(\\mathbb{R}^n\\) a un vector de \\(\\mathbb{R}^m\\).\nEntenderemos una Transformación Lineal como una función que toma un vector de entrada (cada componente \\(x_j\\) es lineal) y lo transforma en otro vector de salida, manteniendo la estructura lineal .\n\n\n\n\n\n\n\n\n\n\n\n\nGradiente de una Transformación Lineal\n\n\nSi: \\[f_i(\\bar{x}) = A_{i,:} \\cdot \\bar{x} = \\sum_{j=1}^n A_{i,j}\\cdot x_j \\implies \\frac{\\partial f_i}{\\partial x_j} = A_{i,j}\\]\n\n\\(f_i(\\bar{x})\\) corresponde a la componente \\(i\\) de la función vectorial \\(f\\) evaluada en \\(\\bar{x}\\).\n\\(\\frac{\\partial f_i}{\\partial x_j}\\) corresponde a la derivada parcial de \\(f_i\\) respecto a la componente \\(x_j\\).\nTodas las derivadas se guardan en el Jacobiano de \\(f\\)."
  },
  {
    "objectID": "tics579/clase-P2.html#matrices-como-transformaciones-lineales-1",
    "href": "tics579/clase-P2.html#matrices-como-transformaciones-lineales-1",
    "title": "TICS-579-Deep Learning",
    "section": "Matrices como Transformaciones Lineales",
    "text": "Matrices como Transformaciones Lineales\nEl Jacobiano de \\(f\\) es entonces:\n\\[\nJ = \\begin{bmatrix}\nA_{1,1} & A_{1,2} & \\cdots & A_{1,n} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\nA_{m,1} & A_{m,2} & \\cdots & A_{m,n}\n\\end{bmatrix}\n\\]\n\n\n\n\n\n\n\nPropiedad\n\n\nDe acá podemos deducir que \\(\\frac{\\partial A \\cdot \\bar{x}}{\\partial \\bar{x}} = A\\). Es decir el calculo matricial se comporta como las reglas de derivación escalar (al menos lo que usaremos nosotros).\n\n\n\n\n\n\n\n\n\n\n\nRecomendación\n\n\nVer los siguientes videos para entender el concepto de Transformación Lineal de una Matriz:\n\nTransformaciones Lineales y Matrices\nMatrices no cuadradas como Transformaciones"
  },
  {
    "objectID": "tics579/clase-P2.html#hessiano",
    "href": "tics579/clase-P2.html#hessiano",
    "title": "TICS-579-Deep Learning",
    "section": "Hessiano",
    "text": "Hessiano\n\n\n\n\n\n\n\nHessiano\n\n\nSi la función a derivar es el Gradiente, entonces el Jacobiano pasa a llamarse Hessiano. Es decir, el Hessiano es el Jacobiano del Gradiente y es equivalente a la segunda derivada de una función vectorial/multivariada.\n\n\n\n\n\n\n\n\n\n\n\nPropiedades\n\n\n\nEl Hessiano es una matriz cuadrada de dimensiones \\(n \\times n\\).\nSiempre es simétrica.\nSi el Hessiano es PSD (Positive Semi-Definite), entonces la función es convexa. Demostrando que \\(\\bar{x}^T H_f(\\bar{x}) \\bar{x} \\geq 0\\) para todo \\(\\bar{x}\\).\n\n\n\n\n\n\\(\\nabla f_i(\\bar{x})\\) corresponde a la componente \\(i\\) del Gradiente de \\(f\\) evaluada en \\(\\bar{x}\\).\n\\[\nH_f(\\bar{x}) = \\begin{bmatrix}\n\\frac{\\partial^2 f}{\\partial x_1^2} & \\frac{\\partial^2 f}{\\partial x_1 \\partial x_2} & \\cdots & \\frac{\\partial^2 f}{\\partial x_1 \\partial x_n} \\\\\n\\frac{\\partial^2 f}{\\partial x_2 \\partial x_1} & \\frac{\\partial^2 f}{\\partial x_2^2} & \\cdots & \\frac{\\partial^2 f}{\\partial x_2 \\partial x_n} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\n\\frac{\\partial^2 f}{\\partial x_n \\partial x_1} & \\frac{\\partial^2 f}{\\partial x_n \\partial x_2} & \\cdots & \\frac{\\partial^2 f}{\\partial x_n^2}\n\\end{bmatrix} = \\begin{bmatrix}\n- \\nabla (\\nabla f_1(\\bar{x})) -\\\\\n- \\nabla (\\nabla f_2(\\bar{x})) -\\\\\n\\vdots \\\\\n- \\nabla (\\nabla f_n(\\bar{x})) -\n\\end{bmatrix}\n\\]"
  },
  {
    "objectID": "tics579/clase-P2.html#hessiano-ejemplo",
    "href": "tics579/clase-P2.html#hessiano-ejemplo",
    "title": "TICS-579-Deep Learning",
    "section": "Hessiano: Ejemplo",
    "text": "Hessiano: Ejemplo\n\\[f(x,y) = 3x^2 + 2xy + y^2 + 5x + 4\\]\nConsideremos entonces que \\(\\bar{x} = (x,y)\\). Es decir, va de \\(\\mathbb{R}^2\\) a \\(\\mathbb{R}\\).\n\n\n\n\n\n\n\nGradiente de \\(f\\)\n\n\n\\[\\nabla f(\\bar{x}) = \\nabla f(x,y) = \\begin{bmatrix}\\partial f_x & \\partial f_y\\end{bmatrix} = \\begin{bmatrix} 6x + 2y + 5 & 2x + 2y\\end{bmatrix}\\]\n\n\n\n\n\n\n\n\n\n\n\nHessiano\n\n\n\\[ H_f(\\bar{x}) = \\begin{bmatrix}\n- \\nabla (\\nabla f_1(\\bar{x})) - \\\\\n- \\nabla (\\nabla f_2(\\bar{x})) - \\\\\n\\end{bmatrix} =\n\\begin{bmatrix}\n6 & 2 \\\\\n2 & 2\n\\end{bmatrix}\\]"
  },
  {
    "objectID": "tics579/clase-P2.html#automatic-differentiation",
    "href": "tics579/clase-P2.html#automatic-differentiation",
    "title": "TICS-579-Deep Learning",
    "section": "Automatic Differentiation",
    "text": "Automatic Differentiation\nSupongamos que tenemos que calcular la derivada de \\(f(1)\\) de la siguiente función:\n\\[f(x) = \\sqrt{x^2 + exp(x^2)} + cos((x^2 + exp(x^2))\\]\n\nSu derivada analítica, luego de bastante esfuerzo es:\n\n\\[f'(x) = 2x \\left(\\frac{1}{2\\sqrt{x^2+exp(x^2)}} - sen(x^2 + exp(x^2))\\right)\\left(1+exp(x^2)\\right)\\] \\[f'(1) = 5.983\\]\n\n\n\n\n\n\n\nAtención\n\n\nCalcular la derivada de manera analítica es muy engorroso y propenso a errores. Además, si la función tiene muchas variables, el cálculo se vuelve inviable y difícil de programar. Por ello se utiliza la diferenciación automática, un proceso algorítmico que permite calcular derivadas de funciones complejas de manera eficiente y precisa."
  },
  {
    "objectID": "tics579/clase-P2.html#automatic-differentiation-ejemplo",
    "href": "tics579/clase-P2.html#automatic-differentiation-ejemplo",
    "title": "TICS-579-Deep Learning",
    "section": "Automatic Differentiation: Ejemplo",
    "text": "Automatic Differentiation: Ejemplo\nPodemos reescribir la función \\(f\\) como una secuencia de operaciones elementales y asignar variables intermedias:\n\n\n\n\n\n\n\n\n\n\\(a = x^2\\)\n\\(b = exp(a)\\)\n\\(c = a + b\\)\n\\(d = \\sqrt{c}\\)\n\\(e = Cos(c)\\)\n\\(f = d + e\\)\n\n\n\n\n\n\n\n\n\nProcedimiento\n\n\n\nLa idea es que el camino entre dos nodos rojos son una derivada entre ambos nodos. Es decir, el camino entre \\(f\\) y \\(d\\) es \\(\\frac{\\partial f}{\\partial d}\\).\nLas derivadas se van acumulando y deben considerar todos los caminos. Por ejemplo, para calcular \\(\\frac{\\partial f}{\\partial c}\\), debemos considerar los caminos \\(f \\to d \\to c\\) y \\(f \\to e \\to c\\).\nTodas las variables definidas permiten calcular sus derivadas respecto a su input.\nSi comenzamos a derivar de atrás hacia adelante podemos reutilizar cálculos anteriores."
  },
  {
    "objectID": "tics579/clase-P2.html#automatic-differentiation-ejemplo-1",
    "href": "tics579/clase-P2.html#automatic-differentiation-ejemplo-1",
    "title": "TICS-579-Deep Learning",
    "section": "Automatic Differentiation: Ejemplo",
    "text": "Automatic Differentiation: Ejemplo\n\n\n\\[\\frac{\\partial f}{\\partial d} = \\frac{\\partial f}{\\partial e} = 1\\] \\[\\frac{\\partial f}{\\partial c} = \\frac{\\partial f}{\\partial d} \\cdot \\frac{\\partial d}{\\partial c} + \\frac{\\partial f}{\\partial e} \\cdot \\frac{\\partial e}{\\partial c} = 1 \\cdot 0.259 + 1 \\cdot 0.545 = 0.8045\\] \\[\n\\begin{align}\n\\frac{\\partial f}{\\partial b} &= \\frac{\\partial f}{\\partial d} \\cdot \\frac{\\partial d}{\\partial c} \\cdot \\frac{\\partial c}{\\partial b} + \\frac{\\partial f}{\\partial e} \\cdot \\frac{\\partial e}{\\partial c} \\cdot \\frac{\\partial c}{\\partial b} \\\\\n&= \\frac{\\partial f}{\\partial c} \\cdot \\frac{\\partial c}{\\partial b} = 0.8045 \\cdot 1 = 0.8045\n\\end{align}\n\\]\n\n\n\n\n\n\nNotar que \\(\\frac{\\partial f}{\\partial c}\\) ya la habíamos calculado.\n\n\n\n\n\n\n\\[\\frac{\\partial f}{\\partial a} = \\frac{\\partial f}{\\partial b} \\cdot \\frac{\\partial b}{\\partial a} + \\frac{\\partial f}{\\partial c} \\cdot \\frac{\\partial c}{\\partial a} = 0.8045 \\cdot 2.7183 + 0.8045 \\cdot 1 = 2.9913\\]\n\\[\\frac{\\partial f}{\\partial x} = \\frac{\\partial f}{\\partial a} \\cdot \\frac{\\partial a}{\\partial x} = 2.9913 \\cdot 2 = 5.983\\]\n\n\nSi \\(x = 1\\), entonces:\n\\(a = x^2 = 1\\)\n\\(b = exp(a) = 2.7183\\)\n\\(c = a + b = 3.7183\\)\n\\(d = \\sqrt{c} = 1.9283\\)\n\\(e = Cos(c) = -0.8383\\)\n\\(f = d + e = 1.09\\)\n\\(\\frac{\\partial d}{\\partial c} = \\frac{1}{2\\sqrt{c}} = 0.259\\)\n\\(\\frac{\\partial e}{\\partial c} = -sen(c) = 0.545\\)\n\\(\\frac{\\partial c}{\\partial b} = 1\\)\n\\(\\frac{\\partial b}{\\partial a} = exp(a) = 2.7183\\)\n\\(\\frac{\\partial a}{\\partial x} = 2x = 2\\)"
  },
  {
    "objectID": "tics579/clase-P2.html#método-de-newton",
    "href": "tics579/clase-P2.html#método-de-newton",
    "title": "TICS-579-Deep Learning",
    "section": "Método de Newton",
    "text": "Método de Newton\n\nEl método de Newton es un algoritmo iterativo utilizado para encontrar las raíces de una función real (los puntos donde la función se hace cero).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAlgotitmo de Newton\n\n\n\nLa idea es acercarse de manera iterativa a un punto \\(x_{k+1}\\) que sea una raíz de la función \\(f(x)\\) (o al menos se acerque), partiendo de un punto inicial \\(x_k\\).\nSe asume que me muevo un espacio \\(h\\).\nAproximo \\(f(x + h)\\) utilizando la aproximación local de la función en torno a \\(x_k\\) como una derivada.\n\n\n\n\n\n\n\n\n\n\nFórmula de Newton\n\n\n\\[x_{k+1} = x_k - \\frac{f(x_k)}{f'(x_k)}\\]"
  },
  {
    "objectID": "tics579/clase-P2.html#aplicación-como-algoritmo-de-optimización",
    "href": "tics579/clase-P2.html#aplicación-como-algoritmo-de-optimización",
    "title": "TICS-579-Deep Learning",
    "section": "Aplicación como Algoritmo de Optimización",
    "text": "Aplicación como Algoritmo de Optimización\n\nNormalmente cuando necesitamos optimizar una función, buscamos los puntos críticos igualando las derivadas a cero. Es decir:\n\n\\[\\frac{d f}{d x_i} = 0\\]\nSi consideramos que \\(f\\) ahora es una derivada. Entonces el Método de Newton se convierte en un algoritmo de optimización.\n\\[x_{k+1} = x_k - \\frac{f'(x_k)}{f''(x_k)}\\]\n\n\n\n\n\n\nVersión Matricial/Multivariada\n\n\n\\[\\bar{x_{k+1}} = \\bar{x_k} - H_f(\\bar{x_k}) \\cdot \\nabla f(\\bar{x_k})\\]\nDonde \\(\\nabla f(\\bar{x_k})\\) es el Gradiente de \\(f\\) evaluado en \\(\\bar{x_k}\\) y \\(H_f(\\bar{x_k})\\) es el Hessiano de \\(f\\) evaluado en \\(\\bar{x_k}\\)."
  },
  {
    "objectID": "tics579/clase-P2.html#optimización-gradient-descent",
    "href": "tics579/clase-P2.html#optimización-gradient-descent",
    "title": "TICS-579-Deep Learning",
    "section": "Optimización: Gradient Descent",
    "text": "Optimización: Gradient Descent\n\nEl Algoritmo de Gradient Descent es un método iterativo para encontrar el mínimo de una función. Básicamente es una “simplificación burda” del método de Newton, dado que calcular el Hessiano es costoso y no siempre es necesario.\n\n\nPara ello se aproxima el Hessiano como una constante \\(\\alpha\\) el cuál llamaremos learning rate. El Gradient Descent queda definido como:\n\n\n\n\n\n\n\n\nGradient Descent\n\n\n\\[x_{k+1} = x_k - \\alpha \\cdot \\nabla f(x_k)\\]\n\n\n\n\n\n\n\n\n\n\n👀 Ojito\n\n\nAdicionalmente este método se generalizó no sólo para escalares y/o vectores sino también para matrices y tensores que requieran optimizar cualquier función \\(f\\).\n\n\n\n\n\n\n\n\n\nOtra forma de verlo\n\n\nSe puede pensar también como que el valor óptimo se encuentra en la dirección opuesta al gradiente moviéndose a un paso constante \\(\\alpha\\)."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Alfonso Tobar, Msc.",
    "section": "",
    "text": "LinkedIn\n  \n  \n    \n     Github\n  \n  \n    \n     datacuber.cl\n  \n\n  \n  \nSoy Alfonso y he trabajado como Científico de Datos por los últimos 10 años. Además me gusta el Machine Learning Competitivo y hasta el momento he ganado 2 competencias.\nActualmente me encuentro cursando mi PhD. en Data Science. Mis intereses de investigación tienen que ver con Machine Learning y Deep Learning enfocándome principalmente en la aplicación de Transformers.\nEn mi tiempo libre practico Tenis de Mesa y escribo sobre Machine Learning en mi blog: datacuber.cl.\n\n\nUniversidad Adolfo Ibañez, Viña del Mar | PhD. in Data Science | 2023 - 2026\nUniversidad Adolfo Ibañez, Viña del Mar | Msc. in Data Science | 2022 - 2024\nUniversidad Técnica Federico Santa María | Ingeniería Civil | 2005 - 2013\nPuedes ver más detalles de mi carrera acá.\n\n\n\n\nHate Speech Recognition in Chilean Tweets"
  },
  {
    "objectID": "index.html#educación",
    "href": "index.html#educación",
    "title": "Alfonso Tobar, Msc.",
    "section": "",
    "text": "Universidad Adolfo Ibañez, Viña del Mar | PhD. in Data Science | 2023 - 2026\nUniversidad Adolfo Ibañez, Viña del Mar | Msc. in Data Science | 2022 - 2024\nUniversidad Técnica Federico Santa María | Ingeniería Civil | 2005 - 2013\nPuedes ver más detalles de mi carrera acá."
  },
  {
    "objectID": "index.html#publicaciones",
    "href": "index.html#publicaciones",
    "title": "Alfonso Tobar, Msc.",
    "section": "",
    "text": "Hate Speech Recognition in Chilean Tweets"
  },
  {
    "objectID": "tics579-labs.html",
    "href": "tics579-labs.html",
    "title": "Prácticos",
    "section": "",
    "text": "Práctico\nColab\n\n\n\n\nRegresión Logística\n\n\n\nIntro Pytorch\n\n\n\nGradiente de un Embedding\n\n\n\nTraining Tricks\n\n\n\nCNNs\n\n\n\n\n\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Notebooks"
    ]
  },
  {
    "objectID": "tics411/clase-11.html#naive-bayes-preliminares",
    "href": "tics411/clase-11.html#naive-bayes-preliminares",
    "title": "TICS-411 Minería de Datos",
    "section": "Naive Bayes: Preliminares",
    "text": "Naive Bayes: Preliminares\n\nTambién conocido como Clasificador Inexperto de Bayes, es uno de los clasificadores más conocidos y sencillos.\n\n\n\n\n\n\n\nSe hizo particularmente conocido como uno de los primeros algoritmos en funcionar como Clasificador de Spam de manera efectiva.\n\n\n\n\nEs un modelo netamente probabilístico basado en el Teorema de Bayes.\n\nAprende una distribucional de Probabilidad Condicional.\nDado un punto \\(x_i\\), el modelo retorna la “probabilidad” de que \\(x_i\\) pertenezca a una clase específica."
  },
  {
    "objectID": "tics411/clase-11.html#definiciones",
    "href": "tics411/clase-11.html#definiciones",
    "title": "TICS-411 Minería de Datos",
    "section": "Definiciones",
    "text": "Definiciones\n\n\n\nProbabilidad Condicional\n\n\\[P(X|C) = \\frac{P(X \\cap C)}{P(C)}\\]\n\nTeorema de Bayes\n\n\\[P(C|X) = \\frac{P(X|C)P(C)}{P(X)}\\]\n\nIndependencia Condicional\n\n\\[P(X_1, X_2, ..., X_k|C) = \\prod_{i=1}^k P(X_i|C)\\]\n\n\n\n\n\n\n\n\n\n\nSe lee como la Probabilidad de que Ocurra \\(X\\) dado que tenemos \\(C\\).\n\n\n\n\n\n\n\n\n\n\nLa probabilidad a posteriori (LHS), depende de el Likelihood, la probabilidad a priori y la evidencia (RHS).\n\n\n\n\n\n\n\n\n\n\nSi asumimos independencia, entonces la probabilidad conjunta de \\(k\\) eventos condicionados, se calcula como la productoria de las probabilidades condicionales independientes."
  },
  {
    "objectID": "tics411/clase-11.html#ejemplo-básico",
    "href": "tics411/clase-11.html#ejemplo-básico",
    "title": "TICS-411 Minería de Datos",
    "section": "Ejemplo básico",
    "text": "Ejemplo básico\n\n\n\nSupongamos que:\n\nSabemos que la Meningitis produce Tortícolis el 50% de las veces.\nLa probabilidad de tener meningitis es: \\(1/50000\\).\nLa probabilidad de tener Tortícolis: \\(1/20\\).\n\n\n\n\nSi su paciente tiene tortícolis, ¿Cuál es la probabilidad de que tenga Meningitis?\n\\[P(M|T) = \\frac{P(T|M)P(M)}{P(T)}=\\frac{0.5 \\cdot 1/50000}{1/20} = 0.0002\\]"
  },
  {
    "objectID": "tics411/clase-11.html#modelo-naive-bayes-aprendizaje",
    "href": "tics411/clase-11.html#modelo-naive-bayes-aprendizaje",
    "title": "TICS-411 Minería de Datos",
    "section": "Modelo Naive Bayes: Aprendizaje",
    "text": "Modelo Naive Bayes: Aprendizaje\n\\[P(y = C_j|X_1, X_2, ..., X_k) = \\frac{P(X_1,X_2,..., X_k|y=C_j)P(y=C_j)}{P(X_1, X_2, ..., X_k)}\\]\n\n\n\n\\(P(y=C_j|X)\\) sería la probabilidad de que la predicción del modelo sea \\(C_j\\) dado que lo alimentamos con las variables \\(X\\).\nLuego \\(P(y=C_j)\\) es la probabilidad a priori de que la clase sea \\(C_j\\).\n\\(P(X|y=C_j)\\) es el likelihood (verosimilitud). Corresponde a la distribución de probabilidad de las variables X cuando la clase es \\(C_j\\).\n\\(P(X)\\) es la evidencia, y normalmente es muy complejo de calcular.\n\n\n\n\n\n\n\n\nPor simplicidad reduciremos \\(X_1, X_2, ..., X_k\\) a \\(X\\).\n\n\n\n\n\n\n\n\n\n\\(P(X)\\) tiene como única función la de normalizar la probabilidad para que vaya en un rango entre 0 y 1."
  },
  {
    "objectID": "tics411/clase-11.html#modelo-naive-bayes-predicción",
    "href": "tics411/clase-11.html#modelo-naive-bayes-predicción",
    "title": "TICS-411 Minería de Datos",
    "section": "Modelo Naive Bayes: Predicción",
    "text": "Modelo Naive Bayes: Predicción\n\\[\\hat{y_i} = \\underset{C_j}{argmax} \\: P(y=C_j|X) \\]\ndonde, \\[P(y = C_j|X) \\propto \\prod_{i=1}^k P(X|y=C_j)P(y=C_j)\\]\n\n\n\n\n\n\nLa predicción de Naive Bayes corresponde a la clase que entrega [un estimado de] la Probabilidad a Posteriori más grande."
  },
  {
    "objectID": "tics411/clase-11.html#ejemplo",
    "href": "tics411/clase-11.html#ejemplo",
    "title": "TICS-411 Minería de Datos",
    "section": "Ejemplo",
    "text": "Ejemplo\n\n\n\n\n\n\n\n\n\n\n\n¿Cómo clasificamos el siguiente punto?\n\\[ X = [C=Soleado,T=Media,H=Alta,V=Débil]\\]\n\n\n\n\n\n\nProbabilidad de Sí\n\n\n\\[P(y = Sí|X) = P(X|y=Sí)P(y=Sí)\\]\n\n\n\n\n\n\nProbabilidad de No\n\n\n\\[ P(y = No|X) = P(X|y=No)P(y=No)\\]"
  },
  {
    "objectID": "tics411/clase-11.html#ejemplo-1",
    "href": "tics411/clase-11.html#ejemplo-1",
    "title": "TICS-411 Minería de Datos",
    "section": "Ejemplo",
    "text": "Ejemplo\n\n\n\n\\[ P(y = Sí|X) = P(C=Soleado|y=Sí)P(T=Media|y=Sí)P(H=Alta|y=Sí)P(V=Débil|y=Sí)P(y=Sí)\\]\n\n\n\n\n\n\n\\[ P(y = No|X) = P(C=Soleado|y=No)P(T=Media|y=No)P(H=Alta|y=No)P(V=Débil|y=No)P(y=No)\\]\n\n\n\n\n\nProbabilidad Condicional para clase Sí\n\\[\\small P(C = Soleado|y = Sí) = 2/9\\] \\[\\small P(T = Media|y = Sí) = 4/9\\]\n\\[\\small P(H = Alta|y = Sí) = 3/9\\] \\[\\small P(V=Débil|y = Sí) = 6/9\\]\n\nProbabilidad Condicional para clase No\n\\[\\small P(C = Soleado|y = No) = 3/5\\] \\[\\small P(T = Media|y = No) = 2/5\\]\n\\[\\small P(H = Alta|y = No) = 4/5\\] \\[\\small P(V=Débil|y = No) = 2/5\\]\n\nProbabilidad a priori\n\\[P(y = Sí) = \\frac{9}{14} = 0.642\\] \\[P(y = No) = \\frac{5}{14} = 0.357\\]"
  },
  {
    "objectID": "tics411/clase-11.html#predicción",
    "href": "tics411/clase-11.html#predicción",
    "title": "TICS-411 Minería de Datos",
    "section": "Predicción",
    "text": "Predicción\n\n\n\n\\[\\scriptsize P(y = Sí|X) = P(C=Soleado|y=Sí)P(T=Media|y=Sí)P(H=Alta|y=Sí)P(V=Débil|y=Sí)P(y=Sí)\\] \\[\\small P(y = Sí|X) = \\frac{2}{9} \\cdot \\frac{4}{9} \\cdot \\frac{3}{9} \\cdot \\frac{6}{9} \\cdot \\frac{9}{14} = 0.0141\\]\n\n\n\n\n\n\n\\[\\scriptsize P(y = No|X) = P(C=Soleado|y=No)P(T=Media|y=No)P(H=Alta|y=No)P(V=Débil|y=No)P(y=No)\\] \\[\\small P(y = No|X) = \\frac{3}{5} \\cdot \\frac{2}{5} \\cdot \\frac{4}{5} \\cdot \\frac{2}{5} \\cdot \\frac{5}{14} = 0.0274\\]\n\n\n\n\n\n\n\n\n\n\\[\\hat{y} = argmax \\{0.0141, 0.0274\\} = No\\]"
  },
  {
    "objectID": "tics411/clase-11.html#smoothing",
    "href": "tics411/clase-11.html#smoothing",
    "title": "TICS-411 Minería de Datos",
    "section": "Smoothing",
    "text": "Smoothing\nSupongamos otro dataset más pequeño:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDado que Naive Bayes se calcula como una Productoria, al tener probabilidades 0 inmediatamente la Probabilidad a Posteriori es 0.\n\n\n\n\\[ P(Clima = Soleado|y = Sí) = \\frac{0}{6}\\] \\[ P(Clima = Soleado|y = No) = \\frac{5}{8}\\]\n\n\\[P(X_j|C = i) = \\frac{N_{yj} + \\alpha}{N_y + M\\alpha}\\]\n\n\\(\\alpha\\): Es un Hiperparámetro. Si \\(\\alpha = 1\\) se le llama Laplace Smoothing, si \\(\\alpha &lt;1\\) entonces se le llama Lidstone Smoothing.\nM: Corresponde al número de posibles valores que puede tomar \\(X_j\\)\n\\(N_{yj}\\): Corresponde a la cantidad de registros que toman el valor de la variable \\(X_j\\) solicitado en la clase \\(y\\).\n\\(N_{y}\\): Corresponde a la cantidad de registros totales que tienen la clase \\(y\\)."
  },
  {
    "objectID": "tics411/clase-11.html#laplace-smoothing",
    "href": "tics411/clase-11.html#laplace-smoothing",
    "title": "TICS-411 Minería de Datos",
    "section": "Laplace Smoothing",
    "text": "Laplace Smoothing\n\n\nSin Laplace\n\n\n\n\n\n\nCon Laplace\n\n\n\n\n\n\n\n\n\n\n\n\nEn este caso \\(\\alpha = 1\\) y \\(M=3\\) ya que Clima puede tomar 3 valores: Soleado, Cubierto y Lluvia."
  },
  {
    "objectID": "tics411/clase-11.html#variables-continuas",
    "href": "tics411/clase-11.html#variables-continuas",
    "title": "TICS-411 Minería de Datos",
    "section": "Variables Continuas",
    "text": "Variables Continuas\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPodemos calcular el Likelihood como una PDF (Probability Density Function). La más común: Distribución Normal (Gaussian Naive Bayes).\n\n\n\n\\[f(x) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}}e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}\\]"
  },
  {
    "objectID": "tics411/clase-11.html#variables-continuas-predicción",
    "href": "tics411/clase-11.html#variables-continuas-predicción",
    "title": "TICS-411 Minería de Datos",
    "section": "Variables Continuas: Predicción",
    "text": "Variables Continuas: Predicción\n\n\n\n\\[P(humedad=74|y = Sí) = \\frac{1}{\\sqrt{2\\pi \\cdot 10.2^2}}e^{-\\frac{(74-79.1)^2}{2\\cdot 10.2^2}} = 0.0345 \\]\n\n\n\n\n\n\n\\[P(humedad=74|y = No) = \\frac{1}{\\sqrt{2\\pi \\cdot 9.7^2}}e^{-\\frac{(74-86.2)^2}{2\\cdot 9.7^2}} = 0.01865 \\]\n\n\n\n\n\n\n\n\n\nLuego la predicción es Sí."
  },
  {
    "objectID": "tics411/clase-11.html#detalles-técnicos",
    "href": "tics411/clase-11.html#detalles-técnicos",
    "title": "TICS-411 Minería de Datos",
    "section": "Detalles Técnicos",
    "text": "Detalles Técnicos\n\n\n\n\n\n\nFortalezas\n\n\n\nFácil de Implementar\nA menudo tiene un rendimiento decente a pesar de que las variables pueden no ser independientes.\nPuede aprender de forma incremental.\nValores faltantes son ignorados en el proceso de Aprendizaje.\nModelo robusto frente a datos atípicos y/o irrelevantes.\n\n\n\n\n\n\n\n\n\n\nDebilidades\n\n\n\nAsumir clases condicionadas produce probabilidades sesgadas.\nDependencias entre las variables no pueden ser modeladas."
  },
  {
    "objectID": "tics411/clase-11.html#implementación-en-scikit-learn",
    "href": "tics411/clase-11.html#implementación-en-scikit-learn",
    "title": "TICS-411 Minería de Datos",
    "section": "Implementación en Scikit-Learn",
    "text": "Implementación en Scikit-Learn\nMultinomial Naive Bayes (Normal)\nfrom sklearn.naive_bayes import MultinomialNB\n\nnb = MultinomialNB(alpha = 1)\nnb.fit(X_train, y_train)\n\ny_pred = nb.predict(X_test)\ny_proba = nb.predict_proba(X_test)\nGaussian Naive Bayes\nfrom sklearn.naive_bayes import GaussianNB\n\ngb = GaussianNB()\ngb.fit(X_train, y_train)\n\ny_pred = gb.predict(X_test)\ny_proba = gb.predict_proba(X_test)"
  },
  {
    "objectID": "tics411/notebooks/knn_desarrollo.html",
    "href": "tics411/notebooks/knn_desarrollo.html",
    "title": "Preprocesamiento",
    "section": "",
    "text": "import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn import set_config\n\nset_config(transform_output=\"pandas\")\n\ndf = sns.load_dataset(\"titanic\")\ndf.dtypes.value_counts().plot(kind=\"bar\")\nplt.tight_layout()\n\n\n\n\n\n\n\n\n\nX = df[[\"sex\", \"age\", \"class\", \"embark_town\", \"fare\"]]\ny = df.alive\ny\n\n0       no\n1      yes\n2      yes\n3      yes\n4       no\n      ... \n886     no\n887    yes\n888     no\n889    yes\n890     no\nName: alive, Length: 891, dtype: object\n\n\n\ny.value_counts(normalize=True).plot(kind=\"bar\")\n\n\n\n\n\n\n\n\n\nimport numpy as np\n\nnum_vars = X.select_dtypes(np.number).columns.tolist()\ncat_vars = [col for col in X.columns if col not in num_vars]\ncat_vars\n\n['sex', 'class', 'embark_town']\n\n\n\nX[num_vars].hist(figsize=(20, 6))\n\narray([[&lt;Axes: title={'center': 'age'}&gt;,\n        &lt;Axes: title={'center': 'fare'}&gt;]], dtype=object)\n\n\n\n\n\n\n\n\n\n\nX.groupby(\"age\").fare.mean()\n\nage\n0.42       8.5167\n0.67      14.5000\n0.75      19.2583\n0.83      23.8750\n0.92     151.5500\n           ...   \n70.00     40.7500\n70.50      7.7500\n71.00     42.0792\n74.00      7.7750\n80.00     30.0000\nName: fare, Length: 88, dtype: float64\n\n\n\ndf[\"rango_edad\"] = pd.cut(X[\"age\"], 5)\ndf.groupby(\"rango_edad\").fare.median()\n\nrango_edad\n(0.34, 16.336]      26.00000\n(16.336, 32.252]    10.50000\n(32.252, 48.168]    24.86875\n(48.168, 64.084]    29.70000\n(64.084, 80.0]      26.55000\nName: fare, dtype: float64\n\n\n\ndf.groupby(\"rango_edad\").fare.mean()\n\nrango_edad\n(0.34, 16.336]      31.588877\n(16.336, 32.252]    28.260499\n(32.252, 48.168]    42.788940\n(48.168, 64.084]    50.327235\n(64.084, 80.0]      28.905691\nName: fare, dtype: float64\n\n\n\ndf.fare.plot(kind=\"box\")\n\n\n\n\n\n\n\n\n\nfor cat in cat_vars:\n    X[cat].value_counts().plot(\n        kind=\"bar\", title=f\"Gráfico de variable {cat}\"\n    )\n    plt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nX.groupby(\"class\").fare.mean()\n\nclass\nFirst     84.154687\nSecond    20.662183\nThird     13.675550\nName: fare, dtype: float64\n\n\n\nX\n\n\n\n\n\n\n\n\nsex\nage\nclass\nembark_town\nfare\n\n\n\n\n0\nmale\n22.0\nThird\nSouthampton\n7.2500\n\n\n1\nfemale\n38.0\nFirst\nCherbourg\n71.2833\n\n\n2\nfemale\n26.0\nThird\nSouthampton\n7.9250\n\n\n3\nfemale\n35.0\nFirst\nSouthampton\n53.1000\n\n\n4\nmale\n35.0\nThird\nSouthampton\n8.0500\n\n\n...\n...\n...\n...\n...\n...\n\n\n886\nmale\n27.0\nSecond\nSouthampton\n13.0000\n\n\n887\nfemale\n19.0\nFirst\nSouthampton\n30.0000\n\n\n888\nfemale\nNaN\nThird\nSouthampton\n23.4500\n\n\n889\nmale\n26.0\nFirst\nCherbourg\n30.0000\n\n\n890\nmale\n32.0\nThird\nQueenstown\n7.7500\n\n\n\n\n891 rows × 5 columns\n\n\n\n\nX.isnull().mean().plot(kind=\"bar\")\n\n\n\n\n\n\n\n\n\nfrom feature_engine.encoding import OneHotEncoder, OrdinalEncoder\nfrom feature_engine.imputation import CategoricalImputer, MeanMedianImputer\n\nmmi = MeanMedianImputer(imputation_method=\"mean\")\nX_imp = mmi.fit_transform(X)\n\nci = CategoricalImputer(imputation_method=\"frequent\")\nX_imp = ci.fit_transform(X_imp)\nX_imp\n\n\n\n\n\n\n\n\nsex\nage\nclass\nembark_town\nfare\n\n\n\n\n0\nmale\n22.000000\nThird\nSouthampton\n7.2500\n\n\n1\nfemale\n38.000000\nFirst\nCherbourg\n71.2833\n\n\n2\nfemale\n26.000000\nThird\nSouthampton\n7.9250\n\n\n3\nfemale\n35.000000\nFirst\nSouthampton\n53.1000\n\n\n4\nmale\n35.000000\nThird\nSouthampton\n8.0500\n\n\n...\n...\n...\n...\n...\n...\n\n\n886\nmale\n27.000000\nSecond\nSouthampton\n13.0000\n\n\n887\nfemale\n19.000000\nFirst\nSouthampton\n30.0000\n\n\n888\nfemale\n29.699118\nThird\nSouthampton\n23.4500\n\n\n889\nmale\n26.000000\nFirst\nCherbourg\n30.0000\n\n\n890\nmale\n32.000000\nThird\nQueenstown\n7.7500\n\n\n\n\n891 rows × 5 columns\n\n\n\n\nohe = OneHotEncoder(variables=[\"sex\", \"embark_town\"])\nX_enc = ohe.fit_transform(X_imp)\nod = OrdinalEncoder(encoding_method=\"arbitrary\")\nX_enc = od.fit_transform(X_enc)\nX_enc\n\n\n\n\n\n\n\n\nage\nclass\nfare\nsex_male\nsex_female\nembark_town_Southampton\nembark_town_Cherbourg\nembark_town_Queenstown\n\n\n\n\n0\n22.000000\n0\n7.2500\n1\n0\n1\n0\n0\n\n\n1\n38.000000\n1\n71.2833\n0\n1\n0\n1\n0\n\n\n2\n26.000000\n0\n7.9250\n0\n1\n1\n0\n0\n\n\n3\n35.000000\n1\n53.1000\n0\n1\n1\n0\n0\n\n\n4\n35.000000\n0\n8.0500\n1\n0\n1\n0\n0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n886\n27.000000\n2\n13.0000\n1\n0\n1\n0\n0\n\n\n887\n19.000000\n1\n30.0000\n0\n1\n1\n0\n0\n\n\n888\n29.699118\n0\n23.4500\n0\n1\n1\n0\n0\n\n\n889\n26.000000\n1\n30.0000\n1\n0\n0\n1\n0\n\n\n890\n32.000000\n0\n7.7500\n1\n0\n0\n0\n1\n\n\n\n\n891 rows × 8 columns\n\n\n\n\nfrom sklearn.preprocessing import StandardScaler\nfrom feature_engine.wrappers import SklearnTransformerWrapper\n\nsc = SklearnTransformerWrapper(StandardScaler(), variables=[\"age\", \"fare\"])\nX_sc = sc.fit_transform(X_enc)\n\n\nsc_all = StandardScaler()\nX_sc_all = sc_all.fit_transform(X_enc)\nX_sc_all\n\n\n\n\n\n\n\n\nage\nclass\nfare\nsex_male\nsex_female\nembark_town_Southampton\nembark_town_Cherbourg\nembark_town_Queenstown\n\n\n\n\n0\n-0.592481\n-0.820037\n-0.502445\n0.737695\n-0.737695\n0.615838\n-0.482043\n-0.307562\n\n\n1\n0.638789\n0.431081\n0.786845\n-1.355574\n1.355574\n-1.623803\n2.074505\n-0.307562\n\n\n2\n-0.284663\n-0.820037\n-0.488854\n-1.355574\n1.355574\n0.615838\n-0.482043\n-0.307562\n\n\n3\n0.407926\n0.431081\n0.420730\n-1.355574\n1.355574\n0.615838\n-0.482043\n-0.307562\n\n\n4\n0.407926\n-0.820037\n-0.486337\n0.737695\n-0.737695\n0.615838\n-0.482043\n-0.307562\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n886\n-0.207709\n1.682199\n-0.386671\n0.737695\n-0.737695\n0.615838\n-0.482043\n-0.307562\n\n\n887\n-0.823344\n0.431081\n-0.044381\n-1.355574\n1.355574\n0.615838\n-0.482043\n-0.307562\n\n\n888\n0.000000\n-0.820037\n-0.176263\n-1.355574\n1.355574\n0.615838\n-0.482043\n-0.307562\n\n\n889\n-0.284663\n0.431081\n-0.044381\n0.737695\n-0.737695\n-1.623803\n2.074505\n-0.307562\n\n\n890\n0.177063\n-0.820037\n-0.492378\n0.737695\n-0.737695\n-1.623803\n-0.482043\n3.251373\n\n\n\n\n891 rows × 8 columns\n\n\n\n\nfrom sklearn.neighbors import KNeighborsClassifier\n\n\ndef knn(X, y, k=3):\n    knn = KNeighborsClassifier(n_neighbors=k, n_jobs=-1)\n    knn.fit(X, y)\n    print(f\"Puntaje para k = {k}: {knn.score(X, y)}\")\n\n\nfor k in [3, 5, 7, 9, 11, 13, 15]:\n    knn(X_sc, y, k=k)\n\nPuntaje para k = 3: 0.8843995510662177\nPuntaje para k = 5: 0.8686868686868687\nPuntaje para k = 7: 0.8608305274971941\nPuntaje para k = 9: 0.8428731762065096\nPuntaje para k = 11: 0.835016835016835\nPuntaje para k = 13: 0.8249158249158249\nPuntaje para k = 15: 0.819304152637486\n\n\n\nfor k in [3, 5, 7, 9, 11, 13, 15]:\n    knn(X_sc_all, y, k=k)\n\nPuntaje para k = 3: 0.8866442199775533\nPuntaje para k = 5: 0.8698092031425365\nPuntaje para k = 7: 0.8552188552188552\nPuntaje para k = 9: 0.8383838383838383\nPuntaje para k = 11: 0.835016835016835\nPuntaje para k = 13: 0.8282828282828283\nPuntaje para k = 15: 0.8237934904601572\n\n\n\nfor k in [3, 5, 7, 9, 11, 13, 15]:\n    knn(X_enc, y, k=k)\n\nPuntaje para k = 3: 0.8372615039281706\nPuntaje para k = 5: 0.8204264870931538\nPuntaje para k = 7: 0.7867564534231201\nPuntaje para k = 9: 0.7721661054994389\nPuntaje para k = 11: 0.7676767676767676\nPuntaje para k = 13: 0.7575757575757576\nPuntaje para k = 15: 0.7508417508417509\n\n\n\nX_enc\n\n\n\n\n\n\n\n\nage\nclass\nfare\nsex_male\nsex_female\nembark_town_Southampton\nembark_town_Cherbourg\nembark_town_Queenstown\n\n\n\n\n0\n22.000000\n0\n7.2500\n1\n0\n1\n0\n0\n\n\n1\n38.000000\n1\n71.2833\n0\n1\n0\n1\n0\n\n\n2\n26.000000\n0\n7.9250\n0\n1\n1\n0\n0\n\n\n3\n35.000000\n1\n53.1000\n0\n1\n1\n0\n0\n\n\n4\n35.000000\n0\n8.0500\n1\n0\n1\n0\n0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n886\n27.000000\n2\n13.0000\n1\n0\n1\n0\n0\n\n\n887\n19.000000\n1\n30.0000\n0\n1\n1\n0\n0\n\n\n888\n29.699118\n0\n23.4500\n0\n1\n1\n0\n0\n\n\n889\n26.000000\n1\n30.0000\n1\n0\n0\n1\n0\n\n\n890\n32.000000\n0\n7.7500\n1\n0\n0\n0\n1\n\n\n\n\n891 rows × 8 columns\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "tics411/notebooks/viz.html",
    "href": "tics411/notebooks/viz.html",
    "title": "Clases UAI",
    "section": "",
    "text": "import matplotlib.pyplot as plt\nimport numpy as np\n\na = np.array([4.5, 4, 4.1, 1, 2.3, 2.2, 2.4, 5, 5.5, 6.2, 6, 6, 6, 6])\nb = np.append(a, a + 1)\n\nfig = plt.figure(figsize=(20, 6))\nax = fig.subplot_mosaic(\"ABC\")\nax[\"A\"].hist(b, bins=5)\nax[\"A\"].set_title(\"Bins 5\")\nax[\"A\"].set_xlabel(\"Notas\")\nax[\"A\"].set_ylabel(\"Número de Estudiantes\")\nax[\"B\"].hist(b, bins=15)\nax[\"B\"].set_title(\"Bins 15\")\nax[\"B\"].set_xlabel(\"Notas\")\nax[\"C\"].hist(b, bins=30)\nax[\"C\"].set_title(\"Bins 30\")\nax[\"C\"].set_xlabel(\"Notas\")\nplt.show()\n\n\n\n\n\n\n\n\n\nfrom sklearn.neighbors import KernelDensity\n\n\nkd_gauss = KernelDensity(kernel=\"epanechnikov\")\nkd_gauss.fit(b[:, np.newaxis])\nx_grid = np.linspace(1, 6, 1000)\nb_gauss = np.exp(kd_gauss.score_samples(x_grid[:, np.newaxis]))\nplt.hist(b)\nplt.plot(b_gauss)\n\n\n\n\n\n\n\n\n\nfrom scipy.stats import norm\n\nnp.random.seed(0)\nx_grid = np.linspace(-4.5, 3.5, 1000)\nx = np.concatenate([norm(-1, 1.0).rvs(400), norm(1, 0.3).rvs(100)])\n\n\ndef kde_sklearn(x, x_grid, bandwidth=0.2, **kwargs):\n    \"\"\"Kernel Density Estimation with Scikit-learn\"\"\"\n    kde_skl = KernelDensity(bandwidth=bandwidth, **kwargs)\n    kde_skl.fit(x[:, np.newaxis])\n    # score_samples() returns the log-likelihood of the samples\n    log_pdf = kde_skl.score_samples(x_grid[:, np.newaxis])\n    return np.exp(log_pdf)\n\n\npdf = kde_sklearn(x, x_grid, bandwidth=0.2)\n\nplt.hist(x)\nplt.plot(x_grid, pdf)\n\n\n\n\n\n\n\n\n\nn = 100\nnp.random.seed(123)\nmuestra_1 = np.random.normal(loc=1, scale=0.5, size=int(n * 0.75))\nmuestra_2 = np.random.normal(loc=-1, scale=0.5, size=int(n * 0.25))\ndatos = np.hstack((muestra_1, muestra_2)) + 3\n\nX_grid = np.linspace(0, 7, 200)\n\nmodelo_kde = KernelDensity(kernel=\"tophat\", bandwidth=0.2)\nmodelo_kde.fit(datos.reshape(-1, 1))\n\nlog_densidad_pred = modelo_kde.score_samples(X_grid.reshape((-1, 1)))\n# Se aplica el exponente para deshacer el logaritmo\ndensidad_pred_tophat = np.exp(log_densidad_pred)\n\n\nn = 100\nnp.random.seed(123)\nmuestra_1 = np.random.normal(loc=1, scale=0.5, size=int(n * 0.75))\nmuestra_2 = np.random.normal(loc=-1, scale=0.5, size=int(n * 0.25))\ndatos = np.hstack((muestra_1, muestra_2)) + 3\n\nX_grid = np.linspace(0, 7, 200)\n\nmodelo_kde = KernelDensity(kernel=\"gaussian\", bandwidth=0.2)\nmodelo_kde.fit(datos.reshape(-1, 1))\n\nlog_densidad_pred = modelo_kde.score_samples(X_grid.reshape((-1, 1)))\n# Se aplica el exponente para deshacer el logaritmo\ndensidad_pred_gaussian = np.exp(log_densidad_pred)\n\n\nn = 100\nnp.random.seed(123)\nmuestra_1 = np.random.normal(loc=1, scale=0.5, size=int(n * 0.75))\nmuestra_2 = np.random.normal(loc=-1, scale=0.5, size=int(n * 0.25))\ndatos = np.hstack((muestra_1, muestra_2)) + 3\n\nX_grid = np.linspace(0, 7, 200)\n\nmodelo_kde = KernelDensity(kernel=\"epanechnikov\", bandwidth=0.2)\nmodelo_kde.fit(datos.reshape(-1, 1))\n\nlog_densidad_pred = modelo_kde.score_samples(X_grid.reshape((-1, 1)))\n# Se aplica el exponente para deshacer el logaritmo\ndensidad_pred_epa = np.exp(log_densidad_pred)\n\n\nfig = plt.figure(figsize=(20, 6))\nax = fig.subplot_mosaic(\"ABC\")\nax[\"A\"].hist(datos, bins=30, density=True, color=\"#3182bd\", alpha=0.5)\nax[\"A\"].plot(X_grid, densidad_pred_tophat, color=\"red\", label=\"predicción\")\nax[\"A\"].set_title(\"Kernel Uniforme/Tophat h=0.2\")\n\nax[\"B\"].hist(datos, bins=30, density=True, color=\"#3182bd\", alpha=0.5)\nax[\"B\"].plot(X_grid, densidad_pred_gaussian, color=\"red\", label=\"predicción\")\nax[\"B\"].set_title(\"Kernel Gaussiano h=0.2\")\n\nax[\"C\"].hist(datos, bins=30, density=True, color=\"#3182bd\", alpha=0.5)\nax[\"C\"].plot(X_grid, densidad_pred_epa, color=\"red\", label=\"predicción\")\nax[\"C\"].set_title(\"Kernel Epanechnikov h=0.2\")\n\nText(0.5, 1.0, 'Kernel Epanechnikov h=0.2')\n\n\n\n\n\n\n\n\n\n\nn = 1000\nnp.random.seed(123)\nmuestra_1 = np.random.normal(loc=1, scale=0.5, size=int(n * 0.75))\nmuestra_2 = np.random.normal(loc=-1, scale=0.5, size=int(n * 0.25))\ndatos = np.hstack((muestra_1, muestra_2))\n\nX_grid = np.linspace(-3, 4, 1000)\n\nmodelo_kde = KernelDensity(kernel=\"linear\", bandwidth=1)\nmodelo_kde.fit(datos.reshape(-1, 1))\n\nlog_densidad_pred = modelo_kde.score_samples(X_grid.reshape((-1, 1)))\n# Se aplica el exponente para deshacer el logaritmo\ndensidad_pred = np.exp(log_densidad_pred)\n\nfig, ax = plt.subplots(figsize=(7, 4))\nax.hist(datos, bins=30, density=True, color=\"#3182bd\", alpha=0.5)\nax.plot(X_grid, densidad_pred, color=\"red\", label=\"predicción\")\n\n\n\n\n\n\n\n\n\nimport seaborn as sns\n\ntitanic_df = sns.load_dataset(\"titanic\")\ntitanic_df[\"embarked\"].value_counts().plot(\n    kind=\"bar\", rot=0, title=\"Personas embarcadas por puerto del Titanic\"\n)\n\n\n\n\n\n\n\n\n\ntitanic_df.dtypes\n\nsurvived          int64\npclass            int64\nsex              object\nage             float64\nsibsp             int64\nparch             int64\nfare            float64\nembarked         object\nclass          category\nwho              object\nadult_male         bool\ndeck           category\nembark_town      object\nalive            object\nalone              bool\ndtype: object\n\n\n\ng = sns.catplot(\n    data=titanic_df, y=\"fare\", x=\"pclass\", kind=\"bar\", errorbar=None, hue=\"sex\"\n)\ng.figure.suptitle(\"Tarifa Promedio de Pasajeros del Titanic\\n por Clase y Sexo.\")\n\n\n\n\n\n\n\n\n\ndata = titanic_df[[\"age\", \"fare\"]].melt(value_vars=[\"age\", \"fare\"])\ndata\n\n\n\n\n\n\n\n\nvariable\nvalue\n\n\n\n\n0\nage\n22.00\n\n\n1\nage\n38.00\n\n\n2\nage\n26.00\n\n\n3\nage\n35.00\n\n\n4\nage\n35.00\n\n\n...\n...\n...\n\n\n1777\nfare\n13.00\n\n\n1778\nfare\n30.00\n\n\n1779\nfare\n23.45\n\n\n1780\nfare\n30.00\n\n\n1781\nfare\n7.75\n\n\n\n\n1782 rows × 2 columns\n\n\n\n\nsns.catplot(\n    kind=\"box\", x=\"variable\", y=\"value\", data=data, height=6, aspect=0.5, hue=\"variable\"\n)\n\n\n\n\n\n\n\n\n\niris_df = sns.load_dataset(\"iris\")\niris_df\n\n\n\n\n\n\n\n\nsepal_length\nsepal_width\npetal_length\npetal_width\nspecies\n\n\n\n\n0\n5.1\n3.5\n1.4\n0.2\nsetosa\n\n\n1\n4.9\n3.0\n1.4\n0.2\nsetosa\n\n\n2\n4.7\n3.2\n1.3\n0.2\nsetosa\n\n\n3\n4.6\n3.1\n1.5\n0.2\nsetosa\n\n\n4\n5.0\n3.6\n1.4\n0.2\nsetosa\n\n\n...\n...\n...\n...\n...\n...\n\n\n145\n6.7\n3.0\n5.2\n2.3\nvirginica\n\n\n146\n6.3\n2.5\n5.0\n1.9\nvirginica\n\n\n147\n6.5\n3.0\n5.2\n2.0\nvirginica\n\n\n148\n6.2\n3.4\n5.4\n2.3\nvirginica\n\n\n149\n5.9\n3.0\n5.1\n1.8\nvirginica\n\n\n\n\n150 rows × 5 columns\n\n\n\n\ndata = iris_df.melt(\n    value_vars=[\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\"]\n)\ndata\n\n\n\n\n\n\n\n\nvariable\nvalue\n\n\n\n\n0\nsepal_length\n5.1\n\n\n1\nsepal_length\n4.9\n\n\n2\nsepal_length\n4.7\n\n\n3\nsepal_length\n4.6\n\n\n4\nsepal_length\n5.0\n\n\n...\n...\n...\n\n\n595\npetal_width\n2.3\n\n\n596\npetal_width\n1.9\n\n\n597\npetal_width\n2.0\n\n\n598\npetal_width\n2.3\n\n\n599\npetal_width\n1.8\n\n\n\n\n600 rows × 2 columns\n\n\n\n\ng = sns.catplot(x=\"variable\", y=\"value\", kind=\"box\", hue=\"variable\", data=data)\ng.figure.suptitle(\"Distribución de Medidas de Flores\")\ng._legend.remove()\ng.set(xlabel=None)\ng.set(ylabel=None)\n\n\n\n\n\n\n\n\n\nplt.scatter(iris_df.sepal_length, iris_df.petal_length)\nplt.title(\"Relación entre Largo del Sépalo y del Pétalo\")\nplt.xlabel(\"Largo del Sépalo\")\nplt.ylabel(\"Largo del Pétalo\")\n\nText(0, 0.5, 'Largo del Pétalo')\n\n\n\n\n\n\n\n\n\n\nanscombe = sns.load_dataset(\"anscombe\")\n\nfig = plt.figure(figsize=(10, 9))\nax = fig.subplot_mosaic(\n    \"\"\"AB\n                        CD\"\"\"\n)\nsns.regplot(data=anscombe.query(\"dataset == 'I'\"), x=\"x\", y=\"y\", ax=ax[\"A\"], ci=None)\nsns.regplot(data=anscombe.query(\"dataset == 'II'\"), x=\"x\", y=\"y\", ax=ax[\"B\"], ci=None)\nsns.regplot(data=anscombe.query(\"dataset == 'III'\"), x=\"x\", y=\"y\", ax=ax[\"C\"], ci=None)\nsns.regplot(data=anscombe.query(\"dataset == 'IV'\"), x=\"x\", y=\"y\", ax=ax[\"D\"], ci=None)\nplt.suptitle(\"Cuarteto de Anscombe\")\n\nText(0.5, 0.98, 'Cuarteto de Anscombe')\n\n\n\n\n\n\n\n\n\n\nimport seaborn as sns\n\niris_df = sns.load_dataset(\"iris\")\niris_df\n\n\n\n\n\n\n\n\nsepal_length\nsepal_width\npetal_length\npetal_width\nspecies\n\n\n\n\n0\n5.1\n3.5\n1.4\n0.2\nsetosa\n\n\n1\n4.9\n3.0\n1.4\n0.2\nsetosa\n\n\n2\n4.7\n3.2\n1.3\n0.2\nsetosa\n\n\n3\n4.6\n3.1\n1.5\n0.2\nsetosa\n\n\n4\n5.0\n3.6\n1.4\n0.2\nsetosa\n\n\n...\n...\n...\n...\n...\n...\n\n\n145\n6.7\n3.0\n5.2\n2.3\nvirginica\n\n\n146\n6.3\n2.5\n5.0\n1.9\nvirginica\n\n\n147\n6.5\n3.0\n5.2\n2.0\nvirginica\n\n\n148\n6.2\n3.4\n5.4\n2.3\nvirginica\n\n\n149\n5.9\n3.0\n5.1\n1.8\nvirginica\n\n\n\n\n150 rows × 5 columns\n\n\n\n\nfrom sklearn.decomposition import PCA\nimport matplotlib.pyplot as plt\n\npca = PCA(n_components=2)\ndata = pca.fit_transform(iris_df.drop(columns=\"species\"))\nx, y = data[:,0], data[:,1]\n\nplt.scatter(x, y);\n\n\n\n\n\n\n\n\n\nc = iris_df.species.astype(\"category\").cat.codes\nplt.scatter(x,y, c = c)\nplt.title(\"3 Clusters\");\n\n\n\n\n\n\n\n\n\nc_prima = (c == 0).astype(\"int64\")\nplt.scatter(x,y, c= c_prima)\nplt.title(\"2 Clusters\")\n\nText(0.5, 1.0, '2 Clusters')\n\n\n\n\n\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "tics411/notebooks/09-ex-apriori.html",
    "href": "tics411/notebooks/09-ex-apriori.html",
    "title": "Algoritmo Apriori",
    "section": "",
    "text": "%%capture\n!pip install mlxtend\n\n\nfrom mlxtend.frequent_patterns import apriori, association_rules\nfrom mlxtend.preprocessing import TransactionEncoder\nimport pandas as pd\n\n## Escribir acá las Transacciones\ntransactions = [\n    [\"Pan\", \"Mantequilla\", \"Leche\"],\n    [\"Pan\", \"Mantequilla\"],\n    [\"Cerveza\", \"Galletas\", \"Pañales\"],\n    [\"Leche\", \"Pañales\", \"Pan\", \"Mantequilla\"],\n    [\"Cerveza\", \"Pañales\"],\n]\n\ntre = TransactionEncoder()\ndf = tre.fit_transform(transactions)\ndf_encoded = pd.DataFrame(df, columns=tre.columns_)\ndf_encoded\n\n\n\n\n\n\n\n\nCerveza\nGalletas\nLeche\nMantequilla\nPan\nPañales\n\n\n\n\n0\nFalse\nFalse\nTrue\nTrue\nTrue\nFalse\n\n\n1\nFalse\nFalse\nFalse\nTrue\nTrue\nFalse\n\n\n2\nTrue\nTrue\nFalse\nFalse\nFalse\nTrue\n\n\n3\nFalse\nFalse\nTrue\nTrue\nTrue\nTrue\n\n\n4\nTrue\nFalse\nFalse\nFalse\nFalse\nTrue\n\n\n\n\n\n\n\n\ndef apriori_algorithm(\n    df,\n    min_supp=0.4,\n    min_conf=0.7,\n    variables=[\n        \"antecedents\",\n        \"consequents\",\n        \"support\",\n        \"confidence\",\n        \"lift\",\n    ],\n):\n\n    frequent_itemsets = apriori(\n        df, min_support=min_supp, use_colnames=True\n    )\n    rules = association_rules(\n        frequent_itemsets, metric=\"confidence\", min_threshold=min_conf\n    )\n\n    return frequent_itemsets, rules[variables]\n\n\nfrequent_itemsets, rules = apriori_algorithm(\n    df_encoded, min_supp=0.4, min_conf=0.7\n)\ndisplay(frequent_itemsets)\ndisplay(rules)\n\n\n\n\n\n\n\n\nsupport\nitemsets\n\n\n\n\n0\n0.4\n(Cerveza)\n\n\n1\n0.4\n(Leche)\n\n\n2\n0.6\n(Mantequilla)\n\n\n3\n0.6\n(Pan)\n\n\n4\n0.6\n(Pañales)\n\n\n5\n0.4\n(Pañales, Cerveza)\n\n\n6\n0.4\n(Mantequilla, Leche)\n\n\n7\n0.4\n(Leche, Pan)\n\n\n8\n0.6\n(Mantequilla, Pan)\n\n\n9\n0.4\n(Mantequilla, Leche, Pan)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nantecedents\nconsequents\nsupport\nconfidence\nlift\n\n\n\n\n0\n(Cerveza)\n(Pañales)\n0.4\n1.0\n1.666667\n\n\n1\n(Leche)\n(Mantequilla)\n0.4\n1.0\n1.666667\n\n\n2\n(Leche)\n(Pan)\n0.4\n1.0\n1.666667\n\n\n3\n(Mantequilla)\n(Pan)\n0.6\n1.0\n1.666667\n\n\n4\n(Pan)\n(Mantequilla)\n0.6\n1.0\n1.666667\n\n\n5\n(Mantequilla, Leche)\n(Pan)\n0.4\n1.0\n1.666667\n\n\n6\n(Leche, Pan)\n(Mantequilla)\n0.4\n1.0\n1.666667\n\n\n7\n(Leche)\n(Mantequilla, Pan)\n0.4\n1.0\n1.666667\n\n\n\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "tics411/notebooks/13-ex-DT.html",
    "href": "tics411/notebooks/13-ex-DT.html",
    "title": "Clases UAI",
    "section": "",
    "text": "import pandas as pd\nimport seaborn as sns\n\ndf = sns.load_dataset(\"titanic\")\ndf\n\n\n\n\n\n\n\n\nsurvived\npclass\nsex\nage\nsibsp\nparch\nfare\nembarked\nclass\nwho\nadult_male\ndeck\nembark_town\nalive\nalone\n\n\n\n\n0\n0\n3\nmale\n22.0\n1\n0\n7.2500\nS\nThird\nman\nTrue\nNaN\nSouthampton\nno\nFalse\n\n\n1\n1\n1\nfemale\n38.0\n1\n0\n71.2833\nC\nFirst\nwoman\nFalse\nC\nCherbourg\nyes\nFalse\n\n\n2\n1\n3\nfemale\n26.0\n0\n0\n7.9250\nS\nThird\nwoman\nFalse\nNaN\nSouthampton\nyes\nTrue\n\n\n3\n1\n1\nfemale\n35.0\n1\n0\n53.1000\nS\nFirst\nwoman\nFalse\nC\nSouthampton\nyes\nFalse\n\n\n4\n0\n3\nmale\n35.0\n0\n0\n8.0500\nS\nThird\nman\nTrue\nNaN\nSouthampton\nno\nTrue\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n886\n0\n2\nmale\n27.0\n0\n0\n13.0000\nS\nSecond\nman\nTrue\nNaN\nSouthampton\nno\nTrue\n\n\n887\n1\n1\nfemale\n19.0\n0\n0\n30.0000\nS\nFirst\nwoman\nFalse\nB\nSouthampton\nyes\nTrue\n\n\n888\n0\n3\nfemale\nNaN\n1\n2\n23.4500\nS\nThird\nwoman\nFalse\nNaN\nSouthampton\nno\nFalse\n\n\n889\n1\n1\nmale\n26.0\n0\n0\n30.0000\nC\nFirst\nman\nTrue\nC\nCherbourg\nyes\nTrue\n\n\n890\n0\n3\nmale\n32.0\n0\n0\n7.7500\nQ\nThird\nman\nTrue\nNaN\nQueenstown\nno\nTrue\n\n\n\n\n891 rows × 15 columns\n\n\n\n\nX = df[[\"class\", \"sex\", \"embark_town\", \"fare\", \"age\"]]\ny = df.survived\n\n\nimport numpy as np\nfrom sklearn.tree import DecisionTreeClassifier, plot_tree\nfrom sklearn.pipeline import Pipeline\nfrom feature_engine.imputation import MeanMedianImputer, CategoricalImputer\nfrom feature_engine.encoding import OneHotEncoder, OrdinalEncoder\nfrom sklearn.preprocessing import StandardScaler\nfrom feature_engine.wrappers import SklearnTransformerWrapper\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score\nfrom sklearn.metrics import RocCurveDisplay, ConfusionMatrixDisplay\nfrom sklego.meta import Thresholder\nimport matplotlib.pyplot as plt\nfrom sklearn import set_config\n\nset_config(transform_output=\"pandas\")\n\n\ndef make_pipeline(parameters):\n    scaler = SklearnTransformerWrapper(\n        StandardScaler(), variables=parameters[\"sc_variables\"]\n    )\n\n    print(\n        f\"Entrenamiento para Decision Tree y threshold = {parameters['threshold']}\"\n    )\n    print(\"===================================\")\n    pipe = Pipeline(\n        steps=[\n            (\n                \"num_imp\",\n                MeanMedianImputer(\n                    imputation_method=parameters[\"num_method\"]\n                ),\n            ),\n            (\n                \"cat_imp\",\n                CategoricalImputer(\n                    imputation_method=parameters[\"cat_method\"]\n                ),\n            ),\n            (\"ohe\", parameters[\"encoder\"]),\n            (\"sc\", scaler),\n            (\n                \"model\",\n                Thresholder(\n                    DecisionTreeClassifier(\n                        random_state=42,\n                        min_samples_leaf=parameters[\"min_samples_leaf\"],\n                        min_samples_split=parameters[\"min_samples_split\"],\n                        max_depth=parameters[\"max_depth\"],\n                    ),\n                    threshold=parameters[\"threshold\"],\n                ),\n            ),\n        ]\n    )\n    return pipe\n\n\ndef make_evaluation(\n    model,\n    X_train,\n    X_test,\n    y_train,\n    y_test,\n):\n    model.fit(X_train, y_train)\n    y_pred_train = model.predict(X_train)\n    y_pred = model.predict(X_test)\n    y_pred_proba = model.predict_proba(X_test)\n\n    train_acc = accuracy_score(y_train, y_pred_train)\n    test_acc = accuracy_score(y_test, y_pred)\n    train_precision = precision_score(y_train, y_pred_train)\n    test_precision = precision_score(y_test, y_pred)\n    train_recall = recall_score(y_train, y_pred_train)\n    test_recall = recall_score(y_test, y_pred)\n\n    print(f\"Train Accuracy {train_acc}\")\n    print(f\"Test Accuracy {test_acc}\")\n    print(\"===================================\")\n    print(f\"Train Precision {train_precision}\")\n    print(f\"Test Precision {test_precision}\")\n    print(\"===================================\")\n    print(f\"Train Recall {train_recall}\")\n    print(f\"Test Recall {test_recall}\")\n\n    ConfusionMatrixDisplay.from_predictions(y_test, y_pred)\n    RocCurveDisplay.from_predictions(y_test, y_pred_proba[:, 1])\n\n\ndef show_tree(pipe, class_names=[\"No\", \"Sí\"], figsize=(20, 6)):\n    feature_names = pipe[-2].feature_names_in_\n    plt.figure(figsize=(20, 6))\n    plot_tree(\n        pipe[-1].estimator_,\n        filled=True,\n        feature_names=feature_names,\n        class_names=class_names,\n    )\n    plt.show()\n\n\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.25, random_state=42\n)\n\n\nparameters = dict(\n    num_method=\"mean\",\n    cat_method=\"frequent\",\n    sc_variables=[\"fare\", \"age\"],\n    min_samples_leaf=1,\n    min_samples_split=2,\n    max_depth=None,\n    encoder=OneHotEncoder(),\n    threshold=0.5,\n)\npipe = make_pipeline(parameters)\nmake_evaluation(pipe, X_train, X_test, y_train, y_test)\nshow_tree(pipe)\n\nEntrenamiento para Decision Tree y threshold = 0.5\n===================================\nTrain Accuracy 0.9805389221556886\nTest Accuracy 0.7533632286995515\n===================================\nTrain Precision 0.9918032786885246\nTest Precision 0.6888888888888889\n===================================\nTrain Recall 0.9565217391304348\nTest Recall 0.6966292134831461\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nparameters = dict(\n    num_method=\"mean\",\n    cat_method=\"frequent\",\n    sc_variables=[\"fare\", \"age\"],\n    min_samples_leaf=1,\n    min_samples_split=2,\n    max_depth=5,\n    encoder=OneHotEncoder(),\n    threshold=0.5,\n)\npipe = make_pipeline(parameters)\nmake_evaluation(pipe, X_train, X_test, y_train, y_test)\nshow_tree(pipe)\n\nEntrenamiento para Decision Tree y threshold = 0.5\n===================================\nTrain Accuracy 0.8488023952095808\nTest Accuracy 0.8071748878923767\n===================================\nTrain Precision 0.8333333333333334\nTest Precision 0.8194444444444444\n===================================\nTrain Recall 0.7509881422924901\nTest Recall 0.6629213483146067\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nparameters = dict(\n    num_method=\"mean\",\n    cat_method=\"frequent\",\n    sc_variables=[\"fare\", \"age\"],\n    min_samples_leaf=1,\n    min_samples_split=2,\n    max_depth=5,\n    encoder=OneHotEncoder(),\n    threshold=0.2,\n)\npipe = make_pipeline(parameters)\nmake_evaluation(pipe, X_train, X_test, y_train, y_test)\nshow_tree(pipe)\n\nEntrenamiento para Decision Tree y threshold = 0.2\n===================================\nTrain Accuracy 0.8068862275449101\nTest Accuracy 0.7892376681614349\n===================================\nTrain Precision 0.6962025316455697\nTest Precision 0.6944444444444444\n===================================\nTrain Recall 0.8695652173913043\nTest Recall 0.8426966292134831\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nparameters = dict(\n    num_method=\"mean\",\n    cat_method=\"frequent\",\n    sc_variables=[\"fare\", \"age\"],\n    min_samples_leaf=1,\n    min_samples_split=2,\n    max_depth=5,\n    encoder=OneHotEncoder(),\n    threshold=0.9,\n)\npipe = make_pipeline(parameters)\nmake_evaluation(pipe, X_train, X_test, y_train, y_test)\nshow_tree(pipe)\n\nEntrenamiento para Decision Tree y threshold = 0.9\n===================================\nTrain Accuracy 0.8173652694610778\nTest Accuracy 0.7713004484304933\n===================================\nTrain Precision 0.9851851851851852\nTest Precision 0.8958333333333334\n===================================\nTrain Recall 0.525691699604743\nTest Recall 0.48314606741573035\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nparameters = dict(\n    num_method=\"mean\",\n    cat_method=\"frequent\",\n    sc_variables=[\"fare\", \"age\"],\n    min_samples_leaf=0.1,\n    min_samples_split=2,\n    max_depth=None,\n    encoder=OneHotEncoder(),\n    threshold=0.2,\n)\npipe = make_pipeline(parameters)\nmake_evaluation(pipe, X_train, X_test, y_train, y_test)\nshow_tree(pipe)\n\nEntrenamiento para Decision Tree y threshold = 0.2\n===================================\nTrain Accuracy 0.6212574850299402\nTest Accuracy 0.6143497757847534\n===================================\nTrain Precision 0.5\nTest Precision 0.50920245398773\n===================================\nTrain Recall 0.924901185770751\nTest Recall 0.9325842696629213\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nparameters = dict(\n    num_method=\"mean\",\n    cat_method=\"frequent\",\n    sc_variables=[\"fare\", \"age\"],\n    min_samples_leaf=1,\n    min_samples_split=0.2,\n    max_depth=None,\n    encoder=OneHotEncoder(),\n    threshold=0.5,\n)\npipe = make_pipeline(parameters)\nmake_evaluation(pipe, X_train, X_test, y_train, y_test)\nshow_tree(pipe)\n\nEntrenamiento para Decision Tree y threshold = 0.5\n===================================\nTrain Accuracy 0.8023952095808383\nTest Accuracy 0.7757847533632287\n===================================\nTrain Precision 0.9290780141843972\nTest Precision 0.8679245283018868\n===================================\nTrain Recall 0.5177865612648221\nTest Recall 0.5168539325842697\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "tics411/notebooks/pauta_guia2.html",
    "href": "tics411/notebooks/pauta_guia2.html",
    "title": "Pregunta 3:",
    "section": "",
    "text": "import pandas as pd\n\ndf = pd.DataFrame(\n    dict(x=[4, 5, 5, 6, 7, 7], y=[1, 1, 2, 7, 6, 7], c=[1, 1, 1, 2, 2, 2]),\n    index=[*range(1, 7)],\n)\ndf\n\n\n\n\n\n\n\n\nx\ny\nc\n\n\n\n\n1\n4\n1\n1\n\n\n2\n5\n1\n1\n\n\n3\n5\n2\n1\n\n\n4\n6\n7\n2\n\n\n5\n7\n6\n2\n\n\n6\n7\n7\n2\nfrom scipy.spatial import distance_matrix\nimport numpy as np\n\npoint = np.array([[8, 4]])\n\n## Distancias del Punto al resto de los puntos\npd.DataFrame(\n    distance_matrix(point, df[[\"x\", \"y\"]]), columns=[*range(1, 7)]\n)\n\n\n\n\n\n\n\n\n1\n2\n3\n4\n5\n6\n\n\n\n\n0\n5.0\n4.242641\n3.605551\n3.605551\n2.236068\n3.162278\nfrom scipy.spatial.distance import cdist\n\npd.DataFrame(\n    cdist(point, df[[\"x\", \"y\"]], \"mahalanobis\"), columns=[*range(1, 7)]\n)\n\n\n\n\n\n\n\n\n1\n2\n3\n4\n5\n6\n\n\n\n\n0\n3.07265\n2.182821\n2.357716\n3.24037\n1.855041\n2.338929"
  },
  {
    "objectID": "tics411/notebooks/pauta_guia2.html#pregunta-7",
    "href": "tics411/notebooks/pauta_guia2.html#pregunta-7",
    "title": "Pregunta 3:",
    "section": "Pregunta 7:",
    "text": "Pregunta 7:\n\nconf_mat = np.array([[8, 2, 0], [4, 13, 13], [5, 12, 43]])\n\n\n## Función para tomar una matriz de confusión y recrear las predicciones\ndef create_vectors(conf_mat):\n    rows, cols = conf_mat.shape\n\n    original_vals = np.empty((0, 2))\n    for i in range(rows):\n        for j in range(cols):\n            interim = np.repeat([[i, j]], conf_mat[i, j], axis=0)\n            original_vals = np.append(original_vals, interim, axis=0)\n\n    y = original_vals[:, 0]\n    y_pred = original_vals[:, 1]\n    return y, y_pred\n\n\ny, y_pred = create_vectors(conf_mat)\n\n\nfrom sklearn.metrics import classification_report, ConfusionMatrixDisplay\n\n## Las predicciones recreadas generan esta matriz de confusión\n\n# OJO: ELIMINÉ un 1 para que hayan 100 valores, si no es lo que se busca,\n# se puede agregar el 1 en el objeto conf_mat de más arriba.\n\nConfusionMatrixDisplay.from_predictions(y, y_pred)\n\n## Esdto entrega el Accuracy único como mandé en un notebook y Precision, Recall y F1 por clases 0,1 y 2.\nprint(classification_report(y, y_pred, digits=3))\n\n              precision    recall  f1-score   support\n\n         0.0      0.471     0.800     0.593        10\n         1.0      0.481     0.433     0.456        30\n         2.0      0.768     0.717     0.741        60\n\n    accuracy                          0.640       100\n   macro avg      0.573     0.650     0.597       100\nweighted avg      0.652     0.640     0.641       100"
  },
  {
    "objectID": "tics411/notebooks/Ejercicio-Matriz-Confusión.html",
    "href": "tics411/notebooks/Ejercicio-Matriz-Confusión.html",
    "title": "Clases UAI",
    "section": "",
    "text": "import pandas as pd\nfrom sklearn.metrics import ConfusionMatrixDisplay, classification_report\n\ndf = pd.DataFrame(\n    dict(\n        y=[1, 1, 0, 2, 1, 0, 1, 2, 0, 1, 2],\n        y_pred=[1, 0, 2, 2, 1, 0, 1, 1, 2, 1, 2],\n    )\n)\n\nprint(classification_report(df.y, df.y_pred, digits=3))\nConfusionMatrixDisplay.from_predictions(df.y, df.y_pred)\n\n              precision    recall  f1-score   support\n\n           0      0.500     0.333     0.400         3\n           1      0.800     0.800     0.800         5\n           2      0.500     0.667     0.571         3\n\n    accuracy                          0.636        11\n   macro avg      0.600     0.600     0.590        11\nweighted avg      0.636     0.636     0.629        11\n\n\n\n\n\n\n\n\n\n\n\nEs importante mencionar que para el caso de más de 2 clases, el Accuracy se calcula como:\n\n\\[Accuracy = \\frac{TP_{Clase\\,0} + TP_{Clase\\,1} + TP_{Clase\\,2}}{Total} = \\frac{1 + 4 + 2}{11} = \\frac{7}{11} = 0.636\\]\nEl accuracy es un sólo valor para todas las clases. Y en el caso que mostramos ayer, el concepto de TN se pierde, por lo que es necesario reducir la matriz a un problema binario para poder poder darle sentido.\n\n\n\n Back to top"
  },
  {
    "objectID": "tics411/notebooks/kmeans.html",
    "href": "tics411/notebooks/kmeans.html",
    "title": "Clases UAI",
    "section": "",
    "text": "import numpy as np\n\n## Primera fila son coordenadas X\n## Segunda fila son coordenadas Y\n## Cada columna es el punto.\npuntos = np.array([[1, 2, 4, 5], [1, 1, 3, 4]])\npuntos\n\nc_1 = np.array([1, 1])\nc_2 = np.array([2, 1])\npuntos\n\narray([[1, 2, 4, 5],\n       [1, 1, 3, 4]])\n\n\n\nimport matplotlib.pyplot as plt\n\n\ndef plot_clusters(puntos, c_1, c_2, c=None):\n    plt.scatter(puntos[0], puntos[1], s=500, c=c)\n    plt.scatter(\n        c_1[0],\n        c_1[1],\n        marker=\"^\",\n        label=\"Centroide Cluster 1\",\n        edgecolors=\"k\",\n        s=200,\n        color=\"orange\",\n    )\n    plt.scatter(\n        c_2[0],\n        c_2[1],\n        marker=\"^\",\n        label=\"Centroide Cluster 2\",\n        edgecolors=\"k\",\n        s=200,\n        c=\"green\",\n    )\n    plt.grid(alpha=0.5)\n    plt.legend()\n\n\nplot_clusters(puntos, c_1, c_2)\n\n\n\n\n\n\n\n\n\ndef distancia(p0, p1):\n    x0 = p0[0]\n    x1 = p1[0]\n    y0 = p0[1]\n    y1 = p1[1]\n    return np.sqrt((x1 - x0) ** 2 + (y1 - y0) ** 2)\n\n\ndef calculate_distances(puntos, c_1, c_2):\n\n    distancia_mat = np.zeros((2, 4))\n    distancia_mat\n\n    for i in range(4):\n        p = puntos[:, i]\n        distancia_mat[0, i] = distancia(p, c_1)\n        distancia_mat[1, i] = distancia(p, c_2)\n\n    return distancia_mat\n\n\ndistancia_mat = calculate_distances(puntos, c_1, c_2)\ndistancia_mat\n\narray([[0.        , 1.        , 3.60555128, 5.        ],\n       [1.        , 0.        , 2.82842712, 4.24264069]])\n\n\n\ndef calculate_clusters(distancia_mat):\n    min_distancia_mat = np.min(distancia_mat, axis=0)\n\n    clusters = distancia_mat == min_distancia_mat\n    return clusters\n\n\nclusters = calculate_clusters(distancia_mat)\nclusters.astype(\"int64\")\n\n## Solo el punto 1 pertenece al cluster 1, todo el resto al cluster 2\n\narray([[1, 0, 0, 0],\n       [0, 1, 1, 1]])\n\n\n\ndef calculate_centroids(clusters):\n    c_1 = puntos[:, clusters[0]].mean(axis=1)\n    c_2 = puntos[:, clusters[1]].mean(axis=1)\n\n    return c_1, c_2\n\n\nc_1, c_2 = calculate_centroids(clusters)\nc_1, c_2\n\n(array([1., 1.]), array([3.66666667, 2.66666667]))\n\n\n\nplot_clusters(puntos, c_1, c_2, c=[\"red\", \"blue\", \"blue\", \"blue\"])\n\n\n\n\n\n\n\n\n\ndistancia_mat = calculate_distances(puntos, c_1, c_2)\nclusters = calculate_clusters(distancia_mat)\nc_1, c_2 = calculate_centroids(clusters)\nclusters\n\narray([[ True,  True, False, False],\n       [False, False,  True,  True]])\n\n\n\nc_1, c_2\n\n(array([1.5, 1. ]), array([4.5, 3.5]))\n\n\n\nplot_clusters(puntos, c_1, c_2, c=[\"red\", \"red\", \"blue\", \"blue\"])\n\n\n\n\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "tics411/notebooks/jerarquico.html",
    "href": "tics411/notebooks/jerarquico.html",
    "title": "Clases UAI",
    "section": "",
    "text": "import pandas as pd\nimport numpy as np\n\ndf = pd.DataFrame(\n    dict(\n        alpha=[9, 10, 1, 6, 1],\n        beta=[3, 2, 9, 5, 10],\n        gamma=[7, 9, 4, 5, 3],\n    )\n)\n\nindices = [\"p53\", \"mdm2\", \"bcl2\", \"cylinE\", \"Caspade\"]\ndf.index = indices\ndf\n\n\n\n\n\n\n\n\nalpha\nbeta\ngamma\n\n\n\n\np53\n9\n3\n7\n\n\nmdm2\n10\n2\n9\n\n\nbcl2\n1\n9\n4\n\n\ncylinE\n6\n5\n5\n\n\nCaspade\n1\n10\n3\n\n\n\n\n\n\n\n\nfrom scipy.spatial import distance_matrix\n\n\ndef calculate_global_min(dm):\n    data = np.triu(dm)\n\n    min_val = np.nanmin(data[np.nonzero(data)])\n    position = [dm.index[val[0]] for val in np.where(data == min_val)]\n    return min_val, position\n\n\noriginal_dm = distance_matrix(df, df, p=2)\noriginal_dm = pd.DataFrame(\n    original_dm, index=df.index, columns=df.index\n).round(2)\noriginal_dm.index = np.arange(5).astype(str)\noriginal_dm.columns = np.arange(5).astype(str)\noriginal_dm\n\n\n\n\n\n\n\n\n0\n1\n2\n3\n4\n\n\n\n\n0\n0.00\n2.45\n10.44\n4.12\n11.36\n\n\n1\n2.45\n0.00\n12.45\n6.40\n13.45\n\n\n2\n10.44\n12.45\n0.00\n6.48\n1.41\n\n\n3\n4.12\n6.40\n6.48\n0.00\n7.35\n\n\n4\n11.36\n13.45\n1.41\n7.35\n0.00\n\n\n\n\n\n\n\n\ndata = original_dm.copy()\ndata.index = indices\ndata.columns = indices\ndata\n\n\n\n\n\n\n\n\np53\nmdm2\nbcl2\ncylinE\nCaspade\n\n\n\n\np53\n0.00\n2.45\n10.44\n4.12\n11.36\n\n\nmdm2\n2.45\n0.00\n12.45\n6.40\n13.45\n\n\nbcl2\n10.44\n12.45\n0.00\n6.48\n1.41\n\n\ncylinE\n4.12\n6.40\n6.48\n0.00\n7.35\n\n\nCaspade\n11.36\n13.45\n1.41\n7.35\n0.00\n\n\n\n\n\n\n\n\ndef clean_position(position):\n    pos = []\n    for p in position:\n        pos.extend(p.split(\",\"))\n    return pos\n\n\ndef new_iteration(dm, original_dm, linkage=np.nanmean):\n    min_val, position = calculate_global_min(dm)\n    print(f\"El valor mínimo encontrado es: {min_val}\")\n    print(f\"Clusters a fusionar: {position}\")\n    non_position = [col for col in dm.columns if col not in position]\n    print(f\"Clusters que no se fusionan: {non_position}\")\n    new_position = \",\".join(position)\n    new_dm = dm.copy()\n    values = []\n    clean_pos = clean_position(position)\n    for n_p in non_position:\n        n_p = n_p.split(\",\")\n        v = linkage(original_dm.loc[n_p, clean_pos])\n        values.append(v)\n\n    new_dm[new_position] = pd.Series(values, index=non_position)\n    new_dm = new_dm.T\n    new_dm[new_position] = pd.Series(values, index=non_position)\n    return new_dm.drop(index=position, columns=position)\n\n\ndm_1 = new_iteration(original_dm, original_dm)\ndm_1\n\nEl valor mínimo encontrado es: 1.41\nClusters a fusionar: ['2', '4']\nClusters que no se fusionan: ['0', '1', '3']\n\n\n\n\n\n\n\n\n\n0\n1\n3\n2,4\n\n\n\n\n0\n0.00\n2.45\n4.120\n10.900\n\n\n1\n2.45\n0.00\n6.400\n12.950\n\n\n3\n4.12\n6.40\n0.000\n6.915\n\n\n2,4\n10.90\n12.95\n6.915\nNaN\n\n\n\n\n\n\n\n\ndm_2 = new_iteration(dm_1, original_dm)\ndm_2\n\nEl valor mínimo encontrado es: 2.45\nClusters a fusionar: ['0', '1']\nClusters que no se fusionan: ['3', '2,4']\n\n\n\n\n\n\n\n\n\n3\n2,4\n0,1\n\n\n\n\n3\n0.000\n6.915\n5.260\n\n\n2,4\n6.915\nNaN\n11.925\n\n\n0,1\n5.260\n11.925\nNaN\n\n\n\n\n\n\n\n\ndm_3 = new_iteration(dm_2, original_dm)\ndm_3\n\nEl valor mínimo encontrado es: 5.26\nClusters a fusionar: ['3', '0,1']\nClusters que no se fusionan: ['2,4']\n\n\n\n\n\n\n\n\n\n2,4\n3,0,1\n\n\n\n\n2,4\nNaN\n10.255\n\n\n3,0,1\n10.255\nNaN\n\n\n\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "tics411/notebooks/05-ex-jerarquico.html",
    "href": "tics411/notebooks/05-ex-jerarquico.html",
    "title": "Ejemplo Clustering Aglomerativo",
    "section": "",
    "text": "import seaborn as sns\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn import set_config\n\nset_config(transform_output=\"pandas\")\n\ndf = sns.load_dataset(\"iris\")\ndf\n\n\n\n\n\n\n\n\nsepal_length\nsepal_width\npetal_length\npetal_width\nspecies\n\n\n\n\n0\n5.1\n3.5\n1.4\n0.2\nsetosa\n\n\n1\n4.9\n3.0\n1.4\n0.2\nsetosa\n\n\n2\n4.7\n3.2\n1.3\n0.2\nsetosa\n\n\n3\n4.6\n3.1\n1.5\n0.2\nsetosa\n\n\n4\n5.0\n3.6\n1.4\n0.2\nsetosa\n\n\n...\n...\n...\n...\n...\n...\n\n\n145\n6.7\n3.0\n5.2\n2.3\nvirginica\n\n\n146\n6.3\n2.5\n5.0\n1.9\nvirginica\n\n\n147\n6.5\n3.0\n5.2\n2.0\nvirginica\n\n\n148\n6.2\n3.4\n5.4\n2.3\nvirginica\n\n\n149\n5.9\n3.0\n5.1\n1.8\nvirginica\n\n\n\n\n150 rows × 5 columns\n\n\n\n\nX = df.drop(columns=\"species\")\nsc = StandardScaler()\nX_sc = sc.fit_transform(X)\nX_sc\n\n\n\n\n\n\n\n\nsepal_length\nsepal_width\npetal_length\npetal_width\n\n\n\n\n0\n-0.900681\n1.019004\n-1.340227\n-1.315444\n\n\n1\n-1.143017\n-0.131979\n-1.340227\n-1.315444\n\n\n2\n-1.385353\n0.328414\n-1.397064\n-1.315444\n\n\n3\n-1.506521\n0.098217\n-1.283389\n-1.315444\n\n\n4\n-1.021849\n1.249201\n-1.340227\n-1.315444\n\n\n...\n...\n...\n...\n...\n\n\n145\n1.038005\n-0.131979\n0.819596\n1.448832\n\n\n146\n0.553333\n-1.282963\n0.705921\n0.922303\n\n\n147\n0.795669\n-0.131979\n0.819596\n1.053935\n\n\n148\n0.432165\n0.788808\n0.933271\n1.448832\n\n\n149\n0.068662\n-0.131979\n0.762758\n0.790671\n\n\n\n\n150 rows × 4 columns\n\n\n\n\nimport matplotlib.pyplot as plt\nfrom sklearn.decomposition import PCA\n\npca = PCA(n_components=2)\npca_iris = pca.fit_transform(X_sc)\n\n\ndef pca_viz(pca, color=None, title=\"\"):\n    plt.scatter(pca_iris[\"pca0\"], pca_iris[\"pca1\"], c=color)\n    plt.title(title)\n    plt.show()\n\n\npca_viz(pca_iris, title=\"Visualización de Iris en 2 dimensiones\")\n\n\n\n\n\n\n\n\n\nfrom scipy.cluster.hierarchy import dendrogram, linkage\n\n\ndef plot_dendogram(X, link=\"ward\"):\n    Z = linkage(X, method=link)\n\n    plt.figure(figsize=(10, 5))\n    plt.title(f\"Clustering Utilizando Iris, Método: {link}\")\n    plt.xlabel(\"Iris Samples\")\n    plt.ylabel(\"Distance\")\n    dendrogram(Z, leaf_rotation=90.0, leaf_font_size=8.0)\n    plt.show()\n\n\nlink_list = [\"single\", \"complete\", \"average\", \"ward\"]\nfor l in link_list:\n    plot_dendogram(X_sc, link=l)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfrom sklearn.cluster import AgglomerativeClustering\n\nagc = AgglomerativeClustering(\n    n_clusters=3, metric=\"euclidean\", linkage=\"ward\"\n)\nlabels = agc.fit_predict(X_sc)\npca_viz(\n    pca_iris,\n    color=labels,\n    title=\"Clustering Iris. Método Average, 3 Clusters.\",\n)\n\n## Transformarlo en función para probar muchas combinaciones...\n\n\n\n\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "tics411/notebooks/02-EDA.html",
    "href": "tics411/notebooks/02-EDA.html",
    "title": "EDA",
    "section": "",
    "text": "El siguiente notebook tiene por propósito mostrar algunos comandos básicos para poder realizar Exploración de Datos utilizando Pandas.\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Vamos a cargar los siguientes datos para poder explorarlos.\niris_df = sns.load_dataset(\"iris\")\ntitanic_df = sns.load_dataset(\"titanic\")\nts_df = sns.load_dataset(\"dowjones\")\niris_df\n\n\n\n\n\n\n\n\nsepal_length\nsepal_width\npetal_length\npetal_width\nspecies\n\n\n\n\n0\n5.1\n3.5\n1.4\n0.2\nsetosa\n\n\n1\n4.9\n3.0\n1.4\n0.2\nsetosa\n\n\n2\n4.7\n3.2\n1.3\n0.2\nsetosa\n\n\n3\n4.6\n3.1\n1.5\n0.2\nsetosa\n\n\n4\n5.0\n3.6\n1.4\n0.2\nsetosa\n\n\n...\n...\n...\n...\n...\n...\n\n\n145\n6.7\n3.0\n5.2\n2.3\nvirginica\n\n\n146\n6.3\n2.5\n5.0\n1.9\nvirginica\n\n\n147\n6.5\n3.0\n5.2\n2.0\nvirginica\n\n\n148\n6.2\n3.4\n5.4\n2.3\nvirginica\n\n\n149\n5.9\n3.0\n5.1\n1.8\nvirginica\n\n\n\n\n150 rows × 5 columns"
  },
  {
    "objectID": "tics411/notebooks/02-EDA.html#medidas-de-tendencia-central",
    "href": "tics411/notebooks/02-EDA.html#medidas-de-tendencia-central",
    "title": "EDA",
    "section": "Medidas de Tendencia Central",
    "text": "Medidas de Tendencia Central\nLos comandos .mean() y .median() permiten calcular la media y la mediana en datos numéricos. Como se ve en los ejemplos permite llamar una Serie de Pandas y calcular un valor.\n\nTip: En caso de querer aplicar estos comandos a un DataFrame se recomienda utilizar el flag numeric_only = True para evitar calcular estos valores en Datos Categóricos donde no hacen sentido.\n\n\nprint(f\"Promedio de Ancho de Petalo {iris_df['sepal_width'].mean()}\")\nprint(f\"Mediana de Largo de Petalo {iris_df['sepal_length'].median()}\")\n\nPromedio de Ancho de Petalo 3.0573333333333337\nMediana de Largo de Petalo 5.8\n\n\nPandas también cuenta con el comando .mode() el cuál devuelve la moda. A diferencia de los comandos anteriores, .mode() puede utilizarse tanto para datos categóricos como datos numéricos.\n\nprint(f\"Moda de Especies: \")\niris_df[\"species\"].mode()\n\nModa de Especies: \n\n\n0        setosa\n1    versicolor\n2     virginica\nName: species, dtype: object\n\n\nEl comando .quantile() permite calcular algún percentil de interés. q es un valor que va entre 0 y 1 para indicar el percentil requerido. Recordar que la mediana es equivalente al Percentil 50.\n\np25 = iris_df[\"sepal_width\"].quantile(q=0.25)\np50 = iris_df[\"sepal_width\"].quantile(q=0.50)\np75 = iris_df[\"sepal_width\"].quantile(q=0.75)\niris_df[\"sepal_width\"].median(), p25, p50, p75\n\n(3.0, 2.8, 3.0, 3.3)"
  },
  {
    "objectID": "tics411/notebooks/02-EDA.html#medidas-de-dispersión",
    "href": "tics411/notebooks/02-EDA.html#medidas-de-dispersión",
    "title": "EDA",
    "section": "Medidas de Dispersión",
    "text": "Medidas de Dispersión\nPandas permite el cálculo de distintas medidas de dispersión. Al igual que los comandos anteriores contiene el flag numeric_only = True para evitar inconvenientes en DataFrames con distintos data types. Además contiene el comando ddof el cuál permitirá diferenciar si se quiere la medida poblacional (ddof = 0) o la muestral (ddof = 1).\n\n# Varianza Poblacional\niris_df.var(numeric_only=True, ddof=0)\n\nsepal_length    0.681122\nsepal_width     0.188713\npetal_length    3.095503\npetal_width     0.577133\ndtype: float64\n\n\n\n# Varianza Muestral\niris_df.var(numeric_only=True, ddof=1)\n\nsepal_length    0.685694\nsepal_width     0.189979\npetal_length    3.116278\npetal_width     0.581006\ndtype: float64\n\n\n\n# Desviación Estándar Muestral\niris_df.std(numeric_only=True, ddof=1)\n\nsepal_length    0.828066\nsepal_width     0.435866\npetal_length    1.765298\npetal_width     0.762238\ndtype: float64\n\n\n\n# Función para calcular el Rango Intercuartil...\ndef calculate_IQR(column):\n    quantiles = iris_df.quantile([0.25, 0.75], numeric_only=True)\n    iqr_sl = quantiles.loc[0.75, column] - quantiles.loc[0.25, column]\n    return iqr_sl\n\n\ncalculate_IQR(\"sepal_length\")\ncalculate_IQR(\"petal_width\")\n\n1.5\n\n\n\n# Coeficiente de Skewness o Asimetría.\niris_df.skew(numeric_only=True)\n\nsepal_length    0.314911\nsepal_width     0.318966\npetal_length   -0.274884\npetal_width    -0.102967\ndtype: float64"
  },
  {
    "objectID": "tics411/notebooks/02-EDA.html#visualizaciones",
    "href": "tics411/notebooks/02-EDA.html#visualizaciones",
    "title": "EDA",
    "section": "Visualizaciones",
    "text": "Visualizaciones\nA continuación se mostrarán comandos propios de Pandas para poder generar los gráficos visto a lo largo de las clases. Se sugiere este tipo de gráficos cuando se trabaje con DataFrames ya que poseen buena documentación y una interfaz común para todos los gráficos.\nOpciones:\n\nkind: Permite indicar mediante un string el tipo de gráfico a mostrar.\nfigsize = (w,h): Permite fijar el tamaño de la figura. Notar que primero se entrega el ancho y luego el alto. Yo normalmente uso (20,6) ya que considero que queda bastante bien.\nedgecolor: Permite indicar el color del borde de las barras mediante un string. Tiene sentido para histogramás y bar plots.\ngrid = True/False: Permite mostrar o no una grilla.\nbins = n: Opción sólo para histogramas que permite indicar en cuántos bins se dividen los datos en el Histograma.\nalpha = 0.5: Corresponde al grado de transparecencia. Es un valor que va entre 0 y 1. Entre más pequeño el valor, más transparente.\ntitle: Permite agregar un Título como String.\nxlabel: Permite agregar un Título al Eje X.\nylabel: Permite agregar un Título al Eje Y.\n\n\nHistogramas\n\niris_df.plot(\n    kind=\"hist\", alpha=0.5, bins=30, figsize=(20, 6), edgecolor=\"black\"\n)\n# Notar que este genera todos los histogramas superpuestos...\n\nPor alguna razón Pandas tiene el comando .hist(). Este comando es bastante útil porque a diferencia del anterior no superpone los histogramas, lo cual la mayoría de las veces es lo que se busca.\n\niris_df.hist(figsize=(20, 6), bins=30, edgecolor=\"black\", grid=False)\n# tight_layout es opcional y a veces evita que hayan traslapes de títulos.\n# Usarlo si es que es necesario.\nplt.tight_layout()\n\n\n\n\n\n\n\n\n\n\nBarplots\nA diferencia de los Histográmas, los Barplots son utilizados para aplicar una agregación antes de gráficar. Esta agregación se puede utilizar mediante .value_counts() que permite contar valores, o mediante .groupby() el cuál permite aplicar otros tipos de agregación.\n\n# Acá por ejemplos contamos la cantidad de pasajeros por Sexo\ntitanic_df[\"sex\"].value_counts()\n\nsex\nmale      577\nfemale    314\nName: count, dtype: int64\n\n\n\n# Una vez que tenemos contados los elementos podemos graficar...\ntitanic_df[\"sex\"].value_counts().plot(\n    kind=\"bar\",\n    figsize=(5, 6),\n    title=\"Número de Pasajeros por Sexo...\",\n    edgecolor=\"black\",\n)\nplt.tight_layout()\n\n\n\n\n\n\n\n\n\n## Otro ejemplo, en este caso calculando el promedio por de Edad y Tarifa por Año.\ntitanic_df.groupby(\"pclass\")[[\"age\", \"fare\"]].mean()\n\n\n\n\n\n\n\n\nage\nfare\n\n\npclass\n\n\n\n\n\n\n1\n38.233441\n84.154687\n\n\n2\n29.877630\n20.662183\n\n\n3\n25.140620\n13.675550\n\n\n\n\n\n\n\n\n## En este caso, el índice Pclass irá al Eje X y los valores agregados de Age y Fare irán como barras.\niris_df.groupby(\"species\").mean().plot(kind=\"bar\", edgecolor=\"black\")\nplt.tight_layout()"
  },
  {
    "objectID": "tics411/notebooks/02-EDA.html#boxplots",
    "href": "tics411/notebooks/02-EDA.html#boxplots",
    "title": "EDA",
    "section": "Boxplots",
    "text": "Boxplots\n\niris_df.drop(columns=\"species\").plot(kind=\"box\")\nplt.tight_layout()\n\n\n\n\n\n\n\n\n\nPuntos\n\nNotar que a diferencia de los casos anteriores, el gráfico de puntos requiere que se definan qué columna irá en x y en y respectivamente.\n\n\niris_df.plot(\n    x=\"petal_length\",\n    y=\"petal_width\",\n    kind=\"scatter\",\n    title=\"Largo de Pétalo vs Ancho de Pétalo\",\n    xlabel=\"Largo\",\n    ylabel=\"Ancho\",\n)"
  },
  {
    "objectID": "tics411/notebooks/02-EDA.html#lineplot",
    "href": "tics411/notebooks/02-EDA.html#lineplot",
    "title": "EDA",
    "section": "Lineplot",
    "text": "Lineplot\nEl lineplot es el gráfico por defecto de Pandas, por lo tanto no es necesario definir el parámetro kind. Al igual que el gráfico de Puntos se debe definir las variables x e y. Se recomienda siempre que x sea una variable de tipo temporal.\n\nts_df.plot(x=\"Date\", y=\"Price\", title=\"Evolución del Dow Jones\")\n\n\n## Este es un ejemplo de varias series de tiempo en conjunto.\n## Este código sólo genera datos sintéticos.\nfrom scipy.stats import norm\n\nts_df[\"AA\"] = ts_df[\"Price\"] + norm.rvs(size=649) * 55 + 1000\nts_df[\"BB\"] = -norm.rvs(size=649) * 55\n\nts_df.set_index(\"Date\").plot(title=\"Comparación distintas Tendencias\")\nplt.tight_layout()"
  },
  {
    "objectID": "tics411/notebooks/02-EDA.html#mosaico",
    "href": "tics411/notebooks/02-EDA.html#mosaico",
    "title": "EDA",
    "section": "Mosaico",
    "text": "Mosaico\nEn muchas ocaciones nosotros queremos mostrar una compilación de todos nuestros gráficos más que cada uno por separado. Para eso Matplotlib cuenta con la opción Mosaico.\nMosaico permite generar una grilla definida como un String. Si se fijan nuestra grilla se define por el string:\n\"\"\"AAA\n   BCC\"\"\"\nEn este caso nuestro canvas se divide en 6 partes, el gráfico que asigne a A utilizará las 3 secciones superiores, B utilizará sólo la sección de abajo a la izquierda y C utilizará las 2 restantes.\nPara asignar cada sección .plot() de pandas posee el parámetro ax donde se debe generar la asignación.\n\nfig = plt.figure(figsize=(20, 10))\nax = fig.subplot_mosaic(\n    \"\"\"AAA\n       BCC\"\"\"\n)\n\n# Gráfico asignado a C\niris_df.drop(columns=\"species\").plot(\n    kind=\"box\", ax=ax[\"C\"], title=\"Distribución de Datos por Variable\"\n)\n\n## Gráfico asignado a B\niris_df.plot(\n    x=\"petal_length\",\n    y=\"petal_width\",\n    kind=\"scatter\",\n    title=\"Largo de Pétalo vs Ancho de Pétalo\",\n    xlabel=\"Largo\",\n    ylabel=\"Ancho\",\n    ax=ax[\"B\"],\n)\n\n## Gráfico asignado a A\niris_df.groupby(\"species\").mean().plot(\n    kind=\"bar\",\n    edgecolor=\"black\",\n    ax=ax[\"A\"],\n    rot=0,\n    title=\"Valores promedio por Especie\",\n)\n\n## Permite Agregar un título general a todo el Gráfico\nplt.suptitle(\"Este será un título para todo el Gráfico\", fontsize=20)\nplt.tight_layout()"
  },
  {
    "objectID": "tics411/notebooks/02-EDA.html#matplotlib",
    "href": "tics411/notebooks/02-EDA.html#matplotlib",
    "title": "EDA",
    "section": "Matplotlib",
    "text": "Matplotlib\nLos comandos mostrados anteriormente son una adaptación de Matplotlib a Pandas. La gracia que tienen es que son fáciles de aprender y funcionarán directamente en Pandas que será nuestra principal fuente de datos.\nEn el caso de trabajar con Numpy, estos comandos NO FUNCIONARÁN. Por lo tanto es necesario utilizar la API de Matplotlib. La traducción no es 100% directa, pero normalmente todos los parámetros de .plot() se cambiarán por comandos del tipo plt.---"
  },
  {
    "objectID": "tics411/notebooks/02-EDA.html#ejemplo",
    "href": "tics411/notebooks/02-EDA.html#ejemplo",
    "title": "EDA",
    "section": "Ejemplo",
    "text": "Ejemplo\nplt.plot(x,y, c = \"red\") #Existe también plt.bar, plt.hist, plt.scatter, plt.boxplot.\nplt.title(\"Este va a ser un título\")\nplt.xlabel(\"Este será una etiqueta del Eje X\")\nAprender Matplotlib es bastante más complicado pero tiene funcionalidades muchísimo más avanzadas que Pandas. Para este curso, no será necesario especializarse en Matplotlib, pero sí más adelante utilizaremos algunos gráficos que no se pueden hacer tan fácilmente en Pandas (pero serán casos puntuales)."
  },
  {
    "objectID": "tics411/notebooks/12-ex-CV.html",
    "href": "tics411/notebooks/12-ex-CV.html",
    "title": "Holdout (Train Test Split)",
    "section": "",
    "text": "import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn import set_config\n\nset_config(transform_output=\"pandas\")\n\ndf = sns.load_dataset(\"titanic\")\ndf\n\n\n\n\n\n\n\n\nsurvived\npclass\nsex\nage\nsibsp\nparch\nfare\nembarked\nclass\nwho\nadult_male\ndeck\nembark_town\nalive\nalone\n\n\n\n\n0\n0\n3\nmale\n22.0\n1\n0\n7.2500\nS\nThird\nman\nTrue\nNaN\nSouthampton\nno\nFalse\n\n\n1\n1\n1\nfemale\n38.0\n1\n0\n71.2833\nC\nFirst\nwoman\nFalse\nC\nCherbourg\nyes\nFalse\n\n\n2\n1\n3\nfemale\n26.0\n0\n0\n7.9250\nS\nThird\nwoman\nFalse\nNaN\nSouthampton\nyes\nTrue\n\n\n3\n1\n1\nfemale\n35.0\n1\n0\n53.1000\nS\nFirst\nwoman\nFalse\nC\nSouthampton\nyes\nFalse\n\n\n4\n0\n3\nmale\n35.0\n0\n0\n8.0500\nS\nThird\nman\nTrue\nNaN\nSouthampton\nno\nTrue\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n886\n0\n2\nmale\n27.0\n0\n0\n13.0000\nS\nSecond\nman\nTrue\nNaN\nSouthampton\nno\nTrue\n\n\n887\n1\n1\nfemale\n19.0\n0\n0\n30.0000\nS\nFirst\nwoman\nFalse\nB\nSouthampton\nyes\nTrue\n\n\n888\n0\n3\nfemale\nNaN\n1\n2\n23.4500\nS\nThird\nwoman\nFalse\nNaN\nSouthampton\nno\nFalse\n\n\n889\n1\n1\nmale\n26.0\n0\n0\n30.0000\nC\nFirst\nman\nTrue\nC\nCherbourg\nyes\nTrue\n\n\n890\n0\n3\nmale\n32.0\n0\n0\n7.7500\nQ\nThird\nman\nTrue\nNaN\nQueenstown\nno\nTrue\n\n\n\n\n891 rows × 15 columns\nX = df[[\"class\", \"sex\", \"embark_town\", \"fare\", \"age\"]]\ny = df.alive\n\nX.shape, y.shape\n\n((891, 5), (891,))\nnum_cols = X.select_dtypes(np.number).columns.tolist()\ncat_cols = [col for col in X.columns if col not in num_cols]\nnum_cols, cat_cols\n\n(['fare', 'age'], ['class', 'sex', 'embark_town'])\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.25, random_state=42\n)\nX_train.shape, X_test.shape\n\n((668, 5), (223, 5))\nfrom sklearn.pipeline import Pipeline\nfrom feature_engine.imputation import CategoricalImputer, MeanMedianImputer\nfrom feature_engine.encoding import OneHotEncoder\nfrom sklearn.preprocessing import StandardScaler\nfrom feature_engine.wrappers import SklearnTransformerWrapper\nfrom sklearn.neighbors import KNeighborsClassifier\n\n\ndef make_pipeline(k, scale=None):\n    if scale is not None:\n        scaler = SklearnTransformerWrapper(\n            StandardScaler(), variables=num_cols\n        )\n    else:\n        scaler = StandardScaler()\n\n    pipe = Pipeline(\n        steps=[\n            (\"ci\", CategoricalImputer(imputation_method=\"frequent\")),\n            (\"mmi\", MeanMedianImputer(imputation_method=\"mean\")),\n            (\"ohe\", OneHotEncoder()),\n            (\"sc\", scaler),\n            (\"model\", KNeighborsClassifier(n_neighbors=k)),\n        ]\n    )\n    return pipe\n\n\npipe = make_pipeline(k=5)\n# pipe = make_pipeline(k=5, scale = num_cols)\npipe.fit(X_train, y_train)\ny_pred = pipe.predict(X_test)\npipe.score(X_test, y_test)\n\n0.7757847533632287"
  },
  {
    "objectID": "tics411/notebooks/12-ex-CV.html#way-holdout-train-validation-test-split",
    "href": "tics411/notebooks/12-ex-CV.html#way-holdout-train-validation-test-split",
    "title": "Holdout (Train Test Split)",
    "section": "3-way Holdout (Train Validation Test Split)",
    "text": "3-way Holdout (Train Validation Test Split)\n\nX_trainval, X_test, y_trainval, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42\n)\nX_train, X_val, y_train, y_val = train_test_split(\n    X, y, test_size=0.25, random_state=42\n)\n\nfor k in [3, 5, 7, 9, 11]:\n    pipe = make_pipeline(k=k)\n    pipe.fit(X_train, y_train)\n    metric = pipe.score(X_val, y_val)\n    print(f\"Puntaje del Modelo, k = {k}: {metric}\")\n    print(\"=============================================\")\n\nPuntaje del Modelo, k = 3: 0.7982062780269058\n=============================================\nPuntaje del Modelo, k = 5: 0.7757847533632287\n=============================================\nPuntaje del Modelo, k = 7: 0.7892376681614349\n=============================================\nPuntaje del Modelo, k = 9: 0.8026905829596412\n=============================================\nPuntaje del Modelo, k = 11: 0.7982062780269058\n============================================="
  },
  {
    "objectID": "tics411/notebooks/12-ex-CV.html#k-fold",
    "href": "tics411/notebooks/12-ex-CV.html#k-fold",
    "title": "Holdout (Train Test Split)",
    "section": "K-Fold",
    "text": "K-Fold\n\nimport numpy as np\nfrom sklearn.model_selection import KFold, StratifiedKFold\n\n\ndef make_kfold(X, y, k, kfold=5):\n    kf = StratifiedKFold(n_splits=kfold, shuffle=True, random_state=42)\n    score = []\n    for fold, (train_idx, val_idx) in enumerate(kf.split(X, y), start=1):\n        X_train = X.iloc[train_idx]\n        y_train = y.iloc[train_idx]\n        X_val = X.iloc[val_idx]\n        y_val = y.iloc[val_idx]\n\n        pipe = make_pipeline(k=k)\n        pipe.fit(X_train, y_train)\n        metric = pipe.score(X_val, y_val)\n        score.append(metric)\n        print(f\"Metric for Fold {fold}: {metric:.3f}\")\n    return score\n\n\nfor k in [1, 3, 5, 7, 9, 11]:\n    print(f\"k = {k}\")\n    kfold_score = make_kfold(X_trainval, y_trainval, k, kfold=5)\n    mean = np.mean(kfold_score)\n    std = np.std(kfold_score)\n    print(f\"K-Fold Score: {mean:.3f} +/- {std:.3f}\")\n    print(\"=========================================\")\n\nk = 1\nMetric for Fold 1: 0.748\nMetric for Fold 2: 0.811\nMetric for Fold 3: 0.725\nMetric for Fold 4: 0.803\nMetric for Fold 5: 0.746\nK-Fold Score: 0.767 +/- 0.034\n=========================================\nk = 3\nMetric for Fold 1: 0.769\nMetric for Fold 2: 0.853\nMetric for Fold 3: 0.789\nMetric for Fold 4: 0.789\nMetric for Fold 5: 0.810\nK-Fold Score: 0.802 +/- 0.029\n=========================================\nk = 5\nMetric for Fold 1: 0.790\nMetric for Fold 2: 0.853\nMetric for Fold 3: 0.803\nMetric for Fold 4: 0.754\nMetric for Fold 5: 0.789\nK-Fold Score: 0.798 +/- 0.032\n=========================================\nk = 7\nMetric for Fold 1: 0.783\nMetric for Fold 2: 0.853\nMetric for Fold 3: 0.803\nMetric for Fold 4: 0.761\nMetric for Fold 5: 0.817\nK-Fold Score: 0.803 +/- 0.031\n=========================================\nk = 9\nMetric for Fold 1: 0.790\nMetric for Fold 2: 0.846\nMetric for Fold 3: 0.789\nMetric for Fold 4: 0.761\nMetric for Fold 5: 0.810\nK-Fold Score: 0.799 +/- 0.028\n=========================================\nk = 11\nMetric for Fold 1: 0.776\nMetric for Fold 2: 0.839\nMetric for Fold 3: 0.796\nMetric for Fold 4: 0.754\nMetric for Fold 5: 0.789\nK-Fold Score: 0.791 +/- 0.028\n========================================="
  },
  {
    "objectID": "tics411/notebooks/12-ex-CV.html#versión-reducida",
    "href": "tics411/notebooks/12-ex-CV.html#versión-reducida",
    "title": "Holdout (Train Test Split)",
    "section": "Versión Reducida",
    "text": "Versión Reducida\n\nfrom sklearn.model_selection import cross_val_score\n\nkf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\nfor k in [1, 3, 5, 7, 9, 11]:\n    pipe = make_pipeline(k=k)\n    vals = cross_val_score(pipe, X_trainval, y_trainval, cv=kf)\n    print(f\"k = {k}\")\n    print(f\"Metric: {np.mean(vals):.3f} +/- {np.std(vals):.3f}\")\n\nk = 1\nMetric: 0.767 +/- 0.034\nk = 3\nMetric: 0.802 +/- 0.029\nk = 5\nMetric: 0.798 +/- 0.032\nk = 7\nMetric: 0.803 +/- 0.031\nk = 9\nMetric: 0.799 +/- 0.028\nk = 11\nMetric: 0.791 +/- 0.028"
  },
  {
    "objectID": "tics411/notebooks/12-ex-CV.html#calcular-test-scores",
    "href": "tics411/notebooks/12-ex-CV.html#calcular-test-scores",
    "title": "Holdout (Train Test Split)",
    "section": "Calcular Test Scores",
    "text": "Calcular Test Scores\n\nfor k in [1, 3, 5, 7, 9, 11]:\n    pipe = make_pipeline(k=k)\n    pipe.fit(X_trainval, y_trainval)\n    metric = pipe.score(X_test, y_test)\n    print(f\"Score for k = {k}: {metric}\")\n\nScore for k = 1: 0.7821229050279329\nScore for k = 3: 0.8156424581005587\nScore for k = 5: 0.770949720670391\nScore for k = 7: 0.8044692737430168\nScore for k = 9: 0.8212290502793296\nScore for k = 11: 0.8156424581005587\n\n\n\nPero, qué está ocurriendo acá?"
  },
  {
    "objectID": "tics411/notebooks/10-resolucion_guia.html",
    "href": "tics411/notebooks/10-resolucion_guia.html",
    "title": "K-Means",
    "section": "",
    "text": "import pandas as pd\nfrom scipy.spatial import distance_matrix\n\ndf = pd.DataFrame(dict(x=[0, 0, 1, 4, 5, 6], y=[1, 0, 0, 4, 4, 6]))\ndisplay(df)\nd_matrix = pd.DataFrame(distance_matrix(df, df))\nd_matrix\n\n\n\n\n\n\n\n\nx\ny\n\n\n\n\n0\n0\n1\n\n\n1\n0\n0\n\n\n2\n1\n0\n\n\n3\n4\n4\n\n\n4\n5\n4\n\n\n5\n6\n6\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0\n1\n2\n3\n4\n5\n\n\n\n\n0\n0.000000\n1.000000\n1.414214\n5.000000\n5.830952\n7.810250\n\n\n1\n1.000000\n0.000000\n1.000000\n5.656854\n6.403124\n8.485281\n\n\n2\n1.414214\n1.000000\n0.000000\n5.000000\n5.656854\n7.810250\n\n\n3\n5.000000\n5.656854\n5.000000\n0.000000\n1.000000\n2.828427\n\n\n4\n5.830952\n6.403124\n5.656854\n1.000000\n0.000000\n2.236068\n\n\n5\n7.810250\n8.485281\n7.810250\n2.828427\n2.236068\n0.000000\ncentroides = pd.DataFrame(dict(x=[1, 5], y=[1, 6]))\ncentroides_2 = pd.DataFrame(dict(x=[1 / 3, 5], y=[1 / 3, 14 / 3]))\nimport matplotlib.pyplot as plt\n\nplt.scatter(df.x, df.y)\nplt.scatter(centroides.x, centroides.y, c=\"red\")\nplt.scatter(centroides_2.x, centroides_2.y, c=\"green\")\nplt.title(\"Centroides Iter 1: Rojo, Iter 2: Verde\")\nplt.tight_layout()\n## Distancia Centroides 1 a Puntos\npd.DataFrame(distance_matrix(centroides, df))\n\n\n\n\n\n\n\n\n0\n1\n2\n3\n4\n5\n\n\n\n\n0\n1.000000\n1.414214\n1.000000\n4.242641\n5.0\n7.071068\n\n\n1\n7.071068\n7.810250\n7.211103\n2.236068\n2.0\n1.000000\n## Distancia Centroides 2 a Puntos\npd.DataFrame(distance_matrix(centroides_2, df))\n\n\n\n\n\n\n\n\n0\n1\n2\n3\n4\n5\n\n\n\n\n0\n0.745356\n0.471405\n0.745356\n5.18545\n5.934831\n8.013877\n\n\n1\n6.200358\n6.839428\n6.146363\n1.20185\n0.666667\n1.666667"
  },
  {
    "objectID": "tics411/notebooks/10-resolucion_guia.html#dbscan",
    "href": "tics411/notebooks/10-resolucion_guia.html#dbscan",
    "title": "K-Means",
    "section": "DBSCAN",
    "text": "DBSCAN\n\nfrom sklearn.cluster import DBSCAN\n\ndbs = DBSCAN(min_samples=2, eps=2)\ndbs.fit_predict(df)\n\narray([ 0,  0,  0,  1,  1, -1])\n\n\n\nfrom sklearn.cluster import DBSCAN\n\ndbs = DBSCAN(min_samples=1, eps=1)\ndbs.fit_predict(df)\n\narray([0, 0, 0, 1, 1, 2])"
  },
  {
    "objectID": "tics411/notebooks/10-resolucion_guia.html#jerarquico-linkage-complete",
    "href": "tics411/notebooks/10-resolucion_guia.html#jerarquico-linkage-complete",
    "title": "K-Means",
    "section": "Jerarquico Linkage Complete",
    "text": "Jerarquico Linkage Complete\n\nfrom scipy.cluster.hierarchy import dendrogram, linkage\n\n\ndef plot_dendogram(X, link=\"ward\"):\n    Z = linkage(X, method=link)\n\n    plt.figure(figsize=(10, 5))\n    plt.title(f\"Clustering Utilizando Iris, Método: {link}\")\n    plt.xlabel(\"Iris Samples\")\n    plt.ylabel(\"Distance\")\n    dendrogram(Z, leaf_rotation=90.0, leaf_font_size=8.0)\n    plt.show()\n\n\nplot_dendogram(df, link=\"complete\")"
  },
  {
    "objectID": "tics411/notebooks/10-resolucion_guia.html#cohesión-y-separación",
    "href": "tics411/notebooks/10-resolucion_guia.html#cohesión-y-separación",
    "title": "K-Means",
    "section": "Cohesión y Separación",
    "text": "Cohesión y Separación\n\nimport numpy as np\n\n\ndef compute_clustering_metrics(X, labels, centers, is_df=True):\n    if is_df:\n        X = X.to_numpy()\n    sse = np.square(X - centers[labels]).sum()\n    count = np.bincount(labels)\n    ssb = (\n        np.square(X.mean(axis=0) - centers) * count.reshape(-1, 1)\n    ).sum()\n    return sse, ssb\n\n\nlabels = np.array([0, 0, 0, 1, 1, 1])\ncenters = centroides_2.values\nsse, ssb = compute_clustering_metrics(df, labels, centers, is_df=True)\nsse, ssb\n\n(6.0, 60.833333333333336)"
  },
  {
    "objectID": "tics411/notebooks/10-resolucion_guia.html#silhouette",
    "href": "tics411/notebooks/10-resolucion_guia.html#silhouette",
    "title": "K-Means",
    "section": "Silhouette",
    "text": "Silhouette\n\ndef silhouette_score_m(d_matrix, clust_labels):\n    n_clusters = len(np.unique(clust_labels))\n    clusters = clust_labels\n    idx_cohesion = clusters == np.arange(n_clusters).reshape(-1, 1)\n    a = np.zeros_like(clusters, dtype=np.float32)\n    bj = np.zeros((len(clusters), n_clusters))\n    for i, (row, c) in enumerate(zip(d_matrix, clusters)):\n        val = row[idx_cohesion[c] & (row != 0)]\n        a[i] = val.mean() if len(val) else 0\n        for cl in range(n_clusters):\n            if cl != c:\n                val = row[idx_cohesion[cl]]\n                bj[i, cl] = val.mean() if len(val) else 0\n\n    b = np.sort(bj, axis=1)[:, 1]\n    return a, b, bj, n_clusters\n\n\nd_matrix = distance_matrix(df, df)\na, b, bj, n_clusters = silhouette_score_m(d_matrix, labels)\n\n\ndef create_table_for_silhouette(a, b, bj, n_clusters):\n    s_score = (b - a) / np.max((a, b), axis=0)\n    columns = (\n        [\"a\"] + [\"b\" + str(i) for i in range(n_clusters)] + [\"b\", \"s\"]\n    )\n\n    s_table = pd.DataFrame(\n        np.hstack(\n            [\n                a.reshape(-1, 1),\n                bj,\n                b.reshape(-1, 1),\n                s_score.reshape(-1, 1),\n            ]\n        ),\n        columns=columns,\n    )\n    return s_table\n\n\ns_score_table = create_table_for_silhouette(a, b, bj, n_clusters)\ns_score_table[\"s\"].mean()\n\n0.7517302154855591\n\n\n\ns_score_table\n\n\n\n\n\n\n\n\na\nb0\nb1\nb\ns\n\n\n\n\n0\n1.207107\n0.000000\n6.213734\n6.213734\n0.805736\n\n\n1\n1.000000\n0.000000\n6.848420\n6.848420\n0.853981\n\n\n2\n1.207107\n0.000000\n6.155701\n6.155701\n0.803904\n\n\n3\n1.914214\n5.218951\n0.000000\n5.218951\n0.633219\n\n\n4\n1.618034\n5.963643\n0.000000\n5.963643\n0.728684\n\n\n5\n2.532248\n8.035260\n0.000000\n8.035260\n0.684858"
  },
  {
    "objectID": "tics411/notebooks/01-Preprocesamiento.html",
    "href": "tics411/notebooks/01-Preprocesamiento.html",
    "title": "Clases UAI",
    "section": "",
    "text": "%%capture\n## Ejecutar esta celda para instalar o actualizar Feature_Engine\n!pip install -U feature_engine\n## Chequear que la versión de Feature Engine sea al menos 1.7\nimport feature_engine\n\nfeature_engine.__version__\n\n'1.7.0'\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nfrom sklearn import set_config\n\n## (Opcional) Este comando permite que el output de Scikit-Learn sean Pandas DataFrames.\n## Por dejecto, Scikit-Learn transforma todo a Numpy, ya que es más eficiente computacionalmente.\nset_config(transform_output=\"pandas\")\n\ndf = sns.load_dataset(\"titanic\")\ndf\n\n\n\n\n\n\n\n\nsurvived\npclass\nsex\nage\nsibsp\nparch\nfare\nembarked\nclass\nwho\nadult_male\ndeck\nembark_town\nalive\nalone\n\n\n\n\n0\n0\n3\nmale\n22.0\n1\n0\n7.2500\nS\nThird\nman\nTrue\nNaN\nSouthampton\nno\nFalse\n\n\n1\n1\n1\nfemale\n38.0\n1\n0\n71.2833\nC\nFirst\nwoman\nFalse\nC\nCherbourg\nyes\nFalse\n\n\n2\n1\n3\nfemale\n26.0\n0\n0\n7.9250\nS\nThird\nwoman\nFalse\nNaN\nSouthampton\nyes\nTrue\n\n\n3\n1\n1\nfemale\n35.0\n1\n0\n53.1000\nS\nFirst\nwoman\nFalse\nC\nSouthampton\nyes\nFalse\n\n\n4\n0\n3\nmale\n35.0\n0\n0\n8.0500\nS\nThird\nman\nTrue\nNaN\nSouthampton\nno\nTrue\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n886\n0\n2\nmale\n27.0\n0\n0\n13.0000\nS\nSecond\nman\nTrue\nNaN\nSouthampton\nno\nTrue\n\n\n887\n1\n1\nfemale\n19.0\n0\n0\n30.0000\nS\nFirst\nwoman\nFalse\nB\nSouthampton\nyes\nTrue\n\n\n888\n0\n3\nfemale\nNaN\n1\n2\n23.4500\nS\nThird\nwoman\nFalse\nNaN\nSouthampton\nno\nFalse\n\n\n889\n1\n1\nmale\n26.0\n0\n0\n30.0000\nC\nFirst\nman\nTrue\nC\nCherbourg\nyes\nTrue\n\n\n890\n0\n3\nmale\n32.0\n0\n0\n7.7500\nQ\nThird\nman\nTrue\nNaN\nQueenstown\nno\nTrue\n\n\n\n\n891 rows × 15 columns"
  },
  {
    "objectID": "tics411/notebooks/01-Preprocesamiento.html#valores-faltantes",
    "href": "tics411/notebooks/01-Preprocesamiento.html#valores-faltantes",
    "title": "Clases UAI",
    "section": "Valores Faltantes",
    "text": "Valores Faltantes\n\n## Para detectar valores faltantes se utiliza el siguiente comando.\ndf.isnull().sum()\n\nsurvived         0\npclass           0\nsex              0\nage            177\nsibsp            0\nparch            0\nfare             0\nembarked         2\nclass            0\nwho              0\nadult_male       0\ndeck           688\nembark_town      2\nalive            0\nalone            0\ndtype: int64\n\n\n\n## Opcionalmente se puede obtener el % o la fracción de nulos utilizando la siguiente variante.\ndf.isnull().mean()\n\nsurvived       0.000000\npclass         0.000000\nsex            0.000000\nage            0.198653\nsibsp          0.000000\nparch          0.000000\nfare           0.000000\nembarked       0.002245\nclass          0.000000\nwho            0.000000\nadult_male     0.000000\ndeck           0.772166\nembark_town    0.002245\nalive          0.000000\nalone          0.000000\ndtype: float64\n\n\nPandas: Es posible imputar valores usando Pandas con el comando .fillna().\n\nmedia = df[\"age\"].mean()\nmediana = df[\"age\"].median()\nprint(f\"Promedio de Edad: {media}\")\nprint(\n    f'Promedio de Edad con Imputación con Ceros: {df[\"age\"].fillna(0).mean()}'\n)\nprint(\n    f'Promedio de Edad con Imputación por Media: {df[\"age\"].fillna(media).mean()}'\n)\nprint(\n    f'Promedio de Edad con Imputación por Mediana: {df[\"age\"].fillna(mediana).mean()}'\n)\n\nPromedio de Edad: 29.69911764705882\nPromedio de Edad con Imputación con Ceros: 23.79929292929293\nPromedio de Edad con Imputación por Media: 29.69911764705882\nPromedio de Edad con Imputación por Mediana: 29.36158249158249\n\n\nScikit-Learn: Utiliza la clase SimpleImputer, el cual permite distintas estrategias de Imputación: \"mean\", \"median\", \"most_frequent\", \"constant\".\n\nfrom sklearn.impute import SimpleImputer\n\nsc = SimpleImputer(strategy=\"mean\")\n## En este caso uso [[]] ya que Scikit Learn espera Matrices o DataFrames.\n## Utilizar [[]] fuerza a que AGE sea un DataFrame de una Columna y no una Serie.\n\ndata_imputed = sc.fit_transform(df[[\"age\"]])\n## Se puede ver que los nuevos datos ya no poseen valores Perdidos.\ndata_imputed.isnull().sum()\n\nage    0\ndtype: int64"
  },
  {
    "objectID": "tics411/notebooks/01-Preprocesamiento.html#outliers",
    "href": "tics411/notebooks/01-Preprocesamiento.html#outliers",
    "title": "Clases UAI",
    "section": "Outliers",
    "text": "Outliers\npandas: En Pandas se pueden acotar los outliers utilizando .clip()\n\nprint(f\"Promedio de Tarifas: {df.fare.mean()}\")\ndf[\"fare\"].agg([\"min\", \"max\"])\n\nPromedio de Tarifas: 32.204207968574636\n\n\nmin      0.0000\nmax    512.3292\nName: fare, dtype: float64\n\n\n\nlower: Define la cota inferior.\nupper: Define la cota superior.\n\n\nclipped_data = df[[\"fare\"]].clip(lower=10, upper=50)\nclipped_data.agg([\"min\", \"max\"])\n\n\n\n\n\n\n\n\nfare\n\n\n\n\nmin\n10.0\n\n\nmax\n50.0\n\n\n\n\n\n\n\n\ndf[[\"fare\"]]\n\n\n\n\n\n\n\n\nfare\n\n\n\n\n0\n7.2500\n\n\n1\n71.2833\n\n\n2\n7.9250\n\n\n3\n53.1000\n\n\n4\n8.0500\n\n\n...\n...\n\n\n886\n13.0000\n\n\n887\n30.0000\n\n\n888\n23.4500\n\n\n889\n30.0000\n\n\n890\n7.7500\n\n\n\n\n891 rows × 1 columns\n\n\n\n\n## Los valores menores a 10 fueron reemplazados por 10.\n## Los valores mayores a 50 fueron reemplazados por 50.\nclipped_data\n\n\n\n\n\n\n\n\nfare\n\n\n\n\n0\n10.00\n\n\n1\n50.00\n\n\n2\n10.00\n\n\n3\n50.00\n\n\n4\n10.00\n\n\n...\n...\n\n\n886\n13.00\n\n\n887\n30.00\n\n\n888\n23.45\n\n\n889\n30.00\n\n\n890\n10.00\n\n\n\n\n891 rows × 1 columns\n\n\n\nsklearn: Para este caso nos apoyaremos de la librería feature_engine la cual posee herramientas para acotar. feature_engine sigue exactamente la misma lógica de Scikit-Learn.\n\nfrom feature_engine.outliers import ArbitraryOutlierCapper, Winsorizer\n\ncapper = ArbitraryOutlierCapper(\n    max_capping_dict=dict(fare=50), min_capping_dict=dict(fare=10)\n)\ncapper.fit_transform(df[[\"fare\"]])\n\n\n\n\n\n\n\n\nfare\n\n\n\n\n0\n10.00\n\n\n1\n50.00\n\n\n2\n10.00\n\n\n3\n50.00\n\n\n4\n10.00\n\n\n...\n...\n\n\n886\n13.00\n\n\n887\n30.00\n\n\n888\n23.45\n\n\n889\n30.00\n\n\n890\n10.00\n\n\n\n\n891 rows × 1 columns\n\n\n\n\ncapping_method: Define la Estragegia a utilizar para el Winsorizer. Ver Docs.\n\n\n## \"gaussian\" permite acotar por mu +/- 3*std\n## \"iqr\" permite rellenar por Q1 - 3*iqr y Q3 + 3*iqr\nwin = Winsorizer(capping_method=\"gaussian\")\nwin.fit_transform(df[[\"fare\"]])\n\n\n\n\n\n\n\n\nfare\n\n\n\n\n0\n7.2500\n\n\n1\n71.2833\n\n\n2\n7.9250\n\n\n3\n53.1000\n\n\n4\n8.0500\n\n\n...\n...\n\n\n886\n13.0000\n\n\n887\n30.0000\n\n\n888\n23.4500\n\n\n889\n30.0000\n\n\n890\n7.7500\n\n\n\n\n891 rows × 1 columns"
  },
  {
    "objectID": "tics411/notebooks/01-Preprocesamiento.html#variables-categóricas",
    "href": "tics411/notebooks/01-Preprocesamiento.html#variables-categóricas",
    "title": "Clases UAI",
    "section": "Variables Categóricas",
    "text": "Variables Categóricas\npandas:\n\nOne Hot Encoding\nPara la conversión de variables categóricas utilizamos pd.get_dummies(). * drop_first: Si es True se elimina la primera categoría.\n\npd.get_dummies(df[\"embark_town\"], drop_first=False)\n\n\n\n\n\n\n\n\nCherbourg\nQueenstown\nSouthampton\n\n\n\n\n0\nFalse\nFalse\nTrue\n\n\n1\nTrue\nFalse\nFalse\n\n\n2\nFalse\nFalse\nTrue\n\n\n3\nFalse\nFalse\nTrue\n\n\n4\nFalse\nFalse\nTrue\n\n\n...\n...\n...\n...\n\n\n886\nFalse\nFalse\nTrue\n\n\n887\nFalse\nFalse\nTrue\n\n\n888\nFalse\nFalse\nTrue\n\n\n889\nTrue\nFalse\nFalse\n\n\n890\nFalse\nTrue\nFalse\n\n\n\n\n891 rows × 3 columns\n\n\n\n\npd.get_dummies(df[\"embark_town\"], drop_first=True)\n# Una ventaja de este procedimiento es que no considera los Nulos como otra categoría...\n\n\n\n\n\n\n\n\nQueenstown\nSouthampton\n\n\n\n\n0\nFalse\nTrue\n\n\n1\nFalse\nFalse\n\n\n2\nFalse\nTrue\n\n\n3\nFalse\nTrue\n\n\n4\nFalse\nTrue\n\n\n...\n...\n...\n\n\n886\nFalse\nTrue\n\n\n887\nFalse\nTrue\n\n\n888\nFalse\nTrue\n\n\n889\nFalse\nFalse\n\n\n890\nTrue\nFalse\n\n\n\n\n891 rows × 2 columns\n\n\n\n\n\nOrdinal Encoder\nSe utiliza pd.factorize(). * sort: Usar True ya que coloca las categorías en orden. Además de esta manera se comporta igual que OrdinalEncoder de Scikit-Learn.\n\npd.DataFrame(\n    pd.factorize(df[\"embark_town\"], sort=True)[0], columns=[\"new_column\"]\n)\n\n\n\n\n\n\n\n\nnew_column\n\n\n\n\n0\n2\n\n\n1\n0\n\n\n2\n2\n\n\n3\n2\n\n\n4\n2\n\n\n...\n...\n\n\n886\n2\n\n\n887\n2\n\n\n888\n2\n\n\n889\n0\n\n\n890\n1\n\n\n\n\n891 rows × 1 columns\n\n\n\nScikit-Learn:\n\n\nOne Hot Encoding\n\nsparse_output: Se debe fijar como False para poder ver el output como Pandas\ndrop: Se debe colocar \"first\" o el nombre de una sóla categoría a eliminar.\n\n\nfrom sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n\nohe = OneHotEncoder(drop=\"first\", sparse_output=False)\nohe.fit_transform(df[[\"embark_town\"]])\n\n\n\n\n\n\n\n\nembark_town_Queenstown\nembark_town_Southampton\nembark_town_nan\n\n\n\n\n0\n0.0\n1.0\n0.0\n\n\n1\n0.0\n0.0\n0.0\n\n\n2\n0.0\n1.0\n0.0\n\n\n3\n0.0\n1.0\n0.0\n\n\n4\n0.0\n1.0\n0.0\n\n\n...\n...\n...\n...\n\n\n886\n0.0\n1.0\n0.0\n\n\n887\n0.0\n1.0\n0.0\n\n\n888\n0.0\n1.0\n0.0\n\n\n889\n0.0\n0.0\n0.0\n\n\n890\n1.0\n0.0\n0.0\n\n\n\n\n891 rows × 3 columns\n\n\n\n\n\nOrdinal Encoder\n\nohe = OneHotEncoder(\n    drop=[\"Queenstown\"], sparse_output=False\n)  # También se puede colocar np.nan.\nohe.fit_transform(df[[\"embark_town\"]])\n\n\n\n\n\n\n\n\nembark_town_Cherbourg\nembark_town_Southampton\nembark_town_nan\n\n\n\n\n0\n0.0\n1.0\n0.0\n\n\n1\n1.0\n0.0\n0.0\n\n\n2\n0.0\n1.0\n0.0\n\n\n3\n0.0\n1.0\n0.0\n\n\n4\n0.0\n1.0\n0.0\n\n\n...\n...\n...\n...\n\n\n886\n0.0\n1.0\n0.0\n\n\n887\n0.0\n1.0\n0.0\n\n\n888\n0.0\n1.0\n0.0\n\n\n889\n1.0\n0.0\n0.0\n\n\n890\n0.0\n0.0\n0.0\n\n\n\n\n891 rows × 3 columns\n\n\n\n\noe = OrdinalEncoder()\noe.fit_transform(df[[\"embark_town\"]])\n\n\n\n\n\n\n\n\nembark_town\n\n\n\n\n0\n2.0\n\n\n1\n0.0\n\n\n2\n2.0\n\n\n3\n2.0\n\n\n4\n2.0\n\n\n...\n...\n\n\n886\n2.0\n\n\n887\n2.0\n\n\n888\n2.0\n\n\n889\n0.0\n\n\n890\n1.0\n\n\n\n\n891 rows × 1 columns"
  },
  {
    "objectID": "tics411/notebooks/01-Preprocesamiento.html#escalamiento",
    "href": "tics411/notebooks/01-Preprocesamiento.html#escalamiento",
    "title": "Clases UAI",
    "section": "Escalamiento",
    "text": "Escalamiento\nEl escalamiento normalmente se realiza sólo en Scikit-Learn. Se mostrarán la Estandarización y Normalización.\n\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\n\n## Llamaremos esto Estandarización... (sólo por convención del curso)\nsc = StandardScaler()\ndata = sc.fit_transform(df[[\"fare\"]])\ndata.agg([\"mean\", \"std\"])\n\n\n\n\n\n\n\n\nfare\n\n\n\n\nmean\n3.987333e-18\n\n\nstd\n1.000562e+00\n\n\n\n\n\n\n\n\n## Llamaremos esto Normalización... (sólo por convención del curso)\nmms = MinMaxScaler()\nmms.fit_transform(df[[\"fare\"]]).agg([\"min\", \"max\"])\n\n\n\n\n\n\n\n\nfare\n\n\n\n\nmin\n0.0\n\n\nmax\n1.0"
  },
  {
    "objectID": "tics411/notebooks/01-Preprocesamiento.html#aplicar-preprocesamientos-sólo-a-algunas-variables.",
    "href": "tics411/notebooks/01-Preprocesamiento.html#aplicar-preprocesamientos-sólo-a-algunas-variables.",
    "title": "Clases UAI",
    "section": "Aplicar Preprocesamientos sólo a algunas variables.",
    "text": "Aplicar Preprocesamientos sólo a algunas variables.\nScikit-Learn fue diseñado para el entrenamiento eficiente de modelos. Para ello, se basó en Numpy, el cuál no cuenta con nombre de columnas, por lo que para poder aplicar pre-procesamientos a ciertas partes del Dataset utiliza lo que se llama el ColumnTransformer(), el cuál va más allá del alcance del curso.\nPara simplificar el proceso de elegir ciertas columnas, feature_engine posee una el SklearnTransformerWrapper que permite elegir qué variables queremos pasar por cierta transformación.\n\n## Sin SklearnTransformerWrapper\n\nohe = OneHotEncoder(sparse_output=False)\nohe.fit_transform(df[[\"age\", \"embark_town\"]])\n## Crea columnas dummies incluso para las variables numéricas.\n\n\n\n\n\n\n\n\nage_0.42\nage_0.67\nage_0.75\nage_0.83\nage_0.92\nage_1.0\nage_2.0\nage_3.0\nage_4.0\nage_5.0\n...\nage_70.0\nage_70.5\nage_71.0\nage_74.0\nage_80.0\nage_nan\nembark_town_Cherbourg\nembark_town_Queenstown\nembark_town_Southampton\nembark_town_nan\n\n\n\n\n0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n1\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n2\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n3\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n4\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n886\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n887\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n888\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n...\n0.0\n0.0\n0.0\n0.0\n0.0\n1.0\n0.0\n0.0\n1.0\n0.0\n\n\n889\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n1.0\n0.0\n0.0\n0.0\n\n\n890\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n1.0\n0.0\n0.0\n\n\n\n\n891 rows × 93 columns\n\n\n\n\n## Aplicar preprocesamientos a ciertas variables...\nfrom feature_engine.wrappers import SklearnTransformerWrapper\n\nohe_w = SklearnTransformerWrapper(\n    OneHotEncoder(sparse_output=False), variables=\"embark_town\"\n)\nohe_w.fit_transform(df[[\"age\", \"embark_town\"]])\n## Crea dummies sólo para la variable embark_town y deja age como estaba.\n\n\n\n\n\n\n\n\nage\nembark_town_Cherbourg\nembark_town_Queenstown\nembark_town_Southampton\nembark_town_nan\n\n\n\n\n0\n22.0\n0.0\n0.0\n1.0\n0.0\n\n\n1\n38.0\n1.0\n0.0\n0.0\n0.0\n\n\n2\n26.0\n0.0\n0.0\n1.0\n0.0\n\n\n3\n35.0\n0.0\n0.0\n1.0\n0.0\n\n\n4\n35.0\n0.0\n0.0\n1.0\n0.0\n\n\n...\n...\n...\n...\n...\n...\n\n\n886\n27.0\n0.0\n0.0\n1.0\n0.0\n\n\n887\n19.0\n0.0\n0.0\n1.0\n0.0\n\n\n888\nNaN\n0.0\n0.0\n1.0\n0.0\n\n\n889\n26.0\n1.0\n0.0\n0.0\n0.0\n\n\n890\n32.0\n0.0\n1.0\n0.0\n0.0\n\n\n\n\n891 rows × 5 columns"
  },
  {
    "objectID": "tics411/clase-7.html#introducción",
    "href": "tics411/clase-7.html#introducción",
    "title": "TICS-411 Minería de Datos",
    "section": "Introducción",
    "text": "Introducción\n\nGracias a los planes de fidelización (juntar puntos, dar RUT, acumular millas, etc.) las empresas son capaces de detectar patrones:\n\n\nQué nos gusta,\nQué compramos,\nCon qué frecuencia lo compramos,\nJunto con qué lo compramos\netc.\n\n\n\n\n\n\n\nMarket Basket Analysis\n\n\nCorresponde al estudio de nuestra canasta de compras. De modo que podamos entender qué cosas son las que como clientes preferimos y una empresa pueda Recomendar de manera más apropiadas."
  },
  {
    "objectID": "tics411/clase-7.html#definiciones",
    "href": "tics411/clase-7.html#definiciones",
    "title": "TICS-411 Minería de Datos",
    "section": "Definiciones",
    "text": "Definiciones\n\nPatrón\n\n\nPredicado (output True/False) para verificar si una estructura buscada ocurre o no.\n\n\nTarea\n\n\nEncontrar reglas de asociación basado en patrones.\n\n\n\nEjemplos\n\nDatasets de supermercados:\n\n10% de los clientes totales compran vino y quedo (patrón: si compro vino, también llevo queso).\n\nDatasets de Alarmas:\n\nSi la alarma A y B suenan en un intervalo de 30 segundos, entonces la alarma C sonará dentro de un intervalo de 60 segundos con 50% de probabilidad."
  },
  {
    "objectID": "tics411/clase-7.html#ejemplo-datos-supermercado",
    "href": "tics411/clase-7.html#ejemplo-datos-supermercado",
    "title": "TICS-411 Minería de Datos",
    "section": "Ejemplo: Datos Supermercado",
    "text": "Ejemplo: Datos Supermercado\n\nDatos Transaccionales\n\n\nUna transacción involucra un conjunto de elementos. Una boleta de supermercado muestra el conjunto de elementos comprados por un cliente. Los productos involucrados en una transacción se denominan items."
  },
  {
    "objectID": "tics411/clase-7.html#ejemplo-datos-supermercado-1",
    "href": "tics411/clase-7.html#ejemplo-datos-supermercado-1",
    "title": "TICS-411 Minería de Datos",
    "section": "Ejemplo: Datos Supermercado",
    "text": "Ejemplo: Datos Supermercado"
  },
  {
    "objectID": "tics411/clase-7.html#objetivo-y-aplicaciones",
    "href": "tics411/clase-7.html#objetivo-y-aplicaciones",
    "title": "TICS-411 Minería de Datos",
    "section": "Objetivo y Aplicaciones",
    "text": "Objetivo y Aplicaciones\n\n\n\n\n\n\nObjetivo\n\n\nEncontrar asociaciones entre elementos u objetos de bases de datos transaccionales.\n\n\n\n\n\n\n\n\n\nAplicaciones\n\n\n\nApoyo a toma de decisiones.\nAnálisis de Información de Ventas.\nDistribución y ubicación de Mercaderías.\nSegmentación de Clientes en base de patrones de compra.\nDiágnostico y predicción de alarmas."
  },
  {
    "objectID": "tics411/clase-7.html#definiciones-medidas",
    "href": "tics411/clase-7.html#definiciones-medidas",
    "title": "TICS-411 Minería de Datos",
    "section": "Definiciones: Medidas",
    "text": "Definiciones: Medidas\n\n\n\n\n\n\nSupport (Soporte)\n\nFracción de Transacciones que contienen a \\(X\\). Probabilidad de que una transacción contenga a \\(X\\).\n\n\n\\[Supp(X) = P(X)\\]\n\n\n\n\n\n\n\nSupport Count\n\nNúmero de Transacciones que contienen a \\(X\\).\n\n\n\\[SuppCount(X) = Count(X)\\]\n\n\n\n\n\n\n\n\nConfidence (Confianza o Eficiencia)\n\nFracción de las Transacciones en las que aparece \\(X\\) que también incluyen \\(Z\\).\n\n\n\\[Conf(X \\implies Z) = \\frac{Supp(X \\cup Z)}{Supp(X)}\\] \\[Conf(X \\implies Z) = \\frac{SuppCount(X \\cup Z)}{SuppCount(X)}\\]\n\n\n\n\n\n\n\n\n\n\nOjo con la Notación \\(\\cup\\). En este caso significa que tanto el producto X como el Producto Z sean parte de la transacción."
  },
  {
    "objectID": "tics411/clase-7.html#ejemplos-support-y-confidence",
    "href": "tics411/clase-7.html#ejemplos-support-y-confidence",
    "title": "TICS-411 Minería de Datos",
    "section": "Ejemplos: Support y Confidence",
    "text": "Ejemplos: Support y Confidence\n\n\n\n\n\n\n\n\n\\[ Supp({Pan}) = 4/7\\] \\[ Supp({Leche}) = 3/7\\] \\[ Supp({Pan, Huevo}) = 2/7\\]\n\\[ Conf({Pan} \\implies {Huevo}) = \\frac{Supp({Pan, Huevo})}{Supp(Pan)} = \\frac{2/7}{4/7}\\]\n\\[ Conf({Pan} \\implies {Leche}) = \\frac{Supp({Pan, Leche})}{Supp(Pan)} = \\frac{1/7}{4/7}\\] \\[ Conf({Leche} \\implies {Pan}) = \\frac{Supp({Pan, Leche})}{Supp(Leche)} = \\frac{1/7}{3/7}\\]"
  },
  {
    "objectID": "tics411/clase-7.html#problema",
    "href": "tics411/clase-7.html#problema",
    "title": "TICS-411 Minería de Datos",
    "section": "Problema",
    "text": "Problema\n\nEn un dataset transaccional de n productos totales y \\(|U_i|\\) elementos para la Transacción \\(i\\).\n\nSe pueden generar un total de \\(N_{reglas}\\) de asociación:\n\\[N_{reglas} = \\sum_{i=1}^{2^{n}} \\sum_{j=0}^{|U_i|}\\binom{|U_i|}{j}\\]\n\n\n\n\n\n\n\n\n\nSi suponemos un supermercado que tiene 1000 productos, y transacciones que pueden ir entre 1 y 50 productos. El problema es muy costoso, y se podrían eventualmente generar demasiadas combinaciones."
  },
  {
    "objectID": "tics411/clase-7.html#algoritmo-apriori",
    "href": "tics411/clase-7.html#algoritmo-apriori",
    "title": "TICS-411 Minería de Datos",
    "section": "Algoritmo Apriori",
    "text": "Algoritmo Apriori\n\nApriori\n\n\nEs un algoritmo para aprender reglas de asociación que utiliza el principio Apriori para buscar de forma eficiente las reglas que satisfacen los límites de soporte y confianza.\n\n\n\n\nAlgoritmo\n\nFijar \\(k=1\\) y determinar lista de candidatos de tamaño \\(k\\).\n\nCalcular la frecuencia del conjunto.\nEliminar conjuntos con baja frecuencia (utilizando un umbral de soporte).\nUnir los conjuntos frecuentes para generar conjuntos de tamaño \\(k+1\\).\nSi existe la posibilidad de seguir creando combinaciones volver al paso a y repetir.\n\nUsar todos los conjuntos frecuentes para generar reglas."
  },
  {
    "objectID": "tics411/clase-7.html#ejemplo-apriori",
    "href": "tics411/clase-7.html#ejemplo-apriori",
    "title": "TICS-411 Minería de Datos",
    "section": "Ejemplo Apriori",
    "text": "Ejemplo Apriori\n\nSupongamos el siguiente dataset transaccional:\n\nSupongamos que queremos calcular las reglas de asociación que tengan un MinSupp=40% y un MinConf=70%.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPodríamos pensar que MinSupp y MinConf son los hiperparámetros de este algoritmo."
  },
  {
    "objectID": "tics411/clase-7.html#ejemplo-apriori-iteración-1",
    "href": "tics411/clase-7.html#ejemplo-apriori-iteración-1",
    "title": "TICS-411 Minería de Datos",
    "section": "Ejemplo Apriori: Iteración 1",
    "text": "Ejemplo Apriori: Iteración 1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGalletas NO CUMPLE con el Soporte Mínimo solicitado. Por lo tanto, lo elimino y genero relaciones de 2 productos sin considerar Galletas."
  },
  {
    "objectID": "tics411/clase-7.html#ejemplo-apriori-iteración-2",
    "href": "tics411/clase-7.html#ejemplo-apriori-iteración-2",
    "title": "TICS-411 Minería de Datos",
    "section": "Ejemplo Apriori: Iteración 2",
    "text": "Ejemplo Apriori: Iteración 2\n\n\n\n\n\n\n\n\n\n\n\n\n\nAcá NO SE ELIMINA ningún producto, ya que en los itemsets que sobrevivieron hay Pan, Mantequilla, Leche, Pañales y Cerveza."
  },
  {
    "objectID": "tics411/clase-7.html#ejemplo-apriori-iteración-3",
    "href": "tics411/clase-7.html#ejemplo-apriori-iteración-3",
    "title": "TICS-411 Minería de Datos",
    "section": "Ejemplo Apriori: Iteración 3",
    "text": "Ejemplo Apriori: Iteración 3\n\n\n\n\n\n\n\n\n\n\n\n\n\nSe puede apreciar que los únicos 3 productos que sobreviven son Pan, Mantequilla y Leche. Por lo tanto, NO ES POSIBLE generar reglas con 4 productos."
  },
  {
    "objectID": "tics411/clase-7.html#ejemplo-apriori-generación-de-reglas",
    "href": "tics411/clase-7.html#ejemplo-apriori-generación-de-reglas",
    "title": "TICS-411 Minería de Datos",
    "section": "Ejemplo Apriori: Generación de Reglas",
    "text": "Ejemplo Apriori: Generación de Reglas\n\n\n\n\n\n\n\n\n\n\nPara {Pan, Mantequilla}:\n\n\\(Conf(Pan \\implies Mantequilla) = \\frac{Supp(Pan, Mantequilla)}{Supp(Pan)} = \\frac{3}{3}\\)✅ \\(Conf(Mantequilla \\implies Pan) = \\frac{Supp(Pan, Mantequilla)}{Supp(Mantequilla)} = \\frac{3}{3}\\)✅\n\n\n\nPara {Pan, Leche}:\n\n\\(Conf(Pan \\implies Leche) = \\frac{Supp(Pan, Leche)}{Supp(Pan)} = \\frac{2}{3}\\) ❌ \\(Conf(Leche \\implies Pan) = \\frac{Supp(Pan, Leche)}{Supp(Leche)} = \\frac{2}{2}\\) ✅\n\n\n\nPara {Mantequilla, Leche}:\n\n\\(Conf(Mantequilla \\implies Leche) = \\frac{Supp(Mantequilla, Leche)}{Supp(Mantequilla)} = \\frac{2}{3}\\) ❌ \\(Conf(Leche \\implies Mantequilla) = \\frac{Supp(Mantequilla, Leche)}{Supp(Leche)} = \\frac{2}{2}\\) ✅"
  },
  {
    "objectID": "tics411/clase-7.html#ejemplo-apriori-generación-de-reglas-1",
    "href": "tics411/clase-7.html#ejemplo-apriori-generación-de-reglas-1",
    "title": "TICS-411 Minería de Datos",
    "section": "Ejemplo Apriori: Generación de Reglas",
    "text": "Ejemplo Apriori: Generación de Reglas\n\n\n\n\n\n\n\n\n\n\nPara {Pañales, Cerveza}:\n\n\\(Conf(Pañales \\implies Cerveza) = \\frac{Supp(Pañales, Cerveza)}{Supp(Pañales)} = \\frac{2}{3}\\)❌ \\(Conf(Cerveza \\implies Pañales) = \\frac{Supp(Pañales, Cerveza)}{Supp(Cerveza)} = \\frac{2}{2}\\)✅\n\n\n\nPara {Pan, Mantequilla, Leche}:\n\n\\(Conf({Pan, Mantequilla} \\implies {Leche}) = \\frac{Supp(Pan, Mantequilla, Leche)}{Supp(Pan, Mantequilla)} = \\frac{2}{3}\\)❌ \\(Conf({Pan, Leche} \\implies {Mantequilla}) = \\frac{Supp(Pan, Mantequilla, Leche)}{Supp(Pan, Leche)} = \\frac{2}{2}\\)✅ \\(Conf({Mantequilla, Leche} \\implies {Pan}) = \\frac{Supp(Pan, Mantequilla, Leche)}{Supp(Mantequilla, Leche)} = \\frac{2}{2}\\)✅\n\n\\(Conf({Leche} \\implies {Pan, Mantequilla}) = \\frac{Supp(Pan, Mantequilla, Leche)}{Supp(Leche)} = \\frac{2}{2}\\)✅ \\(Conf({Mantequilla} \\implies {Pan, Leche}) = \\frac{Supp(Pan, Mantequilla, Leche)}{Supp(Mantequilla)} = \\frac{2}{3}\\)❌ \\(Conf({Pan} \\implies {Mantequilla, Leche}) = \\frac{Supp(Pan, Mantequilla, Leche)}{Supp(Pan)} = \\frac{2}{3}\\)❌"
  },
  {
    "objectID": "tics411/clase-7.html#resultado-final",
    "href": "tics411/clase-7.html#resultado-final",
    "title": "TICS-411 Minería de Datos",
    "section": "Resultado Final",
    "text": "Resultado Final\n\n\nItemset MinSupp = 40%\n\n\n\n\n\n\nReglas Finales MinConf = 70%\n\\[Pan \\implies Mantequilla\\] \\[Mantequilla \\implies Pan\\] \\[Leche \\implies Pan\\] \\[Leche \\implies Mantequilla\\] \\[Cerveza \\implies Pañales\\] \\[\\{Pan, Leche\\} \\implies Mantequilla\\]\n\\[\\{Mantequilla, Leche\\} \\implies Pan\\] \\[Leche \\implies \\{Pan, Mantequilla\\}\\]\n\n\n\n\n\n\nInsights:\n\n\n\nEl Pan, la Leche y la Mantequilla están relacionados.\nParece ser que si llevo Cervezas también llevo Pañales."
  },
  {
    "objectID": "tics411/clase-7.html#evaluación-de-reglas-de-asociación",
    "href": "tics411/clase-7.html#evaluación-de-reglas-de-asociación",
    "title": "TICS-411 Minería de Datos",
    "section": "Evaluación de Reglas de Asociación",
    "text": "Evaluación de Reglas de Asociación\n\nLift\n\nMide qué tan lejos de la independencia están \\(X\\) e \\(Y\\). Lift varía entre 0 y \\(\\infty\\).\n\n\n\\[Lift(X,Y) = \\frac{Conf(X \\implies Y)}{s(Y)}\\]\n\n\\(Lift(X,Y) \\sim 1\\) implica independencia y la regla no es importante.\n\\(Lift(X,Y) &lt; 1\\) implica una asociación negativa de la regla.\n\\(Lift(X,Y) &gt; 1\\) implica una asociativa de la regla. Un mayor Lift implica que la regla es potencialmente útil para el futuro.\n\nEjemplo:\n\\[Lift(Cerveza, Pañales) = \\frac{Conf(Cerveza \\implies Pañales)}{Supp(Pañales)} = \\frac{1}{0.6} = 1.67\\]\n\n\n\n\n\n\nUna persona que compra Cerveza tiene 1.67 más chances de comprar Pañales."
  },
  {
    "objectID": "tics411/clase-7.html#implementación-en-python-preprocesamiento",
    "href": "tics411/clase-7.html#implementación-en-python-preprocesamiento",
    "title": "TICS-411 Minería de Datos",
    "section": "Implementación en Python: Preprocesamiento",
    "text": "Implementación en Python: Preprocesamiento\nPre-procesamiento\nimport pandas as pd\nfrom mlxtend.preprocessing import TransactionEncoder\n\ntre = TransactionEncoder()\ndf = tre.fit_transform(transactions)\ndf_encoded = pd.DataFrame(df, columns = tre.columns_)\nL4: transactions debe ser una lista de listas. Cada fila, son distintas transacciones. Cada transaccion puede tener distinto número de elementos. L5: tre.columns_ extrae los nombres de los productos para que el DataFrame sea más entendible.\n\n\n\n\n\n\ndf_encoded es un DataFrame tipo OneHotEncoder pero con valores Booleanos (Esto es solicitado por la documentación)."
  },
  {
    "objectID": "tics411/clase-7.html#implementación-en-python-itemsets",
    "href": "tics411/clase-7.html#implementación-en-python-itemsets",
    "title": "TICS-411 Minería de Datos",
    "section": "Implementación en Python: Itemsets",
    "text": "Implementación en Python: Itemsets\nfrom mlxtend.frequent_patterns import apriori \n\nitemset = apriori(df_encoded, min_support=0.5, use_colnames = True)\nL3: df_encoded es el DataFrame preprocesado.\n\nmin_support: Corresponde al Soporte Mínimo para generar itemsets. Por defecto 0.5.\nuse_colnames: Permite que las reglas usen los nombres de las columnas para referirse a los productos. Por defecto es False, pero conviene usarlo como True.\nitemset será un DataFrame con los itemsets generados."
  },
  {
    "objectID": "tics411/clase-7.html#implementación-en-python-reglas",
    "href": "tics411/clase-7.html#implementación-en-python-reglas",
    "title": "TICS-411 Minería de Datos",
    "section": "Implementación en Python: Reglas",
    "text": "Implementación en Python: Reglas\nfrom mlxtend.frequent_patterns import association_rules\n\nrules = association_rules(itemsets, metric=\"confidence\", min_threshold=0.8)\nL3: itemset es el dataframe generado en el paso anterior.\n\nmetric: Métrica para definir reglas, puede ser “confidence” y otras definidas acá\nmin_threshold: Corresponde al umbral de la métrica a utilizar. Por defecto 0.8.\nrules corresponde a un Dataset que tiene las Reglas de Asociación detectadas y muchas métricas asociadas."
  },
  {
    "objectID": "tics411/clase-4.html#definiciones",
    "href": "tics411/clase-4.html#definiciones",
    "title": "TICS-411 Minería de Datos",
    "section": "Definiciones",
    "text": "Definiciones\n\nClustering Jerárquico\n\n\nEs un tipo de aprendizaje que no requiere de etiquetas (las respuestas correctas) para poder aprender. Se basa en la construcción de Jerarquías para ir construyendo clusters.\n\n\nDendograma\n\n\nCorresponde a un diagrama en el que se muestran las distancias de atributos entre clases que son parte de un mismo cluster."
  },
  {
    "objectID": "tics411/clase-4.html#clustering-jerarquía",
    "href": "tics411/clase-4.html#clustering-jerarquía",
    "title": "TICS-411 Minería de Datos",
    "section": "Clustering: Jerarquía",
    "text": "Clustering: Jerarquía\n\nLos algoritmos basados en jerarquía pueden seguir 2 estrategias:\n\n\nAglomerativos: Comienzan con cada objeto como un grupo (bottom-up). Estos grupos se van combinando sucesivamente a través de una métrica de similaridad. Para n objetos se realizan n-1 uniones.\nDivisionales: Comienzan con un solo gran cluster (bottom-down). Posteriormente este mega-cluster es dividido sucesivamente de acuerdo a una métrica de similaridad."
  },
  {
    "objectID": "tics411/clase-4.html#clustering-aglomerativo-algoritmo",
    "href": "tics411/clase-4.html#clustering-aglomerativo-algoritmo",
    "title": "TICS-411 Minería de Datos",
    "section": "Clustering Aglomerativo: Algoritmo",
    "text": "Clustering Aglomerativo: Algoritmo\nAlgoritmo\n\nInicialmente se considera cada punto como un cluster.\nCalcula la matriz de proximidad/distancia entre cada cluster.\nRepetir (hasta que exista un solo cluster):\n\nUnir los cluster más cercanos.\nActualizar la matriz de proximidad/distancia.\n\n\n\n\n\n\n\n\nLo más importante de este proceso es el cálculo de la matriz de proximidad/distancia entre clusters\n\n\n\n\n\n\n\n\n\nDistintos enfoques de distancia entre clusters, segmentan los datos en forma distinta."
  },
  {
    "objectID": "tics411/clase-4.html#clustering-aglomerativo-ejemplo",
    "href": "tics411/clase-4.html#clustering-aglomerativo-ejemplo",
    "title": "TICS-411 Minería de Datos",
    "section": "Clustering Aglomerativo: Ejemplo",
    "text": "Clustering Aglomerativo: Ejemplo\nSupongamos que tenemos cinco tipos de genes cuya expresión ha sido determinada por 3 caracteríticas. Las siguientes expresiones pueden ser vistas como la expresión dados los genes en tres experimentos. ​\n\nApliquemos un Clustering Jerárquico Aglomerativo utilizando como medida de similaridad la Distancia Euclideana.\n\n\n\n\n\n\n\nOtros tipos de distancia también son aplicables siguiendo un procedimiento análogo."
  },
  {
    "objectID": "tics411/clase-4.html#algoritmo-1era-iteración",
    "href": "tics411/clase-4.html#algoritmo-1era-iteración",
    "title": "TICS-411 Minería de Datos",
    "section": "Algoritmo: 1era Iteración",
    "text": "Algoritmo: 1era Iteración\n\n\n\n\n\n\nEl algoritmo considerará que todos los puntos inicialmente son un cluster. Por lo tanto, tratará de encontrar los 2 puntos más cercanos e intentará unirnos en un sólo cluster.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProblema: ¿Cómo actualizamos la matriz de Distancias?\n\n\n\n\n\n\n\n\n\n\n\nEntonces crearemos un nuevo cluster: bcl2-Caspade."
  },
  {
    "objectID": "tics411/clase-4.html#clustering-aglomerativo-single-linkage",
    "href": "tics411/clase-4.html#clustering-aglomerativo-single-linkage",
    "title": "TICS-411 Minería de Datos",
    "section": "Clustering Aglomerativo: Single Linkage",
    "text": "Clustering Aglomerativo: Single Linkage\n\n\n\n\n\n\n\n\n\nDistancia entre clusters determinada por los puntos más similares entre los clusters.\n\n\n\n\n\n\n\n\n\n\n\n\\[D(C_i, C_j) = min\\{d(x,y) | x \\in C_i, y \\in C_j\\}\\]\n\n\n\n\n\n\n\n\nVentajas\n\n\n\nGenera Clusters largos y delgados.\n\n\n\n\n\n\n\n\n\n\n\nLimitaciones\n\n\n\nAfectado por Outliers"
  },
  {
    "objectID": "tics411/clase-4.html#clustering-aglomerativo-complete-linkage",
    "href": "tics411/clase-4.html#clustering-aglomerativo-complete-linkage",
    "title": "TICS-411 Minería de Datos",
    "section": "Clustering Aglomerativo: Complete Linkage",
    "text": "Clustering Aglomerativo: Complete Linkage\n\n\n\n\n\n\n\n\n\nDistancia determinada por la distancia ente los puntos más disímiles entre los clusters.\n\n\n\n\n\n\n\n\n\n\n\n\\[D(C_i, C_j) = max\\{d(x,y) | x \\in C_i, y \\in C_j\\}\\]\n\n\n\n\n\n\n\n\nVentajas\n\n\n\nMenos suceptible a dato atípicos.\n\n\n\n\n\n\n\n\n\n\n\nLimitaciones\n\n\n\nTiende a quebrar Clusters Grandes.\nTiene tendencia a generar Clusters circulares."
  },
  {
    "objectID": "tics411/clase-4.html#clustering-aglomerativo-average-linkage",
    "href": "tics411/clase-4.html#clustering-aglomerativo-average-linkage",
    "title": "TICS-411 Minería de Datos",
    "section": "Clustering Aglomerativo: Average Linkage",
    "text": "Clustering Aglomerativo: Average Linkage\n\n\n\n\n\n\n\n\n\nDistancia determinada por el promedio de las distancias que componen los clusters.\nPunto intermedio entre Single y Complete.\n\n\n\n\n\n\n\n\n\n\n\n\\[D(C_i, C_j) = avg\\{d(x,y) | x \\in C_i, y \\in C_j\\}\\]\n\n\n\n\n\n\n\n\nVentajas\n\n\n\nMenos suceptible a datos atípicos.\n\n\n\n\n\n\n\n\n\n\n\nLimitaciones\n\n\n\nTiende a generar clusters circulares."
  },
  {
    "objectID": "tics411/clase-4.html#clustering-aglomerativo-ward-linkage",
    "href": "tics411/clase-4.html#clustering-aglomerativo-ward-linkage",
    "title": "TICS-411 Minería de Datos",
    "section": "Clustering Aglomerativo: Ward Linkage",
    "text": "Clustering Aglomerativo: Ward Linkage\n\n\n\n\n\n\n\n\n\nDistancia determinada por el incremento del Within cluster distance.\nMinimiza la distancia intra cluster y maximiza la distancia entre clusters.\n\n\n\n\n\n\n\n\n\n\n\n\\[D(C_i, C_j) = wc(Cij) - wc(C_i) - wc(C_j) = \\frac{n_i\\cdot n_j}{n_i + n_j}||\\bar{C_i} - \\bar{C_j}||^2\\]\n\n\n\n\n\n\n\n\nVentajas\n\n\n\nMenos suceptible a dato atípicos.\n\n\n\n\n\n\n\n\n\n\n\nLimitaciones\n\n\n\nTiende a generar clusters circulares."
  },
  {
    "objectID": "tics411/clase-4.html#hiperparámetros",
    "href": "tics411/clase-4.html#hiperparámetros",
    "title": "TICS-411 Minería de Datos",
    "section": "Hiperparámetros",
    "text": "Hiperparámetros\nLos Hiperparámetros de este modelo serán:\n\n\n\n\n\n\nNote\n\n\n\nlinkage: La forma de calcular la distancia entre clusters.\ndistancia: La distancia utilizada como similaridad entre los clusters.\n\n\n\n\n\n\n\n\n\n\nA diferencia de K-Means, este método no requiere definir el número de Clusters a priori."
  },
  {
    "objectID": "tics411/clase-4.html#volvamos-a-la-iteración-1",
    "href": "tics411/clase-4.html#volvamos-a-la-iteración-1",
    "title": "TICS-411 Minería de Datos",
    "section": "Volvamos a la Iteración 1",
    "text": "Volvamos a la Iteración 1\n\nSupongamos que por simplicidad utilizaremos Average Linkage. (El proceso para utilizar otro linkage es análogo).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVamos a extraer una Matriz entre los puntos a fusionar y los puntos de los clusters restantes.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDendograma: 1era Iteración"
  },
  {
    "objectID": "tics411/clase-4.html#iteración-2",
    "href": "tics411/clase-4.html#iteración-2",
    "title": "TICS-411 Minería de Datos",
    "section": "Iteración 2",
    "text": "Iteración 2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDendograma: 2da Iteración"
  },
  {
    "objectID": "tics411/clase-4.html#iteración-3",
    "href": "tics411/clase-4.html#iteración-3",
    "title": "TICS-411 Minería de Datos",
    "section": "Iteración 3",
    "text": "Iteración 3\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDendograma: 3ra Iteración"
  },
  {
    "objectID": "tics411/clase-4.html#dendograma-resultante",
    "href": "tics411/clase-4.html#dendograma-resultante",
    "title": "TICS-411 Minería de Datos",
    "section": "Dendograma Resultante",
    "text": "Dendograma Resultante\n\n\n\n\n\n\nNo es necesario realizar la última iteración ya que se entiende que ambos clusters se unen.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n¿Cómo encontramos los clusters una vez que tenemos el Dendograma?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPodemos escoger un umbral de distancia y ver cuántos clusters se forman.\n\n\n\n\n\n\n\n\n\n\n\n\n\nComo regla general se deben escoger clusters más distanciados entre sí."
  },
  {
    "objectID": "tics411/clase-4.html#efecto-del-linkage-escogido",
    "href": "tics411/clase-4.html#efecto-del-linkage-escogido",
    "title": "TICS-411 Minería de Datos",
    "section": "Efecto del Linkage Escogido",
    "text": "Efecto del Linkage Escogido"
  },
  {
    "objectID": "tics411/clase-4.html#clustering-jerárquico-detalles-técnicos",
    "href": "tics411/clase-4.html#clustering-jerárquico-detalles-técnicos",
    "title": "TICS-411 Minería de Datos",
    "section": "Clustering Jerárquico: Detalles Técnicos",
    "text": "Clustering Jerárquico: Detalles Técnicos\n\n\n\n\n\n\nFortalezas\n\n\n\nNo requiere definir el número de Clusters a priori.\nAl tener distintas variantes es posible que los puntos sean agrupados de manera completamente distintas.\n\n\n\n\n\n\n\n\n\n\nDebilidades\n\n\n\nMuy ineficiente computacionalmente debido a que genera una nueva matriz de distancia en cada iteración lo que entrega una complejidad \\(O(n^2)\\) o \\(O(n^3)\\) dependiendo del linkage.\nUna vez que se decide combinar 2 clusters no es posible revertir esta decisión.\nNo tiene capacidad de generalización, ya que no es posible aplicarlo a datos nuevos."
  },
  {
    "objectID": "tics411/clase-4.html#implementación-en-scikit-learn",
    "href": "tics411/clase-4.html#implementación-en-scikit-learn",
    "title": "TICS-411 Minería de Datos",
    "section": "Implementación en Scikit-Learn",
    "text": "Implementación en Scikit-Learn\nfrom sklearn.cluster import AgglomerativeClustering\n\nac = AgglomerativeClustering(n_clusters=2, metric=\"euclidean\",linkage=\"ward\")\n\n## Se entrena y se genera la predicción\nac.fit_predict(X)\n\n\nn_clusters: Define el número de clusters a crear, por defecto 2.\nmetric: Permite distancias L1, L2 y coseno. Por defecto “euclidean”.\nlinkage: Permite single, complete, average y ward. Por defecto “ward”.\n.fit_predict(): Entrenará el modelo en los datos suministrados e inmediatamente genera el cluster asociado a cada elemento.\n\n\n\n\n\n\n\n\n\nSi bien el método de Aglomeración no requiere el número de clusters a generar, Scikit-Learn lo exige de modo de poder etiquetar cada elemento.\n\n\n\n\n\n\n\n\n\n\n\n¿Por qué no existen los métodos .fit() y .predict() por separado?"
  },
  {
    "objectID": "tics411/clase-4.html#otras-implementaciones-dendograma",
    "href": "tics411/clase-4.html#otras-implementaciones-dendograma",
    "title": "TICS-411 Minería de Datos",
    "section": "Otras implementaciones (Dendograma)",
    "text": "Otras implementaciones (Dendograma)\nfrom scipy.cluster.hierarchy import dendrogram, linkage\n\n# Genera los cálculos necesarios para construir el Histograma.\nZ = linkage(X, method='single', metric=\"euclidean\") \n\n# Graficar el Dendograma\nplt.figure(figsize=(10, 5)) # Define el tamaño del Gráfico\nplt.title('Dendograma Clustering Jerárquico') # Define un título para el dendograma\nplt.xlabel('Iris Samples')\nplt.ylabel('Distance')\ndendrogram(Z, leaf_rotation=90., leaf_font_size=8.)\nplt.show()\n\n\nPrincipalmente este código permite graficar el Dendograma completo.\nL4: Genera una instancia del Dendograma. (Sería equivalente al .fit() de Scikit-Learn).\nL5-L12: Corresponde al código necesario para graficar el Dendograma."
  },
  {
    "objectID": "tics411/clase-4.html#sugerencias",
    "href": "tics411/clase-4.html#sugerencias",
    "title": "TICS-411 Minería de Datos",
    "section": "Sugerencias",
    "text": "Sugerencias\n\n\n\n\n\n\nPre-procesamientos\n\n\nEs importante recordar que el clustering aglomerativo también es un Algoritmo basado en distancias, por lo tanto se ve afectado por Outliers y por Escala.\nSe recomienda preprocesar los datos con:\n\nWinsorizer() para eliminar Outliers.\nStandardScaler() o MinMaxScaler() para llevar a una escala común.\n\n\n\n\n\n\n\n\n\n\nOtras técnicas como merge y split, no aplican a este tipo de clustering debido a las limitaciones del algoritmo."
  },
  {
    "objectID": "tics411/clase-4.html#variantes",
    "href": "tics411/clase-4.html#variantes",
    "title": "TICS-411 Minería de Datos",
    "section": "Variantes",
    "text": "Variantes\n\nEn casos en los que no es posible calcular distancias debido a la presencia de datos categóricos, es posible utilizar el Gower Dissimilarity como medida de similitud.\n\n\n\n\n\n\n\n\n\nGower\n\nSe define como la proporción de variables que tienen distinto valor con respecto al total sin considerar donde ambos son ceros.\n\n\n\n\\[Gower(p1,p2) = \\frac{3}{9}\\]"
  },
  {
    "objectID": "tics411/clase-3.html#definiciones",
    "href": "tics411/clase-3.html#definiciones",
    "title": "TICS-411 Minería de Datos",
    "section": "Definiciones",
    "text": "Definiciones\n\nAprendizaje No supervisado\n\n\nEs un tipo de aprendizaje que no requiere de etiquetas (las respuestas correctas) para poder aprender.\n\n\n\n\n\n\n\n\n\nEn nuestro caso nos enfocaremos en un caso particular de Modelación Descriptiva llamada Clustering.\n\n\n\n\nClustering\n\n\nConsiste en agrupar los datos en un menor número de entidades o grupos. A estos grupos se les conoce como clusters y pueden ser generados de manera global, o modelando las principales características de los datos."
  },
  {
    "objectID": "tics411/clase-3.html#intuición",
    "href": "tics411/clase-3.html#intuición",
    "title": "TICS-411 Minería de Datos",
    "section": "Intuición",
    "text": "Intuición\n¿Cuántos clusters se pueden apreciar?"
  },
  {
    "objectID": "tics411/clase-3.html#clustering-introducción",
    "href": "tics411/clase-3.html#clustering-introducción",
    "title": "TICS-411 Minería de Datos",
    "section": "Clustering: Introducción",
    "text": "Clustering: Introducción\n\n\n\n\n\n\nClustering: Consiste en buscar grupos de objetos tales que la similaridad intra-grupo sea alta, mientras que la similaridad inter-grupos sea baja. Normalmente la distancia es usada para determinar qué tan similares son estos grupos."
  },
  {
    "objectID": "tics411/clase-3.html#clustering-evaluación",
    "href": "tics411/clase-3.html#clustering-evaluación",
    "title": "TICS-411 Minería de Datos",
    "section": "Clustering: Evaluación",
    "text": "Clustering: Evaluación\n\n\n\n\n\n\n\nEvaluar el nivel del éxito o logro del Clustering es complicado. ¿Por qué?"
  },
  {
    "objectID": "tics411/clase-3.html#clustering-tipos",
    "href": "tics411/clase-3.html#clustering-tipos",
    "title": "TICS-411 Minería de Datos",
    "section": "Clustering: Tipos",
    "text": "Clustering: Tipos"
  },
  {
    "objectID": "tics411/clase-3.html#clustering-partición",
    "href": "tics411/clase-3.html#clustering-partición",
    "title": "TICS-411 Minería de Datos",
    "section": "Clustering: Partición",
    "text": "Clustering: Partición\n\nLos datos son separados en K clusters, donde cada punto pertenece exclusivamente a un único cluster."
  },
  {
    "objectID": "tics411/clase-3.html#clustering-densidad",
    "href": "tics411/clase-3.html#clustering-densidad",
    "title": "TICS-411 Minería de Datos",
    "section": "Clustering: Densidad",
    "text": "Clustering: Densidad\n\nSe basan en la idea de continuar el crecimiento de un cluster a medida que la densidad (número de objetos o puntos) en el vecindario sobrepase algún umbral."
  },
  {
    "objectID": "tics411/clase-3.html#clustering-jerarquía",
    "href": "tics411/clase-3.html#clustering-jerarquía",
    "title": "TICS-411 Minería de Datos",
    "section": "Clustering: Jerarquía",
    "text": "Clustering: Jerarquía\n\nLos algoritmos basados en jerarquía pueden seguir 2 estrategias:\n\n\nAglomerativos: Comienzan con cada objeto como un grupo (bottom-up). Estos grupos se van combinando sucesivamente a través de una métrica de similaridad. Para n objetos se realizan n-1 uniones.\nDivisionales: Comienzan con un solo gran cluster (bottom-down). Posteriormente este mega-cluster es dividido sucesivamente de acuerdo a una métrica de similaridad."
  },
  {
    "objectID": "tics411/clase-3.html#clustering-probabilístico",
    "href": "tics411/clase-3.html#clustering-probabilístico",
    "title": "TICS-411 Minería de Datos",
    "section": "Clustering: Probabilístico",
    "text": "Clustering: Probabilístico\nSe ajusta cada punto a una distribución de probabilidades que indica cuál es la probabilidad de pertenencia a dicho cluster."
  },
  {
    "objectID": "tics411/clase-3.html#partición",
    "href": "tics411/clase-3.html#partición",
    "title": "TICS-411 Minería de Datos",
    "section": "Partición",
    "text": "Partición\n\nLos datos son separados en K Clusters, donde cada punto pertenece exclusivamente a un único cluster. A K se le considera como un hiperparámetro.\n\n\n\n\n\n\n\n\nCluster Compactos: Minimizar la distancia intra-cluster (within cluster).\nClusters bien separados: Maximizar la distancia inter-cluster (between cluster).\n\n\n\n\n\\[ Score (C,D) = f(wc(C),bc(C))\\]\nEl puntaje/score mide la calidad del clustering \\(C\\) para el Dataset \\(D\\)."
  },
  {
    "objectID": "tics411/clase-3.html#score",
    "href": "tics411/clase-3.html#score",
    "title": "TICS-411 Minería de Datos",
    "section": "Score",
    "text": "Score\n\\[ Score (C,D) = f(wc(C),bc(C))\\]\n\n\n\n\nDistancia Between-Cluster: \\[bc(C) = \\sum_{1 \\le j \\le k \\le K} d(r_j, r_k)\\]\n\ndonde \\(r_k\\) representa el centro del cluster \\(k\\): \\[r_k = \\frac{1}{n_k} \\sum_{x_i \\in C_k} x_i\\]\n\n\nDistancia Within-Cluster (Inercia): \\[wc(C) = \\sum_{k=1}^K \\sum_{x_i \\in C_k} d(x_i, r_k)\\]\n\n\n\n\n\n\n\n\n\n\nDistancia entre los centros de cada cluster.\n\n\n\n\n\n\n\n\n\n\nDistancia entre todos los puntos del cluster y su respectivo centro."
  },
  {
    "objectID": "tics411/clase-3.html#k-means",
    "href": "tics411/clase-3.html#k-means",
    "title": "TICS-411 Minería de Datos",
    "section": "K-Means",
    "text": "K-Means\n\nK-Means\n\n\nDado un número de clusters \\(K\\) (determinado por el usuario), cada cluster es asociado a un centro (centroide). Luego, cada punto es asociado al cluster con el centroide más cercano.\n\n\n\n\n\n\n\n\n\n\n\nNormalmente se utiliza la Distancia Euclideana como medida de similaridad.\n\nSe seleccionan \\(K\\) puntos como centroides iniciales.\nRepite:\n\nForma K clusters asignando todos los puntos al centroide más cercano.\nRecalcula el centroide para cada clase como la media de todos los puntos de dicho cluster.\n\n\n\nSe repite este procedimiento por un número finito de iteraciones o hasta que los centroides no cambien."
  },
  {
    "objectID": "tics411/clase-3.html#k-means-ejemplo",
    "href": "tics411/clase-3.html#k-means-ejemplo",
    "title": "TICS-411 Minería de Datos",
    "section": "K-Means: Ejemplo",
    "text": "K-Means: Ejemplo\nResolvamos el siguiente ejemplo.\nSupongamos que tenemos tipos de manzana, y cada una de ellas tiene 2 atributos (features). Agrupemos estos objetos en 2 grupos de manzanas basados en sus características."
  },
  {
    "objectID": "tics411/clase-3.html#k-means-ejemplo-1",
    "href": "tics411/clase-3.html#k-means-ejemplo-1",
    "title": "TICS-411 Minería de Datos",
    "section": "K-Means: Ejemplo",
    "text": "K-Means: Ejemplo\n1era Iteración\n\n\n\n\nSupongamos los siguientes centroides iniciales: \\[C_1 = (1,1)\\] \\[C_2 = (2,1)\\]\n\n\n\n\n\n\n\n\n\nMatriz de Distancias al Centroide: (coordenada i,j representa distancia del punto j al centroide i)\n\n\n\n\n\n\\[D^1 = \\begin{bmatrix}\n0 & 1 & 3.61 & 5\\\\\n1 & 0 & 2.83 & 4.24\n\\end{bmatrix}\\]\n\n\n\nCalculemos la Matriz de Pertenencia \\(G\\):\n\n\n\n\\[G^1 = \\begin{bmatrix}\n1 & 0 & 0 & 0 \\\\\n0 & 1 & 1 & 1\n\\end{bmatrix}\\]\n\n\n\n\n\n\n\n\nLos nuevos centroides son: \\[C_1 = (1,1)\\] \\[C_2 = (\\frac{11}{3}, \\frac{8}{3})\\]"
  },
  {
    "objectID": "tics411/clase-3.html#k-means-ejemplo-2",
    "href": "tics411/clase-3.html#k-means-ejemplo-2",
    "title": "TICS-411 Minería de Datos",
    "section": "K-Means: Ejemplo",
    "text": "K-Means: Ejemplo\n2da Iteración\n\n\n\n\nLos nuevos centroides son:\n\n\\[C_1 = (1,1)\\] \\[C_2 = (\\frac{11}{3}, \\frac{8}{3})\\]\n\n\n\nCalculamos la Matriz de Distancias al Centroide:\n\n\n\n\\[D^2 = \\begin{bmatrix}\n0 & 1 & 3.61 & 5\\\\\n3.14 & 2.26 & 0.47 & 1.89\n\\end{bmatrix}\\]\n\n\n\nCalculemos la Matriz de Pertenencia \\(G\\):\n\n\n\n\\[G^2 = \\begin{bmatrix}\n1 & 1 & 0 & 0 \\\\\n0 & 0 & 1 & 1\n\\end{bmatrix}\\]\n\n\n\n\n\n\n\n\nLos nuevos centroides son:\n\\(C_1 = (\\frac{3}{2}, 1)\\) y \\(C_2 = (\\frac{9}{2}, \\frac{7}{2})\\)"
  },
  {
    "objectID": "tics411/clase-3.html#k-means-ejemplo-3",
    "href": "tics411/clase-3.html#k-means-ejemplo-3",
    "title": "TICS-411 Minería de Datos",
    "section": "K-Means: Ejemplo",
    "text": "K-Means: Ejemplo\n\n\n\n\n\n\n\n\n\n\n\n\nSi seguimos iterando notaremos que ya no hay cambios en los clusters. El algoritmo converge.\nEste es el resultado de usar \\(K=2\\). Utilizar otro valor de \\(K\\) entregará valores distintos.\n¿Es este el número de clusters óptimos?"
  },
  {
    "objectID": "tics411/clase-3.html#k-means-número-de-clusters-óptimos",
    "href": "tics411/clase-3.html#k-means-número-de-clusters-óptimos",
    "title": "TICS-411 Minería de Datos",
    "section": "K-Means: Número de Clusters Óptimos",
    "text": "K-Means: Número de Clusters Óptimos\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSiempre es posible encontrar el número de clusters indicados.\nEntonces,\n\n¿Cómo debería escoger el valor de \\(K\\)?"
  },
  {
    "objectID": "tics411/clase-3.html#k-means-número-de-clusters-óptimos-1",
    "href": "tics411/clase-3.html#k-means-número-de-clusters-óptimos-1",
    "title": "TICS-411 Minería de Datos",
    "section": "K-Means: Número de Clusters Óptimos",
    "text": "K-Means: Número de Clusters Óptimos\n\nCurva del Codo\n\nEs una heurísitca en la cual gráfica el valor de una métrica de distancia (e.g. within distance) para distintos valores de \\(K\\). El valor óptimo de \\(K\\) será el codo de la curva, que es el valor donde se estabiliza la métrica.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEste valor del codo muchas veces es subjetivo y distintas apreciaciones pueden llegar a distintos \\(K\\) óptimos.\n\n\n\n\n\n\n\n\n\n\nEventualmente otras métricas distintas al within cluster distance podrían también ser usadas.\n\n\n\n\n\n\n\n\n\n¿Cuál es el efecto que está buscando la curva del codo? ¿Qué implica el valor de K escogido?"
  },
  {
    "objectID": "tics411/clase-3.html#k-means-detalles-técnicos",
    "href": "tics411/clase-3.html#k-means-detalles-técnicos",
    "title": "TICS-411 Minería de Datos",
    "section": "K-Means: Detalles Técnicos",
    "text": "K-Means: Detalles Técnicos\n\n\n\n\n\n\nFortalezas\n\n\n\nAlgoritmo relativamente eficiente (\\(O(k \\cdot n \\cdot i)\\)). Donde \\(k\\) es el número de clusters, \\(n\\) el número de puntos, e \\(i\\) el número de iteraciones.\nEncuentra “clusters esféricos”.\n\n\n\n\n\n\n\n\n\n\nDebilidades\n\n\n\nSensible al punto de inicio.\nSolo se puede aplicar cuando el promedio es calculable.\nSe requiere definir K a priori (K es un hiperparámetro).\nSuceptible al ruido y a mínimos locales (podría no converger)."
  },
  {
    "objectID": "tics411/clase-3.html#implementación-en-scikit-learn",
    "href": "tics411/clase-3.html#implementación-en-scikit-learn",
    "title": "TICS-411 Minería de Datos",
    "section": "Implementación en Scikit-Learn",
    "text": "Implementación en Scikit-Learn\nfrom sklearn.cluster import KMeans\n\nkm = KMeans(n_clusters=8, n_init=10,random_state=None)\nkm.fit(X)\nkm.predict(X)\n\n## opcionalmente\nkm.fit_predict(X)\n\n\nn_clusters: Define el número de clusters a crear, por defecto 8.\nn_init: Cuántas veces se ejecuta el algoritmo, por defecto 10.\nrandom_state: Define la semilla aleatoria. Por defecto sin semilla.\ninit: Permite agregar centroides de manera manual.\n.fit(): Entrenará el modelo en los datos suministrados.\n.predict() Entregará las clusters asignados a cada dato suministrado.\n.clusters_centers_: Entregará las coordenadas de los centroides de cada Cluster.\n.inertia_: Entrega valores correspondiente a la within cluster distance.\n\n\n👀 Veamos un ejemplo en Colab."
  },
  {
    "objectID": "tics411/clase-3.html#sugerencias",
    "href": "tics411/clase-3.html#sugerencias",
    "title": "TICS-411 Minería de Datos",
    "section": "Sugerencias",
    "text": "Sugerencias\n\n\n\n\n\n\nPre-procesamientos\n\n\nEs importante recordar que K-Means es un Algoritmo basado en distancias, por lo tanto se ve afectado por Outliers y por Escala.\nSe recomienda preprocesar los datos con:\n\nWinsorizer() para eliminar Outliers.\nStandardScaler() o MinMaxScaler() para llevar a una escala común."
  },
  {
    "objectID": "tics411/clase-3.html#interpretación-clusters",
    "href": "tics411/clase-3.html#interpretación-clusters",
    "title": "TICS-411 Minería de Datos",
    "section": "Interpretación Clusters",
    "text": "Interpretación Clusters\n\n\n\n\n\n\nRecordar, que el clustering no clasifica. Por lo tanto, a pesar de que K-Means nos indica a qué cluster pertenece cierto punto, debemos interpretar cada cluster para entender qué es lo que se agrupó.\n\n\n\n\n\n\n\n\n\nLa interpretación del cluster es principalmente intuición y exploración, por lo tanto el EDA puede ser de utilidad para analizar clusters."
  },
  {
    "objectID": "tics411/clase-3.html#post-procesamiento-merge",
    "href": "tics411/clase-3.html#post-procesamiento-merge",
    "title": "TICS-411 Minería de Datos",
    "section": "Post-Procesamiento: Merge",
    "text": "Post-Procesamiento: Merge\n\nPost-Procesamiento\n\n\nSe define como el tratamiento que podemos realizar al algoritmo luego de haber entregado ya sus predicciones.\n\n\n\nEs posible generar más clusters de los necesarios y luego ir agrupando los más cercanos."
  },
  {
    "objectID": "tics411/clase-3.html#post-procesamiento-merge-1",
    "href": "tics411/clase-3.html#post-procesamiento-merge-1",
    "title": "TICS-411 Minería de Datos",
    "section": "Post-Procesamiento: Merge",
    "text": "Post-Procesamiento: Merge\n\n\n\n\n\n\n\n\n\n\n\n\n¿Cuál es el problema con este caso de Post-Procesamiento?"
  },
  {
    "objectID": "tics411/clase-3.html#post-procesamiento-split",
    "href": "tics411/clase-3.html#post-procesamiento-split",
    "title": "TICS-411 Minería de Datos",
    "section": "Post-Procesamiento: Split",
    "text": "Post-Procesamiento: Split\n\n\n\n\n\n\n\n\n\n\n\nEn Scikit-Learn esto puede conseguirse utilizando el parámetro init. Se entregan los nuevos centroides para forzar a K-Means que separe ciertos clusters."
  },
  {
    "objectID": "tics411/clase-3.html#variantes-k-means",
    "href": "tics411/clase-3.html#variantes-k-means",
    "title": "TICS-411 Minería de Datos",
    "section": "Variantes K-Means",
    "text": "Variantes K-Means\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\[SMD(p_1,p_2) = 4\\]\n\n\n\n\n\n\n\nAcá pueden encontrar una implementación de K-Modes en Python."
  },
  {
    "objectID": "tics411/clase-1.html#avisos-1",
    "href": "tics411/clase-1.html#avisos-1",
    "title": "TICS-411 Minería de Datos",
    "section": "Avisos",
    "text": "Avisos\n\n\n\n\n\n\nAyudantía\n\n\nAvisos\nTenemos (posible) ayudante, pero tenemos un problema de horario.\n\nHorario Actual: Viernes 20:00 a 21:10 hrs.\nHorario Propuesto: Lunes 11:45 a 12:55 hrs.\n\n\n\n\n\n\n\n\n\n\n\n\nTarea 1\n\n\n\nEntrega el 7 de Abril: Parejas inscribirse en Webcursos.\nPlazo para inscribir parejas: Este Domingo.\n\n\n\n\n\n\n\n\n\n\n\n\nFechas de Prueba\n\n\n\nPrueba 1: Martes 30 de Abril 18:30 a 21:00\nPrueba 2: Martes 11 de Julio 18:30 a 21:00"
  },
  {
    "objectID": "tics411/clase-1.html#tipos-de-datos-datos-tabulares",
    "href": "tics411/clase-1.html#tipos-de-datos-datos-tabulares",
    "title": "TICS-411 Minería de Datos",
    "section": "Tipos de Datos: Datos Tabulares",
    "text": "Tipos de Datos: Datos Tabulares\n\n\n\n\n\n\n\n\n\n\n\n\nFilas: Observaciones, registros, instancias. (Normalmente independientes).\nColumnas: Variables, Atributos, Features.\n\n\n\n\n\n\n\n\n\n\n\nProbablemente el tipo de datos más amigable.\nRequiere conocimiento de negocio (Domain Knowledge)\n\n\n\n\n\n\n\n\n\n\n\nEs un % bajísimo del total de datos existentes en el Mundo.\nDistintos tipos, por lo que normalmente requiere de algún tipo de preprocesamiento."
  },
  {
    "objectID": "tics411/clase-1.html#data-types-numéricos",
    "href": "tics411/clase-1.html#data-types-numéricos",
    "title": "TICS-411 Minería de Datos",
    "section": "Data Types: Numéricos",
    "text": "Data Types: Numéricos\n\nNuméricos\n\n\nValores a los que se les puede aplicar alguna operación matemática.\n\n\n\n\n\n\n\n\n\n\nDiscretas: Número finito o contable de valores. Integers (Enteros). Ej: Número de Hijos, Cantidad de Productos, Edad.\nContinuas: Existen infinitos puntos entre dos puntos. Floats (punto flotando o decimales). Ej. Temperatura, Peso."
  },
  {
    "objectID": "tics411/clase-1.html#data-types-categóricos",
    "href": "tics411/clase-1.html#data-types-categóricos",
    "title": "TICS-411 Minería de Datos",
    "section": "Data Types: Categóricos",
    "text": "Data Types: Categóricos\n\nCategóricos\n\n\nDatos que representan una categoría.\n\n\n\n\n\n\n\n\n\n\nNominales: Sólo nombres que no representan ningún orden. Ej: Nacionalidad, género, ocupación.\nOrdinales: Que tienen un orden o jerarquía inherente. Ej: Nivel de Escolaridad, tamaño.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo todas las operaciones matemáticas son aplicables. Ej: Media, Mediana, Sumas, Restas, etc."
  },
  {
    "objectID": "tics411/clase-1.html#data-types-otros",
    "href": "tics411/clase-1.html#data-types-otros",
    "title": "TICS-411 Minería de Datos",
    "section": "Data Types: Otros",
    "text": "Data Types: Otros\n\nStrings\n\n\nDatos de texto, los cuales podrían eventualmente ser tratados y representar algo. Ej: Rescatar comunas de una dirección, rescatar sexo desde el nombre, etc.\n\n\nFechas\n\n\nDatos tipo fecha, los cuales podrían eventualmente ser tratados y representar variables de algún tipo. Ej: Rescatar Años, meses, días, semanas, trimestres (quarters), etc.\n\n\nDatos Geográficos\n\n\nDatos que representan la ubicación geográfica de un elemento. Ej: Latitud, Longitud, Coordenadas.\n\n\n\n\n\n\n\n\n\n\nSin importar el tipo de dato el mayor problema es su calidad."
  },
  {
    "objectID": "tics411/clase-1.html#calidad-de-los-datos-ruido",
    "href": "tics411/clase-1.html#calidad-de-los-datos-ruido",
    "title": "TICS-411 Minería de Datos",
    "section": "Calidad de los Datos: Ruido",
    "text": "Calidad de los Datos: Ruido\n\nRuido\n\nCorresponde al error y extrema variabilidad en la medición en los datos. Este error puede ser aleatorio o sistemático.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSe le llama Señal a la tendencia principal y representa la información significativa y valiosa de los datos."
  },
  {
    "objectID": "tics411/clase-1.html#calidad-de-los-datos-outliers",
    "href": "tics411/clase-1.html#calidad-de-los-datos-outliers",
    "title": "TICS-411 Minería de Datos",
    "section": "Calidad de los Datos: Outliers",
    "text": "Calidad de los Datos: Outliers\n\nOutliers\n\nSon datos considerablemente diferentes a la mayoría del dataset. Dependiendo del caso pueden indicar casos \"interesantes\" o errores de medición.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEs importante notar que dependiendo del caso puede ser una buena idea deshacerse de ellos. ¿En qué casos podría no ser necesario eliminarlos?"
  },
  {
    "objectID": "tics411/clase-1.html#calidad-de-los-datos-valores-faltantes",
    "href": "tics411/clase-1.html#calidad-de-los-datos-valores-faltantes",
    "title": "TICS-411 Minería de Datos",
    "section": "Calidad de los Datos: Valores Faltantes",
    "text": "Calidad de los Datos: Valores Faltantes\n\nMissing Values\n\n\nSon valores que por alguna razón no están presentes.\n\n\n\n\nMissing at Random (MAR): Son valores que no están presentes por causas que no se pueden controlar. Ej: No se registró, no se preguntó, fallas en el sistema de recolección de datos, etc.\nInformative Missing: Es un valor no aplicable. Ej: Sueldo en niños, Precio de la entrada de un concierto si es que NO compró entrada."
  },
  {
    "objectID": "tics411/clase-1.html#calidad-de-los-datos-datos-duplicados",
    "href": "tics411/clase-1.html#calidad-de-los-datos-datos-duplicados",
    "title": "TICS-411 Minería de Datos",
    "section": "Calidad de los Datos: Datos Duplicados",
    "text": "Calidad de los Datos: Datos Duplicados\n\nDuplicates\n\nSe refiere a registros que pueden estar total o parcialmente duplicados.\n\n\n\n\n\n\n\n\n\n\n\n\n\nEsto genera problemas en la confiabilidad de los datos. ¿Cuál es el registro correcto?\nEj: Caso particular de una Jooycar (una startup de seguros)."
  },
  {
    "objectID": "tics411/clase-1.html#calidad-de-los-datos-dominio-del-problema",
    "href": "tics411/clase-1.html#calidad-de-los-datos-dominio-del-problema",
    "title": "TICS-411 Minería de Datos",
    "section": "Calidad de los Datos: Dominio del Problema",
    "text": "Calidad de los Datos: Dominio del Problema\n\n\n\n\n\n\n\n\n\n\n\n\n\nPor lejos el problema de calidad más difícil de encontrar.\nSe requiere experiencia y conocimiento profundo del negocio para detectarlo.\n\nEj: Caso de Super Avances en Cencosud."
  },
  {
    "objectID": "tics411/clase-1.html#feature-engineering-1",
    "href": "tics411/clase-1.html#feature-engineering-1",
    "title": "TICS-411 Minería de Datos",
    "section": "Feature Engineering",
    "text": "Feature Engineering\n\nFeature Engineering\n\n\nTambién conocida como Ingeniería de Atributos, es el arte de trabajar las features existentes para limpiar o corregir variables existentes o crear nuevas variables.\n\n\nPreprocesamiento\n\n\nSe refiere al proceso de preparación de los datos para su ingreso a un modelo. En una primera parte puede incluir limpieza de datos corruptos, redundantes y/o irrelevantes. Por otra parte, también hace referencia a la transformación de datos para que puedan ser consumidos por un algoritmo."
  },
  {
    "objectID": "tics411/clase-1.html#feature-engineering-2",
    "href": "tics411/clase-1.html#feature-engineering-2",
    "title": "TICS-411 Minería de Datos",
    "section": "Feature Engineering",
    "text": "Feature Engineering\n\nNo existe un procedimiento estándar.\nRevisar los datos y ver potenciales errores que puedan afectar el funcionamiento de un modelo."
  },
  {
    "objectID": "tics411/clase-1.html#preprocesamiento-valores-faltantes",
    "href": "tics411/clase-1.html#preprocesamiento-valores-faltantes",
    "title": "TICS-411 Minería de Datos",
    "section": "Preprocesamiento: Valores Faltantes",
    "text": "Preprocesamiento: Valores Faltantes\n\nImputación: Se refiere al proceso de rellenar datos faltantes.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDependiendo del nivel de valores faltantes, es necesario evaluar la eliminación de registros o atributos completos de ser necesario."
  },
  {
    "objectID": "tics411/clase-1.html#preprocesamiento-manejo-de-outliers",
    "href": "tics411/clase-1.html#preprocesamiento-manejo-de-outliers",
    "title": "TICS-411 Minería de Datos",
    "section": "Preprocesamiento: Manejo de Outliers",
    "text": "Preprocesamiento: Manejo de Outliers\n\nCapping\n\nSe refiere al proceso de acotar un atributo eliminando los valores extremos o atípicos (outliers).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAl igual que en el caso anterior, es necesario evaluar la eliminación de registros si es que representan valores atípicos."
  },
  {
    "objectID": "tics411/clase-1.html#preprocesamiento-manejo-de-variables-categóricas",
    "href": "tics411/clase-1.html#preprocesamiento-manejo-de-variables-categóricas",
    "title": "TICS-411 Minería de Datos",
    "section": "Preprocesamiento: Manejo de Variables Categóricas",
    "text": "Preprocesamiento: Manejo de Variables Categóricas\n\nLa mayoría de los modelos no tienen la capacidad de poder lidiar con variables categóricas por lo que deben ser transformadas en una representación numérica antes de ingresar a un modelo.\n\n\n\n\n\n\nOne Hot Encoder\n\n\n\n\n\n\nOrdinal Encoder\n\n\n\n\n\n\n\n\n\n\n\nOne Hot Encoder suele dar mejores resultados en modelos lineales modelos que dependan de distancias.\nOrdinal Encoder suele dar mejores resultados en modelos de árbol.\n\n\n\n\n\n\n¿Son necesarias todas las columnas en un One Hot Encoder?"
  },
  {
    "objectID": "tics411/clase-1.html#preprocesamiento-escalamiento",
    "href": "tics411/clase-1.html#preprocesamiento-escalamiento",
    "title": "TICS-411 Minería de Datos",
    "section": "Preprocesamiento: Escalamiento",
    "text": "Preprocesamiento: Escalamiento\n\nEl escalamiento se refiere al proceso de llevar distintas variables a una misma escala.\n\n\n\n\n\n\n\n\n\nEvitar que la escala de una “sobre-importancia” a una cierta variable.\nPermitir una mejor convergencia de los algoritmos.\n\n\nStandardScaler (Normalización)\n\\[x_j=\\frac{x_j-\\mu_x}{\\sigma_x}\\]\n\n\n\n\n\n\n\nEste proceso fuerza (en la medida de lo posible) a tener media 0 y std 1.\nNotar que \\(\\sigma_x\\) hace referencia a la varianza poblacional.\n\n\n\n\nMinMax Scaler\n\\[x_j=\\frac{x_j-min(x_j)}{max(x_j)-min(x_j)}\\]\n\n\n\n\n\n\nEste proceso fuerza a los datos a distribuirse entre 0 y 1."
  },
  {
    "objectID": "tics411/clase-1.html#preprocesamiento-escalamiento-1",
    "href": "tics411/clase-1.html#preprocesamiento-escalamiento-1",
    "title": "TICS-411 Minería de Datos",
    "section": "Preprocesamiento: Escalamiento",
    "text": "Preprocesamiento: Escalamiento\n\n\n\n\n\n\n\n\n\n\n\n\n\nMedia: 0.75\nStd: 3.1875\nMin: -2\nMax: 3\n\n\n\n\n\n\n\n\n\n\n\n\n\nCentering (Centrado): Se le llama a la diferencia entre la variable y su media.\nScaling (Escalado): Se le llama al cuociente entre la variable y su Desviación Estándar.\nStandardScaler (Normalización): Es Centrado y Escalado."
  },
  {
    "objectID": "tics411/clase-1.html#creación-de-variables",
    "href": "tics411/clase-1.html#creación-de-variables",
    "title": "TICS-411 Minería de Datos",
    "section": "Creación de Variables",
    "text": "Creación de Variables\n\nCombinación\n\n\nCombinar 2 o más variables. Ej: Calcular el área de un sitio a partir del ancho y largo.\n\n\nTransformación\n\n\nAplicar una operación a una variable. Ej: El logaritmo de las ganancias.\n\n\n\n\n\n\nDiscretización (Binning)\n\n\nGenerar categorías a partir de una variable continua."
  },
  {
    "objectID": "tics411/clase-1.html#creación-de-variables-1",
    "href": "tics411/clase-1.html#creación-de-variables-1",
    "title": "TICS-411 Minería de Datos",
    "section": "Creación de Variables",
    "text": "Creación de Variables\n\nRatios\n\nEs una medida que expresa la relación entre dos cantidades. Ej: Puntos por partido, cantidad de transacciones por mes, etc.\n\nAgregación\n\nAgregar o agrupar información resumida de ciertas variables. Ej: Promedio de tiempo en aprobar un tipo de crédito."
  },
  {
    "objectID": "tics411/clase-1.html#selección-de-variables",
    "href": "tics411/clase-1.html#selección-de-variables",
    "title": "TICS-411 Minería de Datos",
    "section": "Selección de Variables",
    "text": "Selección de Variables\n\nSe refiere al proceso de eliminar variables que pueden ser irrelevantes o poco significativas.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProcesos Manuales.\nProcesos Automáticos:\n\nPCA (Principal Component Analysis).\nRecursive Feature Elimination.\nRecursive Feature Addition.\nEliminación mediante alguna medida.\n\n\n\n\n\n\n\n\n\n\n\n\nObjetivo\n\n\n\nPuede ser una técnica apropiada para combatir la Maldición de la Dimensionalidad (Curse of Dimensionality)."
  },
  {
    "objectID": "tics411/clase-1.html#medidas-1",
    "href": "tics411/clase-1.html#medidas-1",
    "title": "TICS-411 Minería de Datos",
    "section": "Medidas",
    "text": "Medidas\n\nSon métricas que permiten cuantificar la relación existente entre dos o más objetos."
  },
  {
    "objectID": "tics411/clase-1.html#medidas-similaridad",
    "href": "tics411/clase-1.html#medidas-similaridad",
    "title": "TICS-411 Minería de Datos",
    "section": "Medidas: Similaridad",
    "text": "Medidas: Similaridad"
  },
  {
    "objectID": "tics411/clase-1.html#medidas-similaridad-nominal",
    "href": "tics411/clase-1.html#medidas-similaridad-nominal",
    "title": "TICS-411 Minería de Datos",
    "section": "Medidas: Similaridad Nominal",
    "text": "Medidas: Similaridad Nominal\n\n\n\nDisimilaridad: \\[D =\n\\begin{cases}\n0,  & \\text{if $p=q$} \\\\[2ex]\n1, & \\text{if $p\\neq q$}\n\\end{cases}\n\\]\n\n\n\nSimilaridad:\n\\[S =\n\\begin{cases}\n1,  & \\text{if $p=q$} \\\\[2ex]\n0, & \\text{if $p\\neq q$}\n\\end{cases}\n\\]\n\n\n\n\n\n\n\n\n\n\n\n\\[S(p,q) = 0\\] \\[D(p,q) = 1\\]"
  },
  {
    "objectID": "tics411/clase-1.html#medidas-similaridad-ordinal",
    "href": "tics411/clase-1.html#medidas-similaridad-ordinal",
    "title": "TICS-411 Minería de Datos",
    "section": "Medidas: Similaridad Ordinal",
    "text": "Medidas: Similaridad Ordinal\n\n\n\nDisimilaridad: \\[D = \\frac{|p-q|}{n}\\]\n\n\n\nSimilaridad:\n\\[S = 1 - \\frac{|p-q|}{n}\\]\n\n\n\n\n\n\n\n\n\n\n\\[S(p,q) = 1 - \\frac{5 - 4}{5} = 0.8\\]"
  },
  {
    "objectID": "tics411/clase-1.html#medidas-similaridad-intervalo-o-ratio",
    "href": "tics411/clase-1.html#medidas-similaridad-intervalo-o-ratio",
    "title": "TICS-411 Minería de Datos",
    "section": "Medidas: Similaridad Intervalo o Ratio",
    "text": "Medidas: Similaridad Intervalo o Ratio\n\n\n\nDisimilaridad: \\[D = |p-q|\\]\n\n\n\nSimilaridad:\n\\[S = -D\\] \\[S = \\frac{1}{1+D}\\]\n\n\n\nSea \\(p=35 °C\\) y \\(q = 40 °C\\). Luego:\n\\[ S(p,q) = -5\\] \\[S(p,q) = \\frac{1}{1 + 5} = 0.17\\]"
  },
  {
    "objectID": "tics411/clase-1.html#medidas-similaridad-datos-categóricos",
    "href": "tics411/clase-1.html#medidas-similaridad-datos-categóricos",
    "title": "TICS-411 Minería de Datos",
    "section": "Medidas: Similaridad Datos Categóricos",
    "text": "Medidas: Similaridad Datos Categóricos\n\nSea p y q vectores de dimensión \\(m\\) con sólo atributos categóricos. Para calcular la similaridad entre vectores se usa lo siguiente:\n\n\\[Sim(p,q) = \\sum_{i=1}^m S(p_i,q_i)\\]\n\n\n\n\nOverlap: \\[S(p_{a_i}, q_{a_i}) =\n\\begin{cases}\n1,  & \\text{if $p_{a_i} = q_{a_i}$} \\\\[2ex]\n0, & \\text{if $p_i\\neq q_i$}\n\\end{cases}\n\\]\n\n\n\nFrecuencia de Ocurrencia Inversa \\[S(p_i, q_i) = \\frac{1}{p_k(p_i)^2}\\]\n\n\n\nMedida de Goodall\n\n\\[S(p_i, q_i) = 1 - p_k(p_i)^2\\]\n\n\n\n\n\n\n\n\n\\(p_k()\\) se refiere a la probabilidad de ocurrencia del atributo k.\nTodas estas medidas son 0 si \\(p_i \\neq q_i\\)"
  },
  {
    "objectID": "tics411/clase-1.html#medidas-similaridad-datos-categóricos-1",
    "href": "tics411/clase-1.html#medidas-similaridad-datos-categóricos-1",
    "title": "TICS-411 Minería de Datos",
    "section": "Medidas: Similaridad Datos Categóricos",
    "text": "Medidas: Similaridad Datos Categóricos\n\n\n\n\n\nEjercicio Propuesto: ¿Cuánto vale la similaridad entre los siguientes registros?\n\n1-4\n2-5\n7-8"
  },
  {
    "objectID": "tics411/clase-1.html#medidas-similaridad-datos-binarios",
    "href": "tics411/clase-1.html#medidas-similaridad-datos-binarios",
    "title": "TICS-411 Minería de Datos",
    "section": "Medidas: Similaridad Datos Binarios",
    "text": "Medidas: Similaridad Datos Binarios\n\nSea p y q vectores de dimensión \\(m\\) con sólo atributos binarios. Para calcular la similaridad entre vectores se usa lo siguiente:\n\n\n\n\\[SMC = \\frac{M_{00} + M_{11}}{M_{00} + M_{01} + M_{10} + M_{11}}\\]\n\nSimple Matching Coefficient = Número de Coincidencias / Total de Atributos\n\n\n\\[JC = \\frac{M_{11}}{M_{01} + M_{10} + M_{11}}\\]\n\nJaccard Coefficient = Número de Coincidencias 11 / Número de Atributos distintos de Ceros."
  },
  {
    "objectID": "tics411/clase-1.html#medidas-similaridad-datos-binarios-1",
    "href": "tics411/clase-1.html#medidas-similaridad-datos-binarios-1",
    "title": "TICS-411 Minería de Datos",
    "section": "Medidas: Similaridad Datos Binarios",
    "text": "Medidas: Similaridad Datos Binarios\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nname\n\\(a_1\\)\n\\(a_2\\)\n\\(a_3\\)\n\\(a_4\\)\n\\(a_5\\)\n\\(a_6\\)\n\\(a_7\\)\n\\(a_8\\)\n\\(a_9\\)\n\\(a_{10}\\)\n\n\n\n\np_i\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\nq_i\n0\n0\n0\n0\n0\n0\n1\n0\n0\n1\n\n\n\n\n\n\n\\[SMC = \\frac{M_{00} + M_{11}}{M_{00} + M_{01} + M_{10} + M_{11}} = \\] \\[JC = \\frac{M_{11}}{M_{01} + M_{10} + M_{11}} = \\]\n\n\n\\[\\frac{7 + 0}{7 + 2 + 1 + 0} = 0.7\\]\n\n\n\\[\\frac{0}{2 + 1 + 0} = 0\\]"
  },
  {
    "objectID": "tics411/clase-1.html#medidas-similaridad-distancia-coseno",
    "href": "tics411/clase-1.html#medidas-similaridad-distancia-coseno",
    "title": "TICS-411 Minería de Datos",
    "section": "Medidas: Similaridad (Distancia Coseno)",
    "text": "Medidas: Similaridad (Distancia Coseno)\n\nSean \\(d_1\\) y \\(d_2\\) dos vectores. La distancia coseno se calcula como:\n\n\\[cos(d_1, d_2) = \\frac{d_1 \\cdot d_2}{||d_1||||d_2||}\\]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nname\n\\(a_1\\)\n\\(a_2\\)\n\\(a_3\\)\n\\(a_4\\)\n\\(a_5\\)\n\\(a_6\\)\n\\(a_7\\)\n\\(a_8\\)\n\\(a_9\\)\n\\(a_{10}\\)\n\n\n\n\nd_1\n3\n2\n0\n5\n0\n0\n0\n2\n0\n0\n\n\nd_2\n1\n0\n0\n0\n0\n0\n1\n1\n0\n2\n\n\nd_3\n6\n4\n0\n10\n0\n0\n0\n4\n0\n0\n\n\n\nEjercicio Propuesto: ¿Cuánto vale \\(cos(d_1,d_2)\\) y \\(cos(d_1,d_3)\\)?"
  },
  {
    "objectID": "tics411/clase-1.html#distancias-1",
    "href": "tics411/clase-1.html#distancias-1",
    "title": "TICS-411 Minería de Datos",
    "section": "Distancias",
    "text": "Distancias\n\nUna métrica o función de distancia es una función que define una distancia para cada par de elementos de un conjunto. Sean dos puntos x e y, una métrica o función de distancia debe satisfacer las siguientes condiciones:\n\n\nNo Negatividad:\n\n\\(d(x,y) = \\ge 0\\)\n\nIdentidad:\n\n\\(d(x,y) = 0 \\Leftrightarrow x = y\\)\n\nSimetría:\n\n\\(d(x,y) = d(y,x)\\)\n\nDesigualdad Triangular:\n\n\\(d(x,z) \\le d(x,y) + d(y,z)\\)"
  },
  {
    "objectID": "tics411/clase-1.html#distancias-distancia-minkowski",
    "href": "tics411/clase-1.html#distancias-distancia-minkowski",
    "title": "TICS-411 Minería de Datos",
    "section": "Distancias: Distancia Minkowski",
    "text": "Distancias: Distancia Minkowski\n\\[d(p,q) = \\left(\\sum_{k=1}^m |p_k - q_k|^r\\right)^{1/r}\\]\n\n\n\n\n\n\n\n\n\n\\(r=1 \\rightarrow\\) Distancia Manhattan (L1).\n\\(r=2 \\rightarrow\\) Distancia Euclideana (L2).\n\\(r=\\infty \\rightarrow\\) Distancia Chebyshev (L\\(\\infty\\)). \\[D_{ch}(p,q) = \\underset{k}{max} |p_k - q_k|\\]\n\n\n\n\n\n\n\nResolvamos en Colab\n\n\n\n\n\n\n\n\n\n\n\nSe denomina Matriz de Distancias a la Matriz que contiene la distancia \\(d(p_i,p_j)\\) en la coordenada \\(i,j\\)."
  },
  {
    "objectID": "tics411/clase-1.html#distancias-distancia-minkowski-resultados",
    "href": "tics411/clase-1.html#distancias-distancia-minkowski-resultados",
    "title": "TICS-411 Minería de Datos",
    "section": "Distancias: Distancia Minkowski (Resultados)",
    "text": "Distancias: Distancia Minkowski (Resultados)"
  },
  {
    "objectID": "tics411/clase-1.html#ayudantías",
    "href": "tics411/clase-1.html#ayudantías",
    "title": "TICS-411 Minería de Datos",
    "section": "Ayudantías",
    "text": "Ayudantías\nAyudante: Sofía Alvarez\nemail: sofalvarez@alumnos.uai.cl\n\n\n\n\n\n\n\nLas ayudantías serán en la manera que sean necesarias.\nEstarán enfocadas principalmente en aplicaciones, código y dudas sobre Tarea."
  },
  {
    "objectID": "tics411/clase-1.html#distancias-distancia-mahalanobis",
    "href": "tics411/clase-1.html#distancias-distancia-mahalanobis",
    "title": "TICS-411 Minería de Datos",
    "section": "Distancias: Distancia Mahalanobis",
    "text": "Distancias: Distancia Mahalanobis\n\\[d(p,q) = \\sqrt{(p-q)^T \\Sigma^{-1}(p-q)}\\]\ndonde \\(\\Sigma\\) es la Matriz de Covarianza de los datos de entrada.\n\\[cov(x,y) = \\frac{1}{n-1}\\sum_{i = 1}^n (x_i - \\bar{x})(y_i - \\bar{y})\\]\n\nPara 2 variables p y q:\n\n\\[\\Sigma = \\begin{bmatrix}\ncov(p,p) & cov(p,q) \\\\\ncov(q,p) & cov(q,q)\n\\end{bmatrix}\n\\]\nEjercicio: Supongamos las siguientes escalas de notas. Calcular la distancia entre la nota (1.0 y 7.0)\n\ntest #1: 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0, 5.5, 6.0, 6.5, 7.0\ntest #2: 1.0, 3.5, 3.6, 3.7, 3.8, 3.9, 4.0, 4.1, 4.2, 4.3, 4.4, 4.5, 7.0"
  },
  {
    "objectID": "tics411/clase-1.html#distancias-distancia-mahalanobis-resultados",
    "href": "tics411/clase-1.html#distancias-distancia-mahalanobis-resultados",
    "title": "TICS-411 Minería de Datos",
    "section": "Distancias: Distancia Mahalanobis (Resultados)",
    "text": "Distancias: Distancia Mahalanobis (Resultados)\n\n\n\n\n\n\ntest #1: \\(d(7.0,1.0) = \\sqrt{(7-1)\\frac{1}{3.79}(7-1)} = 3.08\\)\ntest #2: \\(d(7.0,1.0) = \\sqrt{(7-1)\\frac{1}{1.59}(7-1)} = 4.76\\)\n\n\n\n\n\n\n\n\n\n\nEs importante notar que la covarianza existente entre los datos influye en la distancia."
  },
  {
    "objectID": "tics411/clase-1.html#correlación-1",
    "href": "tics411/clase-1.html#correlación-1",
    "title": "TICS-411 Minería de Datos",
    "section": "Correlación",
    "text": "Correlación\n\nLa correlación mide la relación lineal entre 2 atributos.\n\n\n\n\nCorrelación Poblacional\n\n\\[\\rho(X,Y) = corr(X,Y) = \\frac{cov(X,Y)}{\\sigma_X\\sigma_Y}\\]\n\n\n\n\nCorrelación Muestral o Pearson\n\n\\[r(X,Y) = \\frac{\\sum_{i=1}^n (x_i - \\bar{x})(y_i-\\bar{y})}{S_xS_y}\\]"
  },
  {
    "objectID": "tics411/clase-1.html#correlación-no-es-causalidad",
    "href": "tics411/clase-1.html#correlación-no-es-causalidad",
    "title": "TICS-411 Minería de Datos",
    "section": "Correlación no es Causalidad",
    "text": "Correlación no es Causalidad\n\n\n\n\n\n\n\n\n\n\n\n\nEs importante recalcar que Causalidad no es igual a Correlación. Ver video.\nLa Correlación no se ve afectada por la escala de los datos."
  },
  {
    "objectID": "tics411/clase-1.html#medidas-similaridad-datos-categóricos-2",
    "href": "tics411/clase-1.html#medidas-similaridad-datos-categóricos-2",
    "title": "TICS-411 Minería de Datos",
    "section": "Medidas: Similaridad Datos Categóricos",
    "text": "Medidas: Similaridad Datos Categóricos"
  },
  {
    "objectID": "tics411/clase-1.html#medidas-similaridad-distancia-coseno-1",
    "href": "tics411/clase-1.html#medidas-similaridad-distancia-coseno-1",
    "title": "TICS-411 Minería de Datos",
    "section": "Medidas: Similaridad (Distancia Coseno)",
    "text": "Medidas: Similaridad (Distancia Coseno)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nname\n\\(a_1\\)\n\\(a_2\\)\n\\(a_3\\)\n\\(a_4\\)\n\\(a_5\\)\n\\(a_6\\)\n\\(a_7\\)\n\\(a_8\\)\n\\(a_9\\)\n\\(a_{10}\\)\n\n\n\n\nd_1\n3\n2\n0\n5\n0\n0\n0\n2\n0\n0\n\n\nd_2\n1\n0\n0\n0\n0\n0\n1\n1\n0\n2\n\n\nd_3\n6\n4\n0\n10\n0\n0\n0\n4\n0\n0\n\n\n\n\\[d_1 \\cdot d_2 = 5\\] \\[d_1 \\cdot d_3 = 84\\]\n\\[||d_1|| = \\sqrt{42} = 6.481\\] \\[||d_2|| = \\sqrt{6} = 2.449\\] \\[||d_3|| = \\sqrt{168} = 12.962\\]\n\\[cos(d_1, d_2) = 0.3150\\] \\[cos(d_1, d_3) = 0.9999\\]"
  },
  {
    "objectID": "tics411/clase-12.html#intuición",
    "href": "tics411/clase-12.html#intuición",
    "title": "TICS-411 Minería de Datos",
    "section": "Intuición",
    "text": "Intuición\nSupongamos el siguiente dataset:\n\n\n\n\n\n\n\n\n\n\n\n¿Cómo puedo separar ambas clases?"
  },
  {
    "objectID": "tics411/clase-12.html#intuición-1",
    "href": "tics411/clase-12.html#intuición-1",
    "title": "TICS-411 Minería de Datos",
    "section": "Intuición",
    "text": "Intuición"
  },
  {
    "objectID": "tics411/clase-12.html#intuición-2",
    "href": "tics411/clase-12.html#intuición-2",
    "title": "TICS-411 Minería de Datos",
    "section": "Intuición",
    "text": "Intuición\n\n\n\n\n\n\n\n\n\n\n\n\nLa frontera de decisión se puede caracterizar como la ecuación de una recta (en forma general).\n\n\n\n\n\n\n\n\n\n\n\nAdemás definiremos \\(h_\\theta(X) = \\theta_0 + \\theta_1 X_1 + \\theta_2 X_2\\)."
  },
  {
    "objectID": "tics411/clase-12.html#intuición-3",
    "href": "tics411/clase-12.html#intuición-3",
    "title": "TICS-411 Minería de Datos",
    "section": "Intuición",
    "text": "Intuición\n\n\n\n\n\n\n\n\n\n\n\nPodríamos pensar que si \\(h_\\theta(X)\\) es positivo entonces pertenece a la clase 1 y si \\(h_\\theta(X)\\) es negativo pertenece a la clase 0."
  },
  {
    "objectID": "tics411/clase-12.html#la-función-sigmoide-o-logística",
    "href": "tics411/clase-12.html#la-función-sigmoide-o-logística",
    "title": "TICS-411 Minería de Datos",
    "section": "La Función Sigmoide o Logística",
    "text": "La Función Sigmoide o Logística\n\\[ g(z) = \\frac{1}{1 + e^{-z}}\\]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFunción no lineal.\nFunción acotada entre 0 y 1.\n\\(g(\\varepsilon) = 0.5\\), \\(\\varepsilon = 0\\)\n\n\n\n\n\n\n\n\n\n\n\nDe acá sale la noción del umbral 0.5 que hemos visto en clases anteriores.\n\n\n\n\n\n\n\n\n\n\n\n¿Qué pasaría si ahora decimos que \\(z = \\theta_0 + \\theta_1 X_1 + \\theta_2 X_2\\)?"
  },
  {
    "objectID": "tics411/clase-12.html#la-regresión-logística",
    "href": "tics411/clase-12.html#la-regresión-logística",
    "title": "TICS-411 Minería de Datos",
    "section": "La Regresión Logística",
    "text": "La Regresión Logística\n\\[P[y = 1|X, \\theta] = g(\\theta_0 + \\theta_1 X_1 + \\theta_2 X_2) = \\frac{1}{1 + e^{-(\\theta_0 + \\theta_1 X_1 + \\theta_2 X_2)}}\\]\n\n\n\n\n\n\n\nRegla de Decisión:\n\n\n\nSi \\(g(z) \\ge 0.5 \\implies Clase \\, 1\\).\nSi \\(g(z) &lt; 0.5 \\implies Clase \\, 0\\).\n\n\n\n\n\n\n\n\n\n\n\n\n\\(g(z)\\) se puede interpretar como una probabilidad de pertenecer a la Clase 1.\n\n\n\n\n\n\n\n\n\n\n\n\\(1 -g(z)\\) se puede interpretar como una probabilidad de NO pertenecer a la Clase 1, es decir, pertenecer a la Clase 0."
  },
  {
    "objectID": "tics411/clase-12.html#aprendizaje-del-modelo",
    "href": "tics411/clase-12.html#aprendizaje-del-modelo",
    "title": "TICS-411 Minería de Datos",
    "section": "Aprendizaje del Modelo",
    "text": "Aprendizaje del Modelo\nSupongamos lo siguiente:\n\n\n\\[P(y = 1| X, \\theta) = g(z)\\]\n\n\\[P(y = 0| X, \\theta) = 1-g(z)\\]\n\nAmbas ecuaciones pueden comprimirse en una sola de la siguiente manera: \\[ P(y|X,\\theta) = g(z)^y (1 - g(z))^{1-y}\\]\n\n\n\n\n\n\nPara encontrar los parámetros \\(\\theta\\) podemos utilizar una técnica llamada Maximum Likelihood Estimation."
  },
  {
    "objectID": "tics411/clase-12.html#maximum-likelihood-estimation",
    "href": "tics411/clase-12.html#maximum-likelihood-estimation",
    "title": "TICS-411 Minería de Datos",
    "section": "Maximum Likelihood Estimation",
    "text": "Maximum Likelihood Estimation\n\\[\\mathcal{L}(\\theta) = \\prod_{i=1}^n P(y^{(i)} | x^{(i)}, \\theta)\\]\n\\[ \\underset{\\theta}{argmin} \\ -l(\\theta)\\] \\[l(\\theta) = log (\\mathcal{L(\\theta)}) = \\sum_{i=1}^n y^{(i)} \\cdot log(g(z)) + (1-y^{(i)})\\cdot log(1-g(z))\\]\n\n\n\n\n\n\nEsta ecuación se conoce como Entropía Cruzada o como Negative Log Loss (NLL) y tiene la gracia de que es una curva convexa lo que garantiza un valor único de los parámetros \\(\\theta\\)."
  },
  {
    "objectID": "tics411/clase-12.html#cálculo-de-coeficientes",
    "href": "tics411/clase-12.html#cálculo-de-coeficientes",
    "title": "TICS-411 Minería de Datos",
    "section": "Cálculo de Coeficientes",
    "text": "Cálculo de Coeficientes\n\n\n\n\n\n\nLa técnica más famosa para minimizar este tipo de problemas se conoce como Stochastic Gradient Descent. Lo que genera la siguiente solución:\n\n\n\n\\[\\theta_j \\leftarrow \\theta_j - \\alpha \\frac{1}{n}\\sum_{i=1}^n\\left(g(z)-y^{(i)}\\right)x_j^{(i)}\\]\n\n\n\n\n\n\nA pesar de lo complicado que se ve la ecuación, implementarla en código es bastante sencillo."
  },
  {
    "objectID": "tics411/clase-12.html#frontera-de-decisión",
    "href": "tics411/clase-12.html#frontera-de-decisión",
    "title": "TICS-411 Minería de Datos",
    "section": "Frontera de Decisión",
    "text": "Frontera de Decisión"
  },
  {
    "objectID": "tics411/clase-12.html#inference-time",
    "href": "tics411/clase-12.html#inference-time",
    "title": "TICS-411 Minería de Datos",
    "section": "Inference Time",
    "text": "Inference Time\nEn este caso se calcula: \\[g_\\theta(x^{(i)})=sigmoid(\\theta^t x^{(i)})\\]\n\n\\(\\theta\\): Corresponde a un vector con todos los parámetros calculados.\n\\(x^{(i)}\\): Corresponde a una instancia de \\(m\\) variables la cual generará una probabilidad.\n\n\\(\\theta^t x^{(i)}\\) corresponde al producto punto de dos vectores, que es equivalente a una “suma producto”.\n\n\\(g_\\theta(x^{(i)})\\): Generará un valor entre 0 y 1 al cuál se le aplica la Regla de Decisión."
  },
  {
    "objectID": "tics411/clase-12.html#implementación-en-python",
    "href": "tics411/clase-12.html#implementación-en-python",
    "title": "TICS-411 Minería de Datos",
    "section": "Implementación en Python",
    "text": "Implementación en Python\nfrom sklearn.linear_model import LogisticRegression\n\nlr = LogisticRegression(C=1, penalty=\"l2\", random_state = 42)\nlr.fit(X_train, y_train)\n\ny_pred = lr.predict(X_test)\ny_proba = lr.predict_proba(X_test)\n\n## Visualizacion de los Parámetros \nlr.coef_\nlr.intercept_\n\n\nC: Corresponde a un parámetro de Regularización. Valores más pequeños implica mayor regularización. Por defecto 1.\npenalty: Corresponde al tipo de regularización. Por defecto “l2”.\n\n“l1”: Corresponde a la regularización Lasso. Genera que hayan parámetros cero, ayudando en la selección de variables.\n“l2”: Corresponde a la regularización Ridge. Genera que todos los parámetros sean pequeños, entregando estabilidad y buena interpretabilidad.\n“elasticnet”: Corresponde a la combinación de “l1” y “l2”.\nNone: No hay regularización.\n\n\n\n\n\n\n\n\n\nPara cambiar la regularización, consultar la documentación de Scikit-Learn."
  },
  {
    "objectID": "tics411/clase-12.html#interpretabilidad",
    "href": "tics411/clase-12.html#interpretabilidad",
    "title": "TICS-411 Minería de Datos",
    "section": "Interpretabilidad",
    "text": "Interpretabilidad\n\nUna de las grandes ventajas que tiene la Regresión Logística es que sus predicciones son interpretables.\n\n\nTenemos un dataset de 2 variables:\n\nW: Corresponde al peso del Vehículo.\nqsec: Corresponde al tiempo en Segundos que lo toma en recorrer un cuarto de milla.\n\nQueremos predecir si el vehículo es Ecónomico o no (en términos de consumo de Bencina).\n\n\\[g_\\theta(x) = 0.5 - 3.5 \\cdot W + 1.5 \\cdot qsec \\]\n\n\n\n\n\n\n\n\nSi el vehículo se demora más en el cuarto de milla (qsec aumenta) entonces el vehículo es más económico.\n\nTiene menos potencia.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSi el vehículo es más pesado (W aumenta), entonces es menos económico.\n\nRequiere probablemente más combustible para mover dicho peso.\n\n\n\n\n\n\n\n\n\n\n\n\n\nEl valor del parámetro representa también la magnitud de la contribución."
  },
  {
    "objectID": "tics411/clase-12.html#sugerencias",
    "href": "tics411/clase-12.html#sugerencias",
    "title": "TICS-411 Minería de Datos",
    "section": "Sugerencias",
    "text": "Sugerencias\n\n\n\n\n\n\n\nEstandarización/Normalización de datos: Permite que la escala de los datos no afecte en la interpretabilidad.\nOne Hot Encoder: En general tiende a dar mejores resultados que el Ordinal.\nInteracciones: Combinación de variables.\nVariables no Lineales: Permite que la frontera de Decisión no sea necesariamente lineal (Regresión Polinómica)."
  },
  {
    "objectID": "tics411/clase-8.html#introducción-al-aprendizaje-supervisado",
    "href": "tics411/clase-8.html#introducción-al-aprendizaje-supervisado",
    "title": "TICS-411 Minería de Datos",
    "section": "Introducción al Aprendizaje Supervisado",
    "text": "Introducción al Aprendizaje Supervisado\nLos modelos Predictivos/Supervisados tienen la capacidad de predecir valores en datos no vistos.\n\nChip Huyen, Designing ML Systems (Profesora de Stanford)\n\n\n“Machine Learning Algorithms do not predict the future but encode the past, thus perpetuating the biases in the data and mode…”\n\n\n\nAprenden mediante un proceso de entrenamiento en un train set y evalúan su performance/rendimiento utilizando un test set."
  },
  {
    "objectID": "tics411/clase-8.html#definiciones",
    "href": "tics411/clase-8.html#definiciones",
    "title": "TICS-411 Minería de Datos",
    "section": "Definiciones",
    "text": "Definiciones\n\nFeatures\n\n\nTambién llamadas variables o atributos. Corresponden al input del Modelo y con el cuál el modelo aprende y predice. Normalmente es representado mediante una Matriz denominada \\(X\\).\n\n\nLabels o Etiquetas\n\n\nCorresponden a las respuestas que el modelo necesita mapear para poder descubrir patrones de manera automática. Normalmente se representa mediante un vector denominado \\(y\\)."
  },
  {
    "objectID": "tics411/clase-8.html#ejemplo",
    "href": "tics411/clase-8.html#ejemplo",
    "title": "TICS-411 Minería de Datos",
    "section": "Ejemplo",
    "text": "Ejemplo\n\nQueremos generar un algoritmo de aprendizaje tal que dado un cierto set de datos predigamos si es que a un niño se le dará o no permiso para jugar.\n\n\n\n\n\n\n\nProblema de Clasificación Binaria (Dos clases opuestas)."
  },
  {
    "objectID": "tics411/clase-8.html#definición-del-problema",
    "href": "tics411/clase-8.html#definición-del-problema",
    "title": "TICS-411 Minería de Datos",
    "section": "Definición del Problema",
    "text": "Definición del Problema\n\\[h_\\theta(X) = f(X, \\theta)\\]\n\n\n\n\n\n\n\nA \\(h_\\theta(\\cdot)\\) la denominaremos hipótesis o simplemente modelo.\n\\(X\\) será nuestro set de features (\\(n\\times m\\) donde \\(n\\) es el número de observaciones y \\(m\\) el número de features).\n\nCada fila de \\(X\\) corresponde a un vector \\(x_i\\) que representa una observación de nuestro set de features.\n\\(\\theta\\) corresponde a los parámetros del modelo (existen modelos paramétricos y no paramétricos).\nCada algoritmo tendrá su propio mapeo \\(f(\\cdot)\\) para tratar de predecir una etiqueta.\n\n\n\n\n\n\n\n\n\n\nTipos de Hipótesis\n\n\n\nSi \\(h_\\theta(X)\\) devuelve valores discretos (o categóricos) hablaremos de un modelo de Clasificación.\nSi \\(h_\\theta(X)\\) devuelve valores continuos hablaremos de un modelo de Regresión."
  },
  {
    "objectID": "tics411/clase-8.html#tipos-de-problemas",
    "href": "tics411/clase-8.html#tipos-de-problemas",
    "title": "TICS-411 Minería de Datos",
    "section": "Tipos de Problemas",
    "text": "Tipos de Problemas\n\n\n\n\n\n\nClasificación:\n\n\n\nBinaria: La Clasificación es dicotómica, Perro o Gato, Sí o No, 1 o 0, Clase Positiva o Negativa.\nMulticlase: La clasificación puede tener más de 2 clases, pero sólo una es posible.\n\nEj: Perro, Gato o Canario; 0, 1, 2, 3, 4.\n\nMultilabel: La clasificación puede tener más de 2 clases, y más de una es posible a la vez.\n\nEj: Categorías de Libro: Puede ser Romance y Drama, Películas: Fantasía, Animación y Acción.\n\n\n\n\n\n\n\n\n\n\n\nRegresión:\n\n\n\nSimple: Predigo sólo un valor. Ej: Predecir la Temperatura.\nMultiple: Predigo varios valores continuos a la vez.\n\nEj: Modelo para intentar estimar Temperatura y Humedad a la vez.\n\nForecast: Donde se utilizan valores pasados para estimar valores futuros.\n\nDadas mis ganancias pasadas, estimar las futuras."
  },
  {
    "objectID": "tics411/clase-8.html#clasificación-intuición",
    "href": "tics411/clase-8.html#clasificación-intuición",
    "title": "TICS-411 Minería de Datos",
    "section": "Clasificación: Intuición",
    "text": "Clasificación: Intuición\n\n\n\n\n\n\nSupongamos el siguiente problema de clasificación. Tenemos un algoritmo, que dadas las variables Largo y Peso sean capaces de predecir si es que un Pez es una Reineta o una Sardina."
  },
  {
    "objectID": "tics411/clase-8.html#clasificación-intuición-1",
    "href": "tics411/clase-8.html#clasificación-intuición-1",
    "title": "TICS-411 Minería de Datos",
    "section": "Clasificación: Intuición",
    "text": "Clasificación: Intuición\n\n\n\n\n\n\n\n\n\n\n\n\nQueremos encontrar una Regla de Decisión (Decision Rule) que permita clasificar correctamente un punto nuevo.\nDistintos modelos son capaces de encontrar distintas reglas de decisión. Por lo tanto, sus predicciones pueden ser completamente distintas."
  },
  {
    "objectID": "tics411/clase-8.html#clasificación-detalles",
    "href": "tics411/clase-8.html#clasificación-detalles",
    "title": "TICS-411 Minería de Datos",
    "section": "Clasificación: Detalles",
    "text": "Clasificación: Detalles\nEs importante mencionar que un modelo de clasificación puede generar:\n\nHard Predictions: Es decir, la instancia a predecir es clase 0 o clase 1.\nSoft Prediction: Es decir, la instancia a predecir tiene una probabilidad \\(p\\) de pertenecer a la clase 1 y de \\(1-p\\) de pertenecer a la clase 0.\n\n\n\n\n\n\n\n\nCuando se hace predicción binaria, lo común es usar un Threshold de 0.5 para elegir la clase. Es decir si \\(p&lt;0\\) entonces clase 0, si \\(p \\ge 0.5\\) entonces clase 1.\n\n\n\n\n\n\n\n\n\n\nEn el caso de predicción multiclase o multilabel. Se calcula la probabilidad para cada clase. Por lo tanto se se asigna la clase de mayor probabilidad."
  },
  {
    "objectID": "tics411/clase-8.html#k-nearest-neighbors",
    "href": "tics411/clase-8.html#k-nearest-neighbors",
    "title": "TICS-411 Minería de Datos",
    "section": "K-Nearest Neighbors",
    "text": "K-Nearest Neighbors\n\nEl modelo de vecinos más cercanos, o KNN por sus siglas en Inglés es un modelo basado en distancias. Su regla de decisión se basa en imitar el comportamiento de sus \\(K\\) vecinos más cercanos por votación (para clasificación) o la media (para regresión).\n\n\n\n\n\n\n\nK es un hiperparámetro de este modelo.\n\n\n\n\n\n\n\n\n\n\n\n\nSupongamos \\(K = 3\\).\nEs decir, tomaremos los 3 vecinos más cercanos.\n\n\n\n\n\n\n\nEn general es una buena idea elegir vecinos impares. ¿Por qué?"
  },
  {
    "objectID": "tics411/clase-8.html#knn-paso-1-training-time",
    "href": "tics411/clase-8.html#knn-paso-1-training-time",
    "title": "TICS-411 Minería de Datos",
    "section": "KNN: Paso 1 (Training Time)",
    "text": "KNN: Paso 1 (Training Time)\n\nTraining Time\n\nCorresponde al periodo donde el modelo aprende de los datos. Toma un patrón y ese modelo es utilizado para predecir.\n\n\n\n\n\n\n\n\nEn el caso de un KNN NO HAY APRENDIZAJE en esta etapa.\n\n\n\n\n\n\n\n\n\nEs considerado un modelo no-paramétrico ya que no aprende parámetros para realizar su predicción."
  },
  {
    "objectID": "tics411/clase-8.html#knn-paso-2-test-time",
    "href": "tics411/clase-8.html#knn-paso-2-test-time",
    "title": "TICS-411 Minería de Datos",
    "section": "KNN: Paso 2 (Test Time)",
    "text": "KNN: Paso 2 (Test Time)\n\nInference Time\n\nCorresponde al periodo donde el modelo debe emitir una predicción.\n\n\nEn este caso, KNN calcula las distancias del punto a predecir (en verde) a todos los otros puntos existentes (proceso caro).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLa predicción corresponderá a la etiqueta mayoritaria por votacioń\n\n\n\n\n\n\n\n\nLa predicción corresponderá a la etiqueta mayoritaria por votacioń.\n¿Cuál sería una buena estrategia de predicción para un modelo de Regresión?"
  },
  {
    "objectID": "tics411/clase-8.html#fronteras-de-decisión",
    "href": "tics411/clase-8.html#fronteras-de-decisión",
    "title": "TICS-411 Minería de Datos",
    "section": "Fronteras de Decisión",
    "text": "Fronteras de Decisión\n\n\n\n\n\n\n\n\n\n\n\n\nImplicitamente, todo modelo de Machine Learning generará lo que se llama una Frontera de Decisión.\nSi un punto no visto cae dentro de su frontera entonces se le asigna dicha etiqueta."
  },
  {
    "objectID": "tics411/clase-8.html#implementación-clasificación-en-scikit-learn",
    "href": "tics411/clase-8.html#implementación-clasificación-en-scikit-learn",
    "title": "TICS-411 Minería de Datos",
    "section": "Implementación Clasificación en Scikit-Learn",
    "text": "Implementación Clasificación en Scikit-Learn\nfrom sklearn.neighbors import KNeighborsClassifier\n\nknn_clf = KNeighborsClasifier(n_neighbors = 5, metric=\"minkowski\", p=2, n_jobs=-1)\nknn_clf.fit(X, y)\n\n# Predicción...\ny_pred = knn_clf.predict(X)\n\n\nn_neighbors: \\(K\\) número de vecinos a utilizar. Por defecto 5.\nmetric: Métrica de distancia. Por defecto “Minkowski”.\np: Potencia de Minkowski: \\(p=1\\), Manhattan, \\(p=2\\) Euclideana. Por defecto \\(p=2\\).\nn_jobs: Corresponde a un parámetro interno para poder paralelizar los cálculos. Se recomienda utilizar -1 para utilizar todos sus cores."
  },
  {
    "objectID": "tics411/clase-8.html#implementación-regresión-en-scikit-learn",
    "href": "tics411/clase-8.html#implementación-regresión-en-scikit-learn",
    "title": "TICS-411 Minería de Datos",
    "section": "Implementación Regresión en Scikit-Learn",
    "text": "Implementación Regresión en Scikit-Learn\nfrom sklearn.neighbors import KNeighborsRegressor\n\nknn_clf = KNeighborsRegressor(n_neighbors = 5, metric=\"minkowski\", p=2, n_jobs=-1)\nknn_clf.fit(X, y)\n\n# Predicción...\ny_pred = knn_clf.predict(X)\n\n\nn_neighbors: \\(K\\) número de vecinos a utilizar. Por defecto 5.\nmetric: Métrica de distancia. Por defecto “Minkowski”.\np: Potencia de Minkowski: \\(p=1\\), Manhattan, \\(p=2\\) Euclideana. Por defecto \\(p=2\\).\nn_jobs: Corresponde a un parámetro interno para poder paralelizar los cálculos. Se recomienda utilizar -1 para utilizar todos sus cores.\n\n\n\n\n\n\n\n\n¿Cómo se encuentran las predicciones en un modelo de Regresión?"
  },
  {
    "objectID": "tics411/clase-8.html#knn-detalles-técnicos",
    "href": "tics411/clase-8.html#knn-detalles-técnicos",
    "title": "TICS-411 Minería de Datos",
    "section": "KNN: Detalles Técnicos",
    "text": "KNN: Detalles Técnicos\n\n\n\n\n\n\nFortalezas\n\n\n\nModelo muy simple de implementar y entender.\nMuy eficiente en el aprendizaje.\n\n\n\n\n\n\n\n\n\n\nDebilidades\n\n\n\nInferencia ineficiente: \\(O(mn^2)\\).\nCurse of Dimensionality: A medida que el número de dimensiones del problema crece, se requiere un incremento exponencial en la cantidad de datos para asegurar que existen suficientes vecinos cercanos para cualquier punto."
  },
  {
    "objectID": "tics411/clase-0.html#quién-soy",
    "href": "tics411/clase-0.html#quién-soy",
    "title": "TICS-411 Minería de Datos",
    "section": "¿Quién soy?",
    "text": "¿Quién soy?\n\n\n\n\n\n\n\nAlfonso Tobar-Arancibia, estudié Ingeniería Civil pero llevo 9 años trabajando como:\n\nData Analyst.\nData Scientist.\nML Engineer.\nData Engineer.\n\nTerminando mi Msc. y empezando mi PhD en la UAI.\nMe gusta mucho programar (en vivo).\nContribuyo a HuggingFace y Feature Engine.\nHe ganado 2 competencias de Machine Learning.\nPubliqué mi primer paper el año pasado sobre Hate Speech en Español.\nJuego Tenis de Mesa, hago Agility con mi perrita Kira y escribo en mi Blog."
  },
  {
    "objectID": "tics411/clase-0.html#objetivos-del-curso",
    "href": "tics411/clase-0.html#objetivos-del-curso",
    "title": "TICS-411 Minería de Datos",
    "section": "Objetivos del Curso",
    "text": "Objetivos del Curso\n\n\n\n\n\nIdentificar Elementos Claves del Machine Learning (Terminología, Nomenclatura, Intuición).\nEntender como interactúan los algoritmos más importantes.\nAprender a seleccionar el mejor Algoritmo para el Problema.\nEjecutar y aplicar algoritmos clásicos de Machine Learning.\nEvaluar el desempeño esperado del Modelo."
  },
  {
    "objectID": "tics411/clase-0.html#tópicos",
    "href": "tics411/clase-0.html#tópicos",
    "title": "TICS-411 Minería de Datos",
    "section": "Tópicos",
    "text": "Tópicos\n\n\n\n\n\n\n\nIntroducción a la Minería de Datos\nAnálisis Exploratorio de Datos (EDA)\nModelos No Supervisados/Descriptivos\nModelos Supervisados/Predictivos\n\n\n\n\n\n\nModelos no Supervisados\n\nK-Means\nHierarchical Clustering\nDBScan\nApriori\n\n\nModelos Supervisados\n\nKNN\nÁrboles de Decisión\nNaive Bayes\nRegresión Logística"
  },
  {
    "objectID": "tics411/clase-0.html#sobre-las-clases",
    "href": "tics411/clase-0.html#sobre-las-clases",
    "title": "TICS-411 Minería de Datos",
    "section": "Sobre las clases",
    "text": "Sobre las clases\n\nClases presenciales, con participación activa de los estudiantes.\nEs un curso coordinado.\nCanal oficial será Webcursos.\nMucha terminología y material de estudio será en Inglés.\nHorario: Jueves.\n\n15:30 a 16:40 (Cátedra)\n17:00 a 18:10 (Práctico)\nIdealmente!!\n\nAsistencia es voluntaria, pero altamente recomendada."
  },
  {
    "objectID": "tics411/clase-0.html#materiales-de-clases",
    "href": "tics411/clase-0.html#materiales-de-clases",
    "title": "TICS-411 Minería de Datos",
    "section": "Materiales de Clases",
    "text": "Materiales de Clases\n\nDiapositivas\nPrácticos\n\n\n\n\n\n\n\n\nSlides interactivas (Código se puede copiar e imágenes se pueden ver en grande).\nSe puede buscar contenido en las diapositivas mediante un buscador.\nSe dejarán copias en PDF en Webcursos (levemente distintas).\n\n\n\n\n\n\n\n\n\n\nSe espera que los estudiantes dominen las siguientes tecnologías:\n\nPython\nGoogle Colab\nPandas/Numpy\nScikit-Learn (Se enseñará a lo largo del curso)."
  },
  {
    "objectID": "tics411/clase-0.html#material-complementario",
    "href": "tics411/clase-0.html#material-complementario",
    "title": "TICS-411 Minería de Datos",
    "section": "Material Complementario",
    "text": "Material Complementario\n\n\n\n\n\n\nCurso de Scikit-Learn \n\nTutorial Colab\nAgregar Datos Externos a Colab"
  },
  {
    "objectID": "tics411/clase-0.html#evaluación",
    "href": "tics411/clase-0.html#evaluación",
    "title": "TICS-411 Minería de Datos",
    "section": "Evaluación",
    "text": "Evaluación\n\n\n\n\n\n\n\nDos Evaluaciones Escritas (P1, P2) coordinadas y cuatro tareas prácticas en parejas (T1, T2, T3, T4) \\[NP = 0.35 \\cdot P1 + 0.35 \\cdot P2 + 0.3 \\cdot \\bar{T}\\] \\[ \\bar{T} = (T1 + T2 + T3 + T4)/4 \\]\n\n\n\n\n\n\n\n\n\n\nSi NP &gt; 5\n\n\n\\[NF = NP\\]\n\n\n\n\n\n\n\n\n\nEn caso contrario:\n\n\n\\[NF = 0.7 \\cdot NP + 0.3 \\cdot E\\]"
  },
  {
    "objectID": "tics411/clase-0.html#ayudantías",
    "href": "tics411/clase-0.html#ayudantías",
    "title": "TICS-411 Minería de Datos",
    "section": "Ayudantías",
    "text": "Ayudantías\nAyudante: TBD\nemail: TBD\n\n\n\n\n\n\n\nLas ayudantías serán en la manera que sean necesarias.\nEstarán enfocadas principalmente en aplicaciones y código."
  },
  {
    "objectID": "tics411/clase-0.html#revolución-de-los-datos",
    "href": "tics411/clase-0.html#revolución-de-los-datos",
    "title": "TICS-411 Minería de Datos",
    "section": "Revolución de los Datos",
    "text": "Revolución de los Datos\n\n\n\n\n\n\n\nHablar de los distintos tipos de Datos.\nTodo es datos, y está lleno de ellos en Internet y el mundo."
  },
  {
    "objectID": "tics411/clase-0.html#nace-el-data-science-ciencia-de-datos",
    "href": "tics411/clase-0.html#nace-el-data-science-ciencia-de-datos",
    "title": "TICS-411 Minería de Datos",
    "section": "Nace el Data Science (Ciencia de Datos)",
    "text": "Nace el Data Science (Ciencia de Datos)\n\n\n\n\n\n\n\nExplicar las distintas etapas. Qué son cada uno de ellos.\nExplicar que no estoy de acuerdo con todas las definiciones."
  },
  {
    "objectID": "tics411/clase-0.html#cómo-aprovechar-la-información-que-tenemos",
    "href": "tics411/clase-0.html#cómo-aprovechar-la-información-que-tenemos",
    "title": "TICS-411 Minería de Datos",
    "section": "¿Cómo aprovechar la información que tenemos?",
    "text": "¿Cómo aprovechar la información que tenemos?\n\n\nData Mining (Minería de Datos)\n\n\n“The process of identifying valid, novel, potentially useful, and ultimately understandable patterns in data.” (Fayyad, Piatetsky-Shapiro & Smith 1996)\n\n\n\n\n\n\nMachine Learning (Aprendizaje Automático)\n\n\n“A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P, if its performance at tasks in T, as measured by P, improves with experience E.” (Mitchell, 2006)\n\n\n\n\n\n\nExplicar que estos son dos tipos de Approaches con el que hoy en día se enfrentan los datos.\nEl primero más enfocado en un análisis manual.\nEl segundo en un enfoque más automático."
  },
  {
    "objectID": "tics411/clase-0.html#tipos-de-datos",
    "href": "tics411/clase-0.html#tipos-de-datos",
    "title": "TICS-411 Minería de Datos",
    "section": "Tipos de Datos",
    "text": "Tipos de Datos\n\n\n\n\nDatos Estructurados\n\n\n\n\nDatos No Estructurados"
  },
  {
    "objectID": "tics411/clase-0.html#tipos-de-datos-datos-tabulares",
    "href": "tics411/clase-0.html#tipos-de-datos-datos-tabulares",
    "title": "TICS-411 Minería de Datos",
    "section": "Tipos de Datos: Datos Tabulares",
    "text": "Tipos de Datos: Datos Tabulares\n\n\n\n\n\n\n\n\n\n\n\n\nFilas: Observaciones, instancias, registros. (Normalmente independientes).\nColumnas: Variables, Atributos, Features.\n\n\n\n\n\n\n\n\n\n\n\nProbablemente el tipo de datos más amigable.\nRequiere conocimiento de negocio (Domain Knowledge)\n\n\n\n\n\n\n\n\n\n\n\nEs un % bajísimo del total de datos existentes en el Mundo. También el que más disponible está en las empresas.\nDistintos data types, por lo que normalmente requiere de algún tipo de preprocesamiento."
  },
  {
    "objectID": "tics411/clase-0.html#tipos-de-datos-series-de-tiempo",
    "href": "tics411/clase-0.html#tipos-de-datos-series-de-tiempo",
    "title": "TICS-411 Minería de Datos",
    "section": "Tipos de Datos: Series de Tiempo",
    "text": "Tipos de Datos: Series de Tiempo\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFilas: Instancias temporales (Normalmente interdependientes).\nColumnas: Variables, Atributos, Features (Univariada o Multivariada).\n\n\n\n\n\n\n\n\n\n\n\nEs un % bajísimo del total de datos existentes en el Mundo.\nPropiedad temporal requiere preprocesamiento y modelos especiales."
  },
  {
    "objectID": "tics411/clase-0.html#tipos-de-datos-imágenes",
    "href": "tics411/clase-0.html#tipos-de-datos-imágenes",
    "title": "TICS-411 Minería de Datos",
    "section": "Tipos de Datos: Imágenes",
    "text": "Tipos de Datos: Imágenes\n\n\n\n\n\n\n\n\n\n\n\n\n\nEste es el tipo de Datos que disparó la Inteligencia Artificial.\n¿Cuántos computadores para identificar un Gato? 16,000\n\n\n\n\n\n\n\n\n\n\n\n\nExplicar el concepto de Tensor, extensión de las matrices. Diferencia entre Grayscale y RGB."
  },
  {
    "objectID": "tics411/clase-0.html#tipos-de-datos-texto-libre",
    "href": "tics411/clase-0.html#tipos-de-datos-texto-libre",
    "title": "TICS-411 Minería de Datos",
    "section": "Tipos de Datos: Texto Libre",
    "text": "Tipos de Datos: Texto Libre\n\n\n\n\n\n\n\n\n\n\n\n\nDatos Masivos.\nDificiles de lidiar ya que deben ser llevarse a una representación numérica.\nAlto nivel de Sesgo y Subjetividad.\n\n\n\n\n\n\n\n\n\n\n\nGracias a este tipo de datos se han producido los avances más increíbles del último tiempo: Transformers"
  },
  {
    "objectID": "tics411/clase-0.html#tipos-de-datos-videos",
    "href": "tics411/clase-0.html#tipos-de-datos-videos",
    "title": "TICS-411 Minería de Datos",
    "section": "Tipos de Datos: Videos",
    "text": "Tipos de Datos: Videos\n\n\n\n\n\n\n\n\nLos videos no son más que arreglos de imágenes.\nSon un tipo de dato muy pesado y difícil de lidiar.\nRequiere alto poder de Procesamiento."
  },
  {
    "objectID": "tics411/clase-0.html#tipos-de-aprendizaje",
    "href": "tics411/clase-0.html#tipos-de-aprendizaje",
    "title": "TICS-411 Minería de Datos",
    "section": "Tipos de Aprendizaje",
    "text": "Tipos de Aprendizaje"
  },
  {
    "objectID": "tics411/clase-0.html#reinforcement-learning",
    "href": "tics411/clase-0.html#reinforcement-learning",
    "title": "TICS-411 Minería de Datos",
    "section": "Reinforcement Learning",
    "text": "Reinforcement Learning\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEn este tipo de aprendizaje se enseña por refuerzo. Es decir se da una recompensa si el sistema aprende lo que queremos.\n\n\n\n\n\n\n\n\n\n\n\nSi el premio es mayor, se pueden obtener aprendizajes mayores.\n\n\n\n\n\n\n\n\n\n\n\nUn ejemplo de esto es AlphaTensor en el cual un modelo aprendió una nueva manera de multiplicar matrices que es más eficiente.\n\n\n\n\n\n\n\n\n\n\n\nOtro ejemplo es AlphaFold donde el modelo aprendió/descubrió cómo se doblan las proteínas cuando se vuelven aminoácidos."
  },
  {
    "objectID": "tics411/clase-0.html#problemas-supervisados-regresión-y-clasificación",
    "href": "tics411/clase-0.html#problemas-supervisados-regresión-y-clasificación",
    "title": "TICS-411 Minería de Datos",
    "section": "Problemas Supervisados: Regresión y Clasificación",
    "text": "Problemas Supervisados: Regresión y Clasificación\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRegresión: Se busca estimar un valor continuo.\n\n(Estimar el valor de una casa).\n\nClasificación: Se busca encontrar una categoría o un valor discreto.\n\n(Clasificar una imagen como Perro o Gato).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPara entrenar este tipo de modelos se necesitan etiquetas, es decir, la respuesta esperada del modelo.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAmbos ejemplos se pueden realizar utilizando Largo (Eje Y) y Peso (Eje X)."
  },
  {
    "objectID": "tics411/clase-0.html#clustering",
    "href": "tics411/clase-0.html#clustering",
    "title": "TICS-411 Minería de Datos",
    "section": "Clustering",
    "text": "Clustering\n\n\n\n\n\n\n\n\n\n\n\n\n\nClusters: Una categoría en la que sus componentes son similares. Los clusters normalmente no tienen un nombre propio, sino que uno les asigna uno.\nTambién se les llama segmentos. No usar la palabra clase.\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo requiere de etiquetas, por lo tanto, no es posible evaluar su desempeño de manera 100% acertada."
  },
  {
    "objectID": "tics411/clase-0.html#reducción-de-dimensionalidad",
    "href": "tics411/clase-0.html#reducción-de-dimensionalidad",
    "title": "TICS-411 Minería de Datos",
    "section": "Reducción de Dimensionalidad",
    "text": "Reducción de Dimensionalidad\n\n\n\n\n\n\n\n\n\n\n\n\nReducción de la Dimensionalidad: Eliminar complejidad sin perder información clave para poder entender su comportamiento."
  },
  {
    "objectID": "tics411/clase-0.html#nuestro-sistema-de-ml",
    "href": "tics411/clase-0.html#nuestro-sistema-de-ml",
    "title": "TICS-411 Minería de Datos",
    "section": "Nuestro Sistema de ML",
    "text": "Nuestro Sistema de ML\nCreemos un Sistema de ML que sea capaz de ver una imágen y pronunciar correctamente el uso de la letra C.\n\n\n\n\n\n\nVamos a Entrenar un Modelo."
  },
  {
    "objectID": "tics411/clase-0.html#nuestro-sistema-de-ml-entrenamiento",
    "href": "tics411/clase-0.html#nuestro-sistema-de-ml-entrenamiento",
    "title": "TICS-411 Minería de Datos",
    "section": "Nuestro Sistema de ML: Entrenamiento",
    "text": "Nuestro Sistema de ML: Entrenamiento\n\n\n\n\n\n\nKasa\n\n\n\n\n\n\n\nKokodrilo\n\n\n\n\n\n\n\nKubo\n\n\n\n\n\n\n\n\n\n\n\n\n¿Qué patrones está aprendiendo el modelo?\n\n\n\n\n\nEntrenamiento\n\n\nEs el proceso en el cuál se permite al modelo aprender. En este proceso se le entregan ejemplos (Train Set) para que el modelo de manera autónoma pueda aprender patrones que le permitan resolver la tarea dada."
  },
  {
    "objectID": "tics411/clase-0.html#nuestro-sistema-de-ml-inferencia",
    "href": "tics411/clase-0.html#nuestro-sistema-de-ml-inferencia",
    "title": "TICS-411 Minería de Datos",
    "section": "Nuestro Sistema de ML: Inferencia",
    "text": "Nuestro Sistema de ML: Inferencia\n\nInferencia/Predicción\n\n\nSe refiere al proceso en el que el modelo tiene que demostrar cuál sería su decisión de acuerdo a los patrones aprendidos en el proceso de entrenamiento. Los ejemplos en los que se prueba se le denomina Test Set.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nKollar\n\n\nKonejo\n\n\nKukillo\n\n\nBikikleta\n\n\n\n\n\nGeneralización\n\n\nSe le llama generalización a la capacidad del modelo de aplicar lo aprendido de manera correcta en ejemplos no vistos."
  },
  {
    "objectID": "tics411/clase-0.html#nuestro-sistema-de-ml-nuevas-instancias-de-entrenamiento",
    "href": "tics411/clase-0.html#nuestro-sistema-de-ml-nuevas-instancias-de-entrenamiento",
    "title": "TICS-411 Minería de Datos",
    "section": "Nuestro Sistema de ML: Nuevas instancias de Entrenamiento",
    "text": "Nuestro Sistema de ML: Nuevas instancias de Entrenamiento\n\n\n\n\n\n\nKuchillo\n\n\n\n\n\n\n\nChokolate\n\n\n\n\n\n\n\nSinsel\n\n\n\n\n\n\n\n\n\n\n\n\nNo es bueno entrenar con las mismas instancias de de Test, es decir, con las cuales se evalúa el modelo. ¿Por qué?\n\n\n\n\n\nMencionar el caso de error de ImageNet."
  },
  {
    "objectID": "tics411/clase-0.html#nuestro-sistema-de-ml-reevaluemos-nuestro-modelo",
    "href": "tics411/clase-0.html#nuestro-sistema-de-ml-reevaluemos-nuestro-modelo",
    "title": "TICS-411 Minería de Datos",
    "section": "Nuestro Sistema de ML: Reevaluemos nuestro Modelo",
    "text": "Nuestro Sistema de ML: Reevaluemos nuestro Modelo\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nKollar\n\n\nKonejo\n\n\nKuchillo\n\n\nBisikleta\n\n\n\n\n\nEvaluación\n\n\nUtilizar una métrica que permita ponerle nota al modelo.\n\n\n\n\n\n\n1er Modelo: 2 correctas de 4, es decir 50%.\n\n\n\n\n2do Modelo: 4 correctas de 4, es decir 100%."
  },
  {
    "objectID": "tics411/clase-0.html#problemas-del-aprendizaje",
    "href": "tics411/clase-0.html#problemas-del-aprendizaje",
    "title": "TICS-411 Minería de Datos",
    "section": "Problemas del Aprendizaje",
    "text": "Problemas del Aprendizaje\n\nSupongamos que queremos utilizar nuestro modelo para pronunciar palabras en otro idioma (otro Test Set).\n¿Qué problemas podemos encontrar?\n\n\n\n\nStomach \\(\\rightarrow\\) Stomak\nArcher \\(\\rightarrow\\) Archer\nChurch \\(\\rightarrow\\) Churk\n\nChurch.\n\nArcheology \\(\\rightarrow\\) Archeology\n\nArkeology.\n\nChicago \\(\\rightarrow\\) Chicago\n\nShicago.\n\nMuscle \\(\\rightarrow\\) Muskle\n\nMus_le.\n\nIch mag Schweinefleisch \\(\\rightarrow\\) Ich mag Schweinefleisk.\n\nIj mag Shvaineflaish.\n\n\n\n\n\n\n\n\n\n\nClaramente tenemos un problema. ¿A qué se debe esto?"
  },
  {
    "objectID": "tics411/clase-0.html#problemas-del-aprendizaje-definiciones",
    "href": "tics411/clase-0.html#problemas-del-aprendizaje-definiciones",
    "title": "TICS-411 Minería de Datos",
    "section": "Problemas del Aprendizaje: Definiciones",
    "text": "Problemas del Aprendizaje: Definiciones\n\nOverfitting (Sobreajuste)\n\n\nSe refiere a cuando un modelo no es capaz de generalizar de manera correcta, porque se ajusta demasiado bien (llegando a memorizar) a los datos de entrenamiento. ¿Cómo se puede mitigar este problema?\n\n\n\n\n\n\n\n\n\n\nSe le tiende a llamar sobreentrenamiento, pero no es del todo correcto para el caso de modelos de Machine Learning. Lo más correcto es que el sobreentrenamiento provoca overfitting.\n\n\n\n\n\nMostrar ejemplos en Pizarra de manera gráfica. Ejemplos típicos de Excel.\n\n\n\nUnderfitting (Subajuste)\n\n\nSe refiere a cuando un modelo no es capaz de generalizar de manera correcta, pero a diferencia del overfitting no se ha ajustado correctamente a los datos. ¿Cómo se vería el underfitting en nuestro ejemplo?"
  },
  {
    "objectID": "tics411/clase-0.html#etapas-del-modelamiento-crisp-dm",
    "href": "tics411/clase-0.html#etapas-del-modelamiento-crisp-dm",
    "title": "TICS-411 Minería de Datos",
    "section": "Etapas del Modelamiento: Crisp-DM",
    "text": "Etapas del Modelamiento: Crisp-DM"
  },
  {
    "objectID": "tics411/clase-0.html#etapas-del-modelamiento-kdd",
    "href": "tics411/clase-0.html#etapas-del-modelamiento-kdd",
    "title": "TICS-411 Minería de Datos",
    "section": "Etapas del Modelamiento: KDD",
    "text": "Etapas del Modelamiento: KDD"
  },
  {
    "objectID": "tics411/clase-0.html#etapas-del-modelamiento-semma",
    "href": "tics411/clase-0.html#etapas-del-modelamiento-semma",
    "title": "TICS-411 Minería de Datos",
    "section": "Etapas del Modelamiento: Semma",
    "text": "Etapas del Modelamiento: Semma"
  },
  {
    "objectID": "tics411/clase-0.html#etapas-del-modelamiento-metodología-propia",
    "href": "tics411/clase-0.html#etapas-del-modelamiento-metodología-propia",
    "title": "TICS-411 Minería de Datos",
    "section": "Etapas del Modelamiento: Metodología Propia",
    "text": "Etapas del Modelamiento: Metodología Propia"
  }
]